17/12/21 14:48:21 INFO SparkContext: Running Spark version 2.1.0
17/12/21 14:48:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/21 14:48:22 INFO SecurityManager: Changing view acls to: conan
17/12/21 14:48:22 INFO SecurityManager: Changing modify acls to: conan
17/12/21 14:48:22 INFO SecurityManager: Changing view acls groups to: 
17/12/21 14:48:22 INFO SecurityManager: Changing modify acls groups to: 
17/12/21 14:48:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(conan); groups with view permissions: Set(); users  with modify permissions: Set(conan); groups with modify permissions: Set()
17/12/21 14:48:22 INFO Utils: Successfully started service 'sparkDriver' on port 49771.
17/12/21 14:48:22 INFO SparkEnv: Registering MapOutputTracker
17/12/21 14:48:22 INFO SparkEnv: Registering BlockManagerMaster
17/12/21 14:48:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/21 14:48:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/21 14:48:22 INFO DiskBlockManager: Created local directory at C:\Users\conan\AppData\Local\Temp\blockmgr-21492800-202b-4428-915c-dfc9ac6aa730
17/12/21 14:48:22 INFO MemoryStore: MemoryStore started with capacity 2004.6 MB
17/12/21 14:48:22 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/21 14:48:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/21 14:48:22 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/21 14:48:22 INFO SparkContext: Added JAR file:/C:/Users/conan/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:49771/jars/sparklyr-2.1-2.11.jar with timestamp 1513867702966
17/12/21 14:48:23 INFO Executor: Starting executor ID driver on host localhost
17/12/21 14:48:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49792.
17/12/21 14:48:23 INFO NettyBlockTransferService: Server created on 127.0.0.1:49792
17/12/21 14:48:23 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/21 14:48:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 49792, None)
17/12/21 14:48:23 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:49792 with 2004.6 MB RAM, BlockManagerId(driver, 127.0.0.1, 49792, None)
17/12/21 14:48:23 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 49792, None)
17/12/21 14:48:23 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 49792, None)
17/12/21 14:48:23 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/21 14:48:24 INFO SharedState: Warehouse path is 'C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/21 14:48:24 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/21 14:48:24 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/21 14:48:24 INFO ObjectStore: ObjectStore, initialize called
17/12/21 14:48:24 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/21 14:48:24 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/21 14:48:26 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/21 14:48:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 14:48:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 14:48:27 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 14:48:27 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 14:48:27 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/21 14:48:27 INFO ObjectStore: Initialized ObjectStore
17/12/21 14:48:27 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/21 14:48:27 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/21 14:48:28 INFO HiveMetaStore: Added admin role in metastore
17/12/21 14:48:28 INFO HiveMetaStore: Added public role in metastore
17/12/21 14:48:28 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/21 14:48:28 INFO HiveMetaStore: 0: get_all_databases
17/12/21 14:48:28 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/21 14:48:28 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/21 14:48:28 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/21 14:48:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 14:48:28 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/Temp/41d59f8b-6358-4483-a0e8-11d0c9774fe2_resources
17/12/21 14:48:28 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/41d59f8b-6358-4483-a0e8-11d0c9774fe2
17/12/21 14:48:28 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/41d59f8b-6358-4483-a0e8-11d0c9774fe2
17/12/21 14:48:28 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/41d59f8b-6358-4483-a0e8-11d0c9774fe2/_tmp_space.db
17/12/21 14:48:28 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/21 14:48:28 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:48:28 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:48:28 INFO HiveMetaStore: 0: get_database: global_temp
17/12/21 14:48:28 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/21 14:48:28 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/21 14:48:28 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:48:30 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:48:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:48:30 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:48:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:48:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:48:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:48:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:30 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:48:30 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:48:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:48:30 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:48:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:48:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:48:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:48:31 INFO CodeGenerator: Code generated in 262.54673 ms
17/12/21 14:48:31 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 14:48:31 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/21 14:48:31 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/21 14:48:31 INFO DAGScheduler: Parents of final stage: List()
17/12/21 14:48:31 INFO DAGScheduler: Missing parents: List()
17/12/21 14:48:31 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/12/21 14:48:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 2004.6 MB)
17/12/21 14:48:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2004.6 MB)
17/12/21 14:48:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:49792 (size: 4.6 KB, free: 2004.6 MB)
17/12/21 14:48:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/21 14:48:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/12/21 14:48:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/21 14:48:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/21 14:48:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/21 14:48:31 INFO Executor: Fetching spark://127.0.0.1:49771/jars/sparklyr-2.1-2.11.jar with timestamp 1513867702966
17/12/21 14:48:31 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:49771 after 13 ms (0 ms spent in bootstraps)
17/12/21 14:48:31 INFO Utils: Fetching spark://127.0.0.1:49771/jars/sparklyr-2.1-2.11.jar to C:\Users\conan\AppData\Local\Temp\spark-787a9863-d8d1-4e22-b1c5-f06e04e3f9b5\userFiles-21ff9ed1-7cff-4fdc-a66b-664d808306a5\fetchFileTemp184340026257872504.tmp
17/12/21 14:48:31 INFO Executor: Adding file:/C:/Users/conan/AppData/Local/Temp/spark-787a9863-d8d1-4e22-b1c5-f06e04e3f9b5/userFiles-21ff9ed1-7cff-4fdc-a66b-664d808306a5/sparklyr-2.1-2.11.jar to class loader
17/12/21 14:48:32 INFO CodeGenerator: Code generated in 15.201407 ms
17/12/21 14:48:32 INFO CodeGenerator: Code generated in 12.635367 ms
17/12/21 14:48:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/12/21 14:48:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 384 ms on localhost (executor driver) (1/1)
17/12/21 14:48:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/21 14:48:32 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.400 s
17/12/21 14:48:32 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.661214 s
17/12/21 14:48:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:32 INFO ContextCleaner: Cleaned accumulator 0
17/12/21 14:48:32 INFO ContextCleaner: Cleaned accumulator 1
17/12/21 14:48:32 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 14:48:32 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:49792 in memory (size: 4.6 KB, free: 2004.6 MB)
17/12/21 14:48:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:32 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 14:48:32 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 14:48:32 INFO FileSourceStrategy: Pruning directories with: 
17/12/21 14:48:32 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/21 14:48:32 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double, S4: double, S5: double ... 8 more fields>
17/12/21 14:48:32 INFO FileSourceStrategy: Pushed Filters: 
17/12/21 14:48:32 INFO CodeGenerator: Code generated in 6.208186 ms
17/12/21 14:48:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.7 KB, free 2004.3 MB)
17/12/21 14:48:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2004.3 MB)
17/12/21 14:48:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:49792 (size: 24.0 KB, free: 2004.6 MB)
17/12/21 14:48:32 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/21 14:48:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/21 14:48:32 INFO CodeGenerator: Code generated in 10.084054 ms
17/12/21 14:48:33 INFO CodeGenerator: Code generated in 9.202402 ms
17/12/21 14:48:33 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 14:48:33 INFO DAGScheduler: Registering RDD 10 (sql at <unknown>:0)
17/12/21 14:48:33 INFO DAGScheduler: Registering RDD 15 (sql at <unknown>:0)
17/12/21 14:48:33 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/21 14:48:33 INFO DAGScheduler: Final stage: ResultStage 3 (sql at <unknown>:0)
17/12/21 14:48:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/12/21 14:48:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/12/21 14:48:33 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0), which has no missing parents
17/12/21 14:48:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.1 KB, free 2004.3 MB)
17/12/21 14:48:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.5 KB, free 2004.3 MB)
17/12/21 14:48:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:49792 (size: 7.5 KB, free: 2004.6 MB)
17/12/21 14:48:33 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/21 14:48:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0)
17/12/21 14:48:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/21 14:48:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/21 14:48:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/21 14:48:33 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmponGyKW/spark_serialize_788b3a416b2980031a2db0372e98a357c40845ee209a390e75e3478ca3bb46c6.csv, range: 0-1916, partition values: [empty row]
17/12/21 14:48:33 INFO CodeGenerator: Code generated in 10.366107 ms
17/12/21 14:48:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1632 bytes result sent to driver
17/12/21 14:48:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 177 ms on localhost (executor driver) (1/1)
17/12/21 14:48:33 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/21 14:48:33 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.178 s
17/12/21 14:48:33 INFO DAGScheduler: looking for newly runnable stages
17/12/21 14:48:33 INFO DAGScheduler: running: Set()
17/12/21 14:48:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/12/21 14:48:33 INFO DAGScheduler: failed: Set()
17/12/21 14:48:33 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/21 14:48:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.3 KB, free 2004.3 MB)
17/12/21 14:48:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2004.2 MB)
17/12/21 14:48:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:49792 (size: 6.9 KB, free: 2004.6 MB)
17/12/21 14:48:33 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/21 14:48:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/21 14:48:33 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
17/12/21 14:48:33 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5942 bytes)
17/12/21 14:48:33 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5942 bytes)
17/12/21 14:48:33 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/21 14:48:33 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
17/12/21 14:48:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 14:48:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 14:48:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 14:48:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 14:48:33 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 1512.0 B, free 2004.2 MB)
17/12/21 14:48:33 INFO BlockManagerInfo: Added rdd_12_0 in memory on 127.0.0.1:49792 (size: 1512.0 B, free: 2004.6 MB)
17/12/21 14:48:33 INFO MemoryStore: Block rdd_12_1 stored as values in memory (estimated size 1512.0 B, free 2004.2 MB)
17/12/21 14:48:33 INFO BlockManagerInfo: Added rdd_12_1 in memory on 127.0.0.1:49792 (size: 1512.0 B, free: 2004.6 MB)
17/12/21 14:48:33 INFO CodeGenerator: Code generated in 5.266121 ms
17/12/21 14:48:33 INFO CodeGenerator: Code generated in 15.801383 ms
17/12/21 14:48:33 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 3151 bytes result sent to driver
17/12/21 14:48:33 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 3064 bytes result sent to driver
17/12/21 14:48:33 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 131 ms on localhost (executor driver) (1/2)
17/12/21 14:48:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 131 ms on localhost (executor driver) (2/2)
17/12/21 14:48:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/21 14:48:33 INFO DAGScheduler: ShuffleMapStage 2 (sql at <unknown>:0) finished in 0.131 s
17/12/21 14:48:33 INFO DAGScheduler: looking for newly runnable stages
17/12/21 14:48:33 INFO DAGScheduler: running: Set()
17/12/21 14:48:33 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/12/21 14:48:33 INFO DAGScheduler: failed: Set()
17/12/21 14:48:33 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
17/12/21 14:48:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 2004.2 MB)
17/12/21 14:48:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.2 MB)
17/12/21 14:48:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.6 MB)
17/12/21 14:48:33 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/21 14:48:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0)
17/12/21 14:48:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/21 14:48:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/21 14:48:33 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
17/12/21 14:48:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 14:48:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 14:48:33 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 1884 bytes result sent to driver
17/12/21 14:48:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 15 ms on localhost (executor driver) (1/1)
17/12/21 14:48:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/21 14:48:33 INFO DAGScheduler: ResultStage 3 (sql at <unknown>:0) finished in 0.015 s
17/12/21 14:48:33 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.380571 s
17/12/21 14:48:33 INFO CodeGenerator: Code generated in 6.445684 ms
17/12/21 14:48:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:33 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 14:48:33 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 14:48:33 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/21 14:48:33 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:196)
17/12/21 14:48:33 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/12/21 14:48:33 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:196)
17/12/21 14:48:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/12/21 14:48:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/12/21 14:48:33 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
17/12/21 14:48:33 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 15.3 KB, free 2004.2 MB)
17/12/21 14:48:33 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2004.2 MB)
17/12/21 14:48:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:49792 (size: 6.9 KB, free: 2004.5 MB)
17/12/21 14:48:33 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/21 14:48:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196)
17/12/21 14:48:33 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
17/12/21 14:48:33 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5934 bytes)
17/12/21 14:48:33 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 5934 bytes)
17/12/21 14:48:33 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/21 14:48:33 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/12/21 14:48:33 INFO BlockManager: Found block rdd_12_0 locally
17/12/21 14:48:33 INFO BlockManager: Found block rdd_12_1 locally
17/12/21 14:48:33 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 1871 bytes result sent to driver
17/12/21 14:48:33 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 40 ms on localhost (executor driver) (1/2)
17/12/21 14:48:33 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1950 bytes result sent to driver
17/12/21 14:48:33 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:196) finished in 0.056 s
17/12/21 14:48:33 INFO DAGScheduler: looking for newly runnable stages
17/12/21 14:48:33 INFO DAGScheduler: running: Set()
17/12/21 14:48:33 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/12/21 14:48:33 INFO DAGScheduler: failed: Set()
17/12/21 14:48:33 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196), which has no missing parents
17/12/21 14:48:33 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 2004.2 MB)
17/12/21 14:48:33 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 55 ms on localhost (executor driver) (2/2)
17/12/21 14:48:33 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.2 MB)
17/12/21 14:48:33 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/21 14:48:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.5 MB)
17/12/21 14:48:33 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/12/21 14:48:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196)
17/12/21 14:48:33 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/21 14:48:33 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/21 14:48:33 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
17/12/21 14:48:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 14:48:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/12/21 14:48:33 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1873 bytes result sent to driver
17/12/21 14:48:33 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 10 ms on localhost (executor driver) (1/1)
17/12/21 14:48:33 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:196) finished in 0.011 s
17/12/21 14:48:33 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.089518 s
17/12/21 14:48:33 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/21 14:48:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz1`
WHERE (0 = 1)
17/12/21 14:48:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:34 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S2` + 0.91651514 * RANDN() AS `V1`, `S9` + 0.89442719 * RANDN() AS `V2`, `S6` + 0.92736185 * RANDN() AS `V3`, `S3` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `drflxubbrf`
17/12/21 14:48:34 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 14:48:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz2`
WHERE (0 = 1)
17/12/21 14:48:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 14:48:34 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:49792 in memory (size: 6.9 KB, free: 2004.6 MB)
17/12/21 14:48:34 INFO CodeGenerator: Code generated in 15.375094 ms
17/12/21 14:48:34 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.6 MB)
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 50
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 51
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 57
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 58
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 59
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 60
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 61
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 62
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 63
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 64
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 65
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 66
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 67
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 68
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 69
17/12/21 14:48:34 INFO ContextCleaner: Cleaned shuffle 1
17/12/21 14:48:34 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:49792 in memory (size: 7.5 KB, free: 2004.6 MB)
17/12/21 14:48:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:49792 in memory (size: 6.9 KB, free: 2004.6 MB)
17/12/21 14:48:34 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.6 MB)
17/12/21 14:48:34 INFO ContextCleaner: Cleaned accumulator 238
17/12/21 14:48:34 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 14:48:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/21 14:48:34 INFO DAGScheduler: Got job 3 (take at <unknown>:0) with 1 output partitions
17/12/21 14:48:34 INFO DAGScheduler: Final stage: ResultStage 8 (take at <unknown>:0)
17/12/21 14:48:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/12/21 14:48:34 INFO DAGScheduler: Missing parents: List()
17/12/21 14:48:34 INFO DAGScheduler: Submitting ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18), which has no missing parents
17/12/21 14:48:34 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 104.1 KB, free 2004.2 MB)
17/12/21 14:48:34 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 41.2 KB, free 2004.1 MB)
17/12/21 14:48:34 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:49792 (size: 41.2 KB, free: 2004.5 MB)
17/12/21 14:48:34 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/12/21 14:48:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18)
17/12/21 14:48:34 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/21 14:48:34 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5913 bytes)
17/12/21 14:48:34 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/12/21 14:48:34 INFO BlockManager: Found block rdd_12_0 locally
17/12/21 14:48:34 INFO CodeGenerator: Code generated in 22.054501 ms
17/12/21 14:48:34 INFO CodeGenerator: Code generated in 11.347439 ms
17/12/21 14:48:35 INFO MemoryStore: Block rdd_31_0 stored as values in memory (estimated size 760.0 B, free 2004.1 MB)
17/12/21 14:48:35 INFO BlockManagerInfo: Added rdd_31_0 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.5 MB)
17/12/21 14:48:35 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2747 bytes result sent to driver
17/12/21 14:48:35 INFO DAGScheduler: ResultStage 8 (take at <unknown>:0) finished in 0.791 s
17/12/21 14:48:35 INFO DAGScheduler: Job 3 finished: take at <unknown>:0, took 0.800357 s
17/12/21 14:48:35 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 791 ms on localhost (executor driver) (1/1)
17/12/21 14:48:35 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/21 14:48:35 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 14:48:35 INFO DAGScheduler: Got job 4 (take at <unknown>:0) with 1 output partitions
17/12/21 14:48:35 INFO DAGScheduler: Final stage: ResultStage 10 (take at <unknown>:0)
17/12/21 14:48:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
17/12/21 14:48:35 INFO DAGScheduler: Missing parents: List()
17/12/21 14:48:35 INFO DAGScheduler: Submitting ResultStage 10 (WorkerRDD[31] at RDD at rdd.scala:18), which has no missing parents
17/12/21 14:48:35 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 104.1 KB, free 2004.0 MB)
17/12/21 14:48:35 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 41.2 KB, free 2004.0 MB)
17/12/21 14:48:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:49792 (size: 41.2 KB, free: 2004.5 MB)
17/12/21 14:48:35 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/12/21 14:48:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (WorkerRDD[31] at RDD at rdd.scala:18)
17/12/21 14:48:35 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/12/21 14:48:35 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 5913 bytes)
17/12/21 14:48:35 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
17/12/21 14:48:35 INFO BlockManager: Found block rdd_12_1 locally
17/12/21 14:48:36 INFO MemoryStore: Block rdd_31_1 stored as values in memory (estimated size 760.0 B, free 2004.0 MB)
17/12/21 14:48:36 INFO BlockManagerInfo: Added rdd_31_1 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.5 MB)
17/12/21 14:48:36 WARN Executor: 1 block locks were not released by TID = 9:
[rdd_31_1]
17/12/21 14:48:36 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 2581 bytes result sent to driver
17/12/21 14:48:36 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 850 ms on localhost (executor driver) (1/1)
17/12/21 14:48:36 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/21 14:48:36 INFO DAGScheduler: ResultStage 10 (take at <unknown>:0) finished in 0.850 s
17/12/21 14:48:36 INFO DAGScheduler: Job 4 finished: take at <unknown>:0, took 0.854705 s
17/12/21 14:48:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:36 INFO SparkSqlParser: Parsing command: sparklyr_tmp_17742b7d68f5
17/12/21 14:48:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17742b7d68f5` AS `zzz3`
WHERE (0 = 1)
17/12/21 14:48:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17742b7d68f5`
17/12/21 14:48:36 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 14:48:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz4`
WHERE (0 = 1)
17/12/21 14:48:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:36 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 4e-04) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0055) AS `V3`, (`V4` < 0.0045) AS `V4`
FROM `analyis_tbl`
17/12/21 14:48:36 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 14:48:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz5`
WHERE (0 = 1)
17/12/21 14:48:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 14:48:36 INFO CodeGenerator: Code generated in 14.554234 ms
17/12/21 14:48:36 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 14:48:36 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 2 output partitions
17/12/21 14:48:36 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:196)
17/12/21 14:48:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/12/21 14:48:36 INFO DAGScheduler: Missing parents: List()
17/12/21 14:48:36 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[38] at collect at utils.scala:196), which has no missing parents
17/12/21 14:48:36 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 111.6 KB, free 2003.9 MB)
17/12/21 14:48:36 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 44.4 KB, free 2003.8 MB)
17/12/21 14:48:36 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:49792 (size: 44.4 KB, free: 2004.4 MB)
17/12/21 14:48:36 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/12/21 14:48:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[38] at collect at utils.scala:196)
17/12/21 14:48:36 INFO TaskSchedulerImpl: Adding task set 12.0 with 2 tasks
17/12/21 14:48:36 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5945 bytes)
17/12/21 14:48:36 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 11, localhost, executor driver, partition 1, PROCESS_LOCAL, 5945 bytes)
17/12/21 14:48:36 INFO Executor: Running task 0.0 in stage 12.0 (TID 10)
17/12/21 14:48:36 INFO BlockManager: Found block rdd_31_0 locally
17/12/21 14:48:36 INFO CodeGenerator: Code generated in 13.621986 ms
17/12/21 14:48:36 INFO Executor: Running task 1.0 in stage 12.0 (TID 11)
17/12/21 14:48:36 INFO BlockManager: Found block rdd_31_1 locally
17/12/21 14:48:36 INFO CodeGenerator: Code generated in 46.710157 ms
17/12/21 14:48:36 INFO Executor: Finished task 0.0 in stage 12.0 (TID 10). 1779 bytes result sent to driver
17/12/21 14:48:36 INFO Executor: Finished task 1.0 in stage 12.0 (TID 11). 1606 bytes result sent to driver
17/12/21 14:48:36 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 10) in 84 ms on localhost (executor driver) (1/2)
17/12/21 14:48:36 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 11) in 68 ms on localhost (executor driver) (2/2)
17/12/21 14:48:36 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:196) finished in 0.084 s
17/12/21 14:48:36 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.094083 s
17/12/21 14:48:36 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/12/21 14:48:36 INFO CodeGenerator: Code generated in 8.078721 ms
17/12/21 14:48:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:48:37 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:48:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:48:37 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:48:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:48:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:48:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:48:37 INFO CodeGenerator: Code generated in 7.758155 ms
17/12/21 14:48:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:48:37 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:48:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:48:37 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:48:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:48:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:48:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:48:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:48:37 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:48:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:48:37 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:48:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:48:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:48:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:48:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:48:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:48:37 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:48:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:48:37 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:48:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:48:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:48:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:52:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:52:07 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:52:07 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:52:07 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:52:07 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:52:07 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:52:07 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:52:07 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 14:52:07 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/12/21 14:52:07 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:58)
17/12/21 14:52:07 INFO DAGScheduler: Parents of final stage: List()
17/12/21 14:52:07 INFO DAGScheduler: Missing parents: List()
17/12/21 14:52:07 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[48] at map at utils.scala:55), which has no missing parents
17/12/21 14:52:07 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.7 KB, free 2003.8 MB)
17/12/21 14:52:07 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2003.8 MB)
17/12/21 14:52:07 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:49792 (size: 4.6 KB, free: 2004.4 MB)
17/12/21 14:52:07 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/12/21 14:52:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[48] at map at utils.scala:55)
17/12/21 14:52:07 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
17/12/21 14:52:07 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6432 bytes)
17/12/21 14:52:07 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)
17/12/21 14:52:07 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 938 bytes result sent to driver
17/12/21 14:52:07 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:58) finished in 0.000 s
17/12/21 14:52:07 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.013500 s
17/12/21 14:52:07 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 0 ms on localhost (executor driver) (1/1)
17/12/21 14:52:07 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/12/21 14:52:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:08 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 14:52:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:08 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 14:52:08 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 14:52:08 INFO FileSourceStrategy: Pruning directories with: 
17/12/21 14:52:08 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/21 14:52:08 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double, S4: double, S5: double ... 8 more fields>
17/12/21 14:52:08 INFO FileSourceStrategy: Pushed Filters: 
17/12/21 14:52:08 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 293.7 KB, free 2003.5 MB)
17/12/21 14:52:08 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2003.5 MB)
17/12/21 14:52:08 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:49792 (size: 24.0 KB, free: 2004.4 MB)
17/12/21 14:52:08 INFO SparkContext: Created broadcast 11 from sql at <unknown>:0
17/12/21 14:52:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/21 14:52:08 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 14:52:08 INFO DAGScheduler: Registering RDD 52 (sql at <unknown>:0)
17/12/21 14:52:08 INFO DAGScheduler: Registering RDD 57 (sql at <unknown>:0)
17/12/21 14:52:08 INFO DAGScheduler: Got job 7 (sql at <unknown>:0) with 1 output partitions
17/12/21 14:52:08 INFO DAGScheduler: Final stage: ResultStage 16 (sql at <unknown>:0)
17/12/21 14:52:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
17/12/21 14:52:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
17/12/21 14:52:08 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[52] at sql at <unknown>:0), which has no missing parents
17/12/21 14:52:08 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 13.1 KB, free 2003.5 MB)
17/12/21 14:52:08 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.5 KB, free 2003.5 MB)
17/12/21 14:52:08 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:49792 (size: 7.5 KB, free: 2004.4 MB)
17/12/21 14:52:08 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/12/21 14:52:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[52] at sql at <unknown>:0)
17/12/21 14:52:08 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/12/21 14:52:08 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6677 bytes)
17/12/21 14:52:08 INFO Executor: Running task 0.0 in stage 14.0 (TID 13)
17/12/21 14:52:08 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmponGyKW/spark_serialize_a1a2732a7b0c6769f8ce27069426535302daa3f91eb57df7a1d653bf3388681b.csv, range: 0-1932, partition values: [empty row]
17/12/21 14:52:08 INFO Executor: Finished task 0.0 in stage 14.0 (TID 13). 1632 bytes result sent to driver
17/12/21 14:52:08 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 13) in 62 ms on localhost (executor driver) (1/1)
17/12/21 14:52:08 INFO DAGScheduler: ShuffleMapStage 14 (sql at <unknown>:0) finished in 0.062 s
17/12/21 14:52:08 INFO DAGScheduler: looking for newly runnable stages
17/12/21 14:52:08 INFO DAGScheduler: running: Set()
17/12/21 14:52:08 INFO DAGScheduler: waiting: Set(ShuffleMapStage 15, ResultStage 16)
17/12/21 14:52:08 INFO DAGScheduler: failed: Set()
17/12/21 14:52:08 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/12/21 14:52:08 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[57] at sql at <unknown>:0), which has no missing parents
17/12/21 14:52:08 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 15.3 KB, free 2003.5 MB)
17/12/21 14:52:08 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2003.5 MB)
17/12/21 14:52:08 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.4 MB)
17/12/21 14:52:08 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/12/21 14:52:08 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[57] at sql at <unknown>:0)
17/12/21 14:52:08 INFO TaskSchedulerImpl: Adding task set 15.0 with 2 tasks
17/12/21 14:52:08 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 14, localhost, executor driver, partition 0, ANY, 5943 bytes)
17/12/21 14:52:08 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 15, localhost, executor driver, partition 1, ANY, 5943 bytes)
17/12/21 14:52:08 INFO Executor: Running task 0.0 in stage 15.0 (TID 14)
17/12/21 14:52:08 INFO Executor: Running task 1.0 in stage 15.0 (TID 15)
17/12/21 14:52:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 14:52:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 14:52:08 INFO MemoryStore: Block rdd_54_0 stored as values in memory (estimated size 1512.0 B, free 2003.5 MB)
17/12/21 14:52:08 INFO BlockManagerInfo: Added rdd_54_0 in memory on 127.0.0.1:49792 (size: 1512.0 B, free: 2004.4 MB)
17/12/21 14:52:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 14:52:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 14:52:08 INFO MemoryStore: Block rdd_54_1 stored as values in memory (estimated size 1512.0 B, free 2003.5 MB)
17/12/21 14:52:08 INFO BlockManagerInfo: Added rdd_54_1 in memory on 127.0.0.1:49792 (size: 1512.0 B, free: 2004.4 MB)
17/12/21 14:52:08 INFO Executor: Finished task 0.0 in stage 15.0 (TID 14). 3064 bytes result sent to driver
17/12/21 14:52:08 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 14) in 16 ms on localhost (executor driver) (1/2)
17/12/21 14:52:08 INFO Executor: Finished task 1.0 in stage 15.0 (TID 15). 3241 bytes result sent to driver
17/12/21 14:52:08 INFO DAGScheduler: ShuffleMapStage 15 (sql at <unknown>:0) finished in 0.035 s
17/12/21 14:52:08 INFO DAGScheduler: looking for newly runnable stages
17/12/21 14:52:08 INFO DAGScheduler: running: Set()
17/12/21 14:52:08 INFO DAGScheduler: waiting: Set(ResultStage 16)
17/12/21 14:52:08 INFO DAGScheduler: failed: Set()
17/12/21 14:52:08 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[60] at sql at <unknown>:0), which has no missing parents
17/12/21 14:52:08 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.0 KB, free 2003.5 MB)
17/12/21 14:52:08 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 15) in 34 ms on localhost (executor driver) (2/2)
17/12/21 14:52:08 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/12/21 14:52:08 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.5 MB)
17/12/21 14:52:08 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.4 MB)
17/12/21 14:52:08 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/12/21 14:52:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[60] at sql at <unknown>:0)
17/12/21 14:52:08 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/12/21 14:52:08 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, ANY, 5954 bytes)
17/12/21 14:52:08 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
17/12/21 14:52:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 14:52:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 14:52:08 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1707 bytes result sent to driver
17/12/21 14:52:08 INFO DAGScheduler: ResultStage 16 (sql at <unknown>:0) finished in 0.000 s
17/12/21 14:52:08 INFO DAGScheduler: Job 7 finished: sql at <unknown>:0, took 0.113949 s
17/12/21 14:52:08 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 0 ms on localhost (executor driver) (1/1)
17/12/21 14:52:08 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/12/21 14:52:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:08 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 14:52:08 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 14:52:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 145 bytes
17/12/21 14:52:08 INFO DAGScheduler: Registering RDD 64 (collect at utils.scala:196)
17/12/21 14:52:08 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/12/21 14:52:08 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:196)
17/12/21 14:52:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
17/12/21 14:52:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
17/12/21 14:52:08 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[64] at collect at utils.scala:196), which has no missing parents
17/12/21 14:52:08 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 15.3 KB, free 2003.5 MB)
17/12/21 14:52:08 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2003.4 MB)
17/12/21 14:52:08 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.4 MB)
17/12/21 14:52:08 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/12/21 14:52:08 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[64] at collect at utils.scala:196)
17/12/21 14:52:08 INFO TaskSchedulerImpl: Adding task set 18.0 with 2 tasks
17/12/21 14:52:08 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 5935 bytes)
17/12/21 14:52:08 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 5935 bytes)
17/12/21 14:52:08 INFO Executor: Running task 0.0 in stage 18.0 (TID 17)
17/12/21 14:52:08 INFO Executor: Running task 1.0 in stage 18.0 (TID 18)
17/12/21 14:52:08 INFO BlockManager: Found block rdd_54_1 locally
17/12/21 14:52:08 INFO BlockManager: Found block rdd_54_0 locally
17/12/21 14:52:08 INFO Executor: Finished task 0.0 in stage 18.0 (TID 17). 2048 bytes result sent to driver
17/12/21 14:52:08 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 17) in 27 ms on localhost (executor driver) (1/2)
17/12/21 14:52:08 INFO Executor: Finished task 1.0 in stage 18.0 (TID 18). 2048 bytes result sent to driver
17/12/21 14:52:08 INFO DAGScheduler: ShuffleMapStage 18 (collect at utils.scala:196) finished in 0.030 s
17/12/21 14:52:08 INFO DAGScheduler: looking for newly runnable stages
17/12/21 14:52:08 INFO DAGScheduler: running: Set()
17/12/21 14:52:08 INFO DAGScheduler: waiting: Set(ResultStage 19)
17/12/21 14:52:08 INFO DAGScheduler: failed: Set()
17/12/21 14:52:08 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[67] at collect at utils.scala:196), which has no missing parents
17/12/21 14:52:08 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 18) in 29 ms on localhost (executor driver) (2/2)
17/12/21 14:52:08 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/12/21 14:52:08 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 2003.4 MB)
17/12/21 14:52:08 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.4 MB)
17/12/21 14:52:08 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.4 MB)
17/12/21 14:52:08 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/12/21 14:52:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[67] at collect at utils.scala:196)
17/12/21 14:52:08 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/12/21 14:52:08 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/21 14:52:08 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
17/12/21 14:52:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 14:52:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 14:52:08 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1873 bytes result sent to driver
17/12/21 14:52:08 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 6 ms on localhost (executor driver) (1/1)
17/12/21 14:52:08 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:196) finished in 0.006 s
17/12/21 14:52:08 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.034414 s
17/12/21 14:52:08 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/12/21 14:52:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz6`
WHERE (0 = 1)
17/12/21 14:52:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:08 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S2` + 0.91651514 * RANDN() AS `V1`, `S9` + 0.89442719 * RANDN() AS `V2`, `S6` + 0.92736185 * RANDN() AS `V3`, `S3` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `fqqrdtbhlm`
17/12/21 14:52:08 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 14:52:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz7`
WHERE (0 = 1)
17/12/21 14:52:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 14:52:08 INFO CodeGenerator: Code generated in 10.582083 ms
17/12/21 14:52:08 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 14:52:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 145 bytes
17/12/21 14:52:08 INFO DAGScheduler: Got job 9 (take at <unknown>:0) with 1 output partitions
17/12/21 14:52:08 INFO DAGScheduler: Final stage: ResultStage 21 (take at <unknown>:0)
17/12/21 14:52:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
17/12/21 14:52:08 INFO DAGScheduler: Missing parents: List()
17/12/21 14:52:08 INFO DAGScheduler: Submitting ResultStage 21 (WorkerRDD[73] at RDD at rdd.scala:18), which has no missing parents
17/12/21 14:52:08 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 104.1 KB, free 2003.3 MB)
17/12/21 14:52:08 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 41.2 KB, free 2003.3 MB)
17/12/21 14:52:08 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:49792 (size: 41.2 KB, free: 2004.3 MB)
17/12/21 14:52:08 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/12/21 14:52:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (WorkerRDD[73] at RDD at rdd.scala:18)
17/12/21 14:52:08 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
17/12/21 14:52:08 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/21 14:52:08 INFO Executor: Running task 0.0 in stage 21.0 (TID 20)
17/12/21 14:52:08 INFO BlockManager: Found block rdd_54_0 locally
17/12/21 14:52:09 INFO MemoryStore: Block rdd_73_0 stored as values in memory (estimated size 760.0 B, free 2003.3 MB)
17/12/21 14:52:09 INFO BlockManagerInfo: Added rdd_73_0 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.3 MB)
17/12/21 14:52:09 INFO Executor: Finished task 0.0 in stage 21.0 (TID 20). 2668 bytes result sent to driver
17/12/21 14:52:09 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 20) in 712 ms on localhost (executor driver) (1/1)
17/12/21 14:52:09 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/12/21 14:52:09 INFO DAGScheduler: ResultStage 21 (take at <unknown>:0) finished in 0.712 s
17/12/21 14:52:09 INFO DAGScheduler: Job 9 finished: take at <unknown>:0, took 0.725371 s
17/12/21 14:52:09 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 14:52:09 INFO DAGScheduler: Got job 10 (take at <unknown>:0) with 1 output partitions
17/12/21 14:52:09 INFO DAGScheduler: Final stage: ResultStage 23 (take at <unknown>:0)
17/12/21 14:52:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
17/12/21 14:52:09 INFO DAGScheduler: Missing parents: List()
17/12/21 14:52:09 INFO DAGScheduler: Submitting ResultStage 23 (WorkerRDD[73] at RDD at rdd.scala:18), which has no missing parents
17/12/21 14:52:09 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 104.1 KB, free 2003.2 MB)
17/12/21 14:52:09 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 41.2 KB, free 2003.2 MB)
17/12/21 14:52:09 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:49792 (size: 41.2 KB, free: 2004.3 MB)
17/12/21 14:52:09 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/12/21 14:52:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (WorkerRDD[73] at RDD at rdd.scala:18)
17/12/21 14:52:09 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
17/12/21 14:52:09 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/21 14:52:09 INFO Executor: Running task 0.0 in stage 23.0 (TID 21)
17/12/21 14:52:09 INFO BlockManager: Found block rdd_54_1 locally
17/12/21 14:52:10 INFO MemoryStore: Block rdd_73_1 stored as values in memory (estimated size 760.0 B, free 2003.2 MB)
17/12/21 14:52:10 INFO BlockManagerInfo: Added rdd_73_1 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.3 MB)
17/12/21 14:52:10 WARN Executor: 1 block locks were not released by TID = 21:
[rdd_73_1]
17/12/21 14:52:10 INFO Executor: Finished task 0.0 in stage 23.0 (TID 21). 2581 bytes result sent to driver
17/12/21 14:52:10 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 21) in 748 ms on localhost (executor driver) (1/1)
17/12/21 14:52:10 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
17/12/21 14:52:10 INFO DAGScheduler: ResultStage 23 (take at <unknown>:0) finished in 0.748 s
17/12/21 14:52:10 INFO DAGScheduler: Job 10 finished: take at <unknown>:0, took 0.749136 s
17/12/21 14:52:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:10 INFO SparkSqlParser: Parsing command: sparklyr_tmp_177459971d01
17/12/21 14:52:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_177459971d01` AS `zzz8`
WHERE (0 = 1)
17/12/21 14:52:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_177459971d01`
17/12/21 14:52:10 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 14:52:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz9`
WHERE (0 = 1)
17/12/21 14:52:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:10 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 4e-04) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0055) AS `V3`, (`V4` < 0.0045) AS `V4`
FROM `analyis_tbl`
17/12/21 14:52:10 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 14:52:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz10`
WHERE (0 = 1)
17/12/21 14:52:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 14:52:10 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 14:52:10 INFO DAGScheduler: Got job 11 (collect at utils.scala:196) with 2 output partitions
17/12/21 14:52:10 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:196)
17/12/21 14:52:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
17/12/21 14:52:10 INFO DAGScheduler: Missing parents: List()
17/12/21 14:52:10 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[80] at collect at utils.scala:196), which has no missing parents
17/12/21 14:52:10 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 111.6 KB, free 2003.0 MB)
17/12/21 14:52:10 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 44.4 KB, free 2003.0 MB)
17/12/21 14:52:10 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:49792 (size: 44.4 KB, free: 2004.3 MB)
17/12/21 14:52:10 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/12/21 14:52:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 25 (MapPartitionsRDD[80] at collect at utils.scala:196)
17/12/21 14:52:10 INFO TaskSchedulerImpl: Adding task set 25.0 with 2 tasks
17/12/21 14:52:10 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/21 14:52:10 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 23, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/21 14:52:10 INFO Executor: Running task 0.0 in stage 25.0 (TID 22)
17/12/21 14:52:10 INFO Executor: Running task 1.0 in stage 25.0 (TID 23)
17/12/21 14:52:10 INFO BlockManager: Found block rdd_73_0 locally
17/12/21 14:52:10 INFO BlockManager: Found block rdd_73_1 locally
17/12/21 14:52:10 INFO Executor: Finished task 0.0 in stage 25.0 (TID 22). 1618 bytes result sent to driver
17/12/21 14:52:10 INFO Executor: Finished task 1.0 in stage 25.0 (TID 23). 1684 bytes result sent to driver
17/12/21 14:52:10 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 22) in 14 ms on localhost (executor driver) (1/2)
17/12/21 14:52:10 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:196) finished in 0.014 s
17/12/21 14:52:10 INFO DAGScheduler: Job 11 finished: collect at utils.scala:196, took 0.025642 s
17/12/21 14:52:10 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 23) in 13 ms on localhost (executor driver) (2/2)
17/12/21 14:52:10 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
17/12/21 14:52:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:52:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:52:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:52:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:52:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:52:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:52:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:52:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:52:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:52:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:52:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:52:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:52:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:52:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:52:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:52:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:52:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:52:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:52:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:52:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:52:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:52:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:52:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:52:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:52:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:52:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:52:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:52:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:52:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:54:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:27 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:54:27 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:54:27 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:54:27 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:54:27 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:54:27 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:54:27 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:54:27 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 14:54:27 INFO DAGScheduler: Got job 12 (collect at utils.scala:58) with 1 output partitions
17/12/21 14:54:27 INFO DAGScheduler: Final stage: ResultStage 26 (collect at utils.scala:58)
17/12/21 14:54:27 INFO DAGScheduler: Parents of final stage: List()
17/12/21 14:54:27 INFO DAGScheduler: Missing parents: List()
17/12/21 14:54:27 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[90] at map at utils.scala:55), which has no missing parents
17/12/21 14:54:27 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 8.7 KB, free 2003.0 MB)
17/12/21 14:54:27 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2003.0 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:49792 (size: 4.6 KB, free: 2004.3 MB)
17/12/21 14:54:27 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/12/21 14:54:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[90] at map at utils.scala:55)
17/12/21 14:54:27 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
17/12/21 14:54:27 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 6505 bytes)
17/12/21 14:54:27 INFO Executor: Running task 0.0 in stage 26.0 (TID 24)
17/12/21 14:54:27 INFO Executor: Finished task 0.0 in stage 26.0 (TID 24). 1045 bytes result sent to driver
17/12/21 14:54:27 INFO DAGScheduler: ResultStage 26 (collect at utils.scala:58) finished in 0.007 s
17/12/21 14:54:27 INFO DAGScheduler: Job 12 finished: collect at utils.scala:58, took 0.011054 s
17/12/21 14:54:27 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 24) in 6 ms on localhost (executor driver) (1/1)
17/12/21 14:54:27 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
17/12/21 14:54:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:27 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:49792 in memory (size: 7.5 KB, free: 2004.3 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:49792 in memory (size: 7.0 KB, free: 2004.3 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 781
17/12/21 14:54:27 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:49792 in memory (size: 7.0 KB, free: 2004.3 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:49792 in memory (size: 41.2 KB, free: 2004.3 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:49792 in memory (size: 41.2 KB, free: 2004.4 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:49792 in memory (size: 44.4 KB, free: 2004.4 MB)
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 1086
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 1087
17/12/21 14:54:27 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:49792 in memory (size: 4.6 KB, free: 2004.4 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:49792 in memory (size: 41.2 KB, free: 2004.5 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:49792 in memory (size: 41.2 KB, free: 2004.5 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:49792 in memory (size: 44.4 KB, free: 2004.5 MB)
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 543
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 544
17/12/21 14:54:27 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:49792 in memory (size: 4.6 KB, free: 2004.5 MB)
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 593
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 594
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 600
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 601
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 602
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 603
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 604
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 605
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 606
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 607
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 608
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 609
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 610
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 611
17/12/21 14:54:27 INFO ContextCleaner: Cleaned accumulator 612
17/12/21 14:54:27 INFO ContextCleaner: Cleaned shuffle 4
17/12/21 14:54:27 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 14:54:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:27 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 14:54:27 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 14:54:27 INFO FileSourceStrategy: Pruning directories with: 
17/12/21 14:54:27 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/21 14:54:27 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double, S4: double, S5: double ... 8 more fields>
17/12/21 14:54:27 INFO FileSourceStrategy: Pushed Filters: 
17/12/21 14:54:27 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 293.7 KB, free 2003.7 MB)
17/12/21 14:54:27 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2003.7 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:49792 (size: 24.0 KB, free: 2004.5 MB)
17/12/21 14:54:27 INFO SparkContext: Created broadcast 21 from sql at <unknown>:0
17/12/21 14:54:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/21 14:54:27 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 14:54:27 INFO DAGScheduler: Registering RDD 94 (sql at <unknown>:0)
17/12/21 14:54:27 INFO DAGScheduler: Registering RDD 99 (sql at <unknown>:0)
17/12/21 14:54:27 INFO DAGScheduler: Got job 13 (sql at <unknown>:0) with 1 output partitions
17/12/21 14:54:27 INFO DAGScheduler: Final stage: ResultStage 29 (sql at <unknown>:0)
17/12/21 14:54:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
17/12/21 14:54:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
17/12/21 14:54:27 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[94] at sql at <unknown>:0), which has no missing parents
17/12/21 14:54:27 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 13.1 KB, free 2003.6 MB)
17/12/21 14:54:27 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 7.5 KB, free 2003.6 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:49792 (size: 7.5 KB, free: 2004.5 MB)
17/12/21 14:54:27 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
17/12/21 14:54:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[94] at sql at <unknown>:0)
17/12/21 14:54:27 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
17/12/21 14:54:27 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/21 14:54:27 INFO Executor: Running task 0.0 in stage 27.0 (TID 25)
17/12/21 14:54:27 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmponGyKW/spark_serialize_58f98ca38fb3355be31d1a13f506788c5b5e07a62257771cdfce10e188b07b70.csv, range: 0-1918, partition values: [empty row]
17/12/21 14:54:27 INFO Executor: Finished task 0.0 in stage 27.0 (TID 25). 1553 bytes result sent to driver
17/12/21 14:54:27 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 25) in 31 ms on localhost (executor driver) (1/1)
17/12/21 14:54:27 INFO DAGScheduler: ShuffleMapStage 27 (sql at <unknown>:0) finished in 0.031 s
17/12/21 14:54:27 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
17/12/21 14:54:27 INFO DAGScheduler: looking for newly runnable stages
17/12/21 14:54:27 INFO DAGScheduler: running: Set()
17/12/21 14:54:27 INFO DAGScheduler: waiting: Set(ShuffleMapStage 28, ResultStage 29)
17/12/21 14:54:27 INFO DAGScheduler: failed: Set()
17/12/21 14:54:27 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[99] at sql at <unknown>:0), which has no missing parents
17/12/21 14:54:27 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 15.3 KB, free 2003.6 MB)
17/12/21 14:54:27 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2003.6 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:49792 (size: 6.9 KB, free: 2004.5 MB)
17/12/21 14:54:27 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
17/12/21 14:54:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[99] at sql at <unknown>:0)
17/12/21 14:54:27 INFO TaskSchedulerImpl: Adding task set 28.0 with 2 tasks
17/12/21 14:54:27 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 26, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/21 14:54:27 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 27, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/21 14:54:27 INFO Executor: Running task 0.0 in stage 28.0 (TID 26)
17/12/21 14:54:27 INFO Executor: Running task 1.0 in stage 28.0 (TID 27)
17/12/21 14:54:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 14:54:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 14:54:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 14:54:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 14:54:27 INFO MemoryStore: Block rdd_96_0 stored as values in memory (estimated size 1512.0 B, free 2003.6 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Added rdd_96_0 in memory on 127.0.0.1:49792 (size: 1512.0 B, free: 2004.5 MB)
17/12/21 14:54:27 INFO MemoryStore: Block rdd_96_1 stored as values in memory (estimated size 1512.0 B, free 2003.6 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Added rdd_96_1 in memory on 127.0.0.1:49792 (size: 1512.0 B, free: 2004.5 MB)
17/12/21 14:54:27 INFO Executor: Finished task 1.0 in stage 28.0 (TID 27). 2985 bytes result sent to driver
17/12/21 14:54:27 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 27) in 16 ms on localhost (executor driver) (1/2)
17/12/21 14:54:27 INFO Executor: Finished task 0.0 in stage 28.0 (TID 26). 3064 bytes result sent to driver
17/12/21 14:54:27 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 26) in 32 ms on localhost (executor driver) (2/2)
17/12/21 14:54:27 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
17/12/21 14:54:27 INFO DAGScheduler: ShuffleMapStage 28 (sql at <unknown>:0) finished in 0.032 s
17/12/21 14:54:27 INFO DAGScheduler: looking for newly runnable stages
17/12/21 14:54:27 INFO DAGScheduler: running: Set()
17/12/21 14:54:27 INFO DAGScheduler: waiting: Set(ResultStage 29)
17/12/21 14:54:27 INFO DAGScheduler: failed: Set()
17/12/21 14:54:27 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[102] at sql at <unknown>:0), which has no missing parents
17/12/21 14:54:27 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.0 KB, free 2003.6 MB)
17/12/21 14:54:27 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.6 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.5 MB)
17/12/21 14:54:27 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
17/12/21 14:54:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[102] at sql at <unknown>:0)
17/12/21 14:54:27 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
17/12/21 14:54:27 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 28, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/21 14:54:27 INFO Executor: Running task 0.0 in stage 29.0 (TID 28)
17/12/21 14:54:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 14:54:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 14:54:27 INFO Executor: Finished task 0.0 in stage 29.0 (TID 28). 1707 bytes result sent to driver
17/12/21 14:54:27 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 28) in 0 ms on localhost (executor driver) (1/1)
17/12/21 14:54:27 INFO DAGScheduler: ResultStage 29 (sql at <unknown>:0) finished in 0.000 s
17/12/21 14:54:27 INFO DAGScheduler: Job 13 finished: sql at <unknown>:0, took 0.077361 s
17/12/21 14:54:27 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
17/12/21 14:54:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:27 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 14:54:27 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 14:54:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 145 bytes
17/12/21 14:54:27 INFO DAGScheduler: Registering RDD 106 (collect at utils.scala:196)
17/12/21 14:54:27 INFO DAGScheduler: Got job 14 (collect at utils.scala:196) with 1 output partitions
17/12/21 14:54:27 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:196)
17/12/21 14:54:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
17/12/21 14:54:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
17/12/21 14:54:27 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[106] at collect at utils.scala:196), which has no missing parents
17/12/21 14:54:27 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 15.3 KB, free 2003.6 MB)
17/12/21 14:54:27 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2003.6 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.5 MB)
17/12/21 14:54:27 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
17/12/21 14:54:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[106] at collect at utils.scala:196)
17/12/21 14:54:27 INFO TaskSchedulerImpl: Adding task set 31.0 with 2 tasks
17/12/21 14:54:27 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/21 14:54:27 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 30, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/21 14:54:27 INFO Executor: Running task 0.0 in stage 31.0 (TID 29)
17/12/21 14:54:27 INFO Executor: Running task 1.0 in stage 31.0 (TID 30)
17/12/21 14:54:27 INFO BlockManager: Found block rdd_96_0 locally
17/12/21 14:54:27 INFO BlockManager: Found block rdd_96_1 locally
17/12/21 14:54:27 INFO Executor: Finished task 0.0 in stage 31.0 (TID 29). 1792 bytes result sent to driver
17/12/21 14:54:27 INFO Executor: Finished task 1.0 in stage 31.0 (TID 30). 1792 bytes result sent to driver
17/12/21 14:54:27 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 29) in 0 ms on localhost (executor driver) (1/2)
17/12/21 14:54:27 INFO DAGScheduler: ShuffleMapStage 31 (collect at utils.scala:196) finished in 0.000 s
17/12/21 14:54:27 INFO DAGScheduler: looking for newly runnable stages
17/12/21 14:54:27 INFO DAGScheduler: running: Set()
17/12/21 14:54:27 INFO DAGScheduler: waiting: Set(ResultStage 32)
17/12/21 14:54:27 INFO DAGScheduler: failed: Set()
17/12/21 14:54:27 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[109] at collect at utils.scala:196), which has no missing parents
17/12/21 14:54:27 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 2003.6 MB)
17/12/21 14:54:27 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 30) in 0 ms on localhost (executor driver) (2/2)
17/12/21 14:54:27 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
17/12/21 14:54:27 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.6 MB)
17/12/21 14:54:27 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.5 MB)
17/12/21 14:54:27 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
17/12/21 14:54:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[109] at collect at utils.scala:196)
17/12/21 14:54:27 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
17/12/21 14:54:27 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 31, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/21 14:54:27 INFO Executor: Running task 0.0 in stage 32.0 (TID 31)
17/12/21 14:54:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 14:54:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 14:54:27 INFO Executor: Finished task 0.0 in stage 32.0 (TID 31). 1873 bytes result sent to driver
17/12/21 14:54:27 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:196) finished in 0.004 s
17/12/21 14:54:27 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 31) in 4 ms on localhost (executor driver) (1/1)
17/12/21 14:54:27 INFO DAGScheduler: Job 14 finished: collect at utils.scala:196, took 0.029941 s
17/12/21 14:54:27 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
17/12/21 14:54:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz11`
WHERE (0 = 1)
17/12/21 14:54:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:27 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S2` + 0.91651514 * RANDN() AS `V1`, `S9` + 0.89442719 * RANDN() AS `V2`, `S6` + 0.92736185 * RANDN() AS `V3`, `S3` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `joustxgmfd`
17/12/21 14:54:27 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 14:54:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz12`
WHERE (0 = 1)
17/12/21 14:54:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 14:54:28 INFO CodeGenerator: Code generated in 11.080867 ms
17/12/21 14:54:28 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 14:54:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 145 bytes
17/12/21 14:54:28 INFO DAGScheduler: Got job 15 (take at <unknown>:0) with 1 output partitions
17/12/21 14:54:28 INFO DAGScheduler: Final stage: ResultStage 34 (take at <unknown>:0)
17/12/21 14:54:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
17/12/21 14:54:28 INFO DAGScheduler: Missing parents: List()
17/12/21 14:54:28 INFO DAGScheduler: Submitting ResultStage 34 (WorkerRDD[115] at RDD at rdd.scala:18), which has no missing parents
17/12/21 14:54:28 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 104.1 KB, free 2003.5 MB)
17/12/21 14:54:28 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 41.2 KB, free 2003.4 MB)
17/12/21 14:54:28 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:49792 (size: 41.2 KB, free: 2004.4 MB)
17/12/21 14:54:28 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:996
17/12/21 14:54:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (WorkerRDD[115] at RDD at rdd.scala:18)
17/12/21 14:54:28 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
17/12/21 14:54:28 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/21 14:54:28 INFO Executor: Running task 0.0 in stage 34.0 (TID 32)
17/12/21 14:54:28 INFO BlockManager: Found block rdd_96_0 locally
17/12/21 14:54:28 INFO MemoryStore: Block rdd_115_0 stored as values in memory (estimated size 760.0 B, free 2003.4 MB)
17/12/21 14:54:28 INFO BlockManagerInfo: Added rdd_115_0 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.4 MB)
17/12/21 14:54:28 INFO Executor: Finished task 0.0 in stage 34.0 (TID 32). 2581 bytes result sent to driver
17/12/21 14:54:28 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 32) in 664 ms on localhost (executor driver) (1/1)
17/12/21 14:54:28 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
17/12/21 14:54:28 INFO DAGScheduler: ResultStage 34 (take at <unknown>:0) finished in 0.664 s
17/12/21 14:54:28 INFO DAGScheduler: Job 15 finished: take at <unknown>:0, took 0.679512 s
17/12/21 14:54:28 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 14:54:28 INFO DAGScheduler: Got job 16 (take at <unknown>:0) with 1 output partitions
17/12/21 14:54:28 INFO DAGScheduler: Final stage: ResultStage 36 (take at <unknown>:0)
17/12/21 14:54:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
17/12/21 14:54:28 INFO DAGScheduler: Missing parents: List()
17/12/21 14:54:28 INFO DAGScheduler: Submitting ResultStage 36 (WorkerRDD[115] at RDD at rdd.scala:18), which has no missing parents
17/12/21 14:54:28 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 104.1 KB, free 2003.3 MB)
17/12/21 14:54:28 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 41.2 KB, free 2003.3 MB)
17/12/21 14:54:28 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:49792 (size: 41.2 KB, free: 2004.4 MB)
17/12/21 14:54:28 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
17/12/21 14:54:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (WorkerRDD[115] at RDD at rdd.scala:18)
17/12/21 14:54:28 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
17/12/21 14:54:28 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 33, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/21 14:54:28 INFO Executor: Running task 0.0 in stage 36.0 (TID 33)
17/12/21 14:54:28 INFO BlockManager: Found block rdd_96_1 locally
17/12/21 14:54:29 INFO MemoryStore: Block rdd_115_1 stored as values in memory (estimated size 760.0 B, free 2003.3 MB)
17/12/21 14:54:29 INFO BlockManagerInfo: Added rdd_115_1 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.4 MB)
17/12/21 14:54:29 WARN Executor: 1 block locks were not released by TID = 33:
[rdd_115_1]
17/12/21 14:54:29 INFO Executor: Finished task 0.0 in stage 36.0 (TID 33). 2581 bytes result sent to driver
17/12/21 14:54:29 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 33) in 647 ms on localhost (executor driver) (1/1)
17/12/21 14:54:29 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
17/12/21 14:54:29 INFO DAGScheduler: ResultStage 36 (take at <unknown>:0) finished in 0.647 s
17/12/21 14:54:29 INFO DAGScheduler: Job 16 finished: take at <unknown>:0, took 0.663549 s
17/12/21 14:54:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_17741adef45
17/12/21 14:54:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17741adef45` AS `zzz13`
WHERE (0 = 1)
17/12/21 14:54:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17741adef45`
17/12/21 14:54:29 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 14:54:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz14`
WHERE (0 = 1)
17/12/21 14:54:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:29 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 4e-04) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0055) AS `V3`, (`V4` < 0.0045) AS `V4`
FROM `analyis_tbl`
17/12/21 14:54:29 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 14:54:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz15`
WHERE (0 = 1)
17/12/21 14:54:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 14:54:29 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 14:54:29 INFO DAGScheduler: Got job 17 (collect at utils.scala:196) with 2 output partitions
17/12/21 14:54:29 INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:196)
17/12/21 14:54:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
17/12/21 14:54:29 INFO DAGScheduler: Missing parents: List()
17/12/21 14:54:29 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[122] at collect at utils.scala:196), which has no missing parents
17/12/21 14:54:29 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 111.6 KB, free 2003.2 MB)
17/12/21 14:54:29 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 44.4 KB, free 2003.1 MB)
17/12/21 14:54:29 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:49792 (size: 44.4 KB, free: 2004.4 MB)
17/12/21 14:54:29 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
17/12/21 14:54:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 38 (MapPartitionsRDD[122] at collect at utils.scala:196)
17/12/21 14:54:29 INFO TaskSchedulerImpl: Adding task set 38.0 with 2 tasks
17/12/21 14:54:29 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/21 14:54:29 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/21 14:54:29 INFO Executor: Running task 0.0 in stage 38.0 (TID 34)
17/12/21 14:54:29 INFO Executor: Running task 1.0 in stage 38.0 (TID 35)
17/12/21 14:54:29 INFO BlockManager: Found block rdd_115_0 locally
17/12/21 14:54:29 INFO BlockManager: Found block rdd_115_1 locally
17/12/21 14:54:29 INFO Executor: Finished task 0.0 in stage 38.0 (TID 34). 1629 bytes result sent to driver
17/12/21 14:54:29 INFO Executor: Finished task 1.0 in stage 38.0 (TID 35). 1621 bytes result sent to driver
17/12/21 14:54:29 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 34) in 16 ms on localhost (executor driver) (1/2)
17/12/21 14:54:29 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 35) in 16 ms on localhost (executor driver) (2/2)
17/12/21 14:54:29 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
17/12/21 14:54:29 INFO DAGScheduler: ResultStage 38 (collect at utils.scala:196) finished in 0.016 s
17/12/21 14:54:29 INFO DAGScheduler: Job 17 finished: collect at utils.scala:196, took 0.020313 s
17/12/21 14:54:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:54:29 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:54:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:54:29 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:54:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:54:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:54:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:54:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:54:29 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:54:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:54:29 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:54:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:54:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:54:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:54:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:54:29 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:54:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:54:29 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:54:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:54:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:54:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 14:54:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 14:54:30 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 14:54:30 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:54:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:54:30 INFO HiveMetaStore: 0: get_database: default
17/12/21 14:54:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 14:54:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 14:54:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:00:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:00:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:00:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:00:10 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 15:00:10 INFO DAGScheduler: Got job 18 (collect at utils.scala:58) with 1 output partitions
17/12/21 15:00:10 INFO DAGScheduler: Final stage: ResultStage 39 (collect at utils.scala:58)
17/12/21 15:00:10 INFO DAGScheduler: Parents of final stage: List()
17/12/21 15:00:10 INFO DAGScheduler: Missing parents: List()
17/12/21 15:00:10 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[132] at map at utils.scala:55), which has no missing parents
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 8.7 KB, free 2003.1 MB)
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2003.1 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:49792 (size: 4.6 KB, free: 2004.4 MB)
17/12/21 15:00:10 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[132] at map at utils.scala:55)
17/12/21 15:00:10 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
17/12/21 15:00:10 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 6576 bytes)
17/12/21 15:00:10 INFO Executor: Running task 0.0 in stage 39.0 (TID 36)
17/12/21 15:00:10 INFO Executor: Finished task 0.0 in stage 39.0 (TID 36). 1159 bytes result sent to driver
17/12/21 15:00:10 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 36) in 5 ms on localhost (executor driver) (1/1)
17/12/21 15:00:10 INFO DAGScheduler: ResultStage 39 (collect at utils.scala:58) finished in 0.005 s
17/12/21 15:00:10 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
17/12/21 15:00:10 INFO DAGScheduler: Job 18 finished: collect at utils.scala:58, took 0.008745 s
17/12/21 15:00:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:10 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:00:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:10 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 15:00:10 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 15:00:10 INFO FileSourceStrategy: Pruning directories with: 
17/12/21 15:00:10 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/21 15:00:10 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double, S4: double, S5: double ... 8 more fields>
17/12/21 15:00:10 INFO FileSourceStrategy: Pushed Filters: 
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 293.7 KB, free 2002.8 MB)
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2002.8 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:49792 (size: 24.0 KB, free: 2004.3 MB)
17/12/21 15:00:10 INFO SparkContext: Created broadcast 31 from sql at <unknown>:0
17/12/21 15:00:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/21 15:00:10 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 15:00:10 INFO DAGScheduler: Registering RDD 136 (sql at <unknown>:0)
17/12/21 15:00:10 INFO DAGScheduler: Registering RDD 141 (sql at <unknown>:0)
17/12/21 15:00:10 INFO DAGScheduler: Got job 19 (sql at <unknown>:0) with 1 output partitions
17/12/21 15:00:10 INFO DAGScheduler: Final stage: ResultStage 42 (sql at <unknown>:0)
17/12/21 15:00:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
17/12/21 15:00:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
17/12/21 15:00:10 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[136] at sql at <unknown>:0), which has no missing parents
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 13.1 KB, free 2002.8 MB)
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 7.5 KB, free 2002.8 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:49792 (size: 7.5 KB, free: 2004.3 MB)
17/12/21 15:00:10 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[136] at sql at <unknown>:0)
17/12/21 15:00:10 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
17/12/21 15:00:10 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/21 15:00:10 INFO Executor: Running task 0.0 in stage 40.0 (TID 37)
17/12/21 15:00:10 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmponGyKW/spark_serialize_ee09fcc72cd31608cf32ef99186f19f86dfc4455d743615e1524d0950cb063fd.csv, range: 0-1932, partition values: [empty row]
17/12/21 15:00:10 INFO Executor: Finished task 0.0 in stage 40.0 (TID 37). 1553 bytes result sent to driver
17/12/21 15:00:10 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 37) in 36 ms on localhost (executor driver) (1/1)
17/12/21 15:00:10 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
17/12/21 15:00:10 INFO DAGScheduler: ShuffleMapStage 40 (sql at <unknown>:0) finished in 0.036 s
17/12/21 15:00:10 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:00:10 INFO DAGScheduler: running: Set()
17/12/21 15:00:10 INFO DAGScheduler: waiting: Set(ResultStage 42, ShuffleMapStage 41)
17/12/21 15:00:10 INFO DAGScheduler: failed: Set()
17/12/21 15:00:10 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[141] at sql at <unknown>:0), which has no missing parents
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 15.3 KB, free 2002.8 MB)
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2002.8 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:49792 (size: 6.9 KB, free: 2004.3 MB)
17/12/21 15:00:10 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[141] at sql at <unknown>:0)
17/12/21 15:00:10 INFO TaskSchedulerImpl: Adding task set 41.0 with 2 tasks
17/12/21 15:00:10 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 38, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/21 15:00:10 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 39, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/21 15:00:10 INFO Executor: Running task 0.0 in stage 41.0 (TID 38)
17/12/21 15:00:10 INFO Executor: Running task 1.0 in stage 41.0 (TID 39)
17/12/21 15:00:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 15:00:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 15:00:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:00:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:00:10 INFO MemoryStore: Block rdd_138_1 stored as values in memory (estimated size 1512.0 B, free 2002.8 MB)
17/12/21 15:00:10 INFO MemoryStore: Block rdd_138_0 stored as values in memory (estimated size 1512.0 B, free 2002.8 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Added rdd_138_1 in memory on 127.0.0.1:49792 (size: 1512.0 B, free: 2004.3 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Added rdd_138_0 in memory on 127.0.0.1:49792 (size: 1512.0 B, free: 2004.3 MB)
17/12/21 15:00:10 INFO Executor: Finished task 1.0 in stage 41.0 (TID 39). 3072 bytes result sent to driver
17/12/21 15:00:10 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 39) in 8 ms on localhost (executor driver) (1/2)
17/12/21 15:00:10 INFO Executor: Finished task 0.0 in stage 41.0 (TID 38). 3072 bytes result sent to driver
17/12/21 15:00:10 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 38) in 8 ms on localhost (executor driver) (2/2)
17/12/21 15:00:10 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
17/12/21 15:00:10 INFO DAGScheduler: ShuffleMapStage 41 (sql at <unknown>:0) finished in 0.008 s
17/12/21 15:00:10 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:00:10 INFO DAGScheduler: running: Set()
17/12/21 15:00:10 INFO DAGScheduler: waiting: Set(ResultStage 42)
17/12/21 15:00:10 INFO DAGScheduler: failed: Set()
17/12/21 15:00:10 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[144] at sql at <unknown>:0), which has no missing parents
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 7.0 KB, free 2002.8 MB)
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.8 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.3 MB)
17/12/21 15:00:10 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[144] at sql at <unknown>:0)
17/12/21 15:00:10 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
17/12/21 15:00:10 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 40, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/21 15:00:10 INFO Executor: Running task 0.0 in stage 42.0 (TID 40)
17/12/21 15:00:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 15:00:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:00:10 INFO Executor: Finished task 0.0 in stage 42.0 (TID 40). 1707 bytes result sent to driver
17/12/21 15:00:10 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 40) in 0 ms on localhost (executor driver) (1/1)
17/12/21 15:00:10 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
17/12/21 15:00:10 INFO DAGScheduler: ResultStage 42 (sql at <unknown>:0) finished in 0.000 s
17/12/21 15:00:10 INFO DAGScheduler: Job 19 finished: sql at <unknown>:0, took 0.064738 s
17/12/21 15:00:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:10 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 15:00:10 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 15:00:10 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 145 bytes
17/12/21 15:00:10 INFO DAGScheduler: Registering RDD 148 (collect at utils.scala:196)
17/12/21 15:00:10 INFO DAGScheduler: Got job 20 (collect at utils.scala:196) with 1 output partitions
17/12/21 15:00:10 INFO DAGScheduler: Final stage: ResultStage 45 (collect at utils.scala:196)
17/12/21 15:00:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
17/12/21 15:00:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
17/12/21 15:00:10 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[148] at collect at utils.scala:196), which has no missing parents
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 15.3 KB, free 2002.7 MB)
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2002.7 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.3 MB)
17/12/21 15:00:10 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[148] at collect at utils.scala:196)
17/12/21 15:00:10 INFO TaskSchedulerImpl: Adding task set 44.0 with 2 tasks
17/12/21 15:00:10 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/21 15:00:10 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 42, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/21 15:00:10 INFO Executor: Running task 1.0 in stage 44.0 (TID 42)
17/12/21 15:00:10 INFO Executor: Running task 0.0 in stage 44.0 (TID 41)
17/12/21 15:00:10 INFO BlockManager: Found block rdd_138_0 locally
17/12/21 15:00:10 INFO BlockManager: Found block rdd_138_1 locally
17/12/21 15:00:10 INFO Executor: Finished task 0.0 in stage 44.0 (TID 41). 1871 bytes result sent to driver
17/12/21 15:00:10 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 41) in 15 ms on localhost (executor driver) (1/2)
17/12/21 15:00:10 INFO Executor: Finished task 1.0 in stage 44.0 (TID 42). 1871 bytes result sent to driver
17/12/21 15:00:10 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 42) in 15 ms on localhost (executor driver) (2/2)
17/12/21 15:00:10 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
17/12/21 15:00:10 INFO DAGScheduler: ShuffleMapStage 44 (collect at utils.scala:196) finished in 0.015 s
17/12/21 15:00:10 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:00:10 INFO DAGScheduler: running: Set()
17/12/21 15:00:10 INFO DAGScheduler: waiting: Set(ResultStage 45)
17/12/21 15:00:10 INFO DAGScheduler: failed: Set()
17/12/21 15:00:10 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[151] at collect at utils.scala:196), which has no missing parents
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 7.0 KB, free 2002.7 MB)
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.7 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.3 MB)
17/12/21 15:00:10 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[151] at collect at utils.scala:196)
17/12/21 15:00:10 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
17/12/21 15:00:10 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 43, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/21 15:00:10 INFO Executor: Running task 0.0 in stage 45.0 (TID 43)
17/12/21 15:00:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 15:00:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:00:10 INFO Executor: Finished task 0.0 in stage 45.0 (TID 43). 1707 bytes result sent to driver
17/12/21 15:00:10 INFO DAGScheduler: ResultStage 45 (collect at utils.scala:196) finished in 0.000 s
17/12/21 15:00:10 INFO DAGScheduler: Job 20 finished: collect at utils.scala:196, took 0.026374 s
17/12/21 15:00:10 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 43) in 0 ms on localhost (executor driver) (1/1)
17/12/21 15:00:10 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
17/12/21 15:00:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz16`
WHERE (0 = 1)
17/12/21 15:00:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:10 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S2` + 0.91651514 * RANDN() AS `V1`, `S9` + 0.89442719 * RANDN() AS `V2`, `S6` + 0.92736185 * RANDN() AS `V3`, `S3` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `cnzsyncrzu`
17/12/21 15:00:10 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:00:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz17`
WHERE (0 = 1)
17/12/21 15:00:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 15:00:10 INFO CodeGenerator: Code generated in 11.343664 ms
17/12/21 15:00:10 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 15:00:10 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 145 bytes
17/12/21 15:00:10 INFO DAGScheduler: Got job 21 (take at <unknown>:0) with 1 output partitions
17/12/21 15:00:10 INFO DAGScheduler: Final stage: ResultStage 47 (take at <unknown>:0)
17/12/21 15:00:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
17/12/21 15:00:10 INFO DAGScheduler: Missing parents: List()
17/12/21 15:00:10 INFO DAGScheduler: Submitting ResultStage 47 (WorkerRDD[157] at RDD at rdd.scala:18), which has no missing parents
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 104.1 KB, free 2002.6 MB)
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1136
17/12/21 15:00:10 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 41.2 KB, free 2002.6 MB)
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1137
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1143
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1144
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1145
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1146
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1147
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1148
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1149
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1150
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1151
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1152
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1153
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1154
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1155
17/12/21 15:00:10 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:49792 (size: 41.2 KB, free: 2004.3 MB)
17/12/21 15:00:10 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (WorkerRDD[157] at RDD at rdd.scala:18)
17/12/21 15:00:10 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
17/12/21 15:00:10 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/21 15:00:10 INFO Executor: Running task 0.0 in stage 47.0 (TID 44)
17/12/21 15:00:10 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/21 15:00:10 INFO ContextCleaner: Cleaned shuffle 7
17/12/21 15:00:10 INFO BlockManager: Found block rdd_138_0 locally
17/12/21 15:00:10 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:49792 in memory (size: 7.5 KB, free: 2004.3 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:49792 in memory (size: 6.9 KB, free: 2004.3 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1324
17/12/21 15:00:10 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:49792 in memory (size: 7.0 KB, free: 2004.3 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:49792 in memory (size: 41.2 KB, free: 2004.3 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:49792 in memory (size: 41.2 KB, free: 2004.4 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:49792 in memory (size: 44.4 KB, free: 2004.4 MB)
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1629
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1630
17/12/21 15:00:10 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:49792 in memory (size: 4.6 KB, free: 2004.4 MB)
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1679
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1680
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1686
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1687
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1688
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1689
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1690
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1691
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1692
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1693
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1694
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1695
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1696
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1697
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1698
17/12/21 15:00:10 INFO ContextCleaner: Cleaned shuffle 10
17/12/21 15:00:10 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:49792 in memory (size: 7.5 KB, free: 2004.4 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:49792 in memory (size: 6.9 KB, free: 2004.4 MB)
17/12/21 15:00:10 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.4 MB)
17/12/21 15:00:10 INFO ContextCleaner: Cleaned accumulator 1867
17/12/21 15:00:10 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:49792 in memory (size: 7.0 KB, free: 2004.5 MB)
17/12/21 15:00:11 INFO MemoryStore: Block rdd_157_0 stored as values in memory (estimated size 760.0 B, free 2003.2 MB)
17/12/21 15:00:11 INFO BlockManagerInfo: Added rdd_157_0 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.4 MB)
17/12/21 15:00:11 INFO Executor: Finished task 0.0 in stage 47.0 (TID 44). 2668 bytes result sent to driver
17/12/21 15:00:11 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 44) in 643 ms on localhost (executor driver) (1/1)
17/12/21 15:00:11 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
17/12/21 15:00:11 INFO DAGScheduler: ResultStage 47 (take at <unknown>:0) finished in 0.643 s
17/12/21 15:00:11 INFO DAGScheduler: Job 21 finished: take at <unknown>:0, took 0.653164 s
17/12/21 15:00:11 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 15:00:11 INFO DAGScheduler: Got job 22 (take at <unknown>:0) with 1 output partitions
17/12/21 15:00:11 INFO DAGScheduler: Final stage: ResultStage 49 (take at <unknown>:0)
17/12/21 15:00:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)
17/12/21 15:00:11 INFO DAGScheduler: Missing parents: List()
17/12/21 15:00:11 INFO DAGScheduler: Submitting ResultStage 49 (WorkerRDD[157] at RDD at rdd.scala:18), which has no missing parents
17/12/21 15:00:11 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 104.1 KB, free 2003.1 MB)
17/12/21 15:00:11 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 41.2 KB, free 2003.1 MB)
17/12/21 15:00:11 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:49792 (size: 41.2 KB, free: 2004.4 MB)
17/12/21 15:00:11 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (WorkerRDD[157] at RDD at rdd.scala:18)
17/12/21 15:00:11 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
17/12/21 15:00:11 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 45, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/21 15:00:11 INFO Executor: Running task 0.0 in stage 49.0 (TID 45)
17/12/21 15:00:11 INFO BlockManager: Found block rdd_138_1 locally
17/12/21 15:00:12 INFO MemoryStore: Block rdd_157_1 stored as values in memory (estimated size 760.0 B, free 2003.1 MB)
17/12/21 15:00:12 INFO BlockManagerInfo: Added rdd_157_1 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.4 MB)
17/12/21 15:00:12 WARN Executor: 1 block locks were not released by TID = 45:
[rdd_157_1]
17/12/21 15:00:12 INFO Executor: Finished task 0.0 in stage 49.0 (TID 45). 2581 bytes result sent to driver
17/12/21 15:00:12 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 45) in 669 ms on localhost (executor driver) (1/1)
17/12/21 15:00:12 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
17/12/21 15:00:12 INFO DAGScheduler: ResultStage 49 (take at <unknown>:0) finished in 0.670 s
17/12/21 15:00:12 INFO DAGScheduler: Job 22 finished: take at <unknown>:0, took 0.672929 s
17/12/21 15:00:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:12 INFO SparkSqlParser: Parsing command: sparklyr_tmp_177471a61967
17/12/21 15:00:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_177471a61967` AS `zzz18`
WHERE (0 = 1)
17/12/21 15:00:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_177471a61967`
17/12/21 15:00:12 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:00:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz19`
WHERE (0 = 1)
17/12/21 15:00:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:12 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 4e-04) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0055) AS `V3`, (`V4` < 0.0045) AS `V4`
FROM `analyis_tbl`
17/12/21 15:00:12 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:00:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz20`
WHERE (0 = 1)
17/12/21 15:00:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 15:00:12 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 15:00:12 INFO DAGScheduler: Got job 23 (collect at utils.scala:196) with 2 output partitions
17/12/21 15:00:12 INFO DAGScheduler: Final stage: ResultStage 51 (collect at utils.scala:196)
17/12/21 15:00:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
17/12/21 15:00:12 INFO DAGScheduler: Missing parents: List()
17/12/21 15:00:12 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[164] at collect at utils.scala:196), which has no missing parents
17/12/21 15:00:12 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 111.6 KB, free 2002.9 MB)
17/12/21 15:00:12 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 44.4 KB, free 2002.9 MB)
17/12/21 15:00:12 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:49792 (size: 44.4 KB, free: 2004.4 MB)
17/12/21 15:00:12 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 51 (MapPartitionsRDD[164] at collect at utils.scala:196)
17/12/21 15:00:12 INFO TaskSchedulerImpl: Adding task set 51.0 with 2 tasks
17/12/21 15:00:12 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/21 15:00:12 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 47, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/21 15:00:12 INFO Executor: Running task 1.0 in stage 51.0 (TID 47)
17/12/21 15:00:12 INFO Executor: Running task 0.0 in stage 51.0 (TID 46)
17/12/21 15:00:12 INFO BlockManager: Found block rdd_157_1 locally
17/12/21 15:00:12 INFO BlockManager: Found block rdd_157_0 locally
17/12/21 15:00:12 INFO Executor: Finished task 1.0 in stage 51.0 (TID 47). 1597 bytes result sent to driver
17/12/21 15:00:12 INFO Executor: Finished task 0.0 in stage 51.0 (TID 46). 1597 bytes result sent to driver
17/12/21 15:00:12 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 47) in 16 ms on localhost (executor driver) (1/2)
17/12/21 15:00:12 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 46) in 16 ms on localhost (executor driver) (2/2)
17/12/21 15:00:12 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
17/12/21 15:00:12 INFO DAGScheduler: ResultStage 51 (collect at utils.scala:196) finished in 0.016 s
17/12/21 15:00:12 INFO DAGScheduler: Job 23 finished: collect at utils.scala:196, took 0.013879 s
17/12/21 15:00:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:12 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:00:12 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:12 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:00:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:00:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:12 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:00:12 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:12 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:00:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:00:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:12 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:00:12 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:12 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:00:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:00:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:12 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:00:12 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:12 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:00:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:00:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:00:46 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:46 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:46 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:00:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:00:46 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 15:00:46 INFO DAGScheduler: Got job 24 (collect at utils.scala:58) with 1 output partitions
17/12/21 15:00:46 INFO DAGScheduler: Final stage: ResultStage 52 (collect at utils.scala:58)
17/12/21 15:00:46 INFO DAGScheduler: Parents of final stage: List()
17/12/21 15:00:46 INFO DAGScheduler: Missing parents: List()
17/12/21 15:00:46 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[174] at map at utils.scala:55), which has no missing parents
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 8.7 KB, free 2002.9 MB)
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2002.9 MB)
17/12/21 15:00:46 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:49792 (size: 4.6 KB, free: 2004.4 MB)
17/12/21 15:00:46 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[174] at map at utils.scala:55)
17/12/21 15:00:46 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
17/12/21 15:00:46 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 6648 bytes)
17/12/21 15:00:46 INFO Executor: Running task 0.0 in stage 52.0 (TID 48)
17/12/21 15:00:46 INFO Executor: Finished task 0.0 in stage 52.0 (TID 48). 1187 bytes result sent to driver
17/12/21 15:00:46 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 48) in 4 ms on localhost (executor driver) (1/1)
17/12/21 15:00:46 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
17/12/21 15:00:46 INFO DAGScheduler: ResultStage 52 (collect at utils.scala:58) finished in 0.005 s
17/12/21 15:00:46 INFO DAGScheduler: Job 24 finished: collect at utils.scala:58, took 0.008763 s
17/12/21 15:00:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:46 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:00:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:46 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 15:00:46 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 15:00:46 INFO FileSourceStrategy: Pruning directories with: 
17/12/21 15:00:46 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/21 15:00:46 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double, S4: double, S5: double ... 8 more fields>
17/12/21 15:00:46 INFO FileSourceStrategy: Pushed Filters: 
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 293.7 KB, free 2002.6 MB)
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2002.6 MB)
17/12/21 15:00:46 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:49792 (size: 24.0 KB, free: 2004.3 MB)
17/12/21 15:00:46 INFO SparkContext: Created broadcast 41 from sql at <unknown>:0
17/12/21 15:00:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/21 15:00:46 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 15:00:46 INFO DAGScheduler: Registering RDD 178 (sql at <unknown>:0)
17/12/21 15:00:46 INFO DAGScheduler: Registering RDD 183 (sql at <unknown>:0)
17/12/21 15:00:46 INFO DAGScheduler: Got job 25 (sql at <unknown>:0) with 1 output partitions
17/12/21 15:00:46 INFO DAGScheduler: Final stage: ResultStage 55 (sql at <unknown>:0)
17/12/21 15:00:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
17/12/21 15:00:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 54)
17/12/21 15:00:46 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[178] at sql at <unknown>:0), which has no missing parents
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 13.1 KB, free 2002.6 MB)
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 7.5 KB, free 2002.6 MB)
17/12/21 15:00:46 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:49792 (size: 7.5 KB, free: 2004.3 MB)
17/12/21 15:00:46 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[178] at sql at <unknown>:0)
17/12/21 15:00:46 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
17/12/21 15:00:46 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/21 15:00:46 INFO Executor: Running task 0.0 in stage 53.0 (TID 49)
17/12/21 15:00:46 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmponGyKW/spark_serialize_95ae601646dbdc5a22bea5152626bc09b05459b71b98e6398922093f8a76a2e6.csv, range: 0-1916, partition values: [empty row]
17/12/21 15:00:46 INFO Executor: Finished task 0.0 in stage 53.0 (TID 49). 1632 bytes result sent to driver
17/12/21 15:00:46 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 49) in 37 ms on localhost (executor driver) (1/1)
17/12/21 15:00:46 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
17/12/21 15:00:46 INFO DAGScheduler: ShuffleMapStage 53 (sql at <unknown>:0) finished in 0.037 s
17/12/21 15:00:46 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:00:46 INFO DAGScheduler: running: Set()
17/12/21 15:00:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 54, ResultStage 55)
17/12/21 15:00:46 INFO DAGScheduler: failed: Set()
17/12/21 15:00:46 INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[183] at sql at <unknown>:0), which has no missing parents
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 15.3 KB, free 2002.5 MB)
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2002.5 MB)
17/12/21 15:00:46 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.3 MB)
17/12/21 15:00:46 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:46 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[183] at sql at <unknown>:0)
17/12/21 15:00:46 INFO TaskSchedulerImpl: Adding task set 54.0 with 2 tasks
17/12/21 15:00:46 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 50, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/21 15:00:46 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 51, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/21 15:00:46 INFO Executor: Running task 0.0 in stage 54.0 (TID 50)
17/12/21 15:00:46 INFO Executor: Running task 1.0 in stage 54.0 (TID 51)
17/12/21 15:00:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 15:00:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:00:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 15:00:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:00:46 INFO MemoryStore: Block rdd_180_0 stored as values in memory (estimated size 1512.0 B, free 2002.5 MB)
17/12/21 15:00:46 INFO BlockManagerInfo: Added rdd_180_0 in memory on 127.0.0.1:49792 (size: 1512.0 B, free: 2004.3 MB)
17/12/21 15:00:46 INFO MemoryStore: Block rdd_180_1 stored as values in memory (estimated size 1512.0 B, free 2002.5 MB)
17/12/21 15:00:46 INFO BlockManagerInfo: Added rdd_180_1 in memory on 127.0.0.1:49792 (size: 1512.0 B, free: 2004.3 MB)
17/12/21 15:00:46 INFO Executor: Finished task 0.0 in stage 54.0 (TID 50). 2985 bytes result sent to driver
17/12/21 15:00:46 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 50) in 16 ms on localhost (executor driver) (1/2)
17/12/21 15:00:46 INFO Executor: Finished task 1.0 in stage 54.0 (TID 51). 2985 bytes result sent to driver
17/12/21 15:00:46 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 51) in 16 ms on localhost (executor driver) (2/2)
17/12/21 15:00:46 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
17/12/21 15:00:46 INFO DAGScheduler: ShuffleMapStage 54 (sql at <unknown>:0) finished in 0.016 s
17/12/21 15:00:46 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:00:46 INFO DAGScheduler: running: Set()
17/12/21 15:00:46 INFO DAGScheduler: waiting: Set(ResultStage 55)
17/12/21 15:00:46 INFO DAGScheduler: failed: Set()
17/12/21 15:00:46 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[186] at sql at <unknown>:0), which has no missing parents
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 7.0 KB, free 2002.5 MB)
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.5 MB)
17/12/21 15:00:46 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.3 MB)
17/12/21 15:00:46 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[186] at sql at <unknown>:0)
17/12/21 15:00:46 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
17/12/21 15:00:46 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 52, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/21 15:00:46 INFO Executor: Running task 0.0 in stage 55.0 (TID 52)
17/12/21 15:00:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 15:00:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:00:46 INFO Executor: Finished task 0.0 in stage 55.0 (TID 52). 1865 bytes result sent to driver
17/12/21 15:00:46 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 52) in 16 ms on localhost (executor driver) (1/1)
17/12/21 15:00:46 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
17/12/21 15:00:46 INFO DAGScheduler: ResultStage 55 (sql at <unknown>:0) finished in 0.016 s
17/12/21 15:00:46 INFO DAGScheduler: Job 25 finished: sql at <unknown>:0, took 0.061623 s
17/12/21 15:00:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:46 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 15:00:46 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 15:00:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 145 bytes
17/12/21 15:00:46 INFO DAGScheduler: Registering RDD 190 (collect at utils.scala:196)
17/12/21 15:00:46 INFO DAGScheduler: Got job 26 (collect at utils.scala:196) with 1 output partitions
17/12/21 15:00:46 INFO DAGScheduler: Final stage: ResultStage 58 (collect at utils.scala:196)
17/12/21 15:00:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)
17/12/21 15:00:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 57)
17/12/21 15:00:46 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[190] at collect at utils.scala:196), which has no missing parents
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 15.3 KB, free 2002.5 MB)
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2002.5 MB)
17/12/21 15:00:46 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.3 MB)
17/12/21 15:00:46 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:46 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[190] at collect at utils.scala:196)
17/12/21 15:00:46 INFO TaskSchedulerImpl: Adding task set 57.0 with 2 tasks
17/12/21 15:00:46 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/21 15:00:46 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 54, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/21 15:00:46 INFO Executor: Running task 0.0 in stage 57.0 (TID 53)
17/12/21 15:00:46 INFO Executor: Running task 1.0 in stage 57.0 (TID 54)
17/12/21 15:00:46 INFO BlockManager: Found block rdd_180_1 locally
17/12/21 15:00:46 INFO BlockManager: Found block rdd_180_0 locally
17/12/21 15:00:46 INFO Executor: Finished task 1.0 in stage 57.0 (TID 54). 1958 bytes result sent to driver
17/12/21 15:00:46 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 54) in 3 ms on localhost (executor driver) (1/2)
17/12/21 15:00:46 INFO Executor: Finished task 0.0 in stage 57.0 (TID 53). 1958 bytes result sent to driver
17/12/21 15:00:46 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 53) in 4 ms on localhost (executor driver) (2/2)
17/12/21 15:00:46 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
17/12/21 15:00:46 INFO DAGScheduler: ShuffleMapStage 57 (collect at utils.scala:196) finished in 0.004 s
17/12/21 15:00:46 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:00:46 INFO DAGScheduler: running: Set()
17/12/21 15:00:46 INFO DAGScheduler: waiting: Set(ResultStage 58)
17/12/21 15:00:46 INFO DAGScheduler: failed: Set()
17/12/21 15:00:46 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[193] at collect at utils.scala:196), which has no missing parents
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 7.0 KB, free 2002.5 MB)
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.5 MB)
17/12/21 15:00:46 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.3 MB)
17/12/21 15:00:46 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[193] at collect at utils.scala:196)
17/12/21 15:00:46 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
17/12/21 15:00:46 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 55, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/21 15:00:46 INFO Executor: Running task 0.0 in stage 58.0 (TID 55)
17/12/21 15:00:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 15:00:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:00:46 INFO Executor: Finished task 0.0 in stage 58.0 (TID 55). 1707 bytes result sent to driver
17/12/21 15:00:46 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 55) in 15 ms on localhost (executor driver) (1/1)
17/12/21 15:00:46 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
17/12/21 15:00:46 INFO DAGScheduler: ResultStage 58 (collect at utils.scala:196) finished in 0.015 s
17/12/21 15:00:46 INFO DAGScheduler: Job 26 finished: collect at utils.scala:196, took 0.024664 s
17/12/21 15:00:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz21`
WHERE (0 = 1)
17/12/21 15:00:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:46 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S2` + 0.91651514 * RANDN() AS `V1`, `S9` + 0.89442719 * RANDN() AS `V2`, `S6` + 0.92736185 * RANDN() AS `V3`, `S3` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `eayoxqackb`
17/12/21 15:00:46 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:00:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz22`
WHERE (0 = 1)
17/12/21 15:00:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 15:00:46 INFO CodeGenerator: Code generated in 9.921316 ms
17/12/21 15:00:46 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 15:00:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 145 bytes
17/12/21 15:00:46 INFO DAGScheduler: Got job 27 (take at <unknown>:0) with 1 output partitions
17/12/21 15:00:46 INFO DAGScheduler: Final stage: ResultStage 60 (take at <unknown>:0)
17/12/21 15:00:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
17/12/21 15:00:46 INFO DAGScheduler: Missing parents: List()
17/12/21 15:00:46 INFO DAGScheduler: Submitting ResultStage 60 (WorkerRDD[199] at RDD at rdd.scala:18), which has no missing parents
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 104.1 KB, free 2002.4 MB)
17/12/21 15:00:46 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 41.1 KB, free 2002.4 MB)
17/12/21 15:00:46 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:49792 (size: 41.1 KB, free: 2004.3 MB)
17/12/21 15:00:46 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (WorkerRDD[199] at RDD at rdd.scala:18)
17/12/21 15:00:46 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
17/12/21 15:00:46 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/21 15:00:46 INFO Executor: Running task 0.0 in stage 60.0 (TID 56)
17/12/21 15:00:46 INFO BlockManager: Found block rdd_180_0 locally
17/12/21 15:00:47 INFO MemoryStore: Block rdd_199_0 stored as values in memory (estimated size 760.0 B, free 2002.4 MB)
17/12/21 15:00:47 INFO BlockManagerInfo: Added rdd_199_0 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.3 MB)
17/12/21 15:00:47 INFO Executor: Finished task 0.0 in stage 60.0 (TID 56). 2758 bytes result sent to driver
17/12/21 15:00:47 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 56) in 675 ms on localhost (executor driver) (1/1)
17/12/21 15:00:47 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
17/12/21 15:00:47 INFO DAGScheduler: ResultStage 60 (take at <unknown>:0) finished in 0.675 s
17/12/21 15:00:47 INFO DAGScheduler: Job 27 finished: take at <unknown>:0, took 0.673622 s
17/12/21 15:00:47 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 15:00:47 INFO DAGScheduler: Got job 28 (take at <unknown>:0) with 1 output partitions
17/12/21 15:00:47 INFO DAGScheduler: Final stage: ResultStage 62 (take at <unknown>:0)
17/12/21 15:00:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
17/12/21 15:00:47 INFO DAGScheduler: Missing parents: List()
17/12/21 15:00:47 INFO DAGScheduler: Submitting ResultStage 62 (WorkerRDD[199] at RDD at rdd.scala:18), which has no missing parents
17/12/21 15:00:47 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 104.1 KB, free 2002.3 MB)
17/12/21 15:00:47 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 41.1 KB, free 2002.2 MB)
17/12/21 15:00:47 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:49792 (size: 41.1 KB, free: 2004.2 MB)
17/12/21 15:00:47 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (WorkerRDD[199] at RDD at rdd.scala:18)
17/12/21 15:00:47 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
17/12/21 15:00:47 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 57, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/21 15:00:47 INFO Executor: Running task 0.0 in stage 62.0 (TID 57)
17/12/21 15:00:47 INFO BlockManager: Found block rdd_180_1 locally
17/12/21 15:00:48 INFO MemoryStore: Block rdd_199_1 stored as values in memory (estimated size 760.0 B, free 2002.2 MB)
17/12/21 15:00:48 INFO BlockManagerInfo: Added rdd_199_1 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.2 MB)
17/12/21 15:00:48 WARN Executor: 1 block locks were not released by TID = 57:
[rdd_199_1]
17/12/21 15:00:48 INFO Executor: Finished task 0.0 in stage 62.0 (TID 57). 2581 bytes result sent to driver
17/12/21 15:00:48 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 57) in 670 ms on localhost (executor driver) (1/1)
17/12/21 15:00:48 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
17/12/21 15:00:48 INFO DAGScheduler: ResultStage 62 (take at <unknown>:0) finished in 0.670 s
17/12/21 15:00:48 INFO DAGScheduler: Job 28 finished: take at <unknown>:0, took 0.681697 s
17/12/21 15:00:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:48 INFO SparkSqlParser: Parsing command: sparklyr_tmp_17741f846dd2
17/12/21 15:00:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17741f846dd2` AS `zzz23`
WHERE (0 = 1)
17/12/21 15:00:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17741f846dd2`
17/12/21 15:00:48 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:00:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz24`
WHERE (0 = 1)
17/12/21 15:00:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:48 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 4e-04) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0055) AS `V3`, (`V4` < 0.0045) AS `V4`
FROM `analyis_tbl`
17/12/21 15:00:48 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:00:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz25`
WHERE (0 = 1)
17/12/21 15:00:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 15:00:48 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 15:00:48 INFO DAGScheduler: Got job 29 (collect at utils.scala:196) with 2 output partitions
17/12/21 15:00:48 INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:196)
17/12/21 15:00:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
17/12/21 15:00:48 INFO DAGScheduler: Missing parents: List()
17/12/21 15:00:48 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[206] at collect at utils.scala:196), which has no missing parents
17/12/21 15:00:48 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 111.6 KB, free 2002.1 MB)
17/12/21 15:00:48 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 44.4 KB, free 2002.1 MB)
17/12/21 15:00:48 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:49792 (size: 44.4 KB, free: 2004.2 MB)
17/12/21 15:00:48 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:996
17/12/21 15:00:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 64 (MapPartitionsRDD[206] at collect at utils.scala:196)
17/12/21 15:00:48 INFO TaskSchedulerImpl: Adding task set 64.0 with 2 tasks
17/12/21 15:00:48 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/21 15:00:48 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 59, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/21 15:00:48 INFO Executor: Running task 1.0 in stage 64.0 (TID 59)
17/12/21 15:00:48 INFO Executor: Running task 0.0 in stage 64.0 (TID 58)
17/12/21 15:00:48 INFO BlockManager: Found block rdd_199_0 locally
17/12/21 15:00:48 INFO BlockManager: Found block rdd_199_1 locally
17/12/21 15:00:48 INFO Executor: Finished task 1.0 in stage 64.0 (TID 59). 1439 bytes result sent to driver
17/12/21 15:00:48 INFO Executor: Finished task 0.0 in stage 64.0 (TID 58). 1454 bytes result sent to driver
17/12/21 15:00:48 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 59) in 0 ms on localhost (executor driver) (1/2)
17/12/21 15:00:48 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 58) in 0 ms on localhost (executor driver) (2/2)
17/12/21 15:00:48 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
17/12/21 15:00:48 INFO DAGScheduler: ResultStage 64 (collect at utils.scala:196) finished in 0.000 s
17/12/21 15:00:48 INFO DAGScheduler: Job 29 finished: collect at utils.scala:196, took 0.010918 s
17/12/21 15:00:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:00:48 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:48 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:48 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:48 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:00:48 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:00:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:00:48 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:48 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:48 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:48 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:00:48 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:00:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:00:48 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:48 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:48 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:48 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:00:48 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:00:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:00:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:00:48 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:48 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:48 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:00:48 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:00:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:00:48 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:02:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:53 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:02:53 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:02:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:02:53 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:02:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:02:53 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:02:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:02:53 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 15:02:53 INFO DAGScheduler: Got job 30 (collect at utils.scala:58) with 1 output partitions
17/12/21 15:02:53 INFO DAGScheduler: Final stage: ResultStage 65 (collect at utils.scala:58)
17/12/21 15:02:53 INFO DAGScheduler: Parents of final stage: List()
17/12/21 15:02:53 INFO DAGScheduler: Missing parents: List()
17/12/21 15:02:53 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[216] at map at utils.scala:55), which has no missing parents
17/12/21 15:02:53 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 8.7 KB, free 2002.0 MB)
17/12/21 15:02:53 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2002.0 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:49792 (size: 4.6 KB, free: 2004.2 MB)
17/12/21 15:02:53 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:996
17/12/21 15:02:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[216] at map at utils.scala:55)
17/12/21 15:02:53 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
17/12/21 15:02:53 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 6720 bytes)
17/12/21 15:02:53 INFO Executor: Running task 0.0 in stage 65.0 (TID 60)
17/12/21 15:02:53 INFO Executor: Finished task 0.0 in stage 65.0 (TID 60). 1136 bytes result sent to driver
17/12/21 15:02:53 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 60) in 5 ms on localhost (executor driver) (1/1)
17/12/21 15:02:53 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
17/12/21 15:02:53 INFO DAGScheduler: ResultStage 65 (collect at utils.scala:58) finished in 0.005 s
17/12/21 15:02:53 INFO DAGScheduler: Job 30 finished: collect at utils.scala:58, took 0.009321 s
17/12/21 15:02:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:53 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:02:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:53 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 15:02:53 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 15:02:53 INFO FileSourceStrategy: Pruning directories with: 
17/12/21 15:02:53 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/21 15:02:53 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double, S4: double, S5: double ... 8 more fields>
17/12/21 15:02:53 INFO FileSourceStrategy: Pushed Filters: 
17/12/21 15:02:53 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 293.7 KB, free 2001.8 MB)
17/12/21 15:02:53 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2001.7 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:49792 (size: 24.0 KB, free: 2004.2 MB)
17/12/21 15:02:53 INFO SparkContext: Created broadcast 51 from sql at <unknown>:0
17/12/21 15:02:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/21 15:02:53 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:49792 in memory (size: 41.2 KB, free: 2004.2 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:49792 in memory (size: 41.2 KB, free: 2004.2 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:49792 in memory (size: 44.4 KB, free: 2004.3 MB)
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2172
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2173
17/12/21 15:02:53 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:49792 in memory (size: 4.6 KB, free: 2004.3 MB)
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2222
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2223
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2229
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2230
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2231
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2232
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2233
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2234
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2235
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2236
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2237
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2238
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2239
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2240
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2241
17/12/21 15:02:53 INFO ContextCleaner: Cleaned shuffle 13
17/12/21 15:02:53 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:49792 in memory (size: 7.5 KB, free: 2004.3 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:49792 in memory (size: 7.0 KB, free: 2004.3 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2410
17/12/21 15:02:53 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:49792 in memory (size: 7.0 KB, free: 2004.3 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:49792 in memory (size: 41.1 KB, free: 2004.3 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:49792 in memory (size: 41.1 KB, free: 2004.4 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:49792 in memory (size: 44.4 KB, free: 2004.4 MB)
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2715
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2716
17/12/21 15:02:53 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:49792 in memory (size: 4.6 KB, free: 2004.4 MB)
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2765
17/12/21 15:02:53 INFO ContextCleaner: Cleaned accumulator 2766
17/12/21 15:02:53 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 15:02:53 INFO DAGScheduler: Registering RDD 220 (sql at <unknown>:0)
17/12/21 15:02:53 INFO DAGScheduler: Registering RDD 225 (sql at <unknown>:0)
17/12/21 15:02:53 INFO DAGScheduler: Got job 31 (sql at <unknown>:0) with 1 output partitions
17/12/21 15:02:53 INFO DAGScheduler: Final stage: ResultStage 68 (sql at <unknown>:0)
17/12/21 15:02:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
17/12/21 15:02:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 67)
17/12/21 15:02:53 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[220] at sql at <unknown>:0), which has no missing parents
17/12/21 15:02:53 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 13.1 KB, free 2002.7 MB)
17/12/21 15:02:53 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 7.5 KB, free 2002.7 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:49792 (size: 7.5 KB, free: 2004.4 MB)
17/12/21 15:02:53 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:996
17/12/21 15:02:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[220] at sql at <unknown>:0)
17/12/21 15:02:53 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
17/12/21 15:02:53 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/21 15:02:53 INFO Executor: Running task 0.0 in stage 66.0 (TID 61)
17/12/21 15:02:53 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmponGyKW/spark_serialize_33d4c47d15cf9e7ebff798e3a9d00fe5199f6a9987217e29dee2af28a07e9a00.csv, range: 0-1916, partition values: [empty row]
17/12/21 15:02:53 INFO Executor: Finished task 0.0 in stage 66.0 (TID 61). 1640 bytes result sent to driver
17/12/21 15:02:53 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 61) in 55 ms on localhost (executor driver) (1/1)
17/12/21 15:02:53 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
17/12/21 15:02:53 INFO DAGScheduler: ShuffleMapStage 66 (sql at <unknown>:0) finished in 0.055 s
17/12/21 15:02:53 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:02:53 INFO DAGScheduler: running: Set()
17/12/21 15:02:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 67, ResultStage 68)
17/12/21 15:02:53 INFO DAGScheduler: failed: Set()
17/12/21 15:02:53 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[225] at sql at <unknown>:0), which has no missing parents
17/12/21 15:02:53 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 15.3 KB, free 2002.7 MB)
17/12/21 15:02:53 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2002.7 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.4 MB)
17/12/21 15:02:53 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:996
17/12/21 15:02:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[225] at sql at <unknown>:0)
17/12/21 15:02:53 INFO TaskSchedulerImpl: Adding task set 67.0 with 2 tasks
17/12/21 15:02:53 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 62, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/21 15:02:53 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 63, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/21 15:02:53 INFO Executor: Running task 0.0 in stage 67.0 (TID 62)
17/12/21 15:02:53 INFO Executor: Running task 1.0 in stage 67.0 (TID 63)
17/12/21 15:02:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 15:02:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:02:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 15:02:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:02:53 INFO MemoryStore: Block rdd_222_0 stored as values in memory (estimated size 1512.0 B, free 2002.7 MB)
17/12/21 15:02:53 INFO MemoryStore: Block rdd_222_1 stored as values in memory (estimated size 1512.0 B, free 2002.7 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Added rdd_222_0 in memory on 127.0.0.1:49792 (size: 1512.0 B, free: 2004.4 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Added rdd_222_1 in memory on 127.0.0.1:49792 (size: 1512.0 B, free: 2004.4 MB)
17/12/21 15:02:53 INFO Executor: Finished task 1.0 in stage 67.0 (TID 63). 3072 bytes result sent to driver
17/12/21 15:02:53 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 63) in 12 ms on localhost (executor driver) (1/2)
17/12/21 15:02:53 INFO Executor: Finished task 0.0 in stage 67.0 (TID 62). 3151 bytes result sent to driver
17/12/21 15:02:53 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 62) in 14 ms on localhost (executor driver) (2/2)
17/12/21 15:02:53 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
17/12/21 15:02:53 INFO DAGScheduler: ShuffleMapStage 67 (sql at <unknown>:0) finished in 0.015 s
17/12/21 15:02:53 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:02:53 INFO DAGScheduler: running: Set()
17/12/21 15:02:53 INFO DAGScheduler: waiting: Set(ResultStage 68)
17/12/21 15:02:53 INFO DAGScheduler: failed: Set()
17/12/21 15:02:53 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[228] at sql at <unknown>:0), which has no missing parents
17/12/21 15:02:53 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 7.0 KB, free 2002.7 MB)
17/12/21 15:02:53 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.7 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.4 MB)
17/12/21 15:02:53 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:996
17/12/21 15:02:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[228] at sql at <unknown>:0)
17/12/21 15:02:53 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
17/12/21 15:02:53 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 64, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/21 15:02:53 INFO Executor: Running task 0.0 in stage 68.0 (TID 64)
17/12/21 15:02:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 15:02:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/12/21 15:02:53 INFO Executor: Finished task 0.0 in stage 68.0 (TID 64). 1873 bytes result sent to driver
17/12/21 15:02:53 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 64) in 6 ms on localhost (executor driver) (1/1)
17/12/21 15:02:53 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
17/12/21 15:02:53 INFO DAGScheduler: ResultStage 68 (sql at <unknown>:0) finished in 0.007 s
17/12/21 15:02:53 INFO DAGScheduler: Job 31 finished: sql at <unknown>:0, took 0.086722 s
17/12/21 15:02:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:53 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 15:02:53 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 15:02:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 145 bytes
17/12/21 15:02:53 INFO DAGScheduler: Registering RDD 232 (collect at utils.scala:196)
17/12/21 15:02:53 INFO DAGScheduler: Got job 32 (collect at utils.scala:196) with 1 output partitions
17/12/21 15:02:53 INFO DAGScheduler: Final stage: ResultStage 71 (collect at utils.scala:196)
17/12/21 15:02:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
17/12/21 15:02:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 70)
17/12/21 15:02:53 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[232] at collect at utils.scala:196), which has no missing parents
17/12/21 15:02:53 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 15.3 KB, free 2002.6 MB)
17/12/21 15:02:53 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2002.6 MB)
17/12/21 15:02:53 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.4 MB)
17/12/21 15:02:53 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:996
17/12/21 15:02:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[232] at collect at utils.scala:196)
17/12/21 15:02:53 INFO TaskSchedulerImpl: Adding task set 70.0 with 2 tasks
17/12/21 15:02:53 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/21 15:02:53 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 66, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/21 15:02:53 INFO Executor: Running task 1.0 in stage 70.0 (TID 66)
17/12/21 15:02:53 INFO Executor: Running task 0.0 in stage 70.0 (TID 65)
17/12/21 15:02:53 INFO BlockManager: Found block rdd_222_0 locally
17/12/21 15:02:53 INFO BlockManager: Found block rdd_222_1 locally
17/12/21 15:02:53 INFO Executor: Finished task 1.0 in stage 70.0 (TID 66). 1792 bytes result sent to driver
17/12/21 15:02:53 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 66) in 0 ms on localhost (executor driver) (1/2)
17/12/21 15:02:53 INFO Executor: Finished task 0.0 in stage 70.0 (TID 65). 1792 bytes result sent to driver
17/12/21 15:02:53 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 65) in 0 ms on localhost (executor driver) (2/2)
17/12/21 15:02:53 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
17/12/21 15:02:53 INFO DAGScheduler: ShuffleMapStage 70 (collect at utils.scala:196) finished in 0.000 s
17/12/21 15:02:53 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:02:53 INFO DAGScheduler: running: Set()
17/12/21 15:02:53 INFO DAGScheduler: waiting: Set(ResultStage 71)
17/12/21 15:02:53 INFO DAGScheduler: failed: Set()
17/12/21 15:02:53 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[235] at collect at utils.scala:196), which has no missing parents
17/12/21 15:02:53 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 7.0 KB, free 2002.6 MB)
17/12/21 15:02:54 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.6 MB)
17/12/21 15:02:54 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.4 MB)
17/12/21 15:02:54 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:996
17/12/21 15:02:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[235] at collect at utils.scala:196)
17/12/21 15:02:54 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
17/12/21 15:02:54 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 67, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/21 15:02:54 INFO Executor: Running task 0.0 in stage 71.0 (TID 67)
17/12/21 15:02:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 15:02:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:02:54 INFO Executor: Finished task 0.0 in stage 71.0 (TID 67). 1786 bytes result sent to driver
17/12/21 15:02:54 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 67) in 4 ms on localhost (executor driver) (1/1)
17/12/21 15:02:54 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
17/12/21 15:02:54 INFO DAGScheduler: ResultStage 71 (collect at utils.scala:196) finished in 0.004 s
17/12/21 15:02:54 INFO DAGScheduler: Job 32 finished: collect at utils.scala:196, took 0.020489 s
17/12/21 15:02:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz26`
WHERE (0 = 1)
17/12/21 15:02:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:54 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S2` + 0.91651514 * RANDN() AS `V1`, `S9` + 0.89442719 * RANDN() AS `V2`, `S6` + 0.92736185 * RANDN() AS `V3`, `S3` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `qkxlxaiguh`
17/12/21 15:02:54 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:02:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz27`
WHERE (0 = 1)
17/12/21 15:02:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 15:02:54 INFO CodeGenerator: Code generated in 11.352726 ms
17/12/21 15:02:54 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 15:02:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 145 bytes
17/12/21 15:02:54 INFO DAGScheduler: Got job 33 (take at <unknown>:0) with 1 output partitions
17/12/21 15:02:54 INFO DAGScheduler: Final stage: ResultStage 73 (take at <unknown>:0)
17/12/21 15:02:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)
17/12/21 15:02:54 INFO DAGScheduler: Missing parents: List()
17/12/21 15:02:54 INFO DAGScheduler: Submitting ResultStage 73 (WorkerRDD[241] at RDD at rdd.scala:18), which has no missing parents
17/12/21 15:02:54 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 104.1 KB, free 2002.5 MB)
17/12/21 15:02:54 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 41.2 KB, free 2002.5 MB)
17/12/21 15:02:54 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:49792 (size: 41.2 KB, free: 2004.4 MB)
17/12/21 15:02:54 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:996
17/12/21 15:02:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (WorkerRDD[241] at RDD at rdd.scala:18)
17/12/21 15:02:54 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
17/12/21 15:02:54 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/21 15:02:54 INFO Executor: Running task 0.0 in stage 73.0 (TID 68)
17/12/21 15:02:54 INFO BlockManager: Found block rdd_222_0 locally
17/12/21 15:02:54 INFO MemoryStore: Block rdd_241_0 stored as values in memory (estimated size 760.0 B, free 2002.5 MB)
17/12/21 15:02:54 INFO BlockManagerInfo: Added rdd_241_0 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.4 MB)
17/12/21 15:02:54 INFO Executor: Finished task 0.0 in stage 73.0 (TID 68). 2758 bytes result sent to driver
17/12/21 15:02:54 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 68) in 679 ms on localhost (executor driver) (1/1)
17/12/21 15:02:54 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
17/12/21 15:02:54 INFO DAGScheduler: ResultStage 73 (take at <unknown>:0) finished in 0.679 s
17/12/21 15:02:54 INFO DAGScheduler: Job 33 finished: take at <unknown>:0, took 0.687504 s
17/12/21 15:02:54 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 15:02:54 INFO DAGScheduler: Got job 34 (take at <unknown>:0) with 1 output partitions
17/12/21 15:02:54 INFO DAGScheduler: Final stage: ResultStage 75 (take at <unknown>:0)
17/12/21 15:02:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)
17/12/21 15:02:54 INFO DAGScheduler: Missing parents: List()
17/12/21 15:02:54 INFO DAGScheduler: Submitting ResultStage 75 (WorkerRDD[241] at RDD at rdd.scala:18), which has no missing parents
17/12/21 15:02:54 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 104.1 KB, free 2002.4 MB)
17/12/21 15:02:54 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 41.2 KB, free 2002.3 MB)
17/12/21 15:02:54 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:49792 (size: 41.2 KB, free: 2004.3 MB)
17/12/21 15:02:54 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:996
17/12/21 15:02:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (WorkerRDD[241] at RDD at rdd.scala:18)
17/12/21 15:02:54 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
17/12/21 15:02:54 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 69, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/21 15:02:54 INFO Executor: Running task 0.0 in stage 75.0 (TID 69)
17/12/21 15:02:54 INFO BlockManager: Found block rdd_222_1 locally
17/12/21 15:02:55 INFO MemoryStore: Block rdd_241_1 stored as values in memory (estimated size 760.0 B, free 2002.3 MB)
17/12/21 15:02:55 INFO BlockManagerInfo: Added rdd_241_1 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.3 MB)
17/12/21 15:02:55 WARN Executor: 1 block locks were not released by TID = 69:
[rdd_241_1]
17/12/21 15:02:55 INFO Executor: Finished task 0.0 in stage 75.0 (TID 69). 2581 bytes result sent to driver
17/12/21 15:02:55 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 69) in 683 ms on localhost (executor driver) (1/1)
17/12/21 15:02:55 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
17/12/21 15:02:55 INFO DAGScheduler: ResultStage 75 (take at <unknown>:0) finished in 0.683 s
17/12/21 15:02:55 INFO DAGScheduler: Job 34 finished: take at <unknown>:0, took 0.683342 s
17/12/21 15:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:55 INFO SparkSqlParser: Parsing command: sparklyr_tmp_17743d6338fa
17/12/21 15:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17743d6338fa` AS `zzz28`
WHERE (0 = 1)
17/12/21 15:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17743d6338fa`
17/12/21 15:02:55 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz29`
WHERE (0 = 1)
17/12/21 15:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:55 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 4e-04) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0055) AS `V3`, (`V4` < 0.0045) AS `V4`
FROM `analyis_tbl`
17/12/21 15:02:55 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz30`
WHERE (0 = 1)
17/12/21 15:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 15:02:55 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 15:02:55 INFO DAGScheduler: Got job 35 (collect at utils.scala:196) with 2 output partitions
17/12/21 15:02:55 INFO DAGScheduler: Final stage: ResultStage 77 (collect at utils.scala:196)
17/12/21 15:02:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)
17/12/21 15:02:55 INFO DAGScheduler: Missing parents: List()
17/12/21 15:02:55 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[248] at collect at utils.scala:196), which has no missing parents
17/12/21 15:02:55 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 111.6 KB, free 2002.2 MB)
17/12/21 15:02:55 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 44.4 KB, free 2002.2 MB)
17/12/21 15:02:55 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:49792 (size: 44.4 KB, free: 2004.3 MB)
17/12/21 15:02:55 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:996
17/12/21 15:02:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 77 (MapPartitionsRDD[248] at collect at utils.scala:196)
17/12/21 15:02:55 INFO TaskSchedulerImpl: Adding task set 77.0 with 2 tasks
17/12/21 15:02:55 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/21 15:02:55 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 71, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/21 15:02:55 INFO Executor: Running task 0.0 in stage 77.0 (TID 70)
17/12/21 15:02:55 INFO Executor: Running task 1.0 in stage 77.0 (TID 71)
17/12/21 15:02:55 INFO BlockManager: Found block rdd_241_1 locally
17/12/21 15:02:55 INFO BlockManager: Found block rdd_241_0 locally
17/12/21 15:02:55 INFO Executor: Finished task 1.0 in stage 77.0 (TID 71). 1439 bytes result sent to driver
17/12/21 15:02:55 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 71) in 16 ms on localhost (executor driver) (1/2)
17/12/21 15:02:55 INFO Executor: Finished task 0.0 in stage 77.0 (TID 70). 1518 bytes result sent to driver
17/12/21 15:02:55 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 70) in 16 ms on localhost (executor driver) (2/2)
17/12/21 15:02:55 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
17/12/21 15:02:55 INFO DAGScheduler: ResultStage 77 (collect at utils.scala:196) finished in 0.016 s
17/12/21 15:02:55 INFO DAGScheduler: Job 35 finished: collect at utils.scala:196, took 0.012458 s
17/12/21 15:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:02:55 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:02:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:02:55 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:02:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:02:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:02:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:02:55 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:02:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:02:55 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:02:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:02:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:02:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:02:55 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:02:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:02:55 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:02:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:02:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:02:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:02:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:02:56 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:02:56 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:02:56 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:02:56 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:02:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:02:56 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:03:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:03:14 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:03:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:03:14 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:03:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:03:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:03:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:03:14 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 15:03:14 INFO DAGScheduler: Got job 36 (collect at utils.scala:58) with 1 output partitions
17/12/21 15:03:14 INFO DAGScheduler: Final stage: ResultStage 78 (collect at utils.scala:58)
17/12/21 15:03:14 INFO DAGScheduler: Parents of final stage: List()
17/12/21 15:03:14 INFO DAGScheduler: Missing parents: List()
17/12/21 15:03:14 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[258] at map at utils.scala:55), which has no missing parents
17/12/21 15:03:14 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 8.7 KB, free 2002.2 MB)
17/12/21 15:03:14 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2002.2 MB)
17/12/21 15:03:14 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:49792 (size: 4.6 KB, free: 2004.3 MB)
17/12/21 15:03:14 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:996
17/12/21 15:03:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[258] at map at utils.scala:55)
17/12/21 15:03:14 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks
17/12/21 15:03:14 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 72, localhost, executor driver, partition 0, PROCESS_LOCAL, 6792 bytes)
17/12/21 15:03:14 INFO Executor: Running task 0.0 in stage 78.0 (TID 72)
17/12/21 15:03:14 INFO Executor: Finished task 0.0 in stage 78.0 (TID 72). 1077 bytes result sent to driver
17/12/21 15:03:14 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 72) in 0 ms on localhost (executor driver) (1/1)
17/12/21 15:03:14 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
17/12/21 15:03:14 INFO DAGScheduler: ResultStage 78 (collect at utils.scala:58) finished in 0.000 s
17/12/21 15:03:14 INFO DAGScheduler: Job 36 finished: collect at utils.scala:58, took 0.006072 s
17/12/21 15:03:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:14 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:03:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:14 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 15:03:14 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 15:03:14 INFO FileSourceStrategy: Pruning directories with: 
17/12/21 15:03:14 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/21 15:03:14 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double, S4: double, S5: double ... 8 more fields>
17/12/21 15:03:14 INFO FileSourceStrategy: Pushed Filters: 
17/12/21 15:03:14 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 293.7 KB, free 2001.9 MB)
17/12/21 15:03:14 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2001.9 MB)
17/12/21 15:03:14 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:49792 (size: 24.0 KB, free: 2004.3 MB)
17/12/21 15:03:14 INFO SparkContext: Created broadcast 61 from sql at <unknown>:0
17/12/21 15:03:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/21 15:03:14 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 15:03:14 INFO DAGScheduler: Registering RDD 262 (sql at <unknown>:0)
17/12/21 15:03:14 INFO DAGScheduler: Registering RDD 267 (sql at <unknown>:0)
17/12/21 15:03:14 INFO DAGScheduler: Got job 37 (sql at <unknown>:0) with 1 output partitions
17/12/21 15:03:14 INFO DAGScheduler: Final stage: ResultStage 81 (sql at <unknown>:0)
17/12/21 15:03:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)
17/12/21 15:03:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 80)
17/12/21 15:03:14 INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[262] at sql at <unknown>:0), which has no missing parents
17/12/21 15:03:14 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 13.1 KB, free 2001.9 MB)
17/12/21 15:03:14 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 7.5 KB, free 2001.8 MB)
17/12/21 15:03:14 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:49792 (size: 7.5 KB, free: 2004.2 MB)
17/12/21 15:03:14 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:996
17/12/21 15:03:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[262] at sql at <unknown>:0)
17/12/21 15:03:14 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
17/12/21 15:03:14 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/21 15:03:14 INFO Executor: Running task 0.0 in stage 79.0 (TID 73)
17/12/21 15:03:14 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmponGyKW/spark_serialize_eb64202ddba87f71926f6159bc690f353322427db234b90a1939486e00a03242.csv, range: 0-3780, partition values: [empty row]
17/12/21 15:03:14 INFO Executor: Finished task 0.0 in stage 79.0 (TID 73). 1632 bytes result sent to driver
17/12/21 15:03:14 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 73) in 26 ms on localhost (executor driver) (1/1)
17/12/21 15:03:14 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
17/12/21 15:03:14 INFO DAGScheduler: ShuffleMapStage 79 (sql at <unknown>:0) finished in 0.026 s
17/12/21 15:03:14 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:03:14 INFO DAGScheduler: running: Set()
17/12/21 15:03:14 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 80)
17/12/21 15:03:14 INFO DAGScheduler: failed: Set()
17/12/21 15:03:14 INFO DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[267] at sql at <unknown>:0), which has no missing parents
17/12/21 15:03:14 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 15.3 KB, free 2001.8 MB)
17/12/21 15:03:14 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2001.8 MB)
17/12/21 15:03:14 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:49792 (size: 6.9 KB, free: 2004.2 MB)
17/12/21 15:03:14 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:996
17/12/21 15:03:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[267] at sql at <unknown>:0)
17/12/21 15:03:14 INFO TaskSchedulerImpl: Adding task set 80.0 with 2 tasks
17/12/21 15:03:14 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 74, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/21 15:03:14 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 75, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/21 15:03:14 INFO Executor: Running task 0.0 in stage 80.0 (TID 74)
17/12/21 15:03:14 INFO Executor: Running task 1.0 in stage 80.0 (TID 75)
17/12/21 15:03:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 15:03:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 15:03:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:03:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/12/21 15:03:14 INFO MemoryStore: Block rdd_264_0 stored as values in memory (estimated size 1912.0 B, free 2001.8 MB)
17/12/21 15:03:14 INFO MemoryStore: Block rdd_264_1 stored as values in memory (estimated size 1912.0 B, free 2001.8 MB)
17/12/21 15:03:14 INFO BlockManagerInfo: Added rdd_264_0 in memory on 127.0.0.1:49792 (size: 1912.0 B, free: 2004.2 MB)
17/12/21 15:03:14 INFO BlockManagerInfo: Added rdd_264_1 in memory on 127.0.0.1:49792 (size: 1912.0 B, free: 2004.2 MB)
17/12/21 15:03:14 INFO Executor: Finished task 1.0 in stage 80.0 (TID 75). 3162 bytes result sent to driver
17/12/21 15:03:14 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 75) in 15 ms on localhost (executor driver) (1/2)
17/12/21 15:03:14 INFO Executor: Finished task 0.0 in stage 80.0 (TID 74). 3162 bytes result sent to driver
17/12/21 15:03:14 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 74) in 31 ms on localhost (executor driver) (2/2)
17/12/21 15:03:14 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
17/12/21 15:03:14 INFO DAGScheduler: ShuffleMapStage 80 (sql at <unknown>:0) finished in 0.031 s
17/12/21 15:03:14 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:03:14 INFO DAGScheduler: running: Set()
17/12/21 15:03:14 INFO DAGScheduler: waiting: Set(ResultStage 81)
17/12/21 15:03:14 INFO DAGScheduler: failed: Set()
17/12/21 15:03:14 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[270] at sql at <unknown>:0), which has no missing parents
17/12/21 15:03:14 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 7.0 KB, free 2001.8 MB)
17/12/21 15:03:14 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.8 MB)
17/12/21 15:03:14 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.2 MB)
17/12/21 15:03:14 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:996
17/12/21 15:03:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[270] at sql at <unknown>:0)
17/12/21 15:03:14 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
17/12/21 15:03:14 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 76, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/21 15:03:14 INFO Executor: Running task 0.0 in stage 81.0 (TID 76)
17/12/21 15:03:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 15:03:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:03:14 INFO Executor: Finished task 0.0 in stage 81.0 (TID 76). 1707 bytes result sent to driver
17/12/21 15:03:14 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 76) in 0 ms on localhost (executor driver) (1/1)
17/12/21 15:03:14 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
17/12/21 15:03:14 INFO DAGScheduler: ResultStage 81 (sql at <unknown>:0) finished in 0.000 s
17/12/21 15:03:14 INFO DAGScheduler: Job 37 finished: sql at <unknown>:0, took 0.057471 s
17/12/21 15:03:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:14 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 15:03:15 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 15:03:15 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 145 bytes
17/12/21 15:03:15 INFO DAGScheduler: Registering RDD 274 (collect at utils.scala:196)
17/12/21 15:03:15 INFO DAGScheduler: Got job 38 (collect at utils.scala:196) with 1 output partitions
17/12/21 15:03:15 INFO DAGScheduler: Final stage: ResultStage 84 (collect at utils.scala:196)
17/12/21 15:03:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)
17/12/21 15:03:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 83)
17/12/21 15:03:15 INFO DAGScheduler: Submitting ShuffleMapStage 83 (MapPartitionsRDD[274] at collect at utils.scala:196), which has no missing parents
17/12/21 15:03:15 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 15.3 KB, free 2001.8 MB)
17/12/21 15:03:15 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2001.8 MB)
17/12/21 15:03:15 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:49792 (size: 6.9 KB, free: 2004.2 MB)
17/12/21 15:03:15 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:996
17/12/21 15:03:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 83 (MapPartitionsRDD[274] at collect at utils.scala:196)
17/12/21 15:03:15 INFO TaskSchedulerImpl: Adding task set 83.0 with 2 tasks
17/12/21 15:03:15 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/21 15:03:15 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 78, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/21 15:03:15 INFO Executor: Running task 0.0 in stage 83.0 (TID 77)
17/12/21 15:03:15 INFO Executor: Running task 1.0 in stage 83.0 (TID 78)
17/12/21 15:03:15 INFO BlockManager: Found block rdd_264_0 locally
17/12/21 15:03:15 INFO BlockManager: Found block rdd_264_1 locally
17/12/21 15:03:15 INFO Executor: Finished task 1.0 in stage 83.0 (TID 78). 1950 bytes result sent to driver
17/12/21 15:03:15 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 78) in 16 ms on localhost (executor driver) (1/2)
17/12/21 15:03:15 INFO Executor: Finished task 0.0 in stage 83.0 (TID 77). 1871 bytes result sent to driver
17/12/21 15:03:15 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 77) in 16 ms on localhost (executor driver) (2/2)
17/12/21 15:03:15 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
17/12/21 15:03:15 INFO DAGScheduler: ShuffleMapStage 83 (collect at utils.scala:196) finished in 0.016 s
17/12/21 15:03:15 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:03:15 INFO DAGScheduler: running: Set()
17/12/21 15:03:15 INFO DAGScheduler: waiting: Set(ResultStage 84)
17/12/21 15:03:15 INFO DAGScheduler: failed: Set()
17/12/21 15:03:15 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[277] at collect at utils.scala:196), which has no missing parents
17/12/21 15:03:15 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 7.0 KB, free 2001.8 MB)
17/12/21 15:03:15 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.8 MB)
17/12/21 15:03:15 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.2 MB)
17/12/21 15:03:15 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:996
17/12/21 15:03:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[277] at collect at utils.scala:196)
17/12/21 15:03:15 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
17/12/21 15:03:15 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 79, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/21 15:03:15 INFO Executor: Running task 0.0 in stage 84.0 (TID 79)
17/12/21 15:03:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 15:03:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:03:15 INFO Executor: Finished task 0.0 in stage 84.0 (TID 79). 1707 bytes result sent to driver
17/12/21 15:03:15 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 79) in 0 ms on localhost (executor driver) (1/1)
17/12/21 15:03:15 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
17/12/21 15:03:15 INFO DAGScheduler: ResultStage 84 (collect at utils.scala:196) finished in 0.000 s
17/12/21 15:03:15 INFO DAGScheduler: Job 38 finished: collect at utils.scala:196, took 0.027594 s
17/12/21 15:03:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz31`
WHERE (0 = 1)
17/12/21 15:03:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:15 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S2` + 0.91651514 * RANDN() AS `V1`, `S9` + 0.89442719 * RANDN() AS `V2`, `S6` + 0.92736185 * RANDN() AS `V3`, `S3` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `sifzayvitd`
17/12/21 15:03:15 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:03:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz32`
WHERE (0 = 1)
17/12/21 15:03:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 15:03:15 INFO CodeGenerator: Code generated in 6.46343 ms
17/12/21 15:03:15 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 15:03:15 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 145 bytes
17/12/21 15:03:15 INFO DAGScheduler: Got job 39 (take at <unknown>:0) with 1 output partitions
17/12/21 15:03:15 INFO DAGScheduler: Final stage: ResultStage 86 (take at <unknown>:0)
17/12/21 15:03:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)
17/12/21 15:03:15 INFO DAGScheduler: Missing parents: List()
17/12/21 15:03:15 INFO DAGScheduler: Submitting ResultStage 86 (WorkerRDD[283] at RDD at rdd.scala:18), which has no missing parents
17/12/21 15:03:15 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 104.9 KB, free 2001.7 MB)
17/12/21 15:03:15 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 41.6 KB, free 2001.6 MB)
17/12/21 15:03:15 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:49792 (size: 41.6 KB, free: 2004.2 MB)
17/12/21 15:03:15 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:996
17/12/21 15:03:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (WorkerRDD[283] at RDD at rdd.scala:18)
17/12/21 15:03:15 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks
17/12/21 15:03:15 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/21 15:03:15 INFO Executor: Running task 0.0 in stage 86.0 (TID 80)
17/12/21 15:03:15 INFO BlockManager: Found block rdd_264_0 locally
17/12/21 15:03:15 INFO MemoryStore: Block rdd_283_0 stored as values in memory (estimated size 1496.0 B, free 2001.6 MB)
17/12/21 15:03:15 INFO BlockManagerInfo: Added rdd_283_0 in memory on 127.0.0.1:49792 (size: 1496.0 B, free: 2004.2 MB)
17/12/21 15:03:15 WARN Executor: 1 block locks were not released by TID = 80:
[rdd_283_0]
17/12/21 15:03:15 INFO Executor: Finished task 0.0 in stage 86.0 (TID 80). 3020 bytes result sent to driver
17/12/21 15:03:15 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 80) in 666 ms on localhost (executor driver) (1/1)
17/12/21 15:03:15 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
17/12/21 15:03:15 INFO DAGScheduler: ResultStage 86 (take at <unknown>:0) finished in 0.666 s
17/12/21 15:03:15 INFO DAGScheduler: Job 39 finished: take at <unknown>:0, took 0.669904 s
17/12/21 15:03:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:15 INFO SparkSqlParser: Parsing command: sparklyr_tmp_17747e3d6878
17/12/21 15:03:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17747e3d6878` AS `zzz33`
WHERE (0 = 1)
17/12/21 15:03:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17747e3d6878`
17/12/21 15:03:15 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:03:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz34`
WHERE (0 = 1)
17/12/21 15:03:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:15 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 4e-04) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0055) AS `V3`, (`V4` < 0.0045) AS `V4`
FROM `analyis_tbl`
17/12/21 15:03:15 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:03:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz35`
WHERE (0 = 1)
17/12/21 15:03:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 15:03:15 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 15:03:15 INFO DAGScheduler: Got job 40 (collect at utils.scala:196) with 2 output partitions
17/12/21 15:03:15 INFO DAGScheduler: Final stage: ResultStage 88 (collect at utils.scala:196)
17/12/21 15:03:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 87)
17/12/21 15:03:15 INFO DAGScheduler: Missing parents: List()
17/12/21 15:03:15 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[290] at collect at utils.scala:196), which has no missing parents
17/12/21 15:03:15 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 112.4 KB, free 2001.5 MB)
17/12/21 15:03:15 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 44.9 KB, free 2001.5 MB)
17/12/21 15:03:15 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:49792 (size: 44.9 KB, free: 2004.1 MB)
17/12/21 15:03:15 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:996
17/12/21 15:03:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 88 (MapPartitionsRDD[290] at collect at utils.scala:196)
17/12/21 15:03:15 INFO TaskSchedulerImpl: Adding task set 88.0 with 2 tasks
17/12/21 15:03:15 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/21 15:03:15 INFO TaskSetManager: Starting task 1.0 in stage 88.0 (TID 82, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/21 15:03:15 INFO Executor: Running task 1.0 in stage 88.0 (TID 82)
17/12/21 15:03:15 INFO Executor: Running task 0.0 in stage 88.0 (TID 81)
17/12/21 15:03:15 INFO BlockManager: Found block rdd_283_0 locally
17/12/21 15:03:15 INFO BlockManager: Found block rdd_264_1 locally
17/12/21 15:03:15 INFO Executor: Finished task 0.0 in stage 88.0 (TID 81). 1440 bytes result sent to driver
17/12/21 15:03:15 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 81) in 0 ms on localhost (executor driver) (1/2)
17/12/21 15:03:16 INFO MemoryStore: Block rdd_283_1 stored as values in memory (estimated size 1496.0 B, free 2001.5 MB)
17/12/21 15:03:16 INFO BlockManagerInfo: Added rdd_283_1 in memory on 127.0.0.1:49792 (size: 1496.0 B, free: 2004.1 MB)
17/12/21 15:03:16 INFO Executor: Finished task 1.0 in stage 88.0 (TID 82). 2257 bytes result sent to driver
17/12/21 15:03:16 INFO TaskSetManager: Finished task 1.0 in stage 88.0 (TID 82) in 702 ms on localhost (executor driver) (2/2)
17/12/21 15:03:16 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
17/12/21 15:03:16 INFO DAGScheduler: ResultStage 88 (collect at utils.scala:196) finished in 0.702 s
17/12/21 15:03:16 INFO DAGScheduler: Job 40 finished: collect at utils.scala:196, took 0.709562 s
17/12/21 15:03:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:03:16 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:03:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:03:16 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:03:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:03:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:03:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:03:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:17 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:03:17 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:03:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:03:17 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:03:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:03:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:03:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:03:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:17 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:03:17 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:03:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:03:17 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:03:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:03:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:03:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:03:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:03:17 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:03:17 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:03:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:03:17 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:03:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:03:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:03:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:49792 in memory (size: 44.9 KB, free: 2004.2 MB)
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 2772
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 2773
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 2774
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 2775
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 2776
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 2777
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 2778
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 2779
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 2780
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 2781
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 2782
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 2783
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 2784
17/12/21 15:03:23 INFO ContextCleaner: Cleaned shuffle 16
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:49792 in memory (size: 7.5 KB, free: 2004.2 MB)
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:49792 in memory (size: 7.0 KB, free: 2004.2 MB)
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 2953
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:49792 in memory (size: 7.0 KB, free: 2004.2 MB)
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:49792 in memory (size: 41.2 KB, free: 2004.2 MB)
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:49792 in memory (size: 41.2 KB, free: 2004.3 MB)
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:49792 in memory (size: 44.4 KB, free: 2004.3 MB)
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3258
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3259
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:49792 in memory (size: 4.6 KB, free: 2004.3 MB)
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3308
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3309
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3315
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3316
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3317
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3318
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3319
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3320
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3321
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3322
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3323
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3324
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3325
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3326
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3327
17/12/21 15:03:23 INFO ContextCleaner: Cleaned shuffle 19
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:49792 in memory (size: 7.5 KB, free: 2004.3 MB)
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:49792 in memory (size: 6.9 KB, free: 2004.3 MB)
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.4 MB)
17/12/21 15:03:23 INFO ContextCleaner: Cleaned accumulator 3496
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:49792 in memory (size: 6.9 KB, free: 2004.4 MB)
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.4 MB)
17/12/21 15:03:23 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:49792 in memory (size: 41.6 KB, free: 2004.4 MB)
17/12/21 15:07:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:07:09 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:07:09 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:07:09 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:07:09 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:07:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:07:09 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:07:09 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 15:07:09 INFO DAGScheduler: Got job 41 (collect at utils.scala:58) with 1 output partitions
17/12/21 15:07:09 INFO DAGScheduler: Final stage: ResultStage 89 (collect at utils.scala:58)
17/12/21 15:07:09 INFO DAGScheduler: Parents of final stage: List()
17/12/21 15:07:09 INFO DAGScheduler: Missing parents: List()
17/12/21 15:07:09 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[300] at map at utils.scala:55), which has no missing parents
17/12/21 15:07:09 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 8.7 KB, free 2002.4 MB)
17/12/21 15:07:09 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2002.4 MB)
17/12/21 15:07:09 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:49792 (size: 4.6 KB, free: 2004.4 MB)
17/12/21 15:07:09 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:996
17/12/21 15:07:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[300] at map at utils.scala:55)
17/12/21 15:07:09 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks
17/12/21 15:07:09 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 6864 bytes)
17/12/21 15:07:09 INFO Executor: Running task 0.0 in stage 89.0 (TID 83)
17/12/21 15:07:09 INFO Executor: Finished task 0.0 in stage 89.0 (TID 83). 1108 bytes result sent to driver
17/12/21 15:07:09 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 83) in 0 ms on localhost (executor driver) (1/1)
17/12/21 15:07:09 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
17/12/21 15:07:09 INFO DAGScheduler: ResultStage 89 (collect at utils.scala:58) finished in 0.000 s
17/12/21 15:07:09 INFO DAGScheduler: Job 41 finished: collect at utils.scala:58, took 0.007576 s
17/12/21 15:07:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:09 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:07:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:09 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 15:07:09 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 15:07:09 WARN CacheManager: Asked to cache already cached data.
17/12/21 15:07:09 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 15:07:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 145 bytes
17/12/21 15:07:09 INFO DAGScheduler: Registering RDD 304 (sql at <unknown>:0)
17/12/21 15:07:09 INFO DAGScheduler: Got job 42 (sql at <unknown>:0) with 1 output partitions
17/12/21 15:07:09 INFO DAGScheduler: Final stage: ResultStage 92 (sql at <unknown>:0)
17/12/21 15:07:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 91)
17/12/21 15:07:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 91)
17/12/21 15:07:09 INFO DAGScheduler: Submitting ShuffleMapStage 91 (MapPartitionsRDD[304] at sql at <unknown>:0), which has no missing parents
17/12/21 15:07:09 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 15.4 KB, free 2002.4 MB)
17/12/21 15:07:09 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2002.4 MB)
17/12/21 15:07:09 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.4 MB)
17/12/21 15:07:09 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:996
17/12/21 15:07:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 91 (MapPartitionsRDD[304] at sql at <unknown>:0)
17/12/21 15:07:09 INFO TaskSchedulerImpl: Adding task set 91.0 with 2 tasks
17/12/21 15:07:09 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 5944 bytes)
17/12/21 15:07:09 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 85, localhost, executor driver, partition 1, PROCESS_LOCAL, 5944 bytes)
17/12/21 15:07:09 INFO Executor: Running task 0.0 in stage 91.0 (TID 84)
17/12/21 15:07:09 INFO Executor: Running task 1.0 in stage 91.0 (TID 85)
17/12/21 15:07:09 INFO BlockManager: Found block rdd_222_0 locally
17/12/21 15:07:09 INFO BlockManager: Found block rdd_222_1 locally
17/12/21 15:07:09 INFO Executor: Finished task 1.0 in stage 91.0 (TID 85). 2037 bytes result sent to driver
17/12/21 15:07:09 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 85) in 6 ms on localhost (executor driver) (1/2)
17/12/21 15:07:09 INFO Executor: Finished task 0.0 in stage 91.0 (TID 84). 2037 bytes result sent to driver
17/12/21 15:07:09 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 84) in 7 ms on localhost (executor driver) (2/2)
17/12/21 15:07:09 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
17/12/21 15:07:09 INFO DAGScheduler: ShuffleMapStage 91 (sql at <unknown>:0) finished in 0.007 s
17/12/21 15:07:09 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:07:09 INFO DAGScheduler: running: Set()
17/12/21 15:07:09 INFO DAGScheduler: waiting: Set(ResultStage 92)
17/12/21 15:07:09 INFO DAGScheduler: failed: Set()
17/12/21 15:07:09 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[307] at sql at <unknown>:0), which has no missing parents
17/12/21 15:07:09 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 7.0 KB, free 2002.4 MB)
17/12/21 15:07:09 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.4 MB)
17/12/21 15:07:09 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.4 MB)
17/12/21 15:07:09 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:996
17/12/21 15:07:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[307] at sql at <unknown>:0)
17/12/21 15:07:09 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
17/12/21 15:07:09 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 86, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/21 15:07:09 INFO Executor: Running task 0.0 in stage 92.0 (TID 86)
17/12/21 15:07:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 15:07:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:07:09 INFO Executor: Finished task 0.0 in stage 92.0 (TID 86). 1707 bytes result sent to driver
17/12/21 15:07:09 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 86) in 0 ms on localhost (executor driver) (1/1)
17/12/21 15:07:09 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
17/12/21 15:07:09 INFO DAGScheduler: ResultStage 92 (sql at <unknown>:0) finished in 0.000 s
17/12/21 15:07:09 INFO DAGScheduler: Job 42 finished: sql at <unknown>:0, took 0.025169 s
17/12/21 15:07:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:09 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 15:07:09 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 15:07:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 145 bytes
17/12/21 15:07:09 INFO DAGScheduler: Registering RDD 311 (collect at utils.scala:196)
17/12/21 15:07:09 INFO DAGScheduler: Got job 43 (collect at utils.scala:196) with 1 output partitions
17/12/21 15:07:09 INFO DAGScheduler: Final stage: ResultStage 95 (collect at utils.scala:196)
17/12/21 15:07:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 94)
17/12/21 15:07:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 94)
17/12/21 15:07:09 INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[311] at collect at utils.scala:196), which has no missing parents
17/12/21 15:07:09 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 15.4 KB, free 2002.3 MB)
17/12/21 15:07:09 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2002.3 MB)
17/12/21 15:07:09 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.4 MB)
17/12/21 15:07:09 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:996
17/12/21 15:07:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[311] at collect at utils.scala:196)
17/12/21 15:07:09 INFO TaskSchedulerImpl: Adding task set 94.0 with 2 tasks
17/12/21 15:07:09 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/21 15:07:09 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 88, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/21 15:07:09 INFO Executor: Running task 1.0 in stage 94.0 (TID 88)
17/12/21 15:07:09 INFO Executor: Running task 0.0 in stage 94.0 (TID 87)
17/12/21 15:07:09 INFO BlockManager: Found block rdd_222_1 locally
17/12/21 15:07:09 INFO BlockManager: Found block rdd_222_0 locally
17/12/21 15:07:09 INFO Executor: Finished task 1.0 in stage 94.0 (TID 88). 1950 bytes result sent to driver
17/12/21 15:07:09 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 88) in 16 ms on localhost (executor driver) (1/2)
17/12/21 15:07:09 INFO Executor: Finished task 0.0 in stage 94.0 (TID 87). 1950 bytes result sent to driver
17/12/21 15:07:09 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 87) in 16 ms on localhost (executor driver) (2/2)
17/12/21 15:07:09 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
17/12/21 15:07:09 INFO DAGScheduler: ShuffleMapStage 94 (collect at utils.scala:196) finished in 0.016 s
17/12/21 15:07:09 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:07:09 INFO DAGScheduler: running: Set()
17/12/21 15:07:09 INFO DAGScheduler: waiting: Set(ResultStage 95)
17/12/21 15:07:09 INFO DAGScheduler: failed: Set()
17/12/21 15:07:09 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[314] at collect at utils.scala:196), which has no missing parents
17/12/21 15:07:09 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 7.0 KB, free 2002.3 MB)
17/12/21 15:07:09 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.3 MB)
17/12/21 15:07:09 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.4 MB)
17/12/21 15:07:09 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:996
17/12/21 15:07:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[314] at collect at utils.scala:196)
17/12/21 15:07:09 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks
17/12/21 15:07:09 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 89, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/21 15:07:09 INFO Executor: Running task 0.0 in stage 95.0 (TID 89)
17/12/21 15:07:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 15:07:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:07:09 INFO Executor: Finished task 0.0 in stage 95.0 (TID 89). 1707 bytes result sent to driver
17/12/21 15:07:09 INFO DAGScheduler: ResultStage 95 (collect at utils.scala:196) finished in 0.016 s
17/12/21 15:07:09 INFO DAGScheduler: Job 43 finished: collect at utils.scala:196, took 0.024660 s
17/12/21 15:07:09 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 89) in 16 ms on localhost (executor driver) (1/1)
17/12/21 15:07:09 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
17/12/21 15:07:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz36`
WHERE (0 = 1)
17/12/21 15:07:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:09 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S2` + 0.91651514 * RANDN() AS `V1`, `S9` + 0.89442719 * RANDN() AS `V2`, `S6` + 0.92736185 * RANDN() AS `V3`, `S3` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `qkxlxaiguh`
17/12/21 15:07:09 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:07:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz37`
WHERE (0 = 1)
17/12/21 15:07:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 15:07:09 INFO CodeGenerator: Code generated in 9.476148 ms
17/12/21 15:07:09 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 15:07:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 145 bytes
17/12/21 15:07:09 INFO DAGScheduler: Got job 44 (take at <unknown>:0) with 1 output partitions
17/12/21 15:07:09 INFO DAGScheduler: Final stage: ResultStage 97 (take at <unknown>:0)
17/12/21 15:07:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 96)
17/12/21 15:07:09 INFO DAGScheduler: Missing parents: List()
17/12/21 15:07:09 INFO DAGScheduler: Submitting ResultStage 97 (WorkerRDD[320] at RDD at rdd.scala:18), which has no missing parents
17/12/21 15:07:09 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 104.2 KB, free 2002.2 MB)
17/12/21 15:07:09 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 41.1 KB, free 2002.2 MB)
17/12/21 15:07:09 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:49792 (size: 41.1 KB, free: 2004.3 MB)
17/12/21 15:07:09 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:996
17/12/21 15:07:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (WorkerRDD[320] at RDD at rdd.scala:18)
17/12/21 15:07:09 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks
17/12/21 15:07:09 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/21 15:07:09 INFO Executor: Running task 0.0 in stage 97.0 (TID 90)
17/12/21 15:07:09 INFO BlockManager: Found block rdd_222_0 locally
17/12/21 15:07:10 INFO MemoryStore: Block rdd_320_0 stored as values in memory (estimated size 760.0 B, free 2002.2 MB)
17/12/21 15:07:10 INFO BlockManagerInfo: Added rdd_320_0 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.3 MB)
17/12/21 15:07:10 INFO Executor: Finished task 0.0 in stage 97.0 (TID 90). 2581 bytes result sent to driver
17/12/21 15:07:10 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 90) in 649 ms on localhost (executor driver) (1/1)
17/12/21 15:07:10 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
17/12/21 15:07:10 INFO DAGScheduler: ResultStage 97 (take at <unknown>:0) finished in 0.649 s
17/12/21 15:07:10 INFO DAGScheduler: Job 44 finished: take at <unknown>:0, took 0.654188 s
17/12/21 15:07:10 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 15:07:10 INFO DAGScheduler: Got job 45 (take at <unknown>:0) with 1 output partitions
17/12/21 15:07:10 INFO DAGScheduler: Final stage: ResultStage 99 (take at <unknown>:0)
17/12/21 15:07:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 98)
17/12/21 15:07:10 INFO DAGScheduler: Missing parents: List()
17/12/21 15:07:10 INFO DAGScheduler: Submitting ResultStage 99 (WorkerRDD[320] at RDD at rdd.scala:18), which has no missing parents
17/12/21 15:07:10 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 104.2 KB, free 2002.1 MB)
17/12/21 15:07:10 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 41.1 KB, free 2002.0 MB)
17/12/21 15:07:10 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:49792 (size: 41.1 KB, free: 2004.3 MB)
17/12/21 15:07:10 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:996
17/12/21 15:07:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (WorkerRDD[320] at RDD at rdd.scala:18)
17/12/21 15:07:10 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks
17/12/21 15:07:10 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 91, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/21 15:07:10 INFO Executor: Running task 0.0 in stage 99.0 (TID 91)
17/12/21 15:07:10 INFO BlockManager: Found block rdd_222_1 locally
17/12/21 15:07:10 INFO MemoryStore: Block rdd_320_1 stored as values in memory (estimated size 760.0 B, free 2002.0 MB)
17/12/21 15:07:10 INFO BlockManagerInfo: Added rdd_320_1 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.3 MB)
17/12/21 15:07:10 WARN Executor: 1 block locks were not released by TID = 91:
[rdd_320_1]
17/12/21 15:07:10 INFO Executor: Finished task 0.0 in stage 99.0 (TID 91). 2668 bytes result sent to driver
17/12/21 15:07:10 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 91) in 719 ms on localhost (executor driver) (1/1)
17/12/21 15:07:10 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
17/12/21 15:07:10 INFO DAGScheduler: ResultStage 99 (take at <unknown>:0) finished in 0.719 s
17/12/21 15:07:10 INFO DAGScheduler: Job 45 finished: take at <unknown>:0, took 0.729679 s
17/12/21 15:07:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:10 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1774187e7816
17/12/21 15:07:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1774187e7816` AS `zzz38`
WHERE (0 = 1)
17/12/21 15:07:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1774187e7816`
17/12/21 15:07:10 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:07:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz39`
WHERE (0 = 1)
17/12/21 15:07:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:10 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 4e-04) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0055) AS `V3`, (`V4` < 0.0045) AS `V4`
FROM `analyis_tbl`
17/12/21 15:07:10 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:07:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz40`
WHERE (0 = 1)
17/12/21 15:07:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 15:07:11 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 15:07:11 INFO DAGScheduler: Got job 46 (collect at utils.scala:196) with 2 output partitions
17/12/21 15:07:11 INFO DAGScheduler: Final stage: ResultStage 101 (collect at utils.scala:196)
17/12/21 15:07:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 100)
17/12/21 15:07:11 INFO DAGScheduler: Missing parents: List()
17/12/21 15:07:11 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[327] at collect at utils.scala:196), which has no missing parents
17/12/21 15:07:11 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 111.7 KB, free 2001.9 MB)
17/12/21 15:07:11 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 44.4 KB, free 2001.9 MB)
17/12/21 15:07:11 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:49792 (size: 44.4 KB, free: 2004.3 MB)
17/12/21 15:07:11 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:996
17/12/21 15:07:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 101 (MapPartitionsRDD[327] at collect at utils.scala:196)
17/12/21 15:07:11 INFO TaskSchedulerImpl: Adding task set 101.0 with 2 tasks
17/12/21 15:07:11 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/21 15:07:11 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 93, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/21 15:07:11 INFO Executor: Running task 0.0 in stage 101.0 (TID 92)
17/12/21 15:07:11 INFO Executor: Running task 1.0 in stage 101.0 (TID 93)
17/12/21 15:07:11 INFO BlockManager: Found block rdd_320_0 locally
17/12/21 15:07:11 INFO BlockManager: Found block rdd_320_1 locally
17/12/21 15:07:11 INFO Executor: Finished task 0.0 in stage 101.0 (TID 92). 1439 bytes result sent to driver
17/12/21 15:07:11 INFO Executor: Finished task 1.0 in stage 101.0 (TID 93). 1439 bytes result sent to driver
17/12/21 15:07:11 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 92) in 15 ms on localhost (executor driver) (1/2)
17/12/21 15:07:11 INFO DAGScheduler: ResultStage 101 (collect at utils.scala:196) finished in 0.015 s
17/12/21 15:07:11 INFO DAGScheduler: Job 46 finished: collect at utils.scala:196, took 0.010258 s
17/12/21 15:07:11 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 93) in 15 ms on localhost (executor driver) (2/2)
17/12/21 15:07:11 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
17/12/21 15:07:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:07:11 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:07:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:07:11 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:07:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:07:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:07:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:07:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:07:11 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:07:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:07:11 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:07:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:07:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:07:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:07:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:07:11 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:07:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:07:11 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:07:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:07:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:07:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:07:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:07:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:07:11 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:07:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:07:11 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:07:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:07:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:07:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:15:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:08 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:15:08 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:15:08 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:15:08 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:15:08 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:15:08 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:15:08 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:15:08 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 15:15:08 INFO DAGScheduler: Got job 47 (collect at utils.scala:58) with 1 output partitions
17/12/21 15:15:08 INFO DAGScheduler: Final stage: ResultStage 102 (collect at utils.scala:58)
17/12/21 15:15:08 INFO DAGScheduler: Parents of final stage: List()
17/12/21 15:15:08 INFO DAGScheduler: Missing parents: List()
17/12/21 15:15:08 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[337] at map at utils.scala:55), which has no missing parents
17/12/21 15:15:08 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 8.7 KB, free 2001.9 MB)
17/12/21 15:15:08 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2001.9 MB)
17/12/21 15:15:08 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:49792 (size: 4.6 KB, free: 2004.2 MB)
17/12/21 15:15:08 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:996
17/12/21 15:15:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[337] at map at utils.scala:55)
17/12/21 15:15:08 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
17/12/21 15:15:08 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 6936 bytes)
17/12/21 15:15:08 INFO Executor: Running task 0.0 in stage 102.0 (TID 94)
17/12/21 15:15:08 INFO Executor: Finished task 0.0 in stage 102.0 (TID 94). 1136 bytes result sent to driver
17/12/21 15:15:08 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 94) in 15 ms on localhost (executor driver) (1/1)
17/12/21 15:15:08 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
17/12/21 15:15:08 INFO DAGScheduler: ResultStage 102 (collect at utils.scala:58) finished in 0.015 s
17/12/21 15:15:08 INFO DAGScheduler: Job 47 finished: collect at utils.scala:58, took 0.007319 s
17/12/21 15:15:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:08 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:15:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:08 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 15:15:08 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 15:15:08 WARN CacheManager: Asked to cache already cached data.
17/12/21 15:15:08 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 15:15:08 INFO DAGScheduler: Registering RDD 341 (sql at <unknown>:0)
17/12/21 15:15:08 INFO DAGScheduler: Got job 48 (sql at <unknown>:0) with 1 output partitions
17/12/21 15:15:08 INFO DAGScheduler: Final stage: ResultStage 105 (sql at <unknown>:0)
17/12/21 15:15:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104)
17/12/21 15:15:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 104)
17/12/21 15:15:08 INFO DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[341] at sql at <unknown>:0), which has no missing parents
17/12/21 15:15:08 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 15.4 KB, free 2001.9 MB)
17/12/21 15:15:08 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2001.8 MB)
17/12/21 15:15:08 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:49792 (size: 6.9 KB, free: 2004.2 MB)
17/12/21 15:15:08 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:996
17/12/21 15:15:08 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[341] at sql at <unknown>:0)
17/12/21 15:15:08 INFO TaskSchedulerImpl: Adding task set 104.0 with 2 tasks
17/12/21 15:15:08 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 95, localhost, executor driver, partition 0, PROCESS_LOCAL, 5944 bytes)
17/12/21 15:15:08 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 96, localhost, executor driver, partition 1, PROCESS_LOCAL, 5944 bytes)
17/12/21 15:15:08 INFO Executor: Running task 0.0 in stage 104.0 (TID 95)
17/12/21 15:15:08 INFO Executor: Running task 1.0 in stage 104.0 (TID 96)
17/12/21 15:15:08 INFO BlockManager: Found block rdd_222_0 locally
17/12/21 15:15:08 INFO BlockManager: Found block rdd_222_1 locally
17/12/21 15:15:08 INFO Executor: Finished task 0.0 in stage 104.0 (TID 95). 1871 bytes result sent to driver
17/12/21 15:15:08 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 95) in 15 ms on localhost (executor driver) (1/2)
17/12/21 15:15:08 INFO Executor: Finished task 1.0 in stage 104.0 (TID 96). 1871 bytes result sent to driver
17/12/21 15:15:08 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 96) in 15 ms on localhost (executor driver) (2/2)
17/12/21 15:15:08 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
17/12/21 15:15:08 INFO DAGScheduler: ShuffleMapStage 104 (sql at <unknown>:0) finished in 0.015 s
17/12/21 15:15:08 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:15:08 INFO DAGScheduler: running: Set()
17/12/21 15:15:08 INFO DAGScheduler: waiting: Set(ResultStage 105)
17/12/21 15:15:08 INFO DAGScheduler: failed: Set()
17/12/21 15:15:08 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[344] at sql at <unknown>:0), which has no missing parents
17/12/21 15:15:08 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 7.0 KB, free 2001.8 MB)
17/12/21 15:15:08 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.8 MB)
17/12/21 15:15:08 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.2 MB)
17/12/21 15:15:08 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:996
17/12/21 15:15:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[344] at sql at <unknown>:0)
17/12/21 15:15:08 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks
17/12/21 15:15:08 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 97, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/21 15:15:08 INFO Executor: Running task 0.0 in stage 105.0 (TID 97)
17/12/21 15:15:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 15:15:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:15:08 INFO Executor: Finished task 0.0 in stage 105.0 (TID 97). 1707 bytes result sent to driver
17/12/21 15:15:08 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 97) in 16 ms on localhost (executor driver) (1/1)
17/12/21 15:15:08 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
17/12/21 15:15:08 INFO DAGScheduler: ResultStage 105 (sql at <unknown>:0) finished in 0.016 s
17/12/21 15:15:08 INFO DAGScheduler: Job 48 finished: sql at <unknown>:0, took 0.025068 s
17/12/21 15:15:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:08 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 15:15:08 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 15:15:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 145 bytes
17/12/21 15:15:08 INFO DAGScheduler: Registering RDD 348 (collect at utils.scala:196)
17/12/21 15:15:08 INFO DAGScheduler: Got job 49 (collect at utils.scala:196) with 1 output partitions
17/12/21 15:15:08 INFO DAGScheduler: Final stage: ResultStage 108 (collect at utils.scala:196)
17/12/21 15:15:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 107)
17/12/21 15:15:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 107)
17/12/21 15:15:08 INFO DAGScheduler: Submitting ShuffleMapStage 107 (MapPartitionsRDD[348] at collect at utils.scala:196), which has no missing parents
17/12/21 15:15:08 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 15.4 KB, free 2001.8 MB)
17/12/21 15:15:08 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2001.8 MB)
17/12/21 15:15:08 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:49792 (size: 6.9 KB, free: 2004.2 MB)
17/12/21 15:15:08 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:996
17/12/21 15:15:08 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 107 (MapPartitionsRDD[348] at collect at utils.scala:196)
17/12/21 15:15:08 INFO TaskSchedulerImpl: Adding task set 107.0 with 2 tasks
17/12/21 15:15:08 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/21 15:15:08 INFO TaskSetManager: Starting task 1.0 in stage 107.0 (TID 99, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/21 15:15:08 INFO Executor: Running task 0.0 in stage 107.0 (TID 98)
17/12/21 15:15:08 INFO Executor: Running task 1.0 in stage 107.0 (TID 99)
17/12/21 15:15:08 INFO BlockManager: Found block rdd_222_0 locally
17/12/21 15:15:08 INFO BlockManager: Found block rdd_222_1 locally
17/12/21 15:15:08 INFO Executor: Finished task 0.0 in stage 107.0 (TID 98). 1950 bytes result sent to driver
17/12/21 15:15:08 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 98) in 16 ms on localhost (executor driver) (1/2)
17/12/21 15:15:08 INFO Executor: Finished task 1.0 in stage 107.0 (TID 99). 1871 bytes result sent to driver
17/12/21 15:15:08 INFO TaskSetManager: Finished task 1.0 in stage 107.0 (TID 99) in 16 ms on localhost (executor driver) (2/2)
17/12/21 15:15:08 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
17/12/21 15:15:08 INFO DAGScheduler: ShuffleMapStage 107 (collect at utils.scala:196) finished in 0.016 s
17/12/21 15:15:08 INFO DAGScheduler: looking for newly runnable stages
17/12/21 15:15:08 INFO DAGScheduler: running: Set()
17/12/21 15:15:08 INFO DAGScheduler: waiting: Set(ResultStage 108)
17/12/21 15:15:08 INFO DAGScheduler: failed: Set()
17/12/21 15:15:08 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[351] at collect at utils.scala:196), which has no missing parents
17/12/21 15:15:08 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 7.0 KB, free 2001.8 MB)
17/12/21 15:15:08 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.8 MB)
17/12/21 15:15:08 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.2 MB)
17/12/21 15:15:08 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:996
17/12/21 15:15:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[351] at collect at utils.scala:196)
17/12/21 15:15:08 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks
17/12/21 15:15:08 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 100, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/21 15:15:08 INFO Executor: Running task 0.0 in stage 108.0 (TID 100)
17/12/21 15:15:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 15:15:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 15:15:08 INFO Executor: Finished task 0.0 in stage 108.0 (TID 100). 1707 bytes result sent to driver
17/12/21 15:15:08 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 100) in 0 ms on localhost (executor driver) (1/1)
17/12/21 15:15:08 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
17/12/21 15:15:08 INFO DAGScheduler: ResultStage 108 (collect at utils.scala:196) finished in 0.000 s
17/12/21 15:15:08 INFO DAGScheduler: Job 49 finished: collect at utils.scala:196, took 0.021932 s
17/12/21 15:15:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz41`
WHERE (0 = 1)
17/12/21 15:15:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:08 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S2` + 0.91651514 * RANDN() AS `V1`, `S9` + 0.89442719 * RANDN() AS `V2`, `S6` + 0.92736185 * RANDN() AS `V3`, `S3` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `qkxlxaiguh`
17/12/21 15:15:08 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:15:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz42`
WHERE (0 = 1)
17/12/21 15:15:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 15:15:08 INFO CodeGenerator: Code generated in 7.221235 ms
17/12/21 15:15:08 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 15:15:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 145 bytes
17/12/21 15:15:08 INFO DAGScheduler: Got job 50 (take at <unknown>:0) with 1 output partitions
17/12/21 15:15:08 INFO DAGScheduler: Final stage: ResultStage 110 (take at <unknown>:0)
17/12/21 15:15:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 109)
17/12/21 15:15:08 INFO DAGScheduler: Missing parents: List()
17/12/21 15:15:08 INFO DAGScheduler: Submitting ResultStage 110 (WorkerRDD[357] at RDD at rdd.scala:18), which has no missing parents
17/12/21 15:15:08 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 104.2 KB, free 2001.7 MB)
17/12/21 15:15:08 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 41.2 KB, free 2001.7 MB)
17/12/21 15:15:08 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:49792 (size: 41.2 KB, free: 2004.2 MB)
17/12/21 15:15:08 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:996
17/12/21 15:15:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (WorkerRDD[357] at RDD at rdd.scala:18)
17/12/21 15:15:08 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks
17/12/21 15:15:08 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/21 15:15:08 INFO Executor: Running task 0.0 in stage 110.0 (TID 101)
17/12/21 15:15:08 INFO BlockManager: Found block rdd_222_0 locally
17/12/21 15:15:09 INFO MemoryStore: Block rdd_357_0 stored as values in memory (estimated size 760.0 B, free 2001.7 MB)
17/12/21 15:15:09 INFO BlockManagerInfo: Added rdd_357_0 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.2 MB)
17/12/21 15:15:09 INFO Executor: Finished task 0.0 in stage 110.0 (TID 101). 2581 bytes result sent to driver
17/12/21 15:15:09 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 101) in 621 ms on localhost (executor driver) (1/1)
17/12/21 15:15:09 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
17/12/21 15:15:09 INFO DAGScheduler: ResultStage 110 (take at <unknown>:0) finished in 0.621 s
17/12/21 15:15:09 INFO DAGScheduler: Job 50 finished: take at <unknown>:0, took 0.616945 s
17/12/21 15:15:09 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 15:15:09 INFO DAGScheduler: Got job 51 (take at <unknown>:0) with 1 output partitions
17/12/21 15:15:09 INFO DAGScheduler: Final stage: ResultStage 112 (take at <unknown>:0)
17/12/21 15:15:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 111)
17/12/21 15:15:09 INFO DAGScheduler: Missing parents: List()
17/12/21 15:15:09 INFO DAGScheduler: Submitting ResultStage 112 (WorkerRDD[357] at RDD at rdd.scala:18), which has no missing parents
17/12/21 15:15:09 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 104.2 KB, free 2001.6 MB)
17/12/21 15:15:09 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 41.2 KB, free 2001.5 MB)
17/12/21 15:15:09 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:49792 (size: 41.2 KB, free: 2004.1 MB)
17/12/21 15:15:09 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:996
17/12/21 15:15:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (WorkerRDD[357] at RDD at rdd.scala:18)
17/12/21 15:15:09 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks
17/12/21 15:15:09 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 102, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/21 15:15:09 INFO Executor: Running task 0.0 in stage 112.0 (TID 102)
17/12/21 15:15:09 INFO BlockManager: Found block rdd_222_1 locally
17/12/21 15:15:09 INFO MemoryStore: Block rdd_357_1 stored as values in memory (estimated size 760.0 B, free 2001.5 MB)
17/12/21 15:15:09 INFO BlockManagerInfo: Added rdd_357_1 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.1 MB)
17/12/21 15:15:09 WARN Executor: 1 block locks were not released by TID = 102:
[rdd_357_1]
17/12/21 15:15:09 INFO Executor: Finished task 0.0 in stage 112.0 (TID 102). 2668 bytes result sent to driver
17/12/21 15:15:09 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 102) in 631 ms on localhost (executor driver) (1/1)
17/12/21 15:15:09 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
17/12/21 15:15:09 INFO DAGScheduler: ResultStage 112 (take at <unknown>:0) finished in 0.633 s
17/12/21 15:15:09 INFO DAGScheduler: Job 51 finished: take at <unknown>:0, took 0.636467 s
17/12/21 15:15:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:09 INFO SparkSqlParser: Parsing command: sparklyr_tmp_17745ec1f1a
17/12/21 15:15:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17745ec1f1a` AS `zzz43`
WHERE (0 = 1)
17/12/21 15:15:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17745ec1f1a`
17/12/21 15:15:09 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:15:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz44`
WHERE (0 = 1)
17/12/21 15:15:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:09 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 4e-04) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0055) AS `V3`, (`V4` < 0.0045) AS `V4`
FROM `analyis_tbl`
17/12/21 15:15:09 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 15:15:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz45`
WHERE (0 = 1)
17/12/21 15:15:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3753
17/12/21 15:15:09 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3754
17/12/21 15:15:09 INFO DAGScheduler: Got job 52 (collect at utils.scala:196) with 2 output partitions
17/12/21 15:15:09 INFO DAGScheduler: Final stage: ResultStage 114 (collect at utils.scala:196)
17/12/21 15:15:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 113)
17/12/21 15:15:09 INFO DAGScheduler: Missing parents: List()
17/12/21 15:15:09 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[364] at collect at utils.scala:196), which has no missing parents
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:49792 in memory (size: 4.6 KB, free: 2004.2 MB)
17/12/21 15:15:09 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 111.7 KB, free 2001.4 MB)
17/12/21 15:15:09 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 44.5 KB, free 2001.4 MB)
17/12/21 15:15:09 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:49792 (size: 44.5 KB, free: 2004.1 MB)
17/12/21 15:15:09 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:996
17/12/21 15:15:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 114 (MapPartitionsRDD[364] at collect at utils.scala:196)
17/12/21 15:15:09 INFO TaskSchedulerImpl: Adding task set 114.0 with 2 tasks
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3803
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3804
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3805
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3806
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3807
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3808
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3809
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3810
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3811
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3812
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3813
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3814
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3815
17/12/21 15:15:09 INFO ContextCleaner: Cleaned shuffle 21
17/12/21 15:15:09 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/21 15:15:09 INFO TaskSetManager: Starting task 1.0 in stage 114.0 (TID 104, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/21 15:15:09 INFO Executor: Running task 0.0 in stage 114.0 (TID 103)
17/12/21 15:15:09 INFO BlockManager: Found block rdd_357_0 locally
17/12/21 15:15:09 INFO Executor: Running task 1.0 in stage 114.0 (TID 104)
17/12/21 15:15:09 INFO Executor: Finished task 0.0 in stage 114.0 (TID 103). 1454 bytes result sent to driver
17/12/21 15:15:09 INFO BlockManager: Found block rdd_357_1 locally
17/12/21 15:15:09 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 103) in 0 ms on localhost (executor driver) (1/2)
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:49792 in memory (size: 7.0 KB, free: 2004.1 MB)
17/12/21 15:15:09 INFO Executor: Finished task 1.0 in stage 114.0 (TID 104). 1454 bytes result sent to driver
17/12/21 15:15:09 INFO TaskSetManager: Finished task 1.0 in stage 114.0 (TID 104) in 0 ms on localhost (executor driver) (2/2)
17/12/21 15:15:09 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
17/12/21 15:15:09 INFO DAGScheduler: ResultStage 114 (collect at utils.scala:196) finished in 0.000 s
17/12/21 15:15:09 INFO DAGScheduler: Job 52 finished: collect at utils.scala:196, took 0.015921 s
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.1 MB)
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 3936
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:49792 in memory (size: 7.0 KB, free: 2004.1 MB)
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.1 MB)
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:49792 in memory (size: 41.1 KB, free: 2004.2 MB)
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:49792 in memory (size: 41.1 KB, free: 2004.2 MB)
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:49792 in memory (size: 44.4 KB, free: 2004.3 MB)
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4241
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4242
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:49792 in memory (size: 4.6 KB, free: 2004.3 MB)
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4291
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4292
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4293
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4294
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4295
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4296
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4297
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4298
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4299
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4300
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4301
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4302
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4303
17/12/21 15:15:09 INFO ContextCleaner: Cleaned shuffle 23
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:49792 in memory (size: 6.9 KB, free: 2004.3 MB)
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/21 15:15:09 INFO ContextCleaner: Cleaned accumulator 4424
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:49792 in memory (size: 6.9 KB, free: 2004.3 MB)
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:49792 in memory (size: 41.2 KB, free: 2004.3 MB)
17/12/21 15:15:09 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:49792 in memory (size: 41.2 KB, free: 2004.4 MB)
17/12/21 15:15:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:15:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:15:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:15:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:15:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:15:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:15:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:15:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:15:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:15:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:15:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:15:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:15:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:15:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:15:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:15:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:15:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:15:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:15:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:15:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:15:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:15:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 15:15:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 15:15:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:15:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:15:10 INFO HiveMetaStore: 0: get_database: default
17/12/21 15:15:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 15:15:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 15:15:10 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 15:57:17 WARN NettyRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@14bb0135,BlockManagerId(driver, 127.0.0.1, 49792, None))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 14 more
17/12/21 15:57:30 WARN NettyRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@14bb0135,BlockManagerId(driver, 127.0.0.1, 49792, None))] in 2 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 14 more
17/12/21 15:57:39 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
17/12/21 15:57:39 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
17/12/21 15:58:39 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:49792 in memory (size: 44.5 KB, free: 2004.4 MB)
17/12/21 16:12:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:12:23 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:12:23 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:12:23 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:12:23 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:12:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:12:23 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:12:23 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 16:12:23 INFO DAGScheduler: Got job 53 (collect at utils.scala:58) with 1 output partitions
17/12/21 16:12:23 INFO DAGScheduler: Final stage: ResultStage 115 (collect at utils.scala:58)
17/12/21 16:12:23 INFO DAGScheduler: Parents of final stage: List()
17/12/21 16:12:23 INFO DAGScheduler: Missing parents: List()
17/12/21 16:12:23 INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[374] at map at utils.scala:55), which has no missing parents
17/12/21 16:12:23 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 8.7 KB, free 2002.4 MB)
17/12/21 16:12:23 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2002.4 MB)
17/12/21 16:12:23 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:49792 (size: 4.6 KB, free: 2004.4 MB)
17/12/21 16:12:23 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:996
17/12/21 16:12:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[374] at map at utils.scala:55)
17/12/21 16:12:23 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks
17/12/21 16:12:23 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 7007 bytes)
17/12/21 16:12:23 INFO Executor: Running task 0.0 in stage 115.0 (TID 105)
17/12/21 16:12:23 INFO Executor: Finished task 0.0 in stage 115.0 (TID 105). 1163 bytes result sent to driver
17/12/21 16:12:23 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 105) in 0 ms on localhost (executor driver) (1/1)
17/12/21 16:12:23 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
17/12/21 16:12:23 INFO DAGScheduler: ResultStage 115 (collect at utils.scala:58) finished in 0.000 s
17/12/21 16:12:23 INFO DAGScheduler: Job 53 finished: collect at utils.scala:58, took 0.009399 s
17/12/21 16:12:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:23 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:12:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:23 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 16:12:23 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 16:12:23 WARN CacheManager: Asked to cache already cached data.
17/12/21 16:12:23 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 16:12:23 INFO DAGScheduler: Registering RDD 378 (sql at <unknown>:0)
17/12/21 16:12:23 INFO DAGScheduler: Got job 54 (sql at <unknown>:0) with 1 output partitions
17/12/21 16:12:23 INFO DAGScheduler: Final stage: ResultStage 118 (sql at <unknown>:0)
17/12/21 16:12:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 117)
17/12/21 16:12:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 117)
17/12/21 16:12:23 INFO DAGScheduler: Submitting ShuffleMapStage 117 (MapPartitionsRDD[378] at sql at <unknown>:0), which has no missing parents
17/12/21 16:12:23 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 15.4 KB, free 2002.4 MB)
17/12/21 16:12:23 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2002.4 MB)
17/12/21 16:12:23 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.4 MB)
17/12/21 16:12:23 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:996
17/12/21 16:12:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 117 (MapPartitionsRDD[378] at sql at <unknown>:0)
17/12/21 16:12:23 INFO TaskSchedulerImpl: Adding task set 117.0 with 2 tasks
17/12/21 16:12:23 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 5944 bytes)
17/12/21 16:12:23 INFO TaskSetManager: Starting task 1.0 in stage 117.0 (TID 107, localhost, executor driver, partition 1, PROCESS_LOCAL, 5944 bytes)
17/12/21 16:12:23 INFO Executor: Running task 0.0 in stage 117.0 (TID 106)
17/12/21 16:12:23 INFO Executor: Running task 1.0 in stage 117.0 (TID 107)
17/12/21 16:12:23 INFO BlockManager: Found block rdd_222_0 locally
17/12/21 16:12:23 INFO BlockManager: Found block rdd_222_1 locally
17/12/21 16:12:23 INFO Executor: Finished task 1.0 in stage 117.0 (TID 107). 1792 bytes result sent to driver
17/12/21 16:12:23 INFO TaskSetManager: Finished task 1.0 in stage 117.0 (TID 107) in 0 ms on localhost (executor driver) (1/2)
17/12/21 16:12:23 INFO Executor: Finished task 0.0 in stage 117.0 (TID 106). 1950 bytes result sent to driver
17/12/21 16:12:23 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 106) in 15 ms on localhost (executor driver) (2/2)
17/12/21 16:12:23 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
17/12/21 16:12:23 INFO DAGScheduler: ShuffleMapStage 117 (sql at <unknown>:0) finished in 0.015 s
17/12/21 16:12:23 INFO DAGScheduler: looking for newly runnable stages
17/12/21 16:12:23 INFO DAGScheduler: running: Set()
17/12/21 16:12:23 INFO DAGScheduler: waiting: Set(ResultStage 118)
17/12/21 16:12:23 INFO DAGScheduler: failed: Set()
17/12/21 16:12:23 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[381] at sql at <unknown>:0), which has no missing parents
17/12/21 16:12:23 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 7.0 KB, free 2002.4 MB)
17/12/21 16:12:23 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.3 MB)
17/12/21 16:12:23 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.4 MB)
17/12/21 16:12:23 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:996
17/12/21 16:12:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[381] at sql at <unknown>:0)
17/12/21 16:12:23 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks
17/12/21 16:12:23 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 108, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/21 16:12:23 INFO Executor: Running task 0.0 in stage 118.0 (TID 108)
17/12/21 16:12:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 16:12:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 16:12:23 INFO Executor: Finished task 0.0 in stage 118.0 (TID 108). 1707 bytes result sent to driver
17/12/21 16:12:23 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 108) in 0 ms on localhost (executor driver) (1/1)
17/12/21 16:12:23 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
17/12/21 16:12:23 INFO DAGScheduler: ResultStage 118 (sql at <unknown>:0) finished in 0.000 s
17/12/21 16:12:23 INFO DAGScheduler: Job 54 finished: sql at <unknown>:0, took 0.026400 s
17/12/21 16:12:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:23 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 16:12:23 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 16:12:23 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 145 bytes
17/12/21 16:12:23 INFO DAGScheduler: Registering RDD 385 (collect at utils.scala:196)
17/12/21 16:12:23 INFO DAGScheduler: Got job 55 (collect at utils.scala:196) with 1 output partitions
17/12/21 16:12:23 INFO DAGScheduler: Final stage: ResultStage 121 (collect at utils.scala:196)
17/12/21 16:12:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 120)
17/12/21 16:12:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 120)
17/12/21 16:12:23 INFO DAGScheduler: Submitting ShuffleMapStage 120 (MapPartitionsRDD[385] at collect at utils.scala:196), which has no missing parents
17/12/21 16:12:23 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 15.4 KB, free 2002.3 MB)
17/12/21 16:12:23 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2002.3 MB)
17/12/21 16:12:23 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.4 MB)
17/12/21 16:12:23 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:996
17/12/21 16:12:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 120 (MapPartitionsRDD[385] at collect at utils.scala:196)
17/12/21 16:12:23 INFO TaskSchedulerImpl: Adding task set 120.0 with 2 tasks
17/12/21 16:12:23 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/21 16:12:23 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 110, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/21 16:12:23 INFO Executor: Running task 1.0 in stage 120.0 (TID 110)
17/12/21 16:12:23 INFO Executor: Running task 0.0 in stage 120.0 (TID 109)
17/12/21 16:12:23 INFO BlockManager: Found block rdd_222_1 locally
17/12/21 16:12:23 INFO BlockManager: Found block rdd_222_0 locally
17/12/21 16:12:23 INFO Executor: Finished task 0.0 in stage 120.0 (TID 109). 1871 bytes result sent to driver
17/12/21 16:12:23 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 109) in 16 ms on localhost (executor driver) (1/2)
17/12/21 16:12:23 INFO Executor: Finished task 1.0 in stage 120.0 (TID 110). 1871 bytes result sent to driver
17/12/21 16:12:23 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 110) in 16 ms on localhost (executor driver) (2/2)
17/12/21 16:12:23 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
17/12/21 16:12:23 INFO DAGScheduler: ShuffleMapStage 120 (collect at utils.scala:196) finished in 0.016 s
17/12/21 16:12:23 INFO DAGScheduler: looking for newly runnable stages
17/12/21 16:12:23 INFO DAGScheduler: running: Set()
17/12/21 16:12:23 INFO DAGScheduler: waiting: Set(ResultStage 121)
17/12/21 16:12:23 INFO DAGScheduler: failed: Set()
17/12/21 16:12:23 INFO DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[388] at collect at utils.scala:196), which has no missing parents
17/12/21 16:12:23 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 7.0 KB, free 2002.3 MB)
17/12/21 16:12:23 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.3 MB)
17/12/21 16:12:23 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.4 MB)
17/12/21 16:12:23 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:996
17/12/21 16:12:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[388] at collect at utils.scala:196)
17/12/21 16:12:23 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks
17/12/21 16:12:23 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 111, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/21 16:12:23 INFO Executor: Running task 0.0 in stage 121.0 (TID 111)
17/12/21 16:12:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 16:12:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 16:12:23 INFO Executor: Finished task 0.0 in stage 121.0 (TID 111). 1707 bytes result sent to driver
17/12/21 16:12:23 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 111) in 0 ms on localhost (executor driver) (1/1)
17/12/21 16:12:23 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
17/12/21 16:12:23 INFO DAGScheduler: ResultStage 121 (collect at utils.scala:196) finished in 0.000 s
17/12/21 16:12:23 INFO DAGScheduler: Job 55 finished: collect at utils.scala:196, took 0.019986 s
17/12/21 16:12:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz46`
WHERE (0 = 1)
17/12/21 16:12:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:23 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S2` + 0.91651514 * RANDN() AS `V1`, `S9` + 0.89442719 * RANDN() AS `V2`, `S6` + 0.92736185 * RANDN() AS `V3`, `S3` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `qkxlxaiguh`
17/12/21 16:12:23 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:12:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz47`
WHERE (0 = 1)
17/12/21 16:12:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 16:12:23 INFO CodeGenerator: Code generated in 10.831664 ms
17/12/21 16:12:23 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 16:12:23 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 145 bytes
17/12/21 16:12:23 INFO DAGScheduler: Got job 56 (take at <unknown>:0) with 1 output partitions
17/12/21 16:12:23 INFO DAGScheduler: Final stage: ResultStage 123 (take at <unknown>:0)
17/12/21 16:12:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 122)
17/12/21 16:12:23 INFO DAGScheduler: Missing parents: List()
17/12/21 16:12:23 INFO DAGScheduler: Submitting ResultStage 123 (WorkerRDD[394] at RDD at rdd.scala:18), which has no missing parents
17/12/21 16:12:23 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 104.2 KB, free 2002.2 MB)
17/12/21 16:12:23 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 41.1 KB, free 2002.2 MB)
17/12/21 16:12:23 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:49792 (size: 41.1 KB, free: 2004.3 MB)
17/12/21 16:12:23 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:996
17/12/21 16:12:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 123 (WorkerRDD[394] at RDD at rdd.scala:18)
17/12/21 16:12:23 INFO TaskSchedulerImpl: Adding task set 123.0 with 1 tasks
17/12/21 16:12:23 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 112, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/21 16:12:23 INFO Executor: Running task 0.0 in stage 123.0 (TID 112)
17/12/21 16:12:23 INFO BlockManager: Found block rdd_222_0 locally
17/12/21 16:12:24 INFO MemoryStore: Block rdd_394_0 stored as values in memory (estimated size 760.0 B, free 2002.2 MB)
17/12/21 16:12:24 INFO BlockManagerInfo: Added rdd_394_0 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.3 MB)
17/12/21 16:12:24 INFO Executor: Finished task 0.0 in stage 123.0 (TID 112). 2581 bytes result sent to driver
17/12/21 16:12:24 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 112) in 766 ms on localhost (executor driver) (1/1)
17/12/21 16:12:24 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
17/12/21 16:12:24 INFO DAGScheduler: ResultStage 123 (take at <unknown>:0) finished in 0.766 s
17/12/21 16:12:24 INFO DAGScheduler: Job 56 finished: take at <unknown>:0, took 0.772872 s
17/12/21 16:12:24 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 16:12:24 INFO DAGScheduler: Got job 57 (take at <unknown>:0) with 1 output partitions
17/12/21 16:12:24 INFO DAGScheduler: Final stage: ResultStage 125 (take at <unknown>:0)
17/12/21 16:12:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)
17/12/21 16:12:24 INFO DAGScheduler: Missing parents: List()
17/12/21 16:12:24 INFO DAGScheduler: Submitting ResultStage 125 (WorkerRDD[394] at RDD at rdd.scala:18), which has no missing parents
17/12/21 16:12:24 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 104.2 KB, free 2002.1 MB)
17/12/21 16:12:24 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 41.1 KB, free 2002.0 MB)
17/12/21 16:12:24 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:49792 (size: 41.1 KB, free: 2004.3 MB)
17/12/21 16:12:24 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:996
17/12/21 16:12:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 125 (WorkerRDD[394] at RDD at rdd.scala:18)
17/12/21 16:12:24 INFO TaskSchedulerImpl: Adding task set 125.0 with 1 tasks
17/12/21 16:12:24 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 113, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/21 16:12:24 INFO Executor: Running task 0.0 in stage 125.0 (TID 113)
17/12/21 16:12:24 INFO BlockManager: Found block rdd_222_1 locally
17/12/21 16:12:24 INFO MemoryStore: Block rdd_394_1 stored as values in memory (estimated size 760.0 B, free 2002.0 MB)
17/12/21 16:12:24 INFO BlockManagerInfo: Added rdd_394_1 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.3 MB)
17/12/21 16:12:24 WARN Executor: 1 block locks were not released by TID = 113:
[rdd_394_1]
17/12/21 16:12:24 INFO Executor: Finished task 0.0 in stage 125.0 (TID 113). 2581 bytes result sent to driver
17/12/21 16:12:24 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 113) in 632 ms on localhost (executor driver) (1/1)
17/12/21 16:12:24 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
17/12/21 16:12:24 INFO DAGScheduler: ResultStage 125 (take at <unknown>:0) finished in 0.632 s
17/12/21 16:12:24 INFO DAGScheduler: Job 57 finished: take at <unknown>:0, took 0.640290 s
17/12/21 16:12:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:25 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1774753648d
17/12/21 16:12:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1774753648d` AS `zzz48`
WHERE (0 = 1)
17/12/21 16:12:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1774753648d`
17/12/21 16:12:25 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:12:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz49`
WHERE (0 = 1)
17/12/21 16:12:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:25 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 4e-04) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0055) AS `V3`, (`V4` < 0.0045) AS `V4`
FROM `analyis_tbl`
17/12/21 16:12:25 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:12:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz50`
WHERE (0 = 1)
17/12/21 16:12:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 16:12:25 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 16:12:25 INFO DAGScheduler: Got job 58 (collect at utils.scala:196) with 2 output partitions
17/12/21 16:12:25 INFO DAGScheduler: Final stage: ResultStage 127 (collect at utils.scala:196)
17/12/21 16:12:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 126)
17/12/21 16:12:25 INFO DAGScheduler: Missing parents: List()
17/12/21 16:12:25 INFO DAGScheduler: Submitting ResultStage 127 (MapPartitionsRDD[401] at collect at utils.scala:196), which has no missing parents
17/12/21 16:12:25 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 111.7 KB, free 2001.9 MB)
17/12/21 16:12:25 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 44.4 KB, free 2001.9 MB)
17/12/21 16:12:25 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:49792 (size: 44.4 KB, free: 2004.3 MB)
17/12/21 16:12:25 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:996
17/12/21 16:12:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 127 (MapPartitionsRDD[401] at collect at utils.scala:196)
17/12/21 16:12:25 INFO TaskSchedulerImpl: Adding task set 127.0 with 2 tasks
17/12/21 16:12:25 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 114, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/21 16:12:25 INFO TaskSetManager: Starting task 1.0 in stage 127.0 (TID 115, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/21 16:12:25 INFO Executor: Running task 1.0 in stage 127.0 (TID 115)
17/12/21 16:12:25 INFO Executor: Running task 0.0 in stage 127.0 (TID 114)
17/12/21 16:12:25 INFO BlockManager: Found block rdd_394_0 locally
17/12/21 16:12:25 INFO BlockManager: Found block rdd_394_1 locally
17/12/21 16:12:25 INFO Executor: Finished task 1.0 in stage 127.0 (TID 115). 1454 bytes result sent to driver
17/12/21 16:12:25 INFO Executor: Finished task 0.0 in stage 127.0 (TID 114). 1439 bytes result sent to driver
17/12/21 16:12:25 INFO TaskSetManager: Finished task 1.0 in stage 127.0 (TID 115) in 0 ms on localhost (executor driver) (1/2)
17/12/21 16:12:25 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 114) in 0 ms on localhost (executor driver) (2/2)
17/12/21 16:12:25 INFO DAGScheduler: ResultStage 127 (collect at utils.scala:196) finished in 0.000 s
17/12/21 16:12:25 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
17/12/21 16:12:25 INFO DAGScheduler: Job 58 finished: collect at utils.scala:196, took 0.010650 s
17/12/21 16:12:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:25 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:12:25 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:12:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:12:25 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:12:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:12:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:12:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:12:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:25 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:12:25 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:12:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:12:25 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:12:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:12:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:12:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:12:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:25 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:12:25 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:12:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:12:25 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:12:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:12:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:12:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:12:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:12:25 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:12:25 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:12:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:12:25 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:12:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:12:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:12:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:14:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:14:00 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:00 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:00 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:00 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:14:00 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:14:00 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 16:14:00 INFO DAGScheduler: Got job 59 (collect at utils.scala:58) with 1 output partitions
17/12/21 16:14:00 INFO DAGScheduler: Final stage: ResultStage 128 (collect at utils.scala:58)
17/12/21 16:14:00 INFO DAGScheduler: Parents of final stage: List()
17/12/21 16:14:00 INFO DAGScheduler: Missing parents: List()
17/12/21 16:14:00 INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[411] at map at utils.scala:55), which has no missing parents
17/12/21 16:14:00 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 8.7 KB, free 2001.9 MB)
17/12/21 16:14:00 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2001.9 MB)
17/12/21 16:14:00 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:49792 (size: 4.6 KB, free: 2004.2 MB)
17/12/21 16:14:00 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 128 (MapPartitionsRDD[411] at map at utils.scala:55)
17/12/21 16:14:00 INFO TaskSchedulerImpl: Adding task set 128.0 with 1 tasks
17/12/21 16:14:00 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 7078 bytes)
17/12/21 16:14:00 INFO Executor: Running task 0.0 in stage 128.0 (TID 116)
17/12/21 16:14:00 INFO Executor: Finished task 0.0 in stage 128.0 (TID 116). 1190 bytes result sent to driver
17/12/21 16:14:00 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 116) in 0 ms on localhost (executor driver) (1/1)
17/12/21 16:14:00 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
17/12/21 16:14:00 INFO DAGScheduler: ResultStage 128 (collect at utils.scala:58) finished in 0.000 s
17/12/21 16:14:00 INFO DAGScheduler: Job 59 finished: collect at utils.scala:58, took 0.008629 s
17/12/21 16:14:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:00 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:14:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:00 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 16:14:00 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 16:14:00 WARN CacheManager: Asked to cache already cached data.
17/12/21 16:14:00 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 16:14:00 INFO DAGScheduler: Registering RDD 415 (sql at <unknown>:0)
17/12/21 16:14:00 INFO DAGScheduler: Got job 60 (sql at <unknown>:0) with 1 output partitions
17/12/21 16:14:00 INFO DAGScheduler: Final stage: ResultStage 131 (sql at <unknown>:0)
17/12/21 16:14:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 130)
17/12/21 16:14:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 130)
17/12/21 16:14:00 INFO DAGScheduler: Submitting ShuffleMapStage 130 (MapPartitionsRDD[415] at sql at <unknown>:0), which has no missing parents
17/12/21 16:14:00 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 15.4 KB, free 2001.8 MB)
17/12/21 16:14:00 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2001.8 MB)
17/12/21 16:14:00 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:49792 (size: 6.9 KB, free: 2004.2 MB)
17/12/21 16:14:00 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 130 (MapPartitionsRDD[415] at sql at <unknown>:0)
17/12/21 16:14:00 INFO TaskSchedulerImpl: Adding task set 130.0 with 2 tasks
17/12/21 16:14:00 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 5944 bytes)
17/12/21 16:14:00 INFO TaskSetManager: Starting task 1.0 in stage 130.0 (TID 118, localhost, executor driver, partition 1, PROCESS_LOCAL, 5944 bytes)
17/12/21 16:14:00 INFO Executor: Running task 0.0 in stage 130.0 (TID 117)
17/12/21 16:14:00 INFO Executor: Running task 1.0 in stage 130.0 (TID 118)
17/12/21 16:14:00 INFO BlockManager: Found block rdd_222_1 locally
17/12/21 16:14:00 INFO BlockManager: Found block rdd_222_0 locally
17/12/21 16:14:00 INFO Executor: Finished task 1.0 in stage 130.0 (TID 118). 1950 bytes result sent to driver
17/12/21 16:14:00 INFO TaskSetManager: Finished task 1.0 in stage 130.0 (TID 118) in 16 ms on localhost (executor driver) (1/2)
17/12/21 16:14:00 INFO Executor: Finished task 0.0 in stage 130.0 (TID 117). 1950 bytes result sent to driver
17/12/21 16:14:00 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 117) in 16 ms on localhost (executor driver) (2/2)
17/12/21 16:14:00 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
17/12/21 16:14:00 INFO DAGScheduler: ShuffleMapStage 130 (sql at <unknown>:0) finished in 0.016 s
17/12/21 16:14:00 INFO DAGScheduler: looking for newly runnable stages
17/12/21 16:14:00 INFO DAGScheduler: running: Set()
17/12/21 16:14:00 INFO DAGScheduler: waiting: Set(ResultStage 131)
17/12/21 16:14:00 INFO DAGScheduler: failed: Set()
17/12/21 16:14:00 INFO DAGScheduler: Submitting ResultStage 131 (MapPartitionsRDD[418] at sql at <unknown>:0), which has no missing parents
17/12/21 16:14:00 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 7.0 KB, free 2001.8 MB)
17/12/21 16:14:00 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.8 MB)
17/12/21 16:14:00 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.2 MB)
17/12/21 16:14:00 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 131 (MapPartitionsRDD[418] at sql at <unknown>:0)
17/12/21 16:14:00 INFO TaskSchedulerImpl: Adding task set 131.0 with 1 tasks
17/12/21 16:14:00 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 119, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/21 16:14:00 INFO Executor: Running task 0.0 in stage 131.0 (TID 119)
17/12/21 16:14:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 16:14:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 16:14:00 INFO Executor: Finished task 0.0 in stage 131.0 (TID 119). 1707 bytes result sent to driver
17/12/21 16:14:00 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 119) in 0 ms on localhost (executor driver) (1/1)
17/12/21 16:14:00 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
17/12/21 16:14:00 INFO DAGScheduler: ResultStage 131 (sql at <unknown>:0) finished in 0.000 s
17/12/21 16:14:00 INFO DAGScheduler: Job 60 finished: sql at <unknown>:0, took 0.030158 s
17/12/21 16:14:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:00 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 16:14:00 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 16:14:00 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 145 bytes
17/12/21 16:14:00 INFO DAGScheduler: Registering RDD 422 (collect at utils.scala:196)
17/12/21 16:14:00 INFO DAGScheduler: Got job 61 (collect at utils.scala:196) with 1 output partitions
17/12/21 16:14:00 INFO DAGScheduler: Final stage: ResultStage 134 (collect at utils.scala:196)
17/12/21 16:14:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 133)
17/12/21 16:14:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 133)
17/12/21 16:14:00 INFO DAGScheduler: Submitting ShuffleMapStage 133 (MapPartitionsRDD[422] at collect at utils.scala:196), which has no missing parents
17/12/21 16:14:00 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 15.4 KB, free 2001.8 MB)
17/12/21 16:14:00 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2001.8 MB)
17/12/21 16:14:00 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:49792 (size: 6.9 KB, free: 2004.2 MB)
17/12/21 16:14:00 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 133 (MapPartitionsRDD[422] at collect at utils.scala:196)
17/12/21 16:14:00 INFO TaskSchedulerImpl: Adding task set 133.0 with 2 tasks
17/12/21 16:14:00 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 120, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/21 16:14:00 INFO TaskSetManager: Starting task 1.0 in stage 133.0 (TID 121, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/21 16:14:00 INFO Executor: Running task 0.0 in stage 133.0 (TID 120)
17/12/21 16:14:00 INFO Executor: Running task 1.0 in stage 133.0 (TID 121)
17/12/21 16:14:00 INFO BlockManager: Found block rdd_222_0 locally
17/12/21 16:14:00 INFO BlockManager: Found block rdd_222_1 locally
17/12/21 16:14:00 INFO Executor: Finished task 1.0 in stage 133.0 (TID 121). 1950 bytes result sent to driver
17/12/21 16:14:00 INFO TaskSetManager: Finished task 1.0 in stage 133.0 (TID 121) in 16 ms on localhost (executor driver) (1/2)
17/12/21 16:14:00 INFO Executor: Finished task 0.0 in stage 133.0 (TID 120). 1871 bytes result sent to driver
17/12/21 16:14:00 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 120) in 16 ms on localhost (executor driver) (2/2)
17/12/21 16:14:00 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
17/12/21 16:14:00 INFO DAGScheduler: ShuffleMapStage 133 (collect at utils.scala:196) finished in 0.016 s
17/12/21 16:14:00 INFO DAGScheduler: looking for newly runnable stages
17/12/21 16:14:00 INFO DAGScheduler: running: Set()
17/12/21 16:14:00 INFO DAGScheduler: waiting: Set(ResultStage 134)
17/12/21 16:14:00 INFO DAGScheduler: failed: Set()
17/12/21 16:14:00 INFO DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[425] at collect at utils.scala:196), which has no missing parents
17/12/21 16:14:00 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 7.0 KB, free 2001.8 MB)
17/12/21 16:14:00 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.8 MB)
17/12/21 16:14:00 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.2 MB)
17/12/21 16:14:00 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[425] at collect at utils.scala:196)
17/12/21 16:14:00 INFO TaskSchedulerImpl: Adding task set 134.0 with 1 tasks
17/12/21 16:14:00 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 122, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/21 16:14:00 INFO Executor: Running task 0.0 in stage 134.0 (TID 122)
17/12/21 16:14:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 16:14:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 16:14:00 INFO Executor: Finished task 0.0 in stage 134.0 (TID 122). 1707 bytes result sent to driver
17/12/21 16:14:00 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 122) in 0 ms on localhost (executor driver) (1/1)
17/12/21 16:14:00 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
17/12/21 16:14:00 INFO DAGScheduler: ResultStage 134 (collect at utils.scala:196) finished in 0.000 s
17/12/21 16:14:00 INFO DAGScheduler: Job 61 finished: collect at utils.scala:196, took 0.056221 s
17/12/21 16:14:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz51`
WHERE (0 = 1)
17/12/21 16:14:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:00 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S2` + 0.91651514 * RANDN() AS `V1`, `S9` + 0.89442719 * RANDN() AS `V2`, `S6` + 0.92736185 * RANDN() AS `V3`, `S3` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `qkxlxaiguh`
17/12/21 16:14:00 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:14:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz52`
WHERE (0 = 1)
17/12/21 16:14:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 16:14:00 INFO CodeGenerator: Code generated in 6.847052 ms
17/12/21 16:14:00 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 16:14:00 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 145 bytes
17/12/21 16:14:00 INFO DAGScheduler: Got job 62 (take at <unknown>:0) with 1 output partitions
17/12/21 16:14:00 INFO DAGScheduler: Final stage: ResultStage 136 (take at <unknown>:0)
17/12/21 16:14:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 135)
17/12/21 16:14:00 INFO DAGScheduler: Missing parents: List()
17/12/21 16:14:00 INFO DAGScheduler: Submitting ResultStage 136 (WorkerRDD[431] at RDD at rdd.scala:18), which has no missing parents
17/12/21 16:14:00 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 104.2 KB, free 2001.7 MB)
17/12/21 16:14:00 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 41.1 KB, free 2001.7 MB)
17/12/21 16:14:00 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:49792 (size: 41.1 KB, free: 2004.2 MB)
17/12/21 16:14:00 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (WorkerRDD[431] at RDD at rdd.scala:18)
17/12/21 16:14:00 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks
17/12/21 16:14:00 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 123, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/21 16:14:00 INFO Executor: Running task 0.0 in stage 136.0 (TID 123)
17/12/21 16:14:00 INFO BlockManager: Found block rdd_222_0 locally
17/12/21 16:14:01 INFO MemoryStore: Block rdd_431_0 stored as values in memory (estimated size 760.0 B, free 2001.7 MB)
17/12/21 16:14:01 INFO BlockManagerInfo: Added rdd_431_0 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.2 MB)
17/12/21 16:14:01 INFO Executor: Finished task 0.0 in stage 136.0 (TID 123). 2581 bytes result sent to driver
17/12/21 16:14:01 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 123) in 708 ms on localhost (executor driver) (1/1)
17/12/21 16:14:01 INFO DAGScheduler: ResultStage 136 (take at <unknown>:0) finished in 0.709 s
17/12/21 16:14:01 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
17/12/21 16:14:01 INFO DAGScheduler: Job 62 finished: take at <unknown>:0, took 0.707536 s
17/12/21 16:14:01 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 16:14:01 INFO DAGScheduler: Got job 63 (take at <unknown>:0) with 1 output partitions
17/12/21 16:14:01 INFO DAGScheduler: Final stage: ResultStage 138 (take at <unknown>:0)
17/12/21 16:14:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 137)
17/12/21 16:14:01 INFO DAGScheduler: Missing parents: List()
17/12/21 16:14:01 INFO DAGScheduler: Submitting ResultStage 138 (WorkerRDD[431] at RDD at rdd.scala:18), which has no missing parents
17/12/21 16:14:01 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 104.2 KB, free 2001.6 MB)
17/12/21 16:14:01 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 41.1 KB, free 2001.5 MB)
17/12/21 16:14:01 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:49792 (size: 41.1 KB, free: 2004.1 MB)
17/12/21 16:14:01 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 138 (WorkerRDD[431] at RDD at rdd.scala:18)
17/12/21 16:14:01 INFO TaskSchedulerImpl: Adding task set 138.0 with 1 tasks
17/12/21 16:14:01 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 124, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/21 16:14:01 INFO Executor: Running task 0.0 in stage 138.0 (TID 124)
17/12/21 16:14:01 INFO BlockManager: Found block rdd_222_1 locally
17/12/21 16:14:02 INFO MemoryStore: Block rdd_431_1 stored as values in memory (estimated size 760.0 B, free 2001.5 MB)
17/12/21 16:14:02 INFO BlockManagerInfo: Added rdd_431_1 in memory on 127.0.0.1:49792 (size: 760.0 B, free: 2004.1 MB)
17/12/21 16:14:02 WARN Executor: 1 block locks were not released by TID = 124:
[rdd_431_1]
17/12/21 16:14:02 INFO Executor: Finished task 0.0 in stage 138.0 (TID 124). 2668 bytes result sent to driver
17/12/21 16:14:02 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 124) in 735 ms on localhost (executor driver) (1/1)
17/12/21 16:14:02 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
17/12/21 16:14:02 INFO DAGScheduler: ResultStage 138 (take at <unknown>:0) finished in 0.735 s
17/12/21 16:14:02 INFO DAGScheduler: Job 63 finished: take at <unknown>:0, took 0.745126 s
17/12/21 16:14:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:02 INFO SparkSqlParser: Parsing command: sparklyr_tmp_177460f0b33
17/12/21 16:14:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_177460f0b33` AS `zzz53`
WHERE (0 = 1)
17/12/21 16:14:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_177460f0b33`
17/12/21 16:14:02 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:14:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz54`
WHERE (0 = 1)
17/12/21 16:14:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:02 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 4e-04) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0055) AS `V3`, (`V4` < 0.0045) AS `V4`
FROM `analyis_tbl`
17/12/21 16:14:02 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:14:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz55`
WHERE (0 = 1)
17/12/21 16:14:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5271
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:49792 in memory (size: 41.1 KB, free: 2004.2 MB)
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4729
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4730
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:49792 in memory (size: 4.6 KB, free: 2004.2 MB)
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4779
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4780
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4781
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4782
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4783
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4784
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4785
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4786
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4787
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4788
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4789
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4790
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4791
17/12/21 16:14:02 INFO ContextCleaner: Cleaned shuffle 25
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:49792 in memory (size: 7.0 KB, free: 2004.2 MB)
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 4912
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:49792 in memory (size: 7.0 KB, free: 2004.2 MB)
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:49792 in memory (size: 41.1 KB, free: 2004.2 MB)
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:49792 in memory (size: 41.1 KB, free: 2004.3 MB)
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:49792 in memory (size: 44.4 KB, free: 2004.3 MB)
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5217
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5218
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:49792 in memory (size: 4.6 KB, free: 2004.3 MB)
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5267
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5268
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5269
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5270
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5272
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5273
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5274
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5275
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5276
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5277
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5278
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5279
17/12/21 16:14:02 INFO ContextCleaner: Cleaned shuffle 27
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:49792 in memory (size: 6.9 KB, free: 2004.3 MB)
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/21 16:14:02 INFO ContextCleaner: Cleaned accumulator 5400
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:49792 in memory (size: 6.9 KB, free: 2004.4 MB)
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.4 MB)
17/12/21 16:14:02 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 16:14:02 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:49792 in memory (size: 41.1 KB, free: 2004.4 MB)
17/12/21 16:14:02 INFO DAGScheduler: Got job 64 (collect at utils.scala:196) with 2 output partitions
17/12/21 16:14:02 INFO DAGScheduler: Final stage: ResultStage 140 (collect at utils.scala:196)
17/12/21 16:14:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 139)
17/12/21 16:14:02 INFO DAGScheduler: Missing parents: List()
17/12/21 16:14:02 INFO DAGScheduler: Submitting ResultStage 140 (MapPartitionsRDD[438] at collect at utils.scala:196), which has no missing parents
17/12/21 16:14:02 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 111.7 KB, free 2002.3 MB)
17/12/21 16:14:02 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 44.5 KB, free 2002.2 MB)
17/12/21 16:14:02 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:49792 (size: 44.5 KB, free: 2004.4 MB)
17/12/21 16:14:02 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 140 (MapPartitionsRDD[438] at collect at utils.scala:196)
17/12/21 16:14:02 INFO TaskSchedulerImpl: Adding task set 140.0 with 2 tasks
17/12/21 16:14:02 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 125, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/21 16:14:02 INFO TaskSetManager: Starting task 1.0 in stage 140.0 (TID 126, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/21 16:14:02 INFO Executor: Running task 0.0 in stage 140.0 (TID 125)
17/12/21 16:14:02 INFO Executor: Running task 1.0 in stage 140.0 (TID 126)
17/12/21 16:14:02 INFO BlockManager: Found block rdd_431_0 locally
17/12/21 16:14:02 INFO BlockManager: Found block rdd_431_1 locally
17/12/21 16:14:02 INFO Executor: Finished task 1.0 in stage 140.0 (TID 126). 1439 bytes result sent to driver
17/12/21 16:14:02 INFO Executor: Finished task 0.0 in stage 140.0 (TID 125). 1439 bytes result sent to driver
17/12/21 16:14:02 INFO TaskSetManager: Finished task 1.0 in stage 140.0 (TID 126) in 0 ms on localhost (executor driver) (1/2)
17/12/21 16:14:02 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 125) in 2 ms on localhost (executor driver) (2/2)
17/12/21 16:14:02 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
17/12/21 16:14:02 INFO DAGScheduler: ResultStage 140 (collect at utils.scala:196) finished in 0.002 s
17/12/21 16:14:02 INFO DAGScheduler: Job 64 finished: collect at utils.scala:196, took 0.012462 s
17/12/21 16:14:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:14:03 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:03 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:14:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:14:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:14:03 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:03 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:14:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:14:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:14:03 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:03 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:14:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:14:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:14:03 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:03 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:14:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:14:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:49 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:14:49 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:49 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:49 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:14:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:14:49 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 16:14:49 INFO DAGScheduler: Got job 65 (collect at utils.scala:58) with 1 output partitions
17/12/21 16:14:49 INFO DAGScheduler: Final stage: ResultStage 141 (collect at utils.scala:58)
17/12/21 16:14:49 INFO DAGScheduler: Parents of final stage: List()
17/12/21 16:14:49 INFO DAGScheduler: Missing parents: List()
17/12/21 16:14:49 INFO DAGScheduler: Submitting ResultStage 141 (MapPartitionsRDD[448] at map at utils.scala:55), which has no missing parents
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 8.7 KB, free 2002.2 MB)
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2002.2 MB)
17/12/21 16:14:49 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:49792 (size: 4.6 KB, free: 2004.3 MB)
17/12/21 16:14:49 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 141 (MapPartitionsRDD[448] at map at utils.scala:55)
17/12/21 16:14:49 INFO TaskSchedulerImpl: Adding task set 141.0 with 1 tasks
17/12/21 16:14:49 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 127, localhost, executor driver, partition 0, PROCESS_LOCAL, 7149 bytes)
17/12/21 16:14:49 INFO Executor: Running task 0.0 in stage 141.0 (TID 127)
17/12/21 16:14:49 INFO Executor: Finished task 0.0 in stage 141.0 (TID 127). 1217 bytes result sent to driver
17/12/21 16:14:49 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 127) in 0 ms on localhost (executor driver) (1/1)
17/12/21 16:14:49 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool 
17/12/21 16:14:49 INFO DAGScheduler: ResultStage 141 (collect at utils.scala:58) finished in 0.000 s
17/12/21 16:14:49 INFO DAGScheduler: Job 65 finished: collect at utils.scala:58, took 0.007404 s
17/12/21 16:14:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:49 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:14:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:49 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 16:14:49 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 16:14:49 INFO FileSourceStrategy: Pruning directories with: 
17/12/21 16:14:49 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/21 16:14:49 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double, S4: double, S5: double ... 8 more fields>
17/12/21 16:14:49 INFO FileSourceStrategy: Pushed Filters: 
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 293.7 KB, free 2001.9 MB)
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2001.9 MB)
17/12/21 16:14:49 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:49792 (size: 24.0 KB, free: 2004.3 MB)
17/12/21 16:14:49 INFO SparkContext: Created broadcast 102 from sql at <unknown>:0
17/12/21 16:14:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/21 16:14:49 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 16:14:49 INFO DAGScheduler: Registering RDD 452 (sql at <unknown>:0)
17/12/21 16:14:49 INFO DAGScheduler: Registering RDD 457 (sql at <unknown>:0)
17/12/21 16:14:49 INFO DAGScheduler: Got job 66 (sql at <unknown>:0) with 1 output partitions
17/12/21 16:14:49 INFO DAGScheduler: Final stage: ResultStage 144 (sql at <unknown>:0)
17/12/21 16:14:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 143)
17/12/21 16:14:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 143)
17/12/21 16:14:49 INFO DAGScheduler: Submitting ShuffleMapStage 142 (MapPartitionsRDD[452] at sql at <unknown>:0), which has no missing parents
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 13.1 KB, free 2001.9 MB)
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 7.5 KB, free 2001.9 MB)
17/12/21 16:14:49 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:49792 (size: 7.5 KB, free: 2004.3 MB)
17/12/21 16:14:49 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 142 (MapPartitionsRDD[452] at sql at <unknown>:0)
17/12/21 16:14:49 INFO TaskSchedulerImpl: Adding task set 142.0 with 1 tasks
17/12/21 16:14:49 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 128, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/21 16:14:49 INFO Executor: Running task 0.0 in stage 142.0 (TID 128)
17/12/21 16:14:49 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmponGyKW/spark_serialize_35795e4173ded5c0b599ddd6d104b596d88065142be55e339fc2bd137b669278.csv, range: 0-7506, partition values: [empty row]
17/12/21 16:14:49 INFO Executor: Finished task 0.0 in stage 142.0 (TID 128). 1632 bytes result sent to driver
17/12/21 16:14:49 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 128) in 98 ms on localhost (executor driver) (1/1)
17/12/21 16:14:49 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool 
17/12/21 16:14:49 INFO DAGScheduler: ShuffleMapStage 142 (sql at <unknown>:0) finished in 0.099 s
17/12/21 16:14:49 INFO DAGScheduler: looking for newly runnable stages
17/12/21 16:14:49 INFO DAGScheduler: running: Set()
17/12/21 16:14:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 143, ResultStage 144)
17/12/21 16:14:49 INFO DAGScheduler: failed: Set()
17/12/21 16:14:49 INFO DAGScheduler: Submitting ShuffleMapStage 143 (MapPartitionsRDD[457] at sql at <unknown>:0), which has no missing parents
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 15.3 KB, free 2001.9 MB)
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2001.9 MB)
17/12/21 16:14:49 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.3 MB)
17/12/21 16:14:49 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 143 (MapPartitionsRDD[457] at sql at <unknown>:0)
17/12/21 16:14:49 INFO TaskSchedulerImpl: Adding task set 143.0 with 2 tasks
17/12/21 16:14:49 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 129, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/21 16:14:49 INFO TaskSetManager: Starting task 1.0 in stage 143.0 (TID 130, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/21 16:14:49 INFO Executor: Running task 0.0 in stage 143.0 (TID 129)
17/12/21 16:14:49 INFO Executor: Running task 1.0 in stage 143.0 (TID 130)
17/12/21 16:14:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 16:14:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 16:14:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 16:14:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 16:14:49 INFO MemoryStore: Block rdd_454_0 stored as values in memory (estimated size 2.9 KB, free 2001.9 MB)
17/12/21 16:14:49 INFO MemoryStore: Block rdd_454_1 stored as values in memory (estimated size 2.9 KB, free 2001.9 MB)
17/12/21 16:14:49 INFO BlockManagerInfo: Added rdd_454_0 in memory on 127.0.0.1:49792 (size: 2.9 KB, free: 2004.3 MB)
17/12/21 16:14:49 INFO BlockManagerInfo: Added rdd_454_1 in memory on 127.0.0.1:49792 (size: 2.9 KB, free: 2004.3 MB)
17/12/21 16:14:49 INFO Executor: Finished task 0.0 in stage 143.0 (TID 129). 3064 bytes result sent to driver
17/12/21 16:14:49 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 129) in 16 ms on localhost (executor driver) (1/2)
17/12/21 16:14:49 INFO Executor: Finished task 1.0 in stage 143.0 (TID 130). 3064 bytes result sent to driver
17/12/21 16:14:49 INFO TaskSetManager: Finished task 1.0 in stage 143.0 (TID 130) in 16 ms on localhost (executor driver) (2/2)
17/12/21 16:14:49 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
17/12/21 16:14:49 INFO DAGScheduler: ShuffleMapStage 143 (sql at <unknown>:0) finished in 0.016 s
17/12/21 16:14:49 INFO DAGScheduler: looking for newly runnable stages
17/12/21 16:14:49 INFO DAGScheduler: running: Set()
17/12/21 16:14:49 INFO DAGScheduler: waiting: Set(ResultStage 144)
17/12/21 16:14:49 INFO DAGScheduler: failed: Set()
17/12/21 16:14:49 INFO DAGScheduler: Submitting ResultStage 144 (MapPartitionsRDD[460] at sql at <unknown>:0), which has no missing parents
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 7.0 KB, free 2001.9 MB)
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.9 MB)
17/12/21 16:14:49 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.3 MB)
17/12/21 16:14:49 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[460] at sql at <unknown>:0)
17/12/21 16:14:49 INFO TaskSchedulerImpl: Adding task set 144.0 with 1 tasks
17/12/21 16:14:49 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 131, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/21 16:14:49 INFO Executor: Running task 0.0 in stage 144.0 (TID 131)
17/12/21 16:14:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 16:14:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 16:14:49 INFO Executor: Finished task 0.0 in stage 144.0 (TID 131). 1707 bytes result sent to driver
17/12/21 16:14:49 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 131) in 0 ms on localhost (executor driver) (1/1)
17/12/21 16:14:49 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool 
17/12/21 16:14:49 INFO DAGScheduler: ResultStage 144 (sql at <unknown>:0) finished in 0.000 s
17/12/21 16:14:49 INFO DAGScheduler: Job 66 finished: sql at <unknown>:0, took 0.114214 s
17/12/21 16:14:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:49 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 16:14:49 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 16:14:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 29 is 145 bytes
17/12/21 16:14:49 INFO DAGScheduler: Registering RDD 464 (collect at utils.scala:196)
17/12/21 16:14:49 INFO DAGScheduler: Got job 67 (collect at utils.scala:196) with 1 output partitions
17/12/21 16:14:49 INFO DAGScheduler: Final stage: ResultStage 147 (collect at utils.scala:196)
17/12/21 16:14:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 146)
17/12/21 16:14:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 146)
17/12/21 16:14:49 INFO DAGScheduler: Submitting ShuffleMapStage 146 (MapPartitionsRDD[464] at collect at utils.scala:196), which has no missing parents
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 15.3 KB, free 2001.8 MB)
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2001.8 MB)
17/12/21 16:14:49 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.3 MB)
17/12/21 16:14:49 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 146 (MapPartitionsRDD[464] at collect at utils.scala:196)
17/12/21 16:14:49 INFO TaskSchedulerImpl: Adding task set 146.0 with 2 tasks
17/12/21 16:14:49 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 132, localhost, executor driver, partition 0, PROCESS_LOCAL, 5937 bytes)
17/12/21 16:14:49 INFO TaskSetManager: Starting task 1.0 in stage 146.0 (TID 133, localhost, executor driver, partition 1, PROCESS_LOCAL, 5937 bytes)
17/12/21 16:14:49 INFO Executor: Running task 0.0 in stage 146.0 (TID 132)
17/12/21 16:14:49 INFO Executor: Running task 1.0 in stage 146.0 (TID 133)
17/12/21 16:14:49 INFO BlockManager: Found block rdd_454_1 locally
17/12/21 16:14:49 INFO BlockManager: Found block rdd_454_0 locally
17/12/21 16:14:49 INFO Executor: Finished task 1.0 in stage 146.0 (TID 133). 1792 bytes result sent to driver
17/12/21 16:14:49 INFO TaskSetManager: Finished task 1.0 in stage 146.0 (TID 133) in 0 ms on localhost (executor driver) (1/2)
17/12/21 16:14:49 INFO Executor: Finished task 0.0 in stage 146.0 (TID 132). 1792 bytes result sent to driver
17/12/21 16:14:49 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 132) in 0 ms on localhost (executor driver) (2/2)
17/12/21 16:14:49 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
17/12/21 16:14:49 INFO DAGScheduler: ShuffleMapStage 146 (collect at utils.scala:196) finished in 0.000 s
17/12/21 16:14:49 INFO DAGScheduler: looking for newly runnable stages
17/12/21 16:14:49 INFO DAGScheduler: running: Set()
17/12/21 16:14:49 INFO DAGScheduler: waiting: Set(ResultStage 147)
17/12/21 16:14:49 INFO DAGScheduler: failed: Set()
17/12/21 16:14:49 INFO DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[467] at collect at utils.scala:196), which has no missing parents
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 7.0 KB, free 2001.8 MB)
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.8 MB)
17/12/21 16:14:49 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.3 MB)
17/12/21 16:14:49 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[467] at collect at utils.scala:196)
17/12/21 16:14:49 INFO TaskSchedulerImpl: Adding task set 147.0 with 1 tasks
17/12/21 16:14:49 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 134, localhost, executor driver, partition 0, ANY, 5948 bytes)
17/12/21 16:14:49 INFO Executor: Running task 0.0 in stage 147.0 (TID 134)
17/12/21 16:14:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 16:14:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 16:14:49 INFO Executor: Finished task 0.0 in stage 147.0 (TID 134). 1707 bytes result sent to driver
17/12/21 16:14:49 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 134) in 0 ms on localhost (executor driver) (1/1)
17/12/21 16:14:49 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
17/12/21 16:14:49 INFO DAGScheduler: ResultStage 147 (collect at utils.scala:196) finished in 0.000 s
17/12/21 16:14:49 INFO DAGScheduler: Job 67 finished: collect at utils.scala:196, took 0.021942 s
17/12/21 16:14:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz56`
WHERE (0 = 1)
17/12/21 16:14:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:49 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S2` + 0.91651514 * RANDN() AS `V1`, `S9` + 0.89442719 * RANDN() AS `V2`, `S6` + 0.92736185 * RANDN() AS `V3`, `S3` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `qisfbzuwnt`
17/12/21 16:14:49 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:14:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz57`
WHERE (0 = 1)
17/12/21 16:14:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 16:14:49 INFO CodeGenerator: Code generated in 7.98206 ms
17/12/21 16:14:49 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 16:14:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 29 is 145 bytes
17/12/21 16:14:49 INFO DAGScheduler: Got job 68 (take at <unknown>:0) with 1 output partitions
17/12/21 16:14:49 INFO DAGScheduler: Final stage: ResultStage 149 (take at <unknown>:0)
17/12/21 16:14:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 148)
17/12/21 16:14:49 INFO DAGScheduler: Missing parents: List()
17/12/21 16:14:49 INFO DAGScheduler: Submitting ResultStage 149 (WorkerRDD[473] at RDD at rdd.scala:18), which has no missing parents
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 106.4 KB, free 2001.7 MB)
17/12/21 16:14:49 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 42.6 KB, free 2001.7 MB)
17/12/21 16:14:49 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:49792 (size: 42.6 KB, free: 2004.3 MB)
17/12/21 16:14:49 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 149 (WorkerRDD[473] at RDD at rdd.scala:18)
17/12/21 16:14:49 INFO TaskSchedulerImpl: Adding task set 149.0 with 1 tasks
17/12/21 16:14:49 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 135, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/21 16:14:49 INFO Executor: Running task 0.0 in stage 149.0 (TID 135)
17/12/21 16:14:49 INFO BlockManager: Found block rdd_454_0 locally
17/12/21 16:14:50 INFO MemoryStore: Block rdd_473_0 stored as values in memory (estimated size 2.9 KB, free 2001.7 MB)
17/12/21 16:14:50 INFO BlockManagerInfo: Added rdd_473_0 in memory on 127.0.0.1:49792 (size: 2.9 KB, free: 2004.2 MB)
17/12/21 16:14:50 WARN Executor: 1 block locks were not released by TID = 135:
[rdd_473_0]
17/12/21 16:14:50 INFO Executor: Finished task 0.0 in stage 149.0 (TID 135). 3028 bytes result sent to driver
17/12/21 16:14:50 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 135) in 671 ms on localhost (executor driver) (1/1)
17/12/21 16:14:50 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
17/12/21 16:14:50 INFO DAGScheduler: ResultStage 149 (take at <unknown>:0) finished in 0.672 s
17/12/21 16:14:50 INFO DAGScheduler: Job 68 finished: take at <unknown>:0, took 0.682923 s
17/12/21 16:14:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:50 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1774665d9cf
17/12/21 16:14:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1774665d9cf` AS `zzz58`
WHERE (0 = 1)
17/12/21 16:14:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1774665d9cf`
17/12/21 16:14:50 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:14:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz59`
WHERE (0 = 1)
17/12/21 16:14:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:50 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 4e-04) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0055) AS `V3`, (`V4` < 0.0045) AS `V4`
FROM `analyis_tbl`
17/12/21 16:14:50 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:14:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz60`
WHERE (0 = 1)
17/12/21 16:14:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 16:14:50 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 16:14:50 INFO DAGScheduler: Got job 69 (collect at utils.scala:196) with 2 output partitions
17/12/21 16:14:50 INFO DAGScheduler: Final stage: ResultStage 151 (collect at utils.scala:196)
17/12/21 16:14:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 150)
17/12/21 16:14:50 INFO DAGScheduler: Missing parents: List()
17/12/21 16:14:50 INFO DAGScheduler: Submitting ResultStage 151 (MapPartitionsRDD[480] at collect at utils.scala:196), which has no missing parents
17/12/21 16:14:50 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 113.9 KB, free 2001.6 MB)
17/12/21 16:14:50 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 46.0 KB, free 2001.5 MB)
17/12/21 16:14:50 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:49792 (size: 46.0 KB, free: 2004.2 MB)
17/12/21 16:14:50 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:996
17/12/21 16:14:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 151 (MapPartitionsRDD[480] at collect at utils.scala:196)
17/12/21 16:14:50 INFO TaskSchedulerImpl: Adding task set 151.0 with 2 tasks
17/12/21 16:14:50 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 136, localhost, executor driver, partition 0, PROCESS_LOCAL, 5948 bytes)
17/12/21 16:14:50 INFO TaskSetManager: Starting task 1.0 in stage 151.0 (TID 137, localhost, executor driver, partition 1, PROCESS_LOCAL, 5948 bytes)
17/12/21 16:14:50 INFO Executor: Running task 1.0 in stage 151.0 (TID 137)
17/12/21 16:14:50 INFO Executor: Running task 0.0 in stage 151.0 (TID 136)
17/12/21 16:14:50 INFO BlockManager: Found block rdd_473_0 locally
17/12/21 16:14:50 INFO BlockManager: Found block rdd_454_1 locally
17/12/21 16:14:50 INFO Executor: Finished task 0.0 in stage 151.0 (TID 136). 1456 bytes result sent to driver
17/12/21 16:14:50 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 136) in 0 ms on localhost (executor driver) (1/2)
17/12/21 16:14:51 INFO MemoryStore: Block rdd_473_1 stored as values in memory (estimated size 2.9 KB, free 2001.5 MB)
17/12/21 16:14:51 INFO BlockManagerInfo: Added rdd_473_1 in memory on 127.0.0.1:49792 (size: 2.9 KB, free: 2004.2 MB)
17/12/21 16:14:51 INFO Executor: Finished task 1.0 in stage 151.0 (TID 137). 2251 bytes result sent to driver
17/12/21 16:14:51 INFO TaskSetManager: Finished task 1.0 in stage 151.0 (TID 137) in 679 ms on localhost (executor driver) (2/2)
17/12/21 16:14:51 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool 
17/12/21 16:14:51 INFO DAGScheduler: ResultStage 151 (collect at utils.scala:196) finished in 0.679 s
17/12/21 16:14:51 INFO DAGScheduler: Job 69 finished: collect at utils.scala:196, took 0.686241 s
17/12/21 16:14:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:51 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:14:51 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:51 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:51 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:51 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:51 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:14:51 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:14:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:51 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:14:51 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:51 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:51 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:51 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:51 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:14:51 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:14:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:51 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:14:51 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:51 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:52 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:52 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:14:52 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:14:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:14:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:14:52 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:52 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:52 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:14:52 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:14:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:14:52 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:15:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:15:37 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:15:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:15:37 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:15:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:15:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:15:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:15:37 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 16:15:37 INFO DAGScheduler: Got job 70 (collect at utils.scala:58) with 1 output partitions
17/12/21 16:15:37 INFO DAGScheduler: Final stage: ResultStage 152 (collect at utils.scala:58)
17/12/21 16:15:37 INFO DAGScheduler: Parents of final stage: List()
17/12/21 16:15:37 INFO DAGScheduler: Missing parents: List()
17/12/21 16:15:37 INFO DAGScheduler: Submitting ResultStage 152 (MapPartitionsRDD[490] at map at utils.scala:55), which has no missing parents
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 8.7 KB, free 2001.5 MB)
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2001.5 MB)
17/12/21 16:15:37 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:49792 (size: 4.6 KB, free: 2004.2 MB)
17/12/21 16:15:37 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:996
17/12/21 16:15:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 152 (MapPartitionsRDD[490] at map at utils.scala:55)
17/12/21 16:15:37 INFO TaskSchedulerImpl: Adding task set 152.0 with 1 tasks
17/12/21 16:15:37 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 138, localhost, executor driver, partition 0, PROCESS_LOCAL, 7221 bytes)
17/12/21 16:15:37 INFO Executor: Running task 0.0 in stage 152.0 (TID 138)
17/12/21 16:15:37 INFO Executor: Finished task 0.0 in stage 152.0 (TID 138). 1244 bytes result sent to driver
17/12/21 16:15:37 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 138) in 0 ms on localhost (executor driver) (1/1)
17/12/21 16:15:37 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool 
17/12/21 16:15:37 INFO DAGScheduler: ResultStage 152 (collect at utils.scala:58) finished in 0.000 s
17/12/21 16:15:37 INFO DAGScheduler: Job 70 finished: collect at utils.scala:58, took 0.006560 s
17/12/21 16:15:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:37 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:15:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:37 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 16:15:37 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 16:15:37 INFO FileSourceStrategy: Pruning directories with: 
17/12/21 16:15:37 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/21 16:15:37 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double, S4: double, S5: double ... 8 more fields>
17/12/21 16:15:37 INFO FileSourceStrategy: Pushed Filters: 
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 293.7 KB, free 2001.2 MB)
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2001.2 MB)
17/12/21 16:15:37 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:49792 (size: 24.0 KB, free: 2004.2 MB)
17/12/21 16:15:37 INFO SparkContext: Created broadcast 111 from sql at <unknown>:0
17/12/21 16:15:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/21 16:15:37 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 16:15:37 INFO DAGScheduler: Registering RDD 494 (sql at <unknown>:0)
17/12/21 16:15:37 INFO DAGScheduler: Registering RDD 499 (sql at <unknown>:0)
17/12/21 16:15:37 INFO DAGScheduler: Got job 71 (sql at <unknown>:0) with 1 output partitions
17/12/21 16:15:37 INFO DAGScheduler: Final stage: ResultStage 155 (sql at <unknown>:0)
17/12/21 16:15:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 154)
17/12/21 16:15:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 154)
17/12/21 16:15:37 INFO DAGScheduler: Submitting ShuffleMapStage 153 (MapPartitionsRDD[494] at sql at <unknown>:0), which has no missing parents
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 13.1 KB, free 2001.2 MB)
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 7.5 KB, free 2001.2 MB)
17/12/21 16:15:37 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:49792 (size: 7.5 KB, free: 2004.2 MB)
17/12/21 16:15:37 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:996
17/12/21 16:15:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 153 (MapPartitionsRDD[494] at sql at <unknown>:0)
17/12/21 16:15:37 INFO TaskSchedulerImpl: Adding task set 153.0 with 1 tasks
17/12/21 16:15:37 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:49792 in memory (size: 44.5 KB, free: 2004.2 MB)
17/12/21 16:15:37 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 139, localhost, executor driver, partition 0, PROCESS_LOCAL, 6679 bytes)
17/12/21 16:15:37 INFO Executor: Running task 0.0 in stage 153.0 (TID 139)
17/12/21 16:15:37 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:49792 in memory (size: 7.5 KB, free: 2004.2 MB)
17/12/21 16:15:37 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:49792 in memory (size: 7.0 KB, free: 2004.2 MB)
17/12/21 16:15:37 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmponGyKW/spark_serialize_b657069e848d31d66de7236ec1c7c0cb7c314731b65c54454a21b07cadc91676.csv, range: 0-186818, partition values: [empty row]
17/12/21 16:15:37 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5943
17/12/21 16:15:37 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:49792 in memory (size: 7.0 KB, free: 2004.2 MB)
17/12/21 16:15:37 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:49792 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/21 16:15:37 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:49792 in memory (size: 42.6 KB, free: 2004.3 MB)
17/12/21 16:15:37 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:49792 in memory (size: 46.0 KB, free: 2004.3 MB)
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 6200
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 6201
17/12/21 16:15:37 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:49792 in memory (size: 4.6 KB, free: 2004.3 MB)
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 6250
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 6251
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 6257
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5705
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5706
17/12/21 16:15:37 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:49792 in memory (size: 4.6 KB, free: 2004.3 MB)
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5755
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5756
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5762
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5763
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5764
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5765
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5766
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5767
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5768
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5769
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5770
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5771
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5772
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5773
17/12/21 16:15:37 INFO ContextCleaner: Cleaned accumulator 5774
17/12/21 16:15:37 INFO ContextCleaner: Cleaned shuffle 30
17/12/21 16:15:37 INFO Executor: Finished task 0.0 in stage 153.0 (TID 139). 1632 bytes result sent to driver
17/12/21 16:15:37 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 139) in 101 ms on localhost (executor driver) (1/1)
17/12/21 16:15:37 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool 
17/12/21 16:15:37 INFO DAGScheduler: ShuffleMapStage 153 (sql at <unknown>:0) finished in 0.101 s
17/12/21 16:15:37 INFO DAGScheduler: looking for newly runnable stages
17/12/21 16:15:37 INFO DAGScheduler: running: Set()
17/12/21 16:15:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 154, ResultStage 155)
17/12/21 16:15:37 INFO DAGScheduler: failed: Set()
17/12/21 16:15:37 INFO DAGScheduler: Submitting ShuffleMapStage 154 (MapPartitionsRDD[499] at sql at <unknown>:0), which has no missing parents
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 15.3 KB, free 2001.7 MB)
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2001.7 MB)
17/12/21 16:15:37 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:49792 (size: 6.9 KB, free: 2004.3 MB)
17/12/21 16:15:37 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:996
17/12/21 16:15:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 154 (MapPartitionsRDD[499] at sql at <unknown>:0)
17/12/21 16:15:37 INFO TaskSchedulerImpl: Adding task set 154.0 with 2 tasks
17/12/21 16:15:37 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 140, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/21 16:15:37 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 141, localhost, executor driver, partition 1, ANY, 5945 bytes)
17/12/21 16:15:37 INFO Executor: Running task 0.0 in stage 154.0 (TID 140)
17/12/21 16:15:37 INFO Executor: Running task 1.0 in stage 154.0 (TID 141)
17/12/21 16:15:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 16:15:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 16:15:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 16:15:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 16:15:37 INFO MemoryStore: Block rdd_496_0 stored as values in memory (estimated size 40.5 KB, free 2001.7 MB)
17/12/21 16:15:37 INFO MemoryStore: Block rdd_496_1 stored as values in memory (estimated size 40.5 KB, free 2001.6 MB)
17/12/21 16:15:37 INFO BlockManagerInfo: Added rdd_496_0 in memory on 127.0.0.1:49792 (size: 40.5 KB, free: 2004.3 MB)
17/12/21 16:15:37 INFO BlockManagerInfo: Added rdd_496_1 in memory on 127.0.0.1:49792 (size: 40.5 KB, free: 2004.2 MB)
17/12/21 16:15:37 INFO Executor: Finished task 1.0 in stage 154.0 (TID 141). 3064 bytes result sent to driver
17/12/21 16:15:37 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 141) in 37 ms on localhost (executor driver) (1/2)
17/12/21 16:15:37 INFO Executor: Finished task 0.0 in stage 154.0 (TID 140). 3064 bytes result sent to driver
17/12/21 16:15:37 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 140) in 39 ms on localhost (executor driver) (2/2)
17/12/21 16:15:37 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
17/12/21 16:15:37 INFO DAGScheduler: ShuffleMapStage 154 (sql at <unknown>:0) finished in 0.039 s
17/12/21 16:15:37 INFO DAGScheduler: looking for newly runnable stages
17/12/21 16:15:37 INFO DAGScheduler: running: Set()
17/12/21 16:15:37 INFO DAGScheduler: waiting: Set(ResultStage 155)
17/12/21 16:15:37 INFO DAGScheduler: failed: Set()
17/12/21 16:15:37 INFO DAGScheduler: Submitting ResultStage 155 (MapPartitionsRDD[502] at sql at <unknown>:0), which has no missing parents
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 7.0 KB, free 2001.6 MB)
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.6 MB)
17/12/21 16:15:37 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.2 MB)
17/12/21 16:15:37 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:996
17/12/21 16:15:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 155 (MapPartitionsRDD[502] at sql at <unknown>:0)
17/12/21 16:15:37 INFO TaskSchedulerImpl: Adding task set 155.0 with 1 tasks
17/12/21 16:15:37 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 142, localhost, executor driver, partition 0, ANY, 5956 bytes)
17/12/21 16:15:37 INFO Executor: Running task 0.0 in stage 155.0 (TID 142)
17/12/21 16:15:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 16:15:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 16:15:37 INFO Executor: Finished task 0.0 in stage 155.0 (TID 142). 1873 bytes result sent to driver
17/12/21 16:15:37 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 142) in 3 ms on localhost (executor driver) (1/1)
17/12/21 16:15:37 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
17/12/21 16:15:37 INFO DAGScheduler: ResultStage 155 (sql at <unknown>:0) finished in 0.004 s
17/12/21 16:15:37 INFO DAGScheduler: Job 71 finished: sql at <unknown>:0, took 0.144985 s
17/12/21 16:15:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:37 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 16:15:37 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 16:15:37 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 145 bytes
17/12/21 16:15:37 INFO DAGScheduler: Registering RDD 506 (collect at utils.scala:196)
17/12/21 16:15:37 INFO DAGScheduler: Got job 72 (collect at utils.scala:196) with 1 output partitions
17/12/21 16:15:37 INFO DAGScheduler: Final stage: ResultStage 158 (collect at utils.scala:196)
17/12/21 16:15:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 157)
17/12/21 16:15:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 157)
17/12/21 16:15:37 INFO DAGScheduler: Submitting ShuffleMapStage 157 (MapPartitionsRDD[506] at collect at utils.scala:196), which has no missing parents
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 15.3 KB, free 2001.6 MB)
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2001.6 MB)
17/12/21 16:15:37 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:49792 (size: 7.0 KB, free: 2004.2 MB)
17/12/21 16:15:37 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:996
17/12/21 16:15:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 157 (MapPartitionsRDD[506] at collect at utils.scala:196)
17/12/21 16:15:37 INFO TaskSchedulerImpl: Adding task set 157.0 with 2 tasks
17/12/21 16:15:37 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 143, localhost, executor driver, partition 0, PROCESS_LOCAL, 5937 bytes)
17/12/21 16:15:37 INFO TaskSetManager: Starting task 1.0 in stage 157.0 (TID 144, localhost, executor driver, partition 1, PROCESS_LOCAL, 5937 bytes)
17/12/21 16:15:37 INFO Executor: Running task 1.0 in stage 157.0 (TID 144)
17/12/21 16:15:37 INFO Executor: Running task 0.0 in stage 157.0 (TID 143)
17/12/21 16:15:37 INFO BlockManager: Found block rdd_496_1 locally
17/12/21 16:15:37 INFO BlockManager: Found block rdd_496_0 locally
17/12/21 16:15:37 INFO Executor: Finished task 1.0 in stage 157.0 (TID 144). 1950 bytes result sent to driver
17/12/21 16:15:37 INFO TaskSetManager: Finished task 1.0 in stage 157.0 (TID 144) in 15 ms on localhost (executor driver) (1/2)
17/12/21 16:15:37 INFO Executor: Finished task 0.0 in stage 157.0 (TID 143). 1871 bytes result sent to driver
17/12/21 16:15:37 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 143) in 15 ms on localhost (executor driver) (2/2)
17/12/21 16:15:37 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool 
17/12/21 16:15:37 INFO DAGScheduler: ShuffleMapStage 157 (collect at utils.scala:196) finished in 0.015 s
17/12/21 16:15:37 INFO DAGScheduler: looking for newly runnable stages
17/12/21 16:15:37 INFO DAGScheduler: running: Set()
17/12/21 16:15:37 INFO DAGScheduler: waiting: Set(ResultStage 158)
17/12/21 16:15:37 INFO DAGScheduler: failed: Set()
17/12/21 16:15:37 INFO DAGScheduler: Submitting ResultStage 158 (MapPartitionsRDD[509] at collect at utils.scala:196), which has no missing parents
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 7.0 KB, free 2001.6 MB)
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.6 MB)
17/12/21 16:15:37 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:49792 (size: 3.7 KB, free: 2004.2 MB)
17/12/21 16:15:37 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:996
17/12/21 16:15:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 158 (MapPartitionsRDD[509] at collect at utils.scala:196)
17/12/21 16:15:37 INFO TaskSchedulerImpl: Adding task set 158.0 with 1 tasks
17/12/21 16:15:37 INFO TaskSetManager: Starting task 0.0 in stage 158.0 (TID 145, localhost, executor driver, partition 0, ANY, 5948 bytes)
17/12/21 16:15:37 INFO Executor: Running task 0.0 in stage 158.0 (TID 145)
17/12/21 16:15:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 16:15:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 16:15:37 INFO Executor: Finished task 0.0 in stage 158.0 (TID 145). 1707 bytes result sent to driver
17/12/21 16:15:37 INFO TaskSetManager: Finished task 0.0 in stage 158.0 (TID 145) in 0 ms on localhost (executor driver) (1/1)
17/12/21 16:15:37 INFO TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool 
17/12/21 16:15:37 INFO DAGScheduler: ResultStage 158 (collect at utils.scala:196) finished in 0.000 s
17/12/21 16:15:37 INFO DAGScheduler: Job 72 finished: collect at utils.scala:196, took 0.018432 s
17/12/21 16:15:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz61`
WHERE (0 = 1)
17/12/21 16:15:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:37 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S2` + 0.91651514 * RANDN() AS `V1`, `S9` + 0.89442719 * RANDN() AS `V2`, `S6` + 0.92736185 * RANDN() AS `V3`, `S3` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `gzqhcxhfui`
17/12/21 16:15:37 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:15:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz62`
WHERE (0 = 1)
17/12/21 16:15:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 16:15:37 INFO CodeGenerator: Code generated in 7.673577 ms
17/12/21 16:15:37 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 16:15:37 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 145 bytes
17/12/21 16:15:37 INFO DAGScheduler: Got job 73 (take at <unknown>:0) with 1 output partitions
17/12/21 16:15:37 INFO DAGScheduler: Final stage: ResultStage 160 (take at <unknown>:0)
17/12/21 16:15:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 159)
17/12/21 16:15:37 INFO DAGScheduler: Missing parents: List()
17/12/21 16:15:37 INFO DAGScheduler: Submitting ResultStage 160 (WorkerRDD[515] at RDD at rdd.scala:18), which has no missing parents
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 181.4 KB, free 2001.4 MB)
17/12/21 16:15:37 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 111.7 KB, free 2001.3 MB)
17/12/21 16:15:37 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:49792 (size: 111.7 KB, free: 2004.1 MB)
17/12/21 16:15:37 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:996
17/12/21 16:15:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 160 (WorkerRDD[515] at RDD at rdd.scala:18)
17/12/21 16:15:37 INFO TaskSchedulerImpl: Adding task set 160.0 with 1 tasks
17/12/21 16:15:37 INFO TaskSetManager: Starting task 0.0 in stage 160.0 (TID 146, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/21 16:15:37 INFO Executor: Running task 0.0 in stage 160.0 (TID 146)
17/12/21 16:15:37 INFO BlockManager: Found block rdd_496_0 locally
17/12/21 16:15:38 INFO MemoryStore: Block rdd_515_0 stored as values in memory (estimated size 72.3 KB, free 2001.2 MB)
17/12/21 16:15:38 INFO BlockManagerInfo: Added rdd_515_0 in memory on 127.0.0.1:49792 (size: 72.3 KB, free: 2004.1 MB)
17/12/21 16:15:38 WARN Executor: 1 block locks were not released by TID = 146:
[rdd_515_0]
17/12/21 16:15:38 INFO Executor: Finished task 0.0 in stage 160.0 (TID 146). 3020 bytes result sent to driver
17/12/21 16:15:38 INFO TaskSetManager: Finished task 0.0 in stage 160.0 (TID 146) in 798 ms on localhost (executor driver) (1/1)
17/12/21 16:15:38 INFO TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool 
17/12/21 16:15:38 INFO DAGScheduler: ResultStage 160 (take at <unknown>:0) finished in 0.798 s
17/12/21 16:15:38 INFO DAGScheduler: Job 73 finished: take at <unknown>:0, took 0.806365 s
17/12/21 16:15:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:38 INFO SparkSqlParser: Parsing command: sparklyr_tmp_17746fc3ae0
17/12/21 16:15:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17746fc3ae0` AS `zzz63`
WHERE (0 = 1)
17/12/21 16:15:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17746fc3ae0`
17/12/21 16:15:38 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:15:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz64`
WHERE (0 = 1)
17/12/21 16:15:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:38 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 4e-04) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0055) AS `V3`, (`V4` < 0.0045) AS `V4`
FROM `analyis_tbl`
17/12/21 16:15:38 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 16:15:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz65`
WHERE (0 = 1)
17/12/21 16:15:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 16:15:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 16:15:38 INFO DAGScheduler: Got job 74 (collect at utils.scala:196) with 2 output partitions
17/12/21 16:15:38 INFO DAGScheduler: Final stage: ResultStage 162 (collect at utils.scala:196)
17/12/21 16:15:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 161)
17/12/21 16:15:38 INFO DAGScheduler: Missing parents: List()
17/12/21 16:15:38 INFO DAGScheduler: Submitting ResultStage 162 (MapPartitionsRDD[522] at collect at utils.scala:196), which has no missing parents
17/12/21 16:15:38 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 188.9 KB, free 2001.1 MB)
17/12/21 16:15:38 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 114.8 KB, free 2000.9 MB)
17/12/21 16:15:38 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:49792 (size: 114.8 KB, free: 2003.9 MB)
17/12/21 16:15:38 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:996
17/12/21 16:15:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 162 (MapPartitionsRDD[522] at collect at utils.scala:196)
17/12/21 16:15:38 INFO TaskSchedulerImpl: Adding task set 162.0 with 2 tasks
17/12/21 16:15:38 INFO TaskSetManager: Starting task 0.0 in stage 162.0 (TID 147, localhost, executor driver, partition 0, PROCESS_LOCAL, 5948 bytes)
17/12/21 16:15:38 INFO TaskSetManager: Starting task 1.0 in stage 162.0 (TID 148, localhost, executor driver, partition 1, PROCESS_LOCAL, 5948 bytes)
17/12/21 16:15:38 INFO Executor: Running task 1.0 in stage 162.0 (TID 148)
17/12/21 16:15:38 INFO Executor: Running task 0.0 in stage 162.0 (TID 147)
17/12/21 16:15:38 INFO BlockManager: Found block rdd_496_1 locally
17/12/21 16:15:38 INFO BlockManager: Found block rdd_515_0 locally
17/12/21 16:15:38 INFO Executor: Finished task 0.0 in stage 162.0 (TID 147). 1861 bytes result sent to driver
17/12/21 16:15:38 INFO TaskSetManager: Finished task 0.0 in stage 162.0 (TID 147) in 0 ms on localhost (executor driver) (1/2)
17/12/21 16:15:39 INFO MemoryStore: Block rdd_515_1 stored as values in memory (estimated size 72.3 KB, free 2000.9 MB)
17/12/21 16:15:39 INFO BlockManagerInfo: Added rdd_515_1 in memory on 127.0.0.1:49792 (size: 72.3 KB, free: 2003.9 MB)
17/12/21 16:15:39 INFO Executor: Finished task 1.0 in stage 162.0 (TID 148). 2560 bytes result sent to driver
17/12/21 16:15:39 INFO TaskSetManager: Finished task 1.0 in stage 162.0 (TID 148) in 831 ms on localhost (executor driver) (2/2)
17/12/21 16:15:39 INFO TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool 
17/12/21 16:15:39 INFO DAGScheduler: ResultStage 162 (collect at utils.scala:196) finished in 0.831 s
17/12/21 16:15:39 INFO DAGScheduler: Job 74 finished: collect at utils.scala:196, took 0.834933 s
17/12/21 16:15:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:40 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:15:40 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:15:40 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:15:40 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:15:40 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:15:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:15:40 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:15:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:40 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:15:40 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:15:40 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:15:40 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:15:40 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:15:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:15:40 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:15:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:40 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:15:40 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:15:40 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:15:40 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:15:40 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:15:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:15:40 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:15:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 16:15:40 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 16:15:40 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:15:40 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:15:40 INFO HiveMetaStore: 0: get_database: default
17/12/21 16:15:40 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 16:15:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 16:15:40 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 16:16:39 INFO SparkContext: Invoking stop() from shutdown hook
17/12/21 16:16:39 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/21 16:16:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/21 16:16:39 INFO MemoryStore: MemoryStore cleared
17/12/21 16:16:39 INFO BlockManager: BlockManager stopped
17/12/21 16:16:39 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/21 16:16:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/21 16:16:39 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-787a9863-d8d1-4e22-b1c5-f06e04e3f9b5\userFiles-21ff9ed1-7cff-4fdc-a66b-664d808306a5
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-787a9863-d8d1-4e22-b1c5-f06e04e3f9b5\userFiles-21ff9ed1-7cff-4fdc-a66b-664d808306a5
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/21 16:16:39 INFO SparkContext: Successfully stopped SparkContext
17/12/21 16:16:39 INFO ShutdownHookManager: Shutdown hook called
17/12/21 16:16:39 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-787a9863-d8d1-4e22-b1c5-f06e04e3f9b5\userFiles-21ff9ed1-7cff-4fdc-a66b-664d808306a5
17/12/21 16:16:39 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-787a9863-d8d1-4e22-b1c5-f06e04e3f9b5\userFiles-21ff9ed1-7cff-4fdc-a66b-664d808306a5
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-787a9863-d8d1-4e22-b1c5-f06e04e3f9b5\userFiles-21ff9ed1-7cff-4fdc-a66b-664d808306a5
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/21 16:16:39 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-787a9863-d8d1-4e22-b1c5-f06e04e3f9b5
17/12/21 16:16:39 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-787a9863-d8d1-4e22-b1c5-f06e04e3f9b5
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-787a9863-d8d1-4e22-b1c5-f06e04e3f9b5
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/21 17:55:49 INFO SparkContext: Running Spark version 2.1.0
17/12/21 17:55:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/21 17:55:49 INFO SecurityManager: Changing view acls to: conan
17/12/21 17:55:49 INFO SecurityManager: Changing modify acls to: conan
17/12/21 17:55:49 INFO SecurityManager: Changing view acls groups to: 
17/12/21 17:55:49 INFO SecurityManager: Changing modify acls groups to: 
17/12/21 17:55:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(conan); groups with view permissions: Set(); users  with modify permissions: Set(conan); groups with modify permissions: Set()
17/12/21 17:55:49 INFO Utils: Successfully started service 'sparkDriver' on port 51308.
17/12/21 17:55:49 INFO SparkEnv: Registering MapOutputTracker
17/12/21 17:55:49 INFO SparkEnv: Registering BlockManagerMaster
17/12/21 17:55:49 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/21 17:55:49 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/21 17:55:49 INFO DiskBlockManager: Created local directory at C:\Users\conan\AppData\Local\Temp\blockmgr-59481db0-1bc3-4544-981a-103ac955c47a
17/12/21 17:55:49 INFO MemoryStore: MemoryStore started with capacity 2004.6 MB
17/12/21 17:55:49 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/21 17:55:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/21 17:55:49 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/21 17:55:49 INFO SparkContext: Added JAR file:/C:/Users/conan/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:51308/jars/sparklyr-2.1-2.11.jar with timestamp 1513878949974
17/12/21 17:55:50 INFO Executor: Starting executor ID driver on host localhost
17/12/21 17:55:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51329.
17/12/21 17:55:50 INFO NettyBlockTransferService: Server created on 127.0.0.1:51329
17/12/21 17:55:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/21 17:55:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51329, None)
17/12/21 17:55:50 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51329 with 2004.6 MB RAM, BlockManagerId(driver, 127.0.0.1, 51329, None)
17/12/21 17:55:50 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51329, None)
17/12/21 17:55:50 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51329, None)
17/12/21 17:55:50 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/21 17:55:50 INFO SharedState: Warehouse path is 'C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/21 17:55:50 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/21 17:55:51 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/21 17:55:51 INFO ObjectStore: ObjectStore, initialize called
17/12/21 17:55:51 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/21 17:55:51 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/21 17:55:53 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/21 17:55:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 17:55:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 17:55:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 17:55:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 17:55:54 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/21 17:55:54 INFO ObjectStore: Initialized ObjectStore
17/12/21 17:55:54 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/21 17:55:54 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/21 17:55:55 INFO HiveMetaStore: Added admin role in metastore
17/12/21 17:55:55 INFO HiveMetaStore: Added public role in metastore
17/12/21 17:55:55 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/21 17:55:55 INFO HiveMetaStore: 0: get_all_databases
17/12/21 17:55:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/21 17:55:55 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/21 17:55:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/21 17:55:55 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 17:55:55 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/Temp/80e3ed45-ce04-4e97-8661-5e77e08389a7_resources
17/12/21 17:55:55 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/80e3ed45-ce04-4e97-8661-5e77e08389a7
17/12/21 17:55:55 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/80e3ed45-ce04-4e97-8661-5e77e08389a7
17/12/21 17:55:55 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/80e3ed45-ce04-4e97-8661-5e77e08389a7/_tmp_space.db
17/12/21 17:55:55 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/21 17:55:55 INFO HiveMetaStore: 0: get_database: default
17/12/21 17:55:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 17:55:55 INFO HiveMetaStore: 0: get_database: global_temp
17/12/21 17:55:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/21 17:55:55 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/21 17:55:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 17:55:57 INFO HiveMetaStore: 0: get_database: default
17/12/21 17:55:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 17:55:57 INFO HiveMetaStore: 0: get_database: default
17/12/21 17:55:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 17:55:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 17:55:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 17:56:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:56:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 17:56:45 INFO HiveMetaStore: 0: get_database: default
17/12/21 17:56:45 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 17:56:45 INFO HiveMetaStore: 0: get_database: default
17/12/21 17:56:45 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 17:56:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 17:56:45 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 17:56:46 INFO CodeGenerator: Code generated in 256.016468 ms
17/12/21 17:56:46 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 17:56:46 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/21 17:56:46 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/21 17:56:46 INFO DAGScheduler: Parents of final stage: List()
17/12/21 17:56:46 INFO DAGScheduler: Missing parents: List()
17/12/21 17:56:46 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/12/21 17:56:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 2004.6 MB)
17/12/21 17:56:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2004.6 MB)
17/12/21 17:56:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:51329 (size: 4.6 KB, free: 2004.6 MB)
17/12/21 17:56:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/21 17:56:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/12/21 17:56:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/21 17:56:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/21 17:56:46 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/21 17:56:46 INFO Executor: Fetching spark://127.0.0.1:51308/jars/sparklyr-2.1-2.11.jar with timestamp 1513878949974
17/12/21 17:56:46 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:51308 after 14 ms (0 ms spent in bootstraps)
17/12/21 17:56:46 INFO Utils: Fetching spark://127.0.0.1:51308/jars/sparklyr-2.1-2.11.jar to C:\Users\conan\AppData\Local\Temp\spark-2c30f56e-91b1-495b-9db2-35c583f5f965\userFiles-b039936d-07e9-4503-af8d-91f73f25a936\fetchFileTemp2289469474992913220.tmp
17/12/21 17:56:46 INFO Executor: Adding file:/C:/Users/conan/AppData/Local/Temp/spark-2c30f56e-91b1-495b-9db2-35c583f5f965/userFiles-b039936d-07e9-4503-af8d-91f73f25a936/sparklyr-2.1-2.11.jar to class loader
17/12/21 17:56:46 INFO CodeGenerator: Code generated in 17.807093 ms
17/12/21 17:56:46 INFO CodeGenerator: Code generated in 14.227248 ms
17/12/21 17:56:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/12/21 17:56:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 377 ms on localhost (executor driver) (1/1)
17/12/21 17:56:46 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.408 s
17/12/21 17:56:46 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.534881 s
17/12/21 17:56:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/21 17:56:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:56:47 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 17:56:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:56:47 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 17:56:47 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 17:56:47 INFO FileSourceStrategy: Pruning directories with: 
17/12/21 17:56:47 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/21 17:56:47 INFO FileSourceStrategy: Output Data Schema: struct<S1: double>
17/12/21 17:56:47 INFO FileSourceStrategy: Pushed Filters: 
17/12/21 17:56:47 INFO CodeGenerator: Code generated in 7.428149 ms
17/12/21 17:56:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.7 KB, free 2004.3 MB)
17/12/21 17:56:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2004.3 MB)
17/12/21 17:56:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:51329 (size: 24.0 KB, free: 2004.6 MB)
17/12/21 17:56:47 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/21 17:56:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/21 17:56:47 INFO CodeGenerator: Code generated in 12.057291 ms
17/12/21 17:56:47 INFO CodeGenerator: Code generated in 11.551333 ms
17/12/21 17:56:47 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 17:56:47 INFO DAGScheduler: Registering RDD 10 (sql at <unknown>:0)
17/12/21 17:56:47 INFO DAGScheduler: Registering RDD 15 (sql at <unknown>:0)
17/12/21 17:56:47 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/21 17:56:47 INFO DAGScheduler: Final stage: ResultStage 3 (sql at <unknown>:0)
17/12/21 17:56:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/12/21 17:56:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/12/21 17:56:47 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0), which has no missing parents
17/12/21 17:56:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.8 KB, free 2004.3 MB)
17/12/21 17:56:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KB, free 2004.3 MB)
17/12/21 17:56:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:51329 (size: 7.2 KB, free: 2004.6 MB)
17/12/21 17:56:47 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/21 17:56:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0)
17/12/21 17:56:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/21 17:56:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/21 17:56:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/21 17:56:47 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpEzPCXP/spark_serialize_3bb0e80ed074a0348124a46b373e4d0a84728f82a7776c578f1f69dae1c96ce1.csv, range: 0-19612, partition values: [empty row]
17/12/21 17:56:47 INFO CodeGenerator: Code generated in 6.167407 ms
17/12/21 17:56:47 INFO ContextCleaner: Cleaned accumulator 0
17/12/21 17:56:47 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:51329 in memory (size: 4.6 KB, free: 2004.6 MB)
17/12/21 17:56:47 INFO ContextCleaner: Cleaned accumulator 50
17/12/21 17:56:47 INFO ContextCleaner: Cleaned accumulator 51
17/12/21 17:56:47 INFO ContextCleaner: Cleaned accumulator 57
17/12/21 17:56:47 INFO ContextCleaner: Cleaned accumulator 1
17/12/21 17:56:47 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1792 bytes result sent to driver
17/12/21 17:56:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 178 ms on localhost (executor driver) (1/1)
17/12/21 17:56:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/21 17:56:47 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.178 s
17/12/21 17:56:47 INFO DAGScheduler: looking for newly runnable stages
17/12/21 17:56:47 INFO DAGScheduler: running: Set()
17/12/21 17:56:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/12/21 17:56:47 INFO DAGScheduler: failed: Set()
17/12/21 17:56:47 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/21 17:56:47 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.9 KB, free 2004.3 MB)
17/12/21 17:56:47 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.6 KB, free 2004.3 MB)
17/12/21 17:56:47 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:51329 (size: 5.6 KB, free: 2004.6 MB)
17/12/21 17:56:47 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/21 17:56:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/21 17:56:47 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
17/12/21 17:56:47 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5942 bytes)
17/12/21 17:56:47 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5942 bytes)
17/12/21 17:56:47 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/21 17:56:47 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
17/12/21 17:56:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 17:56:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 17:56:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
17/12/21 17:56:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
17/12/21 17:56:48 INFO MemoryStore: Block rdd_12_1 stored as values in memory (estimated size 4.2 KB, free 2004.2 MB)
17/12/21 17:56:48 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 4.2 KB, free 2004.2 MB)
17/12/21 17:56:48 INFO BlockManagerInfo: Added rdd_12_1 in memory on 127.0.0.1:51329 (size: 4.2 KB, free: 2004.6 MB)
17/12/21 17:56:48 INFO BlockManagerInfo: Added rdd_12_0 in memory on 127.0.0.1:51329 (size: 4.2 KB, free: 2004.6 MB)
17/12/21 17:56:48 INFO CodeGenerator: Code generated in 5.384682 ms
17/12/21 17:56:48 INFO CodeGenerator: Code generated in 16.014717 ms
17/12/21 17:56:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 3064 bytes result sent to driver
17/12/21 17:56:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 3151 bytes result sent to driver
17/12/21 17:56:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 141 ms on localhost (executor driver) (1/2)
17/12/21 17:56:48 INFO DAGScheduler: ShuffleMapStage 2 (sql at <unknown>:0) finished in 0.141 s
17/12/21 17:56:48 INFO DAGScheduler: looking for newly runnable stages
17/12/21 17:56:48 INFO DAGScheduler: running: Set()
17/12/21 17:56:48 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/12/21 17:56:48 INFO DAGScheduler: failed: Set()
17/12/21 17:56:48 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
17/12/21 17:56:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 141 ms on localhost (executor driver) (2/2)
17/12/21 17:56:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/21 17:56:48 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 2004.2 MB)
17/12/21 17:56:48 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.2 MB)
17/12/21 17:56:48 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:51329 (size: 3.7 KB, free: 2004.6 MB)
17/12/21 17:56:48 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/21 17:56:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0)
17/12/21 17:56:48 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/21 17:56:48 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/21 17:56:48 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
17/12/21 17:56:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 17:56:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 17:56:48 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 1707 bytes result sent to driver
17/12/21 17:56:48 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 0 ms on localhost (executor driver) (1/1)
17/12/21 17:56:48 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/21 17:56:48 INFO DAGScheduler: ResultStage 3 (sql at <unknown>:0) finished in 0.000 s
17/12/21 17:56:48 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.399079 s
17/12/21 17:56:48 INFO CodeGenerator: Code generated in 7.792892 ms
17/12/21 17:56:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:56:48 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 17:56:48 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 17:56:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/21 17:56:48 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:196)
17/12/21 17:56:48 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/12/21 17:56:48 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:196)
17/12/21 17:56:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/12/21 17:56:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/12/21 17:56:48 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
17/12/21 17:56:48 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.9 KB, free 2004.2 MB)
17/12/21 17:56:48 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.6 KB, free 2004.2 MB)
17/12/21 17:56:48 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:51329 (size: 5.6 KB, free: 2004.5 MB)
17/12/21 17:56:48 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/21 17:56:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196)
17/12/21 17:56:48 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
17/12/21 17:56:48 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5934 bytes)
17/12/21 17:56:48 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 5934 bytes)
17/12/21 17:56:48 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/21 17:56:48 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/12/21 17:56:48 INFO BlockManager: Found block rdd_12_0 locally
17/12/21 17:56:48 INFO BlockManager: Found block rdd_12_1 locally
17/12/21 17:56:48 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1871 bytes result sent to driver
17/12/21 17:56:48 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 16 ms on localhost (executor driver) (1/2)
17/12/21 17:56:48 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 1969 bytes result sent to driver
17/12/21 17:56:48 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 16 ms on localhost (executor driver) (2/2)
17/12/21 17:56:48 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:196) finished in 0.016 s
17/12/21 17:56:48 INFO DAGScheduler: looking for newly runnable stages
17/12/21 17:56:48 INFO DAGScheduler: running: Set()
17/12/21 17:56:48 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/12/21 17:56:48 INFO DAGScheduler: failed: Set()
17/12/21 17:56:48 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196), which has no missing parents
17/12/21 17:56:48 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/21 17:56:48 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 2004.2 MB)
17/12/21 17:56:48 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.2 MB)
17/12/21 17:56:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:51329 (size: 3.7 KB, free: 2004.5 MB)
17/12/21 17:56:48 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/12/21 17:56:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196)
17/12/21 17:56:48 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/21 17:56:48 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/21 17:56:48 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
17/12/21 17:56:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 17:56:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/12/21 17:56:48 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1786 bytes result sent to driver
17/12/21 17:56:48 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:196) finished in 0.006 s
17/12/21 17:56:48 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.046870 s
17/12/21 17:56:48 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 6 ms on localhost (executor driver) (1/1)
17/12/21 17:56:48 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/21 17:56:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:56:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz1`
WHERE (0 = 1)
17/12/21 17:56:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:56:49 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`, `V11` AS `V11`, `V12` AS `V12`, `V13` AS `V13`, `V14` AS `V14`, `V15` AS `V15`, `V16` AS `V16`, `V17` AS `V17`, `V18` AS `V18`, `V19` AS `V19`, `V20` AS `V20`, `V21` AS `V21`, `V22` AS `V22`, `V23` AS `V23`, `V24` AS `V24`, `V25` AS `V25`, `V26` AS `V26`, `V27` AS `V27`, `V28` AS `V28`, `V29` AS `V29`, `V30` AS `V30`, `V31` AS `V31`, `V32` AS `V32`, `V33` AS `V33`, `V34` AS `V34`, `V35` AS `V35`, `V36` AS `V36`, `V37` AS `V37`, `V38` AS `V38`, `V39` AS `V39`, `V40` AS `V40`, `V41` AS `V41`, `V42` AS `V42`, `V43` AS `V43`, `V44` AS `V44`, `V45` AS `V45`, `V46` AS `V46`, `V47` AS `V47`, `V48` AS `V48`, `V49` AS `V49`, `V50` AS `V50`, `V51` AS `V51`, `V52` AS `V52`, `V53` AS `V53`, `V54` AS `V54`, `V55` AS `V55`, `V56` AS `V56`, `V57` AS `V57`, `V58` AS `V58`, `V59` AS `V59`, `V60` AS `V60`, `V61` AS `V61`, `V62` AS `V62`, `V63` AS `V63`, `V64` AS `V64`, `V65` AS `V65`, `V66` AS `V66`, `V67` AS `V67`, `V68` AS `V68`, `V69` AS `V69`, `V70` AS `V70`, `V71` AS `V71`, `V72` AS `V72`, `V73` AS `V73`, `V74` AS `V74`, `V75` AS `V75`, `V76` AS `V76`, `V77` AS `V77`, `V78` AS `V78`, `V79` AS `V79`, `V80` AS `V80`, `V81` AS `V81`, `V82` AS `V82`, `V83` AS `V83`, `V84` AS `V84`, `V85` AS `V85`, `V86` AS `V86`, `V87` AS `V87`, `V88` AS `V88`, `V89` AS `V89`, `V90` AS `V90`, `V91` AS `V91`, `V92` AS `V92`, `V93` AS `V93`, `V94` AS `V94`, `V95` AS `V95`, `V96` AS `V96`, `V97` AS `V97`, `V98` AS `V98`, `V99` AS `V99`, `V100` AS `V100`, `V101` AS `V101`, `V102` AS `V102`, `V103` AS `V103`, `V104` AS `V104`, `V105` AS `V105`, `V106` AS `V106`, `V107` AS `V107`, `V108` AS `V108`, `V109` AS `V109`, `V110` AS `V110`, `V111` AS `V111`, `V112` AS `V112`, `V113` AS `V113`, `V114` AS `V114`, `V115` AS `V115`, `V116` AS `V116`, `V117` AS `V117`, `V118` AS `V118`, `V119` AS `V119`, `V120` AS `V120`, `V121` AS `V121`, `V122` AS `V122`, `V123` AS `V123`, `V124` AS `V124`, `V125` AS `V125`, `V126` AS `V126`, `V127` AS `V127`, `V128` AS `V128`, `V129` AS `V129`, `V130` AS `V130`, `V131` AS `V131`, `V132` AS `V132`, `V133` AS `V133`, `V134` AS `V134`, `V135` AS `V135`, `V136` AS `V136`, `V137` AS `V137`, `V138` AS `V138`, `V139` AS `V139`, `V140` AS `V140`, `V141` AS `V141`, `V142` AS `V142`, `V143` AS `V143`, `V144` AS `V144`, `V145` AS `V145`, `V146` AS `V146`, `V147` AS `V147`, `V148` AS `V148`, `V149` AS `V149`, `V150` AS `V150`, `V151` AS `V151`, `V152` AS `V152`, `V153` AS `V153`, `V154` AS `V154`, `V155` AS `V155`, `V156` AS `V156`, `V157` AS `V157`, `V158` AS `V158`, `V159` AS `V159`, `V160` AS `V160`, `V161` AS `V161`, `V162` AS `V162`, `V163` AS `V163`, `V164` AS `V164`, `V165` AS `V165`, `V166` AS `V166`, `V167` AS `V167`, `V168` AS `V168`, `V169` AS `V169`, `V170` AS `V170`, `V171` AS `V171`, `V172` AS `V172`, `V173` AS `V173`, `V174` AS `V174`, `V175` AS `V175`, `V176` AS `V176`, `V177` AS `V177`, `V178` AS `V178`, `V179` AS `V179`, `V180` AS `V180`, `V181` AS `V181`, `V182` AS `V182`, `V183` AS `V183`, `V184` AS `V184`, `V185` AS `V185`, `V186` AS `V186`, `V187` AS `V187`, `V188` AS `V188`, `V189` AS `V189`, `V190` AS `V190`, `V191` AS `V191`, `V192` AS `V192`, `V193` AS `V193`, `V194` AS `V194`, `V195` AS `V195`, `V196` AS `V196`, `V197` AS `V197`, `V198` AS `V198`, `V199` AS `V199`, `V200` AS `V200`, `V201` AS `V201`, `V202` AS `V202`, `V203` AS `V203`, `V204` AS `V204`, `V205` AS `V205`, `V206` AS `V206`, `V207` AS `V207`, `V208` AS `V208`, `V209` AS `V209`, `V210` AS `V210`, `V211` AS `V211`, `V212` AS `V212`, `V213` AS `V213`, `V214` AS `V214`, `V215` AS `V215`, `V216` AS `V216`, `V217` AS `V217`, `V218` AS `V218`, `V219` AS `V219`, `V220` AS `V220`, `V221` AS `V221`, `V222` AS `V222`, `V223` AS `V223`, `V224` AS `V224`, `V225` AS `V225`, `V226` AS `V226`, `V227` AS `V227`, `V228` AS `V228`, `V229` AS `V229`, `V230` AS `V230`, `V231` AS `V231`, `V232` AS `V232`, `V233` AS `V233`, `V234` AS `V234`, `V235` AS `V235`, `V236` AS `V236`, `V237` AS `V237`, `V238` AS `V238`, `V239` AS `V239`, `V240` AS `V240`, `V241` AS `V241`, `V242` AS `V242`, `V243` AS `V243`, `V244` AS `V244`, `V245` AS `V245`, `V246` AS `V246`, `V247` AS `V247`, `V248` AS `V248`, `V249` AS `V249`, `V250` AS `V250`, `V251` AS `V251`, `V252` AS `V252`, `V253` AS `V253`, `V254` AS `V254`, `V255` AS `V255`, `V256` AS `V256`, `V257` AS `V257`, `V258` AS `V258`, `V259` AS `V259`, `V260` AS `V260`, `V261` AS `V261`, `V262` AS `V262`, `V263` AS `V263`, `V264` AS `V264`, `V265` AS `V265`, `V266` AS `V266`, `V267` AS `V267`, `V268` AS `V268`, `V269` AS `V269`, `V270` AS `V270`, `V271` AS `V271`, `V272` AS `V272`, `V273` AS `V273`, `V274` AS `V274`, `V275` AS `V275`, `V276` AS `V276`, `V277` AS `V277`, `V278` AS `V278`, `V279` AS `V279`, `V280` AS `V280`, `V281` AS `V281`, `V282` AS `V282`, `V283` AS `V283`, `V284` AS `V284`, `V285` AS `V285`, `V286` AS `V286`, `V287` AS `V287`, `V288` AS `V288`, `V289` AS `V289`, `V290` AS `V290`, `V291` AS `V291`, `V292` AS `V292`, `V293` AS `V293`, `V294` AS `V294`, `V295` AS `V295`, `V296` AS `V296`, `V297` AS `V297`, `V298` AS `V298`, `V299` AS `V299`, `V300` AS `V300`, `V301` AS `V301`, `V302` AS `V302`, `V303` AS `V303`, `V304` AS `V304`, `V305` AS `V305`, `V306` AS `V306`, `V307` AS `V307`, `V308` AS `V308`, `V309` AS `V309`, `V310` AS `V310`, `V311` AS `V311`, `V312` AS `V312`, `V313` AS `V313`, `V314` AS `V314`, `V315` AS `V315`, `V316` AS `V316`, `V317` AS `V317`, `V318` AS `V318`, `V319` AS `V319`, `V320` AS `V320`, `V321` AS `V321`, `V322` AS `V322`, `V323` AS `V323`, `V324` AS `V324`, `V325` AS `V325`, `V326` AS `V326`, `V327` AS `V327`, `V328` AS `V328`, `V329` AS `V329`, `V330` AS `V330`, `V331` AS `V331`, `V332` AS `V332`, `V333` AS `V333`, `V334` AS `V334`, `V335` AS `V335`, `V336` AS `V336`, `V337` AS `V337`, `V338` AS `V338`, `V339` AS `V339`, `V340` AS `V340`, `V341` AS `V341`, `V342` AS `V342`, `V343` AS `V343`, `V344` AS `V344`, `V345` AS `V345`, `V346` AS `V346`, `V347` AS `V347`, `V348` AS `V348`, `V349` AS `V349`, `V350` AS `V350`, `V351` AS `V351`, `V352` AS `V352`, `V353` AS `V353`, `V354` AS `V354`, `V355` AS `V355`, `V356` AS `V356`, `V357` AS `V357`, `V358` AS `V358`, `V359` AS `V359`, `V360` AS `V360`, `V361` AS `V361`, `V362` AS `V362`, `V363` AS `V363`, `V364` AS `V364`, `V365` AS `V365`, `V366` AS `V366`, `V367` AS `V367`, `V368` AS `V368`, `V369` AS `V369`, `V370` AS `V370`, `V371` AS `V371`, `V372` AS `V372`, `V373` AS `V373`, `V374` AS `V374`, `V375` AS `V375`, `V376` AS `V376`, `V377` AS `V377`, `V378` AS `V378`, `V379` AS `V379`, `V380` AS `V380`, `V381` AS `V381`, `V382` AS `V382`, `V383` AS `V383`, `V384` AS `V384`, `V385` AS `V385`, `V386` AS `V386`, `V387` AS `V387`, `V388` AS `V388`, `V389` AS `V389`, `V390` AS `V390`, `V391` AS `V391`, `V392` AS `V392`, `V393` AS `V393`, `V394` AS `V394`, `V395` AS `V395`, `V396` AS `V396`, `V397` AS `V397`, `V398` AS `V398`, `V399` AS `V399`, `V400` AS `V400`, `V401` AS `V401`, `V402` AS `V402`, `V403` AS `V403`, `V404` AS `V404`, `V405` AS `V405`, `V406` AS `V406`, `V407` AS `V407`, `V408` AS `V408`, `V409` AS `V409`, `V410` AS `V410`, `V411` AS `V411`, `V412` AS `V412`, `V413` AS `V413`, `V414` AS `V414`, `V415` AS `V415`, `V416` AS `V416`, `V417` AS `V417`, `V418` AS `V418`, `V419` AS `V419`, `V420` AS `V420`, `V421` AS `V421`, `V422` AS `V422`, `V423` AS `V423`, `V424` AS `V424`, `V425` AS `V425`, `V426` AS `V426`, `V427` AS `V427`, `V428` AS `V428`, `V429` AS `V429`, `V430` AS `V430`, `V431` AS `V431`, `V432` AS `V432`, `V433` AS `V433`, `V434` AS `V434`, `V435` AS `V435`, `V436` AS `V436`, `V437` AS `V437`, `V438` AS `V438`, `V439` AS `V439`, `V440` AS `V440`, `V441` AS `V441`, `V442` AS `V442`, `V443` AS `V443`, `V444` AS `V444`, `V445` AS `V445`, `V446` AS `V446`, `V447` AS `V447`, `V448` AS `V448`, `V449` AS `V449`, `V450` AS `V450`, `V451` AS `V451`, `V452` AS `V452`, `V453` AS `V453`, `V454` AS `V454`, `V455` AS `V455`, `V456` AS `V456`, `V457` AS `V457`, `V458` AS `V458`, `V459` AS `V459`, `V460` AS `V460`, `V461` AS `V461`, `V462` AS `V462`, `V463` AS `V463`, `V464` AS `V464`, `V465` AS `V465`, `V466` AS `V466`, `V467` AS `V467`, `V468` AS `V468`, `V469` AS `V469`, `V470` AS `V470`, `V471` AS `V471`, `V472` AS `V472`, `V473` AS `V473`, `V474` AS `V474`, `V475` AS `V475`, `V476` AS `V476`, `V477` AS `V477`, `V478` AS `V478`, `V479` AS `V479`, `V480` AS `V480`, `V481` AS `V481`, `V482` AS `V482`, `V483` AS `V483`, `V484` AS `V484`, `V485` AS `V485`, `V486` AS `V486`, `V487` AS `V487`, `V488` AS `V488`, `V489` AS `V489`, `V490` AS `V490`, `V491` AS `V491`, `V492` AS `V492`, `V493` AS `V493`, `V494` AS `V494`, `V495` AS `V495`, `V496` AS `V496`, `V497` AS `V497`, `V498` AS `V498`, `V499` AS `V499`, `V500` AS `V500`
FROM (SELECT `S1`, `S1` + 0.92195445 * RANDN() AS `V1`, `S1` + 0.92195445 * RANDN() AS `V2`, `S1` + 0.92195445 * RANDN() AS `V3`, `S1` + 0.92195445 * RANDN() AS `V4`, `S1` + 0.92195445 * RANDN() AS `V5`, `S1` + 0.92195445 * RANDN() AS `V6`, `S1` + 0.92195445 * RANDN() AS `V7`, `S1` + 0.92195445 * RANDN() AS `V8`, `S1` + 0.92195445 * RANDN() AS `V9`, `S1` + 0.92195445 * RANDN() AS `V10`, `S1` + 0.92195445 * RANDN() AS `V11`, `S1` + 0.92195445 * RANDN() AS `V12`, `S1` + 0.92195445 * RANDN() AS `V13`, `S1` + 0.92195445 * RANDN() AS `V14`, `S1` + 0.92195445 * RANDN() AS `V15`, `S1` + 0.92195445 * RANDN() AS `V16`, `S1` + 0.92195445 * RANDN() AS `V17`, `S1` + 0.92195445 * RANDN() AS `V18`, `S1` + 0.92195445 * RANDN() AS `V19`, `S1` + 0.92195445 * RANDN() AS `V20`, `S1` + 0.92195445 * RANDN() AS `V21`, `S1` + 0.92195445 * RANDN() AS `V22`, `S1` + 0.92195445 * RANDN() AS `V23`, `S1` + 0.92195445 * RANDN() AS `V24`, `S1` + 0.92195445 * RANDN() AS `V25`, `S1` + 0.92195445 * RANDN() AS `V26`, `S1` + 0.92195445 * RANDN() AS `V27`, `S1` + 0.92195445 * RANDN() AS `V28`, `S1` + 0.92195445 * RANDN() AS `V29`, `S1` + 0.92195445 * RANDN() AS `V30`, `S1` + 0.92195445 * RANDN() AS `V31`, `S1` + 0.92195445 * RANDN() AS `V32`, `S1` + 0.92195445 * RANDN() AS `V33`, `S1` + 0.92195445 * RANDN() AS `V34`, `S1` + 0.92195445 * RANDN() AS `V35`, `S1` + 0.92195445 * RANDN() AS `V36`, `S1` + 0.92195445 * RANDN() AS `V37`, `S1` + 0.92195445 * RANDN() AS `V38`, `S1` + 0.92195445 * RANDN() AS `V39`, `S1` + 0.92195445 * RANDN() AS `V40`, `S1` + 0.92195445 * RANDN() AS `V41`, `S1` + 0.92195445 * RANDN() AS `V42`, `S1` + 0.92195445 * RANDN() AS `V43`, `S1` + 0.92195445 * RANDN() AS `V44`, `S1` + 0.92195445 * RANDN() AS `V45`, `S1` + 0.92195445 * RANDN() AS `V46`, `S1` + 0.92195445 * RANDN() AS `V47`, `S1` + 0.92195445 * RANDN() AS `V48`, `S1` + 0.92195445 * RANDN() AS `V49`, `S1` + 0.92195445 * RANDN() AS `V50`, `S1` + 0.92195445 * RANDN() AS `V51`, `S1` + 0.92195445 * RANDN() AS `V52`, `S1` + 0.92195445 * RANDN() AS `V53`, `S1` + 0.92195445 * RANDN() AS `V54`, `S1` + 0.92195445 * RANDN() AS `V55`, `S1` + 0.92195445 * RANDN() AS `V56`, `S1` + 0.92195445 * RANDN() AS `V57`, `S1` + 0.92195445 * RANDN() AS `V58`, `S1` + 0.92195445 * RANDN() AS `V59`, `S1` + 0.92195445 * RANDN() AS `V60`, `S1` + 0.92195445 * RANDN() AS `V61`, `S1` + 0.92195445 * RANDN() AS `V62`, `S1` + 0.92195445 * RANDN() AS `V63`, `S1` + 0.92195445 * RANDN() AS `V64`, `S1` + 0.92195445 * RANDN() AS `V65`, `S1` + 0.92195445 * RANDN() AS `V66`, `S1` + 0.92195445 * RANDN() AS `V67`, `S1` + 0.92195445 * RANDN() AS `V68`, `S1` + 0.92195445 * RANDN() AS `V69`, `S1` + 0.92195445 * RANDN() AS `V70`, `S1` + 0.92195445 * RANDN() AS `V71`, `S1` + 0.92195445 * RANDN() AS `V72`, `S1` + 0.92195445 * RANDN() AS `V73`, `S1` + 0.92195445 * RANDN() AS `V74`, `S1` + 0.92195445 * RANDN() AS `V75`, `S1` + 0.92195445 * RANDN() AS `V76`, `S1` + 0.92195445 * RANDN() AS `V77`, `S1` + 0.92195445 * RANDN() AS `V78`, `S1` + 0.92195445 * RANDN() AS `V79`, `S1` + 0.92195445 * RANDN() AS `V80`, `S1` + 0.92195445 * RANDN() AS `V81`, `S1` + 0.92195445 * RANDN() AS `V82`, `S1` + 0.92195445 * RANDN() AS `V83`, `S1` + 0.92195445 * RANDN() AS `V84`, `S1` + 0.92195445 * RANDN() AS `V85`, `S1` + 0.92195445 * RANDN() AS `V86`, `S1` + 0.92195445 * RANDN() AS `V87`, `S1` + 0.92195445 * RANDN() AS `V88`, `S1` + 0.92195445 * RANDN() AS `V89`, `S1` + 0.92195445 * RANDN() AS `V90`, `S1` + 0.92195445 * RANDN() AS `V91`, `S1` + 0.92195445 * RANDN() AS `V92`, `S1` + 0.92195445 * RANDN() AS `V93`, `S1` + 0.92195445 * RANDN() AS `V94`, `S1` + 0.92195445 * RANDN() AS `V95`, `S1` + 0.92195445 * RANDN() AS `V96`, `S1` + 0.92195445 * RANDN() AS `V97`, `S1` + 0.92195445 * RANDN() AS `V98`, `S1` + 0.92195445 * RANDN() AS `V99`, `S1` + 0.92195445 * RANDN() AS `V100`, `S1` + 0.92195445 * RANDN() AS `V101`, `S1` + 0.92195445 * RANDN() AS `V102`, `S1` + 0.92195445 * RANDN() AS `V103`, `S1` + 0.92195445 * RANDN() AS `V104`, `S1` + 0.92195445 * RANDN() AS `V105`, `S1` + 0.92195445 * RANDN() AS `V106`, `S1` + 0.92195445 * RANDN() AS `V107`, `S1` + 0.92195445 * RANDN() AS `V108`, `S1` + 0.92195445 * RANDN() AS `V109`, `S1` + 0.92195445 * RANDN() AS `V110`, `S1` + 0.92195445 * RANDN() AS `V111`, `S1` + 0.92195445 * RANDN() AS `V112`, `S1` + 0.92195445 * RANDN() AS `V113`, `S1` + 0.92195445 * RANDN() AS `V114`, `S1` + 0.92195445 * RANDN() AS `V115`, `S1` + 0.92195445 * RANDN() AS `V116`, `S1` + 0.92195445 * RANDN() AS `V117`, `S1` + 0.92195445 * RANDN() AS `V118`, `S1` + 0.92195445 * RANDN() AS `V119`, `S1` + 0.92195445 * RANDN() AS `V120`, `S1` + 0.92195445 * RANDN() AS `V121`, `S1` + 0.92195445 * RANDN() AS `V122`, `S1` + 0.92195445 * RANDN() AS `V123`, `S1` + 0.92195445 * RANDN() AS `V124`, `S1` + 0.92195445 * RANDN() AS `V125`, `S1` + 0.92195445 * RANDN() AS `V126`, `S1` + 0.92195445 * RANDN() AS `V127`, `S1` + 0.92195445 * RANDN() AS `V128`, `S1` + 0.92195445 * RANDN() AS `V129`, `S1` + 0.92195445 * RANDN() AS `V130`, `S1` + 0.92195445 * RANDN() AS `V131`, `S1` + 0.92195445 * RANDN() AS `V132`, `S1` + 0.92195445 * RANDN() AS `V133`, `S1` + 0.92195445 * RANDN() AS `V134`, `S1` + 0.92195445 * RANDN() AS `V135`, `S1` + 0.92195445 * RANDN() AS `V136`, `S1` + 0.92195445 * RANDN() AS `V137`, `S1` + 0.92195445 * RANDN() AS `V138`, `S1` + 0.92195445 * RANDN() AS `V139`, `S1` + 0.92195445 * RANDN() AS `V140`, `S1` + 0.92195445 * RANDN() AS `V141`, `S1` + 0.92195445 * RANDN() AS `V142`, `S1` + 0.92195445 * RANDN() AS `V143`, `S1` + 0.92195445 * RANDN() AS `V144`, `S1` + 0.92195445 * RANDN() AS `V145`, `S1` + 0.92195445 * RANDN() AS `V146`, `S1` + 0.92195445 * RANDN() AS `V147`, `S1` + 0.92195445 * RANDN() AS `V148`, `S1` + 0.92195445 * RANDN() AS `V149`, `S1` + 0.92195445 * RANDN() AS `V150`, `S1` + 0.92195445 * RANDN() AS `V151`, `S1` + 0.92195445 * RANDN() AS `V152`, `S1` + 0.92195445 * RANDN() AS `V153`, `S1` + 0.92195445 * RANDN() AS `V154`, `S1` + 0.92195445 * RANDN() AS `V155`, `S1` + 0.92195445 * RANDN() AS `V156`, `S1` + 0.92195445 * RANDN() AS `V157`, `S1` + 0.92195445 * RANDN() AS `V158`, `S1` + 0.92195445 * RANDN() AS `V159`, `S1` + 0.92195445 * RANDN() AS `V160`, `S1` + 0.92195445 * RANDN() AS `V161`, `S1` + 0.92195445 * RANDN() AS `V162`, `S1` + 0.92195445 * RANDN() AS `V163`, `S1` + 0.92195445 * RANDN() AS `V164`, `S1` + 0.92195445 * RANDN() AS `V165`, `S1` + 0.92195445 * RANDN() AS `V166`, `S1` + 0.92195445 * RANDN() AS `V167`, `S1` + 0.92195445 * RANDN() AS `V168`, `S1` + 0.92195445 * RANDN() AS `V169`, `S1` + 0.92195445 * RANDN() AS `V170`, `S1` + 0.92195445 * RANDN() AS `V171`, `S1` + 0.92195445 * RANDN() AS `V172`, `S1` + 0.92195445 * RANDN() AS `V173`, `S1` + 0.92195445 * RANDN() AS `V174`, `S1` + 0.92195445 * RANDN() AS `V175`, `S1` + 0.92195445 * RANDN() AS `V176`, `S1` + 0.92195445 * RANDN() AS `V177`, `S1` + 0.92195445 * RANDN() AS `V178`, `S1` + 0.92195445 * RANDN() AS `V179`, `S1` + 0.92195445 * RANDN() AS `V180`, `S1` + 0.92195445 * RANDN() AS `V181`, `S1` + 0.92195445 * RANDN() AS `V182`, `S1` + 0.92195445 * RANDN() AS `V183`, `S1` + 0.92195445 * RANDN() AS `V184`, `S1` + 0.92195445 * RANDN() AS `V185`, `S1` + 0.92195445 * RANDN() AS `V186`, `S1` + 0.92195445 * RANDN() AS `V187`, `S1` + 0.92195445 * RANDN() AS `V188`, `S1` + 0.92195445 * RANDN() AS `V189`, `S1` + 0.92195445 * RANDN() AS `V190`, `S1` + 0.92195445 * RANDN() AS `V191`, `S1` + 0.92195445 * RANDN() AS `V192`, `S1` + 0.92195445 * RANDN() AS `V193`, `S1` + 0.92195445 * RANDN() AS `V194`, `S1` + 0.92195445 * RANDN() AS `V195`, `S1` + 0.92195445 * RANDN() AS `V196`, `S1` + 0.92195445 * RANDN() AS `V197`, `S1` + 0.92195445 * RANDN() AS `V198`, `S1` + 0.92195445 * RANDN() AS `V199`, `S1` + 0.92195445 * RANDN() AS `V200`, `S1` + 0.92195445 * RANDN() AS `V201`, `S1` + 0.92195445 * RANDN() AS `V202`, `S1` + 0.92195445 * RANDN() AS `V203`, `S1` + 0.92195445 * RANDN() AS `V204`, `S1` + 0.92195445 * RANDN() AS `V205`, `S1` + 0.92195445 * RANDN() AS `V206`, `S1` + 0.92195445 * RANDN() AS `V207`, `S1` + 0.92195445 * RANDN() AS `V208`, `S1` + 0.92195445 * RANDN() AS `V209`, `S1` + 0.92195445 * RANDN() AS `V210`, `S1` + 0.92195445 * RANDN() AS `V211`, `S1` + 0.92195445 * RANDN() AS `V212`, `S1` + 0.92195445 * RANDN() AS `V213`, `S1` + 0.92195445 * RANDN() AS `V214`, `S1` + 0.92195445 * RANDN() AS `V215`, `S1` + 0.92195445 * RANDN() AS `V216`, `S1` + 0.92195445 * RANDN() AS `V217`, `S1` + 0.92195445 * RANDN() AS `V218`, `S1` + 0.92195445 * RANDN() AS `V219`, `S1` + 0.92195445 * RANDN() AS `V220`, `S1` + 0.92195445 * RANDN() AS `V221`, `S1` + 0.92195445 * RANDN() AS `V222`, `S1` + 0.92195445 * RANDN() AS `V223`, `S1` + 0.92195445 * RANDN() AS `V224`, `S1` + 0.92195445 * RANDN() AS `V225`, `S1` + 0.92195445 * RANDN() AS `V226`, `S1` + 0.92195445 * RANDN() AS `V227`, `S1` + 0.92195445 * RANDN() AS `V228`, `S1` + 0.92195445 * RANDN() AS `V229`, `S1` + 0.92195445 * RANDN() AS `V230`, `S1` + 0.92195445 * RANDN() AS `V231`, `S1` + 0.92195445 * RANDN() AS `V232`, `S1` + 0.92195445 * RANDN() AS `V233`, `S1` + 0.92195445 * RANDN() AS `V234`, `S1` + 0.92195445 * RANDN() AS `V235`, `S1` + 0.92195445 * RANDN() AS `V236`, `S1` + 0.92195445 * RANDN() AS `V237`, `S1` + 0.92195445 * RANDN() AS `V238`, `S1` + 0.92195445 * RANDN() AS `V239`, `S1` + 0.92195445 * RANDN() AS `V240`, `S1` + 0.92195445 * RANDN() AS `V241`, `S1` + 0.92195445 * RANDN() AS `V242`, `S1` + 0.92195445 * RANDN() AS `V243`, `S1` + 0.92195445 * RANDN() AS `V244`, `S1` + 0.92195445 * RANDN() AS `V245`, `S1` + 0.92195445 * RANDN() AS `V246`, `S1` + 0.92195445 * RANDN() AS `V247`, `S1` + 0.92195445 * RANDN() AS `V248`, `S1` + 0.92195445 * RANDN() AS `V249`, `S1` + 0.92195445 * RANDN() AS `V250`, `S1` + 0.92195445 * RANDN() AS `V251`, `S1` + 0.92195445 * RANDN() AS `V252`, `S1` + 0.92195445 * RANDN() AS `V253`, `S1` + 0.92195445 * RANDN() AS `V254`, `S1` + 0.92195445 * RANDN() AS `V255`, `S1` + 0.92195445 * RANDN() AS `V256`, `S1` + 0.92195445 * RANDN() AS `V257`, `S1` + 0.92195445 * RANDN() AS `V258`, `S1` + 0.92195445 * RANDN() AS `V259`, `S1` + 0.92195445 * RANDN() AS `V260`, `S1` + 0.92195445 * RANDN() AS `V261`, `S1` + 0.92195445 * RANDN() AS `V262`, `S1` + 0.92195445 * RANDN() AS `V263`, `S1` + 0.92195445 * RANDN() AS `V264`, `S1` + 0.92195445 * RANDN() AS `V265`, `S1` + 0.92195445 * RANDN() AS `V266`, `S1` + 0.92195445 * RANDN() AS `V267`, `S1` + 0.92195445 * RANDN() AS `V268`, `S1` + 0.92195445 * RANDN() AS `V269`, `S1` + 0.92195445 * RANDN() AS `V270`, `S1` + 0.92195445 * RANDN() AS `V271`, `S1` + 0.92195445 * RANDN() AS `V272`, `S1` + 0.92195445 * RANDN() AS `V273`, `S1` + 0.92195445 * RANDN() AS `V274`, `S1` + 0.92195445 * RANDN() AS `V275`, `S1` + 0.92195445 * RANDN() AS `V276`, `S1` + 0.92195445 * RANDN() AS `V277`, `S1` + 0.92195445 * RANDN() AS `V278`, `S1` + 0.92195445 * RANDN() AS `V279`, `S1` + 0.92195445 * RANDN() AS `V280`, `S1` + 0.92195445 * RANDN() AS `V281`, `S1` + 0.92195445 * RANDN() AS `V282`, `S1` + 0.92195445 * RANDN() AS `V283`, `S1` + 0.92195445 * RANDN() AS `V284`, `S1` + 0.92195445 * RANDN() AS `V285`, `S1` + 0.92195445 * RANDN() AS `V286`, `S1` + 0.92195445 * RANDN() AS `V287`, `S1` + 0.92195445 * RANDN() AS `V288`, `S1` + 0.92195445 * RANDN() AS `V289`, `S1` + 0.92195445 * RANDN() AS `V290`, `S1` + 0.92195445 * RANDN() AS `V291`, `S1` + 0.92195445 * RANDN() AS `V292`, `S1` + 0.92195445 * RANDN() AS `V293`, `S1` + 0.92195445 * RANDN() AS `V294`, `S1` + 0.92195445 * RANDN() AS `V295`, `S1` + 0.92195445 * RANDN() AS `V296`, `S1` + 0.92195445 * RANDN() AS `V297`, `S1` + 0.92195445 * RANDN() AS `V298`, `S1` + 0.92195445 * RANDN() AS `V299`, `S1` + 0.92195445 * RANDN() AS `V300`, `S1` + 0.92195445 * RANDN() AS `V301`, `S1` + 0.92195445 * RANDN() AS `V302`, `S1` + 0.92195445 * RANDN() AS `V303`, `S1` + 0.92195445 * RANDN() AS `V304`, `S1` + 0.92195445 * RANDN() AS `V305`, `S1` + 0.92195445 * RANDN() AS `V306`, `S1` + 0.92195445 * RANDN() AS `V307`, `S1` + 0.92195445 * RANDN() AS `V308`, `S1` + 0.92195445 * RANDN() AS `V309`, `S1` + 0.92195445 * RANDN() AS `V310`, `S1` + 0.92195445 * RANDN() AS `V311`, `S1` + 0.92195445 * RANDN() AS `V312`, `S1` + 0.92195445 * RANDN() AS `V313`, `S1` + 0.92195445 * RANDN() AS `V314`, `S1` + 0.92195445 * RANDN() AS `V315`, `S1` + 0.92195445 * RANDN() AS `V316`, `S1` + 0.92195445 * RANDN() AS `V317`, `S1` + 0.92195445 * RANDN() AS `V318`, `S1` + 0.92195445 * RANDN() AS `V319`, `S1` + 0.92195445 * RANDN() AS `V320`, `S1` + 0.92195445 * RANDN() AS `V321`, `S1` + 0.92195445 * RANDN() AS `V322`, `S1` + 0.92195445 * RANDN() AS `V323`, `S1` + 0.92195445 * RANDN() AS `V324`, `S1` + 0.92195445 * RANDN() AS `V325`, `S1` + 0.92195445 * RANDN() AS `V326`, `S1` + 0.92195445 * RANDN() AS `V327`, `S1` + 0.92195445 * RANDN() AS `V328`, `S1` + 0.92195445 * RANDN() AS `V329`, `S1` + 0.92195445 * RANDN() AS `V330`, `S1` + 0.92195445 * RANDN() AS `V331`, `S1` + 0.92195445 * RANDN() AS `V332`, `S1` + 0.92195445 * RANDN() AS `V333`, `S1` + 0.92195445 * RANDN() AS `V334`, `S1` + 0.92195445 * RANDN() AS `V335`, `S1` + 0.92195445 * RANDN() AS `V336`, `S1` + 0.92195445 * RANDN() AS `V337`, `S1` + 0.92195445 * RANDN() AS `V338`, `S1` + 0.92195445 * RANDN() AS `V339`, `S1` + 0.92195445 * RANDN() AS `V340`, `S1` + 0.92195445 * RANDN() AS `V341`, `S1` + 0.92195445 * RANDN() AS `V342`, `S1` + 0.92195445 * RANDN() AS `V343`, `S1` + 0.92195445 * RANDN() AS `V344`, `S1` + 0.92195445 * RANDN() AS `V345`, `S1` + 0.92195445 * RANDN() AS `V346`, `S1` + 0.92195445 * RANDN() AS `V347`, `S1` + 0.92195445 * RANDN() AS `V348`, `S1` + 0.92195445 * RANDN() AS `V349`, `S1` + 0.92195445 * RANDN() AS `V350`, `S1` + 0.92195445 * RANDN() AS `V351`, `S1` + 0.92195445 * RANDN() AS `V352`, `S1` + 0.92195445 * RANDN() AS `V353`, `S1` + 0.92195445 * RANDN() AS `V354`, `S1` + 0.92195445 * RANDN() AS `V355`, `S1` + 0.92195445 * RANDN() AS `V356`, `S1` + 0.92195445 * RANDN() AS `V357`, `S1` + 0.92195445 * RANDN() AS `V358`, `S1` + 0.92195445 * RANDN() AS `V359`, `S1` + 0.92195445 * RANDN() AS `V360`, `S1` + 0.92195445 * RANDN() AS `V361`, `S1` + 0.92195445 * RANDN() AS `V362`, `S1` + 0.92195445 * RANDN() AS `V363`, `S1` + 0.92195445 * RANDN() AS `V364`, `S1` + 0.92195445 * RANDN() AS `V365`, `S1` + 0.92195445 * RANDN() AS `V366`, `S1` + 0.92195445 * RANDN() AS `V367`, `S1` + 0.92195445 * RANDN() AS `V368`, `S1` + 0.92195445 * RANDN() AS `V369`, `S1` + 0.92195445 * RANDN() AS `V370`, `S1` + 0.92195445 * RANDN() AS `V371`, `S1` + 0.92195445 * RANDN() AS `V372`, `S1` + 0.92195445 * RANDN() AS `V373`, `S1` + 0.92195445 * RANDN() AS `V374`, `S1` + 0.92195445 * RANDN() AS `V375`, `S1` + 0.92195445 * RANDN() AS `V376`, `S1` + 0.92195445 * RANDN() AS `V377`, `S1` + 0.92195445 * RANDN() AS `V378`, `S1` + 0.92195445 * RANDN() AS `V379`, `S1` + 0.92195445 * RANDN() AS `V380`, `S1` + 0.92195445 * RANDN() AS `V381`, `S1` + 0.92195445 * RANDN() AS `V382`, `S1` + 0.92195445 * RANDN() AS `V383`, `S1` + 0.92195445 * RANDN() AS `V384`, `S1` + 0.92195445 * RANDN() AS `V385`, `S1` + 0.92195445 * RANDN() AS `V386`, `S1` + 0.92195445 * RANDN() AS `V387`, `S1` + 0.92195445 * RANDN() AS `V388`, `S1` + 0.92195445 * RANDN() AS `V389`, `S1` + 0.92195445 * RANDN() AS `V390`, `S1` + 0.92195445 * RANDN() AS `V391`, `S1` + 0.92195445 * RANDN() AS `V392`, `S1` + 0.92195445 * RANDN() AS `V393`, `S1` + 0.92195445 * RANDN() AS `V394`, `S1` + 0.92195445 * RANDN() AS `V395`, `S1` + 0.92195445 * RANDN() AS `V396`, `S1` + 0.92195445 * RANDN() AS `V397`, `S1` + 0.92195445 * RANDN() AS `V398`, `S1` + 0.92195445 * RANDN() AS `V399`, `S1` + 0.92195445 * RANDN() AS `V400`, `S1` + 0.92195445 * RANDN() AS `V401`, `S1` + 0.92195445 * RANDN() AS `V402`, `S1` + 0.92195445 * RANDN() AS `V403`, `S1` + 0.92195445 * RANDN() AS `V404`, `S1` + 0.92195445 * RANDN() AS `V405`, `S1` + 0.92195445 * RANDN() AS `V406`, `S1` + 0.92195445 * RANDN() AS `V407`, `S1` + 0.92195445 * RANDN() AS `V408`, `S1` + 0.92195445 * RANDN() AS `V409`, `S1` + 0.92195445 * RANDN() AS `V410`, `S1` + 0.92195445 * RANDN() AS `V411`, `S1` + 0.92195445 * RANDN() AS `V412`, `S1` + 0.92195445 * RANDN() AS `V413`, `S1` + 0.92195445 * RANDN() AS `V414`, `S1` + 0.92195445 * RANDN() AS `V415`, `S1` + 0.92195445 * RANDN() AS `V416`, `S1` + 0.92195445 * RANDN() AS `V417`, `S1` + 0.92195445 * RANDN() AS `V418`, `S1` + 0.92195445 * RANDN() AS `V419`, `S1` + 0.92195445 * RANDN() AS `V420`, `S1` + 0.92195445 * RANDN() AS `V421`, `S1` + 0.92195445 * RANDN() AS `V422`, `S1` + 0.92195445 * RANDN() AS `V423`, `S1` + 0.92195445 * RANDN() AS `V424`, `S1` + 0.92195445 * RANDN() AS `V425`, `S1` + 0.92195445 * RANDN() AS `V426`, `S1` + 0.92195445 * RANDN() AS `V427`, `S1` + 0.92195445 * RANDN() AS `V428`, `S1` + 0.92195445 * RANDN() AS `V429`, `S1` + 0.92195445 * RANDN() AS `V430`, `S1` + 0.92195445 * RANDN() AS `V431`, `S1` + 0.92195445 * RANDN() AS `V432`, `S1` + 0.92195445 * RANDN() AS `V433`, `S1` + 0.92195445 * RANDN() AS `V434`, `S1` + 0.92195445 * RANDN() AS `V435`, `S1` + 0.92195445 * RANDN() AS `V436`, `S1` + 0.92195445 * RANDN() AS `V437`, `S1` + 0.92195445 * RANDN() AS `V438`, `S1` + 0.92195445 * RANDN() AS `V439`, `S1` + 0.92195445 * RANDN() AS `V440`, `S1` + 0.92195445 * RANDN() AS `V441`, `S1` + 0.92195445 * RANDN() AS `V442`, `S1` + 0.92195445 * RANDN() AS `V443`, `S1` + 0.92195445 * RANDN() AS `V444`, `S1` + 0.92195445 * RANDN() AS `V445`, `S1` + 0.92195445 * RANDN() AS `V446`, `S1` + 0.92195445 * RANDN() AS `V447`, `S1` + 0.92195445 * RANDN() AS `V448`, `S1` + 0.92195445 * RANDN() AS `V449`, `S1` + 0.92195445 * RANDN() AS `V450`, `S1` + 0.92195445 * RANDN() AS `V451`, `S1` + 0.92195445 * RANDN() AS `V452`, `S1` + 0.92195445 * RANDN() AS `V453`, `S1` + 0.92195445 * RANDN() AS `V454`, `S1` + 0.92195445 * RANDN() AS `V455`, `S1` + 0.92195445 * RANDN() AS `V456`, `S1` + 0.92195445 * RANDN() AS `V457`, `S1` + 0.92195445 * RANDN() AS `V458`, `S1` + 0.92195445 * RANDN() AS `V459`, `S1` + 0.92195445 * RANDN() AS `V460`, `S1` + 0.92195445 * RANDN() AS `V461`, `S1` + 0.92195445 * RANDN() AS `V462`, `S1` + 0.92195445 * RANDN() AS `V463`, `S1` + 0.92195445 * RANDN() AS `V464`, `S1` + 0.92195445 * RANDN() AS `V465`, `S1` + 0.92195445 * RANDN() AS `V466`, `S1` + 0.92195445 * RANDN() AS `V467`, `S1` + 0.92195445 * RANDN() AS `V468`, `S1` + 0.92195445 * RANDN() AS `V469`, `S1` + 0.92195445 * RANDN() AS `V470`, `S1` + 0.92195445 * RANDN() AS `V471`, `S1` + 0.92195445 * RANDN() AS `V472`, `S1` + 0.92195445 * RANDN() AS `V473`, `S1` + 0.92195445 * RANDN() AS `V474`, `S1` + 0.92195445 * RANDN() AS `V475`, `S1` + 0.92195445 * RANDN() AS `V476`, `S1` + 0.92195445 * RANDN() AS `V477`, `S1` + 0.92195445 * RANDN() AS `V478`, `S1` + 0.92195445 * RANDN() AS `V479`, `S1` + 0.92195445 * RANDN() AS `V480`, `S1` + 0.92195445 * RANDN() AS `V481`, `S1` + 0.92195445 * RANDN() AS `V482`, `S1` + 0.92195445 * RANDN() AS `V483`, `S1` + 0.92195445 * RANDN() AS `V484`, `S1` + 0.92195445 * RANDN() AS `V485`, `S1` + 0.92195445 * RANDN() AS `V486`, `S1` + 0.92195445 * RANDN() AS `V487`, `S1` + 0.92195445 * RANDN() AS `V488`, `S1` + 0.92195445 * RANDN() AS `V489`, `S1` + 0.92195445 * RANDN() AS `V490`, `S1` + 0.92195445 * RANDN() AS `V491`, `S1` + 0.92195445 * RANDN() AS `V492`, `S1` + 0.92195445 * RANDN() AS `V493`, `S1` + 0.92195445 * RANDN() AS `V494`, `S1` + 0.92195445 * RANDN() AS `V495`, `S1` + 0.92195445 * RANDN() AS `V496`, `S1` + 0.92195445 * RANDN() AS `V497`, `S1` + 0.92195445 * RANDN() AS `V498`, `S1` + 0.92195445 * RANDN() AS `V499`, `S1` + 0.92195445 * RANDN() AS `V500`
FROM `analyis_tbl`) `okmobmqkrm`
17/12/21 17:56:50 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:51329 in memory (size: 7.2 KB, free: 2004.6 MB)
17/12/21 17:56:50 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:51329 in memory (size: 5.6 KB, free: 2004.6 MB)
17/12/21 17:56:50 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:51329 in memory (size: 5.6 KB, free: 2004.6 MB)
17/12/21 17:56:50 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:51329 in memory (size: 3.7 KB, free: 2004.6 MB)
17/12/21 17:56:50 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:51329 in memory (size: 3.7 KB, free: 2004.6 MB)
17/12/21 17:56:50 INFO ContextCleaner: Cleaned accumulator 238
17/12/21 17:56:50 INFO ContextCleaner: Cleaned shuffle 1
17/12/21 17:56:50 INFO ContextCleaner: Cleaned accumulator 69
17/12/21 17:56:50 INFO ContextCleaner: Cleaned accumulator 68
17/12/21 17:56:50 INFO ContextCleaner: Cleaned accumulator 67
17/12/21 17:56:50 INFO ContextCleaner: Cleaned accumulator 66
17/12/21 17:56:50 INFO ContextCleaner: Cleaned accumulator 65
17/12/21 17:56:50 INFO ContextCleaner: Cleaned accumulator 64
17/12/21 17:56:50 INFO ContextCleaner: Cleaned accumulator 63
17/12/21 17:56:50 INFO ContextCleaner: Cleaned accumulator 62
17/12/21 17:56:50 INFO ContextCleaner: Cleaned accumulator 61
17/12/21 17:56:50 INFO ContextCleaner: Cleaned accumulator 60
17/12/21 17:56:50 INFO ContextCleaner: Cleaned accumulator 59
17/12/21 17:56:50 INFO ContextCleaner: Cleaned accumulator 58
17/12/21 17:56:51 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 17:56:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:56:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz2`
WHERE (0 = 1)
17/12/21 17:56:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:56:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 17:56:51 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 17:56:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/21 17:56:51 INFO DAGScheduler: Got job 3 (take at <unknown>:0) with 1 output partitions
17/12/21 17:56:51 INFO DAGScheduler: Final stage: ResultStage 8 (take at <unknown>:0)
17/12/21 17:56:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/12/21 17:56:51 INFO DAGScheduler: Missing parents: List()
17/12/21 17:56:51 INFO DAGScheduler: Submitting ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18), which has no missing parents
17/12/21 17:56:51 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 296.4 KB, free 2004.0 MB)
17/12/21 17:56:51 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 78.6 KB, free 2003.9 MB)
17/12/21 17:56:51 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:51329 (size: 78.6 KB, free: 2004.5 MB)
17/12/21 17:56:51 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/12/21 17:56:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18)
17/12/21 17:56:51 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/21 17:56:51 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5913 bytes)
17/12/21 17:56:51 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/12/21 17:56:51 INFO BlockManager: Found block rdd_12_0 locally
17/12/21 17:56:51 INFO CodeGenerator: Code generated in 21.233262 ms
17/12/21 17:56:52 INFO CodeGenerator: Code generated in 319.291099 ms
17/12/21 17:56:52 INFO CodeGenerator: Code generated in 109.444091 ms
17/12/21 17:57:01 INFO MemoryStore: Block rdd_31_0 stored as values in memory (estimated size 6.7 MB, free 1997.2 MB)
17/12/21 17:57:01 INFO BlockManagerInfo: Added rdd_31_0 in memory on 127.0.0.1:51329 (size: 6.7 MB, free: 1997.8 MB)
17/12/21 17:57:01 WARN Executor: 1 block locks were not released by TID = 8:
[rdd_31_0]
17/12/21 17:57:01 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 72956 bytes result sent to driver
17/12/21 17:57:01 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 10186 ms on localhost (executor driver) (1/1)
17/12/21 17:57:01 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/21 17:57:01 INFO DAGScheduler: ResultStage 8 (take at <unknown>:0) finished in 10.202 s
17/12/21 17:57:01 INFO DAGScheduler: Job 3 finished: take at <unknown>:0, took 10.214707 s
17/12/21 17:57:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:57:02 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1b2072a72e0c
17/12/21 17:57:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:57:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1b2072a72e0c` AS `zzz3`
WHERE (0 = 1)
17/12/21 17:57:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:57:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1b2072a72e0c`
17/12/21 17:57:02 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 17:57:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:57:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz4`
WHERE (0 = 1)
17/12/21 17:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:57:03 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.01) AS `V1`, (`V2` < 0.01) AS `V2`, (`V3` < 0.01) AS `V3`, (`V4` < 0.01) AS `V4`, (`V5` < 0.01) AS `V5`, (`V6` < 0.01) AS `V6`, (`V7` < 0.01) AS `V7`, (`V8` < 0.01) AS `V8`, (`V9` < 0.01) AS `V9`, (`V10` < 0.01) AS `V10`, (`V11` < 0.01) AS `V11`, (`V12` < 0.01) AS `V12`, (`V13` < 0.01) AS `V13`, (`V14` < 0.01) AS `V14`, (`V15` < 0.01) AS `V15`, (`V16` < 0.01) AS `V16`, (`V17` < 0.01) AS `V17`, (`V18` < 0.01) AS `V18`, (`V19` < 0.01) AS `V19`, (`V20` < 0.01) AS `V20`, (`V21` < 0.01) AS `V21`, (`V22` < 0.01) AS `V22`, (`V23` < 0.01) AS `V23`, (`V24` < 0.01) AS `V24`, (`V25` < 0.01) AS `V25`, (`V26` < 0.01) AS `V26`, (`V27` < 0.01) AS `V27`, (`V28` < 0.01) AS `V28`, (`V29` < 0.01) AS `V29`, (`V30` < 0.01) AS `V30`, (`V31` < 0.01) AS `V31`, (`V32` < 0.01) AS `V32`, (`V33` < 0.01) AS `V33`, (`V34` < 0.01) AS `V34`, (`V35` < 0.01) AS `V35`, (`V36` < 0.01) AS `V36`, (`V37` < 0.01) AS `V37`, (`V38` < 0.01) AS `V38`, (`V39` < 0.01) AS `V39`, (`V40` < 0.01) AS `V40`, (`V41` < 0.01) AS `V41`, (`V42` < 0.01) AS `V42`, (`V43` < 0.01) AS `V43`, (`V44` < 0.01) AS `V44`, (`V45` < 0.01) AS `V45`, (`V46` < 0.01) AS `V46`, (`V47` < 0.01) AS `V47`, (`V48` < 0.01) AS `V48`, (`V49` < 0.01) AS `V49`, (`V50` < 0.01) AS `V50`, (`V51` < 0.01) AS `V51`, (`V52` < 0.01) AS `V52`, (`V53` < 0.01) AS `V53`, (`V54` < 0.01) AS `V54`, (`V55` < 0.01) AS `V55`, (`V56` < 0.01) AS `V56`, (`V57` < 0.01) AS `V57`, (`V58` < 0.01) AS `V58`, (`V59` < 0.01) AS `V59`, (`V60` < 0.01) AS `V60`, (`V61` < 0.01) AS `V61`, (`V62` < 0.01) AS `V62`, (`V63` < 0.01) AS `V63`, (`V64` < 0.01) AS `V64`, (`V65` < 0.01) AS `V65`, (`V66` < 0.01) AS `V66`, (`V67` < 0.01) AS `V67`, (`V68` < 0.01) AS `V68`, (`V69` < 0.01) AS `V69`, (`V70` < 0.01) AS `V70`, (`V71` < 0.01) AS `V71`, (`V72` < 0.01) AS `V72`, (`V73` < 0.01) AS `V73`, (`V74` < 0.01) AS `V74`, (`V75` < 0.01) AS `V75`, (`V76` < 0.01) AS `V76`, (`V77` < 0.01) AS `V77`, (`V78` < 0.01) AS `V78`, (`V79` < 0.01) AS `V79`, (`V80` < 0.01) AS `V80`, (`V81` < 0.01) AS `V81`, (`V82` < 0.01) AS `V82`, (`V83` < 0.01) AS `V83`, (`V84` < 0.01) AS `V84`, (`V85` < 0.01) AS `V85`, (`V86` < 0.01) AS `V86`, (`V87` < 0.01) AS `V87`, (`V88` < 0.01) AS `V88`, (`V89` < 0.01) AS `V89`, (`V90` < 0.01) AS `V90`, (`V91` < 0.01) AS `V91`, (`V92` < 0.01) AS `V92`, (`V93` < 0.01) AS `V93`, (`V94` < 0.01) AS `V94`, (`V95` < 0.01) AS `V95`, (`V96` < 0.01) AS `V96`, (`V97` < 0.01) AS `V97`, (`V98` < 0.01) AS `V98`, (`V99` < 0.01) AS `V99`, (`V100` < 0.01) AS `V100`, (`V101` < 0.01) AS `V101`, (`V102` < 0.01) AS `V102`, (`V103` < 0.01) AS `V103`, (`V104` < 0.01) AS `V104`, (`V105` < 0.01) AS `V105`, (`V106` < 0.01) AS `V106`, (`V107` < 0.01) AS `V107`, (`V108` < 0.01) AS `V108`, (`V109` < 0.01) AS `V109`, (`V110` < 0.01) AS `V110`, (`V111` < 0.01) AS `V111`, (`V112` < 0.01) AS `V112`, (`V113` < 0.01) AS `V113`, (`V114` < 0.01) AS `V114`, (`V115` < 0.01) AS `V115`, (`V116` < 0.01) AS `V116`, (`V117` < 0.01) AS `V117`, (`V118` < 0.01) AS `V118`, (`V119` < 0.01) AS `V119`, (`V120` < 0.01) AS `V120`, (`V121` < 0.01) AS `V121`, (`V122` < 0.01) AS `V122`, (`V123` < 0.01) AS `V123`, (`V124` < 0.01) AS `V124`, (`V125` < 0.01) AS `V125`, (`V126` < 0.01) AS `V126`, (`V127` < 0.01) AS `V127`, (`V128` < 0.01) AS `V128`, (`V129` < 0.01) AS `V129`, (`V130` < 0.01) AS `V130`, (`V131` < 0.01) AS `V131`, (`V132` < 0.01) AS `V132`, (`V133` < 0.01) AS `V133`, (`V134` < 0.01) AS `V134`, (`V135` < 0.01) AS `V135`, (`V136` < 0.01) AS `V136`, (`V137` < 0.01) AS `V137`, (`V138` < 0.01) AS `V138`, (`V139` < 0.01) AS `V139`, (`V140` < 0.01) AS `V140`, (`V141` < 0.01) AS `V141`, (`V142` < 0.01) AS `V142`, (`V143` < 0.01) AS `V143`, (`V144` < 0.01) AS `V144`, (`V145` < 0.01) AS `V145`, (`V146` < 0.01) AS `V146`, (`V147` < 0.01) AS `V147`, (`V148` < 0.01) AS `V148`, (`V149` < 0.01) AS `V149`, (`V150` < 0.01) AS `V150`, (`V151` < 0.01) AS `V151`, (`V152` < 0.01) AS `V152`, (`V153` < 0.01) AS `V153`, (`V154` < 0.01) AS `V154`, (`V155` < 0.01) AS `V155`, (`V156` < 0.01) AS `V156`, (`V157` < 0.01) AS `V157`, (`V158` < 0.01) AS `V158`, (`V159` < 0.01) AS `V159`, (`V160` < 0.01) AS `V160`, (`V161` < 0.01) AS `V161`, (`V162` < 0.01) AS `V162`, (`V163` < 0.01) AS `V163`, (`V164` < 0.01) AS `V164`, (`V165` < 0.01) AS `V165`, (`V166` < 0.01) AS `V166`, (`V167` < 0.01) AS `V167`, (`V168` < 0.01) AS `V168`, (`V169` < 0.01) AS `V169`, (`V170` < 0.01) AS `V170`, (`V171` < 0.01) AS `V171`, (`V172` < 0.01) AS `V172`, (`V173` < 0.01) AS `V173`, (`V174` < 0.01) AS `V174`, (`V175` < 0.01) AS `V175`, (`V176` < 0.01) AS `V176`, (`V177` < 0.01) AS `V177`, (`V178` < 0.01) AS `V178`, (`V179` < 0.01) AS `V179`, (`V180` < 0.01) AS `V180`, (`V181` < 0.01) AS `V181`, (`V182` < 0.01) AS `V182`, (`V183` < 0.01) AS `V183`, (`V184` < 0.01) AS `V184`, (`V185` < 0.01) AS `V185`, (`V186` < 0.01) AS `V186`, (`V187` < 0.01) AS `V187`, (`V188` < 0.01) AS `V188`, (`V189` < 0.01) AS `V189`, (`V190` < 0.01) AS `V190`, (`V191` < 0.01) AS `V191`, (`V192` < 0.01) AS `V192`, (`V193` < 0.01) AS `V193`, (`V194` < 0.01) AS `V194`, (`V195` < 0.01) AS `V195`, (`V196` < 0.01) AS `V196`, (`V197` < 0.01) AS `V197`, (`V198` < 0.01) AS `V198`, (`V199` < 0.01) AS `V199`, (`V200` < 0.01) AS `V200`, (`V201` < 0.01) AS `V201`, (`V202` < 0.01) AS `V202`, (`V203` < 0.01) AS `V203`, (`V204` < 0.01) AS `V204`, (`V205` < 0.01) AS `V205`, (`V206` < 0.01) AS `V206`, (`V207` < 0.01) AS `V207`, (`V208` < 0.01) AS `V208`, (`V209` < 0.01) AS `V209`, (`V210` < 0.01) AS `V210`, (`V211` < 0.01) AS `V211`, (`V212` < 0.01) AS `V212`, (`V213` < 0.01) AS `V213`, (`V214` < 0.01) AS `V214`, (`V215` < 0.01) AS `V215`, (`V216` < 0.01) AS `V216`, (`V217` < 0.01) AS `V217`, (`V218` < 0.01) AS `V218`, (`V219` < 0.01) AS `V219`, (`V220` < 0.01) AS `V220`, (`V221` < 0.01) AS `V221`, (`V222` < 0.01) AS `V222`, (`V223` < 0.01) AS `V223`, (`V224` < 0.01) AS `V224`, (`V225` < 0.01) AS `V225`, (`V226` < 0.01) AS `V226`, (`V227` < 0.01) AS `V227`, (`V228` < 0.01) AS `V228`, (`V229` < 0.01) AS `V229`, (`V230` < 0.01) AS `V230`, (`V231` < 0.01) AS `V231`, (`V232` < 0.01) AS `V232`, (`V233` < 0.01) AS `V233`, (`V234` < 0.01) AS `V234`, (`V235` < 0.01) AS `V235`, (`V236` < 0.01) AS `V236`, (`V237` < 0.01) AS `V237`, (`V238` < 0.01) AS `V238`, (`V239` < 0.01) AS `V239`, (`V240` < 0.01) AS `V240`, (`V241` < 0.01) AS `V241`, (`V242` < 0.01) AS `V242`, (`V243` < 0.01) AS `V243`, (`V244` < 0.01) AS `V244`, (`V245` < 0.01) AS `V245`, (`V246` < 0.01) AS `V246`, (`V247` < 0.01) AS `V247`, (`V248` < 0.01) AS `V248`, (`V249` < 0.01) AS `V249`, (`V250` < 0.01) AS `V250`, (`V251` < 0.01) AS `V251`, (`V252` < 0.01) AS `V252`, (`V253` < 0.01) AS `V253`, (`V254` < 0.01) AS `V254`, (`V255` < 0.01) AS `V255`, (`V256` < 0.01) AS `V256`, (`V257` < 0.01) AS `V257`, (`V258` < 0.01) AS `V258`, (`V259` < 0.01) AS `V259`, (`V260` < 0.01) AS `V260`, (`V261` < 0.01) AS `V261`, (`V262` < 0.01) AS `V262`, (`V263` < 0.01) AS `V263`, (`V264` < 0.01) AS `V264`, (`V265` < 0.01) AS `V265`, (`V266` < 0.01) AS `V266`, (`V267` < 0.01) AS `V267`, (`V268` < 0.01) AS `V268`, (`V269` < 0.01) AS `V269`, (`V270` < 0.01) AS `V270`, (`V271` < 0.01) AS `V271`, (`V272` < 0.01) AS `V272`, (`V273` < 0.01) AS `V273`, (`V274` < 0.01) AS `V274`, (`V275` < 0.01) AS `V275`, (`V276` < 0.01) AS `V276`, (`V277` < 0.01) AS `V277`, (`V278` < 0.01) AS `V278`, (`V279` < 0.01) AS `V279`, (`V280` < 0.01) AS `V280`, (`V281` < 0.01) AS `V281`, (`V282` < 0.01) AS `V282`, (`V283` < 0.01) AS `V283`, (`V284` < 0.01) AS `V284`, (`V285` < 0.01) AS `V285`, (`V286` < 0.01) AS `V286`, (`V287` < 0.01) AS `V287`, (`V288` < 0.01) AS `V288`, (`V289` < 0.01) AS `V289`, (`V290` < 0.01) AS `V290`, (`V291` < 0.01) AS `V291`, (`V292` < 0.01) AS `V292`, (`V293` < 0.01) AS `V293`, (`V294` < 0.01) AS `V294`, (`V295` < 0.01) AS `V295`, (`V296` < 0.01) AS `V296`, (`V297` < 0.01) AS `V297`, (`V298` < 0.01) AS `V298`, (`V299` < 0.01) AS `V299`, (`V300` < 0.01) AS `V300`, (`V301` < 0.01) AS `V301`, (`V302` < 0.01) AS `V302`, (`V303` < 0.01) AS `V303`, (`V304` < 0.01) AS `V304`, (`V305` < 0.01) AS `V305`, (`V306` < 0.01) AS `V306`, (`V307` < 0.01) AS `V307`, (`V308` < 0.01) AS `V308`, (`V309` < 0.01) AS `V309`, (`V310` < 0.01) AS `V310`, (`V311` < 0.01) AS `V311`, (`V312` < 0.01) AS `V312`, (`V313` < 0.01) AS `V313`, (`V314` < 0.01) AS `V314`, (`V315` < 0.01) AS `V315`, (`V316` < 0.01) AS `V316`, (`V317` < 0.01) AS `V317`, (`V318` < 0.01) AS `V318`, (`V319` < 0.01) AS `V319`, (`V320` < 0.01) AS `V320`, (`V321` < 0.01) AS `V321`, (`V322` < 0.01) AS `V322`, (`V323` < 0.01) AS `V323`, (`V324` < 0.01) AS `V324`, (`V325` < 0.01) AS `V325`, (`V326` < 0.01) AS `V326`, (`V327` < 0.01) AS `V327`, (`V328` < 0.01) AS `V328`, (`V329` < 0.01) AS `V329`, (`V330` < 0.01) AS `V330`, (`V331` < 0.01) AS `V331`, (`V332` < 0.01) AS `V332`, (`V333` < 0.01) AS `V333`, (`V334` < 0.01) AS `V334`, (`V335` < 0.01) AS `V335`, (`V336` < 0.01) AS `V336`, (`V337` < 0.01) AS `V337`, (`V338` < 0.01) AS `V338`, (`V339` < 0.01) AS `V339`, (`V340` < 0.01) AS `V340`, (`V341` < 0.01) AS `V341`, (`V342` < 0.01) AS `V342`, (`V343` < 0.01) AS `V343`, (`V344` < 0.01) AS `V344`, (`V345` < 0.01) AS `V345`, (`V346` < 0.01) AS `V346`, (`V347` < 0.01) AS `V347`, (`V348` < 0.01) AS `V348`, (`V349` < 0.01) AS `V349`, (`V350` < 0.01) AS `V350`, (`V351` < 0.01) AS `V351`, (`V352` < 0.01) AS `V352`, (`V353` < 0.01) AS `V353`, (`V354` < 0.01) AS `V354`, (`V355` < 0.01) AS `V355`, (`V356` < 0.01) AS `V356`, (`V357` < 0.01) AS `V357`, (`V358` < 0.01) AS `V358`, (`V359` < 0.01) AS `V359`, (`V360` < 0.01) AS `V360`, (`V361` < 0.01) AS `V361`, (`V362` < 0.01) AS `V362`, (`V363` < 0.01) AS `V363`, (`V364` < 0.01) AS `V364`, (`V365` < 0.01) AS `V365`, (`V366` < 0.01) AS `V366`, (`V367` < 0.01) AS `V367`, (`V368` < 0.01) AS `V368`, (`V369` < 0.01) AS `V369`, (`V370` < 0.01) AS `V370`, (`V371` < 0.01) AS `V371`, (`V372` < 0.01) AS `V372`, (`V373` < 0.01) AS `V373`, (`V374` < 0.01) AS `V374`, (`V375` < 0.01) AS `V375`, (`V376` < 0.01) AS `V376`, (`V377` < 0.01) AS `V377`, (`V378` < 0.01) AS `V378`, (`V379` < 0.01) AS `V379`, (`V380` < 0.01) AS `V380`, (`V381` < 0.01) AS `V381`, (`V382` < 0.01) AS `V382`, (`V383` < 0.01) AS `V383`, (`V384` < 0.01) AS `V384`, (`V385` < 0.01) AS `V385`, (`V386` < 0.01) AS `V386`, (`V387` < 0.01) AS `V387`, (`V388` < 0.01) AS `V388`, (`V389` < 0.01) AS `V389`, (`V390` < 0.01) AS `V390`, (`V391` < 0.01) AS `V391`, (`V392` < 0.01) AS `V392`, (`V393` < 0.01) AS `V393`, (`V394` < 0.01) AS `V394`, (`V395` < 0.01) AS `V395`, (`V396` < 0.01) AS `V396`, (`V397` < 0.01) AS `V397`, (`V398` < 0.01) AS `V398`, (`V399` < 0.01) AS `V399`, (`V400` < 0.01) AS `V400`, (`V401` < 0.01) AS `V401`, (`V402` < 0.01) AS `V402`, (`V403` < 0.01) AS `V403`, (`V404` < 0.01) AS `V404`, (`V405` < 0.01) AS `V405`, (`V406` < 0.01) AS `V406`, (`V407` < 0.01) AS `V407`, (`V408` < 0.01) AS `V408`, (`V409` < 0.01) AS `V409`, (`V410` < 0.01) AS `V410`, (`V411` < 0.01) AS `V411`, (`V412` < 0.01) AS `V412`, (`V413` < 0.01) AS `V413`, (`V414` < 0.01) AS `V414`, (`V415` < 0.01) AS `V415`, (`V416` < 0.01) AS `V416`, (`V417` < 0.01) AS `V417`, (`V418` < 0.01) AS `V418`, (`V419` < 0.01) AS `V419`, (`V420` < 0.01) AS `V420`, (`V421` < 0.01) AS `V421`, (`V422` < 0.01) AS `V422`, (`V423` < 0.01) AS `V423`, (`V424` < 0.01) AS `V424`, (`V425` < 0.01) AS `V425`, (`V426` < 0.01) AS `V426`, (`V427` < 0.01) AS `V427`, (`V428` < 0.01) AS `V428`, (`V429` < 0.01) AS `V429`, (`V430` < 0.01) AS `V430`, (`V431` < 0.01) AS `V431`, (`V432` < 0.01) AS `V432`, (`V433` < 0.01) AS `V433`, (`V434` < 0.01) AS `V434`, (`V435` < 0.01) AS `V435`, (`V436` < 0.01) AS `V436`, (`V437` < 0.01) AS `V437`, (`V438` < 0.01) AS `V438`, (`V439` < 0.01) AS `V439`, (`V440` < 0.01) AS `V440`, (`V441` < 0.01) AS `V441`, (`V442` < 0.01) AS `V442`, (`V443` < 0.01) AS `V443`, (`V444` < 0.01) AS `V444`, (`V445` < 0.01) AS `V445`, (`V446` < 0.01) AS `V446`, (`V447` < 0.01) AS `V447`, (`V448` < 0.01) AS `V448`, (`V449` < 0.01) AS `V449`, (`V450` < 0.01) AS `V450`, (`V451` < 0.01) AS `V451`, (`V452` < 0.01) AS `V452`, (`V453` < 0.01) AS `V453`, (`V454` < 0.01) AS `V454`, (`V455` < 0.01) AS `V455`, (`V456` < 0.01) AS `V456`, (`V457` < 0.01) AS `V457`, (`V458` < 0.01) AS `V458`, (`V459` < 0.01) AS `V459`, (`V460` < 0.01) AS `V460`, (`V461` < 0.01) AS `V461`, (`V462` < 0.01) AS `V462`, (`V463` < 0.01) AS `V463`, (`V464` < 0.01) AS `V464`, (`V465` < 0.01) AS `V465`, (`V466` < 0.01) AS `V466`, (`V467` < 0.01) AS `V467`, (`V468` < 0.01) AS `V468`, (`V469` < 0.01) AS `V469`, (`V470` < 0.01) AS `V470`, (`V471` < 0.01) AS `V471`, (`V472` < 0.01) AS `V472`, (`V473` < 0.01) AS `V473`, (`V474` < 0.01) AS `V474`, (`V475` < 0.01) AS `V475`, (`V476` < 0.01) AS `V476`, (`V477` < 0.01) AS `V477`, (`V478` < 0.01) AS `V478`, (`V479` < 0.01) AS `V479`, (`V480` < 0.01) AS `V480`, (`V481` < 0.01) AS `V481`, (`V482` < 0.01) AS `V482`, (`V483` < 0.01) AS `V483`, (`V484` < 0.01) AS `V484`, (`V485` < 0.01) AS `V485`, (`V486` < 0.01) AS `V486`, (`V487` < 0.01) AS `V487`, (`V488` < 0.01) AS `V488`, (`V489` < 0.01) AS `V489`, (`V490` < 0.01) AS `V490`, (`V491` < 0.01) AS `V491`, (`V492` < 0.01) AS `V492`, (`V493` < 0.01) AS `V493`, (`V494` < 0.01) AS `V494`, (`V495` < 0.01) AS `V495`, (`V496` < 0.01) AS `V496`, (`V497` < 0.01) AS `V497`, (`V498` < 0.01) AS `V498`, (`V499` < 0.01) AS `V499`, (`V500` < 0.01) AS `V500`
FROM `analyis_tbl`
17/12/21 17:57:04 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 17:57:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:57:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz5`
WHERE (0 = 1)
17/12/21 17:57:04 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:51329 in memory (size: 78.6 KB, free: 1997.9 MB)
17/12/21 17:57:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:57:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 17:57:04 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/12/21 17:57:04 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 17:57:04 INFO DAGScheduler: Got job 4 (collect at utils.scala:196) with 2 output partitions
17/12/21 17:57:04 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:196)
17/12/21 17:57:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
17/12/21 17:57:04 INFO DAGScheduler: Missing parents: List()
17/12/21 17:57:04 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196), which has no missing parents
17/12/21 17:57:04 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 545.6 KB, free 1997.1 MB)
17/12/21 17:57:04 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 125.7 KB, free 1996.9 MB)
17/12/21 17:57:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:51329 (size: 125.7 KB, free: 1997.8 MB)
17/12/21 17:57:04 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/12/21 17:57:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196)
17/12/21 17:57:04 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks
17/12/21 17:57:04 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5945 bytes)
17/12/21 17:57:04 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 5945 bytes)
17/12/21 17:57:04 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
17/12/21 17:57:04 INFO Executor: Running task 1.0 in stage 10.0 (TID 10)
17/12/21 17:57:04 INFO BlockManager: Found block rdd_31_0 locally
17/12/21 17:57:04 INFO BlockManager: Found block rdd_12_1 locally
17/12/21 17:57:04 INFO CodeGenerator: Code generated in 175.606083 ms
17/12/21 17:57:05 INFO CodeGenerator: Code generated in 269.091341 ms
17/12/21 17:57:06 INFO CodeGenerator: Code generated in 1262.298282 ms
17/12/21 17:57:07 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 27921 bytes result sent to driver
17/12/21 17:57:07 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 2585 ms on localhost (executor driver) (1/2)
17/12/21 17:57:16 INFO MemoryStore: Block rdd_31_1 stored as values in memory (estimated size 6.7 MB, free 1990.2 MB)
17/12/21 17:57:16 INFO BlockManagerInfo: Added rdd_31_1 in memory on 127.0.0.1:51329 (size: 6.7 MB, free: 1991.1 MB)
17/12/21 17:57:17 INFO Executor: Finished task 1.0 in stage 10.0 (TID 10). 27971 bytes result sent to driver
17/12/21 17:57:17 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 10) in 12364 ms on localhost (executor driver) (2/2)
17/12/21 17:57:17 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/21 17:57:17 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:196) finished in 12.365 s
17/12/21 17:57:17 INFO DAGScheduler: Job 4 finished: collect at utils.scala:196, took 12.396890 s
17/12/21 17:57:17 INFO CodeGenerator: Code generated in 70.57629 ms
17/12/21 17:57:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:57:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 17:57:19 INFO HiveMetaStore: 0: get_database: default
17/12/21 17:57:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 17:57:19 INFO HiveMetaStore: 0: get_database: default
17/12/21 17:57:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 17:57:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 17:57:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 17:57:19 INFO CodeGenerator: Code generated in 6.120964 ms
17/12/21 17:57:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:57:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 17:57:19 INFO HiveMetaStore: 0: get_database: default
17/12/21 17:57:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 17:57:19 INFO HiveMetaStore: 0: get_database: default
17/12/21 17:57:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 17:57:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 17:57:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 17:57:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:57:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 17:57:19 INFO HiveMetaStore: 0: get_database: default
17/12/21 17:57:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 17:57:19 INFO HiveMetaStore: 0: get_database: default
17/12/21 17:57:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 17:57:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 17:57:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 17:57:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 17:57:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 17:57:19 INFO HiveMetaStore: 0: get_database: default
17/12/21 17:57:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 17:57:19 INFO HiveMetaStore: 0: get_database: default
17/12/21 17:57:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 17:57:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 17:57:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 18:02:39 INFO SparkContext: Invoking stop() from shutdown hook
17/12/21 18:02:39 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/21 18:02:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/21 18:02:39 INFO MemoryStore: MemoryStore cleared
17/12/21 18:02:39 INFO BlockManager: BlockManager stopped
17/12/21 18:02:39 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/21 18:02:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/21 18:02:39 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-2c30f56e-91b1-495b-9db2-35c583f5f965\userFiles-b039936d-07e9-4503-af8d-91f73f25a936
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-2c30f56e-91b1-495b-9db2-35c583f5f965\userFiles-b039936d-07e9-4503-af8d-91f73f25a936
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/21 18:02:39 INFO SparkContext: Successfully stopped SparkContext
17/12/21 18:02:39 INFO ShutdownHookManager: Shutdown hook called
17/12/21 18:02:39 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-2c30f56e-91b1-495b-9db2-35c583f5f965
17/12/21 18:02:39 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-2c30f56e-91b1-495b-9db2-35c583f5f965
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-2c30f56e-91b1-495b-9db2-35c583f5f965
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/21 18:02:39 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-2c30f56e-91b1-495b-9db2-35c583f5f965\userFiles-b039936d-07e9-4503-af8d-91f73f25a936
17/12/21 18:02:39 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-2c30f56e-91b1-495b-9db2-35c583f5f965\userFiles-b039936d-07e9-4503-af8d-91f73f25a936
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-2c30f56e-91b1-495b-9db2-35c583f5f965\userFiles-b039936d-07e9-4503-af8d-91f73f25a936
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/21 18:03:09 INFO SparkContext: Running Spark version 2.1.0
17/12/21 18:03:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/21 18:03:09 INFO SecurityManager: Changing view acls to: conan
17/12/21 18:03:09 INFO SecurityManager: Changing modify acls to: conan
17/12/21 18:03:09 INFO SecurityManager: Changing view acls groups to: 
17/12/21 18:03:09 INFO SecurityManager: Changing modify acls groups to: 
17/12/21 18:03:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(conan); groups with view permissions: Set(); users  with modify permissions: Set(conan); groups with modify permissions: Set()
17/12/21 18:03:09 INFO Utils: Successfully started service 'sparkDriver' on port 51475.
17/12/21 18:03:09 INFO SparkEnv: Registering MapOutputTracker
17/12/21 18:03:09 INFO SparkEnv: Registering BlockManagerMaster
17/12/21 18:03:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/21 18:03:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/21 18:03:09 INFO DiskBlockManager: Created local directory at C:\Users\conan\AppData\Local\Temp\blockmgr-7e81c791-b9b6-4858-849a-8c9c46197162
17/12/21 18:03:09 INFO MemoryStore: MemoryStore started with capacity 2004.6 MB
17/12/21 18:03:09 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/21 18:03:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/21 18:03:09 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/21 18:03:10 INFO SparkContext: Added JAR file:/C:/Users/conan/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:51475/jars/sparklyr-2.1-2.11.jar with timestamp 1513879390010
17/12/21 18:03:10 INFO Executor: Starting executor ID driver on host localhost
17/12/21 18:03:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51496.
17/12/21 18:03:10 INFO NettyBlockTransferService: Server created on 127.0.0.1:51496
17/12/21 18:03:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/21 18:03:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51496, None)
17/12/21 18:03:10 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51496 with 2004.6 MB RAM, BlockManagerId(driver, 127.0.0.1, 51496, None)
17/12/21 18:03:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51496, None)
17/12/21 18:03:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51496, None)
17/12/21 18:03:10 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/21 18:03:10 INFO SharedState: Warehouse path is 'C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/21 18:03:10 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/21 18:03:11 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/21 18:03:11 INFO ObjectStore: ObjectStore, initialize called
17/12/21 18:03:11 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/21 18:03:11 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/21 18:03:12 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/21 18:03:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:03:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:03:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:03:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:03:14 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/21 18:03:14 INFO ObjectStore: Initialized ObjectStore
17/12/21 18:03:14 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/21 18:03:14 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/21 18:03:14 INFO HiveMetaStore: Added admin role in metastore
17/12/21 18:03:14 INFO HiveMetaStore: Added public role in metastore
17/12/21 18:03:14 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/21 18:03:15 INFO HiveMetaStore: 0: get_all_databases
17/12/21 18:03:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/21 18:03:15 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/21 18:03:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/21 18:03:15 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:03:15 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/Temp/38e1fac2-fb6e-40c0-8155-eb957d457b00_resources
17/12/21 18:03:15 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/38e1fac2-fb6e-40c0-8155-eb957d457b00
17/12/21 18:03:15 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/38e1fac2-fb6e-40c0-8155-eb957d457b00
17/12/21 18:03:15 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/38e1fac2-fb6e-40c0-8155-eb957d457b00/_tmp_space.db
17/12/21 18:03:15 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/21 18:03:15 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:03:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:03:15 INFO HiveMetaStore: 0: get_database: global_temp
17/12/21 18:03:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/21 18:03:15 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/21 18:03:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 18:03:17 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:03:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:03:17 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:03:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:03:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 18:03:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 18:03:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:03:31 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 18:03:31 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:03:31 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:03:31 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:03:31 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:03:31 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 18:03:31 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 18:03:31 INFO CodeGenerator: Code generated in 297.06631 ms
17/12/21 18:03:31 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 18:03:31 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/21 18:03:31 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/21 18:03:31 INFO DAGScheduler: Parents of final stage: List()
17/12/21 18:03:31 INFO DAGScheduler: Missing parents: List()
17/12/21 18:03:31 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/12/21 18:03:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 2004.6 MB)
17/12/21 18:03:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2004.6 MB)
17/12/21 18:03:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:51496 (size: 4.6 KB, free: 2004.6 MB)
17/12/21 18:03:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/21 18:03:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/12/21 18:03:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/21 18:03:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/21 18:03:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/21 18:03:31 INFO Executor: Fetching spark://127.0.0.1:51475/jars/sparklyr-2.1-2.11.jar with timestamp 1513879390010
17/12/21 18:03:31 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:51475 after 13 ms (0 ms spent in bootstraps)
17/12/21 18:03:31 INFO Utils: Fetching spark://127.0.0.1:51475/jars/sparklyr-2.1-2.11.jar to C:\Users\conan\AppData\Local\Temp\spark-115ef8b1-ed82-49f0-8cc2-c7f74746f82c\userFiles-8c65ebda-ad5b-4c12-9316-71a40db91823\fetchFileTemp4980539599133082507.tmp
17/12/21 18:03:32 INFO Executor: Adding file:/C:/Users/conan/AppData/Local/Temp/spark-115ef8b1-ed82-49f0-8cc2-c7f74746f82c/userFiles-8c65ebda-ad5b-4c12-9316-71a40db91823/sparklyr-2.1-2.11.jar to class loader
17/12/21 18:03:32 INFO CodeGenerator: Code generated in 15.81913 ms
17/12/21 18:03:32 INFO CodeGenerator: Code generated in 14.848746 ms
17/12/21 18:03:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/12/21 18:03:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 316 ms on localhost (executor driver) (1/1)
17/12/21 18:03:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/21 18:03:32 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.344 s
17/12/21 18:03:32 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.519358 s
17/12/21 18:03:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:03:32 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 18:03:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:03:32 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 18:03:32 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 18:03:32 INFO FileSourceStrategy: Pruning directories with: 
17/12/21 18:03:32 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/21 18:03:32 INFO FileSourceStrategy: Output Data Schema: struct<S1: double>
17/12/21 18:03:32 INFO FileSourceStrategy: Pushed Filters: 
17/12/21 18:03:32 INFO CodeGenerator: Code generated in 6.6492 ms
17/12/21 18:03:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.7 KB, free 2004.3 MB)
17/12/21 18:03:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2004.3 MB)
17/12/21 18:03:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:51496 (size: 24.0 KB, free: 2004.6 MB)
17/12/21 18:03:32 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/21 18:03:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/21 18:03:32 INFO CodeGenerator: Code generated in 13.09073 ms
17/12/21 18:03:32 INFO CodeGenerator: Code generated in 11.466377 ms
17/12/21 18:03:32 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 18:03:32 INFO DAGScheduler: Registering RDD 10 (sql at <unknown>:0)
17/12/21 18:03:32 INFO DAGScheduler: Registering RDD 15 (sql at <unknown>:0)
17/12/21 18:03:32 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/21 18:03:32 INFO DAGScheduler: Final stage: ResultStage 3 (sql at <unknown>:0)
17/12/21 18:03:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/12/21 18:03:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/12/21 18:03:32 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0), which has no missing parents
17/12/21 18:03:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.8 KB, free 2004.3 MB)
17/12/21 18:03:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KB, free 2004.3 MB)
17/12/21 18:03:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:51496 (size: 7.2 KB, free: 2004.6 MB)
17/12/21 18:03:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/21 18:03:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0)
17/12/21 18:03:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/21 18:03:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/21 18:03:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/21 18:03:33 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpEzPCXP/spark_serialize_2163a57e8fee164c1d0f72df85175c010512acb0dda29233ba180b4846672bc4.csv, range: 0-196022, partition values: [empty row]
17/12/21 18:03:33 INFO CodeGenerator: Code generated in 5.303124 ms
17/12/21 18:03:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1719 bytes result sent to driver
17/12/21 18:03:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 227 ms on localhost (executor driver) (1/1)
17/12/21 18:03:33 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/21 18:03:33 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.228 s
17/12/21 18:03:33 INFO DAGScheduler: looking for newly runnable stages
17/12/21 18:03:33 INFO DAGScheduler: running: Set()
17/12/21 18:03:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/12/21 18:03:33 INFO DAGScheduler: failed: Set()
17/12/21 18:03:33 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/21 18:03:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.9 KB, free 2004.2 MB)
17/12/21 18:03:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.6 KB, free 2004.2 MB)
17/12/21 18:03:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:51496 (size: 5.6 KB, free: 2004.6 MB)
17/12/21 18:03:33 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/21 18:03:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/21 18:03:33 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
17/12/21 18:03:33 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5942 bytes)
17/12/21 18:03:33 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5942 bytes)
17/12/21 18:03:33 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/21 18:03:33 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
17/12/21 18:03:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 18:03:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 18:03:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 18:03:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 18:03:33 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 39.3 KB, free 2004.2 MB)
17/12/21 18:03:33 INFO MemoryStore: Block rdd_12_1 stored as values in memory (estimated size 39.3 KB, free 2004.2 MB)
17/12/21 18:03:33 INFO BlockManagerInfo: Added rdd_12_0 in memory on 127.0.0.1:51496 (size: 39.3 KB, free: 2004.5 MB)
17/12/21 18:03:33 INFO BlockManagerInfo: Added rdd_12_1 in memory on 127.0.0.1:51496 (size: 39.3 KB, free: 2004.5 MB)
17/12/21 18:03:33 INFO CodeGenerator: Code generated in 4.122428 ms
17/12/21 18:03:33 INFO CodeGenerator: Code generated in 19.24039 ms
17/12/21 18:03:33 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 3064 bytes result sent to driver
17/12/21 18:03:33 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 3241 bytes result sent to driver
17/12/21 18:03:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 147 ms on localhost (executor driver) (1/2)
17/12/21 18:03:33 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 147 ms on localhost (executor driver) (2/2)
17/12/21 18:03:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/21 18:03:33 INFO DAGScheduler: ShuffleMapStage 2 (sql at <unknown>:0) finished in 0.147 s
17/12/21 18:03:33 INFO DAGScheduler: looking for newly runnable stages
17/12/21 18:03:33 INFO DAGScheduler: running: Set()
17/12/21 18:03:33 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/12/21 18:03:33 INFO DAGScheduler: failed: Set()
17/12/21 18:03:33 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
17/12/21 18:03:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 2004.2 MB)
17/12/21 18:03:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.2 MB)
17/12/21 18:03:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:51496 (size: 3.7 KB, free: 2004.5 MB)
17/12/21 18:03:33 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/21 18:03:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0)
17/12/21 18:03:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/21 18:03:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/21 18:03:33 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
17/12/21 18:03:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 18:03:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 18:03:33 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 1707 bytes result sent to driver
17/12/21 18:03:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 0 ms on localhost (executor driver) (1/1)
17/12/21 18:03:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/21 18:03:33 INFO DAGScheduler: ResultStage 3 (sql at <unknown>:0) finished in 0.000 s
17/12/21 18:03:33 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.440614 s
17/12/21 18:03:33 INFO CodeGenerator: Code generated in 6.688468 ms
17/12/21 18:03:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:03:33 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 18:03:33 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 18:03:33 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/21 18:03:33 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:196)
17/12/21 18:03:33 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/12/21 18:03:33 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:196)
17/12/21 18:03:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/12/21 18:03:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/12/21 18:03:33 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
17/12/21 18:03:33 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.9 KB, free 2004.1 MB)
17/12/21 18:03:33 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.6 KB, free 2004.1 MB)
17/12/21 18:03:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:51496 (size: 5.6 KB, free: 2004.5 MB)
17/12/21 18:03:33 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/21 18:03:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196)
17/12/21 18:03:33 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
17/12/21 18:03:33 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5934 bytes)
17/12/21 18:03:33 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 5934 bytes)
17/12/21 18:03:33 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/21 18:03:33 INFO BlockManager: Found block rdd_12_0 locally
17/12/21 18:03:33 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/12/21 18:03:33 INFO BlockManager: Found block rdd_12_1 locally
17/12/21 18:03:33 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1950 bytes result sent to driver
17/12/21 18:03:33 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 16 ms on localhost (executor driver) (1/2)
17/12/21 18:03:33 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 1950 bytes result sent to driver
17/12/21 18:03:33 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 16 ms on localhost (executor driver) (2/2)
17/12/21 18:03:33 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/21 18:03:33 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:196) finished in 0.016 s
17/12/21 18:03:33 INFO DAGScheduler: looking for newly runnable stages
17/12/21 18:03:33 INFO DAGScheduler: running: Set()
17/12/21 18:03:33 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/12/21 18:03:33 INFO DAGScheduler: failed: Set()
17/12/21 18:03:33 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196), which has no missing parents
17/12/21 18:03:33 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 2004.1 MB)
17/12/21 18:03:33 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.1 MB)
17/12/21 18:03:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:51496 (size: 3.7 KB, free: 2004.5 MB)
17/12/21 18:03:33 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/12/21 18:03:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196)
17/12/21 18:03:33 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/21 18:03:33 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/21 18:03:33 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
17/12/21 18:03:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 18:03:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 18:03:33 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1707 bytes result sent to driver
17/12/21 18:03:33 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:196) finished in 0.000 s
17/12/21 18:03:33 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.057125 s
17/12/21 18:03:33 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 0 ms on localhost (executor driver) (1/1)
17/12/21 18:03:33 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/21 18:03:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:03:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz6`
WHERE (0 = 1)
17/12/21 18:03:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:03:36 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`, `V11` AS `V11`, `V12` AS `V12`, `V13` AS `V13`, `V14` AS `V14`, `V15` AS `V15`, `V16` AS `V16`, `V17` AS `V17`, `V18` AS `V18`, `V19` AS `V19`, `V20` AS `V20`, `V21` AS `V21`, `V22` AS `V22`, `V23` AS `V23`, `V24` AS `V24`, `V25` AS `V25`, `V26` AS `V26`, `V27` AS `V27`, `V28` AS `V28`, `V29` AS `V29`, `V30` AS `V30`, `V31` AS `V31`, `V32` AS `V32`, `V33` AS `V33`, `V34` AS `V34`, `V35` AS `V35`, `V36` AS `V36`, `V37` AS `V37`, `V38` AS `V38`, `V39` AS `V39`, `V40` AS `V40`, `V41` AS `V41`, `V42` AS `V42`, `V43` AS `V43`, `V44` AS `V44`, `V45` AS `V45`, `V46` AS `V46`, `V47` AS `V47`, `V48` AS `V48`, `V49` AS `V49`, `V50` AS `V50`, `V51` AS `V51`, `V52` AS `V52`, `V53` AS `V53`, `V54` AS `V54`, `V55` AS `V55`, `V56` AS `V56`, `V57` AS `V57`, `V58` AS `V58`, `V59` AS `V59`, `V60` AS `V60`, `V61` AS `V61`, `V62` AS `V62`, `V63` AS `V63`, `V64` AS `V64`, `V65` AS `V65`, `V66` AS `V66`, `V67` AS `V67`, `V68` AS `V68`, `V69` AS `V69`, `V70` AS `V70`, `V71` AS `V71`, `V72` AS `V72`, `V73` AS `V73`, `V74` AS `V74`, `V75` AS `V75`, `V76` AS `V76`, `V77` AS `V77`, `V78` AS `V78`, `V79` AS `V79`, `V80` AS `V80`, `V81` AS `V81`, `V82` AS `V82`, `V83` AS `V83`, `V84` AS `V84`, `V85` AS `V85`, `V86` AS `V86`, `V87` AS `V87`, `V88` AS `V88`, `V89` AS `V89`, `V90` AS `V90`, `V91` AS `V91`, `V92` AS `V92`, `V93` AS `V93`, `V94` AS `V94`, `V95` AS `V95`, `V96` AS `V96`, `V97` AS `V97`, `V98` AS `V98`, `V99` AS `V99`, `V100` AS `V100`, `V101` AS `V101`, `V102` AS `V102`, `V103` AS `V103`, `V104` AS `V104`, `V105` AS `V105`, `V106` AS `V106`, `V107` AS `V107`, `V108` AS `V108`, `V109` AS `V109`, `V110` AS `V110`, `V111` AS `V111`, `V112` AS `V112`, `V113` AS `V113`, `V114` AS `V114`, `V115` AS `V115`, `V116` AS `V116`, `V117` AS `V117`, `V118` AS `V118`, `V119` AS `V119`, `V120` AS `V120`, `V121` AS `V121`, `V122` AS `V122`, `V123` AS `V123`, `V124` AS `V124`, `V125` AS `V125`, `V126` AS `V126`, `V127` AS `V127`, `V128` AS `V128`, `V129` AS `V129`, `V130` AS `V130`, `V131` AS `V131`, `V132` AS `V132`, `V133` AS `V133`, `V134` AS `V134`, `V135` AS `V135`, `V136` AS `V136`, `V137` AS `V137`, `V138` AS `V138`, `V139` AS `V139`, `V140` AS `V140`, `V141` AS `V141`, `V142` AS `V142`, `V143` AS `V143`, `V144` AS `V144`, `V145` AS `V145`, `V146` AS `V146`, `V147` AS `V147`, `V148` AS `V148`, `V149` AS `V149`, `V150` AS `V150`, `V151` AS `V151`, `V152` AS `V152`, `V153` AS `V153`, `V154` AS `V154`, `V155` AS `V155`, `V156` AS `V156`, `V157` AS `V157`, `V158` AS `V158`, `V159` AS `V159`, `V160` AS `V160`, `V161` AS `V161`, `V162` AS `V162`, `V163` AS `V163`, `V164` AS `V164`, `V165` AS `V165`, `V166` AS `V166`, `V167` AS `V167`, `V168` AS `V168`, `V169` AS `V169`, `V170` AS `V170`, `V171` AS `V171`, `V172` AS `V172`, `V173` AS `V173`, `V174` AS `V174`, `V175` AS `V175`, `V176` AS `V176`, `V177` AS `V177`, `V178` AS `V178`, `V179` AS `V179`, `V180` AS `V180`, `V181` AS `V181`, `V182` AS `V182`, `V183` AS `V183`, `V184` AS `V184`, `V185` AS `V185`, `V186` AS `V186`, `V187` AS `V187`, `V188` AS `V188`, `V189` AS `V189`, `V190` AS `V190`, `V191` AS `V191`, `V192` AS `V192`, `V193` AS `V193`, `V194` AS `V194`, `V195` AS `V195`, `V196` AS `V196`, `V197` AS `V197`, `V198` AS `V198`, `V199` AS `V199`, `V200` AS `V200`, `V201` AS `V201`, `V202` AS `V202`, `V203` AS `V203`, `V204` AS `V204`, `V205` AS `V205`, `V206` AS `V206`, `V207` AS `V207`, `V208` AS `V208`, `V209` AS `V209`, `V210` AS `V210`, `V211` AS `V211`, `V212` AS `V212`, `V213` AS `V213`, `V214` AS `V214`, `V215` AS `V215`, `V216` AS `V216`, `V217` AS `V217`, `V218` AS `V218`, `V219` AS `V219`, `V220` AS `V220`, `V221` AS `V221`, `V222` AS `V222`, `V223` AS `V223`, `V224` AS `V224`, `V225` AS `V225`, `V226` AS `V226`, `V227` AS `V227`, `V228` AS `V228`, `V229` AS `V229`, `V230` AS `V230`, `V231` AS `V231`, `V232` AS `V232`, `V233` AS `V233`, `V234` AS `V234`, `V235` AS `V235`, `V236` AS `V236`, `V237` AS `V237`, `V238` AS `V238`, `V239` AS `V239`, `V240` AS `V240`, `V241` AS `V241`, `V242` AS `V242`, `V243` AS `V243`, `V244` AS `V244`, `V245` AS `V245`, `V246` AS `V246`, `V247` AS `V247`, `V248` AS `V248`, `V249` AS `V249`, `V250` AS `V250`, `V251` AS `V251`, `V252` AS `V252`, `V253` AS `V253`, `V254` AS `V254`, `V255` AS `V255`, `V256` AS `V256`, `V257` AS `V257`, `V258` AS `V258`, `V259` AS `V259`, `V260` AS `V260`, `V261` AS `V261`, `V262` AS `V262`, `V263` AS `V263`, `V264` AS `V264`, `V265` AS `V265`, `V266` AS `V266`, `V267` AS `V267`, `V268` AS `V268`, `V269` AS `V269`, `V270` AS `V270`, `V271` AS `V271`, `V272` AS `V272`, `V273` AS `V273`, `V274` AS `V274`, `V275` AS `V275`, `V276` AS `V276`, `V277` AS `V277`, `V278` AS `V278`, `V279` AS `V279`, `V280` AS `V280`, `V281` AS `V281`, `V282` AS `V282`, `V283` AS `V283`, `V284` AS `V284`, `V285` AS `V285`, `V286` AS `V286`, `V287` AS `V287`, `V288` AS `V288`, `V289` AS `V289`, `V290` AS `V290`, `V291` AS `V291`, `V292` AS `V292`, `V293` AS `V293`, `V294` AS `V294`, `V295` AS `V295`, `V296` AS `V296`, `V297` AS `V297`, `V298` AS `V298`, `V299` AS `V299`, `V300` AS `V300`, `V301` AS `V301`, `V302` AS `V302`, `V303` AS `V303`, `V304` AS `V304`, `V305` AS `V305`, `V306` AS `V306`, `V307` AS `V307`, `V308` AS `V308`, `V309` AS `V309`, `V310` AS `V310`, `V311` AS `V311`, `V312` AS `V312`, `V313` AS `V313`, `V314` AS `V314`, `V315` AS `V315`, `V316` AS `V316`, `V317` AS `V317`, `V318` AS `V318`, `V319` AS `V319`, `V320` AS `V320`, `V321` AS `V321`, `V322` AS `V322`, `V323` AS `V323`, `V324` AS `V324`, `V325` AS `V325`, `V326` AS `V326`, `V327` AS `V327`, `V328` AS `V328`, `V329` AS `V329`, `V330` AS `V330`, `V331` AS `V331`, `V332` AS `V332`, `V333` AS `V333`, `V334` AS `V334`, `V335` AS `V335`, `V336` AS `V336`, `V337` AS `V337`, `V338` AS `V338`, `V339` AS `V339`, `V340` AS `V340`, `V341` AS `V341`, `V342` AS `V342`, `V343` AS `V343`, `V344` AS `V344`, `V345` AS `V345`, `V346` AS `V346`, `V347` AS `V347`, `V348` AS `V348`, `V349` AS `V349`, `V350` AS `V350`, `V351` AS `V351`, `V352` AS `V352`, `V353` AS `V353`, `V354` AS `V354`, `V355` AS `V355`, `V356` AS `V356`, `V357` AS `V357`, `V358` AS `V358`, `V359` AS `V359`, `V360` AS `V360`, `V361` AS `V361`, `V362` AS `V362`, `V363` AS `V363`, `V364` AS `V364`, `V365` AS `V365`, `V366` AS `V366`, `V367` AS `V367`, `V368` AS `V368`, `V369` AS `V369`, `V370` AS `V370`, `V371` AS `V371`, `V372` AS `V372`, `V373` AS `V373`, `V374` AS `V374`, `V375` AS `V375`, `V376` AS `V376`, `V377` AS `V377`, `V378` AS `V378`, `V379` AS `V379`, `V380` AS `V380`, `V381` AS `V381`, `V382` AS `V382`, `V383` AS `V383`, `V384` AS `V384`, `V385` AS `V385`, `V386` AS `V386`, `V387` AS `V387`, `V388` AS `V388`, `V389` AS `V389`, `V390` AS `V390`, `V391` AS `V391`, `V392` AS `V392`, `V393` AS `V393`, `V394` AS `V394`, `V395` AS `V395`, `V396` AS `V396`, `V397` AS `V397`, `V398` AS `V398`, `V399` AS `V399`, `V400` AS `V400`, `V401` AS `V401`, `V402` AS `V402`, `V403` AS `V403`, `V404` AS `V404`, `V405` AS `V405`, `V406` AS `V406`, `V407` AS `V407`, `V408` AS `V408`, `V409` AS `V409`, `V410` AS `V410`, `V411` AS `V411`, `V412` AS `V412`, `V413` AS `V413`, `V414` AS `V414`, `V415` AS `V415`, `V416` AS `V416`, `V417` AS `V417`, `V418` AS `V418`, `V419` AS `V419`, `V420` AS `V420`, `V421` AS `V421`, `V422` AS `V422`, `V423` AS `V423`, `V424` AS `V424`, `V425` AS `V425`, `V426` AS `V426`, `V427` AS `V427`, `V428` AS `V428`, `V429` AS `V429`, `V430` AS `V430`, `V431` AS `V431`, `V432` AS `V432`, `V433` AS `V433`, `V434` AS `V434`, `V435` AS `V435`, `V436` AS `V436`, `V437` AS `V437`, `V438` AS `V438`, `V439` AS `V439`, `V440` AS `V440`, `V441` AS `V441`, `V442` AS `V442`, `V443` AS `V443`, `V444` AS `V444`, `V445` AS `V445`, `V446` AS `V446`, `V447` AS `V447`, `V448` AS `V448`, `V449` AS `V449`, `V450` AS `V450`, `V451` AS `V451`, `V452` AS `V452`, `V453` AS `V453`, `V454` AS `V454`, `V455` AS `V455`, `V456` AS `V456`, `V457` AS `V457`, `V458` AS `V458`, `V459` AS `V459`, `V460` AS `V460`, `V461` AS `V461`, `V462` AS `V462`, `V463` AS `V463`, `V464` AS `V464`, `V465` AS `V465`, `V466` AS `V466`, `V467` AS `V467`, `V468` AS `V468`, `V469` AS `V469`, `V470` AS `V470`, `V471` AS `V471`, `V472` AS `V472`, `V473` AS `V473`, `V474` AS `V474`, `V475` AS `V475`, `V476` AS `V476`, `V477` AS `V477`, `V478` AS `V478`, `V479` AS `V479`, `V480` AS `V480`, `V481` AS `V481`, `V482` AS `V482`, `V483` AS `V483`, `V484` AS `V484`, `V485` AS `V485`, `V486` AS `V486`, `V487` AS `V487`, `V488` AS `V488`, `V489` AS `V489`, `V490` AS `V490`, `V491` AS `V491`, `V492` AS `V492`, `V493` AS `V493`, `V494` AS `V494`, `V495` AS `V495`, `V496` AS `V496`, `V497` AS `V497`, `V498` AS `V498`, `V499` AS `V499`, `V500` AS `V500`, `V501` AS `V501`, `V502` AS `V502`, `V503` AS `V503`, `V504` AS `V504`, `V505` AS `V505`, `V506` AS `V506`, `V507` AS `V507`, `V508` AS `V508`, `V509` AS `V509`, `V510` AS `V510`, `V511` AS `V511`, `V512` AS `V512`, `V513` AS `V513`, `V514` AS `V514`, `V515` AS `V515`, `V516` AS `V516`, `V517` AS `V517`, `V518` AS `V518`, `V519` AS `V519`, `V520` AS `V520`, `V521` AS `V521`, `V522` AS `V522`, `V523` AS `V523`, `V524` AS `V524`, `V525` AS `V525`, `V526` AS `V526`, `V527` AS `V527`, `V528` AS `V528`, `V529` AS `V529`, `V530` AS `V530`, `V531` AS `V531`, `V532` AS `V532`, `V533` AS `V533`, `V534` AS `V534`, `V535` AS `V535`, `V536` AS `V536`, `V537` AS `V537`, `V538` AS `V538`, `V539` AS `V539`, `V540` AS `V540`, `V541` AS `V541`, `V542` AS `V542`, `V543` AS `V543`, `V544` AS `V544`, `V545` AS `V545`, `V546` AS `V546`, `V547` AS `V547`, `V548` AS `V548`, `V549` AS `V549`, `V550` AS `V550`, `V551` AS `V551`, `V552` AS `V552`, `V553` AS `V553`, `V554` AS `V554`, `V555` AS `V555`, `V556` AS `V556`, `V557` AS `V557`, `V558` AS `V558`, `V559` AS `V559`, `V560` AS `V560`, `V561` AS `V561`, `V562` AS `V562`, `V563` AS `V563`, `V564` AS `V564`, `V565` AS `V565`, `V566` AS `V566`, `V567` AS `V567`, `V568` AS `V568`, `V569` AS `V569`, `V570` AS `V570`, `V571` AS `V571`, `V572` AS `V572`, `V573` AS `V573`, `V574` AS `V574`, `V575` AS `V575`, `V576` AS `V576`, `V577` AS `V577`, `V578` AS `V578`, `V579` AS `V579`, `V580` AS `V580`, `V581` AS `V581`, `V582` AS `V582`, `V583` AS `V583`, `V584` AS `V584`, `V585` AS `V585`, `V586` AS `V586`, `V587` AS `V587`, `V588` AS `V588`, `V589` AS `V589`, `V590` AS `V590`, `V591` AS `V591`, `V592` AS `V592`, `V593` AS `V593`, `V594` AS `V594`, `V595` AS `V595`, `V596` AS `V596`, `V597` AS `V597`, `V598` AS `V598`, `V599` AS `V599`, `V600` AS `V600`, `V601` AS `V601`, `V602` AS `V602`, `V603` AS `V603`, `V604` AS `V604`, `V605` AS `V605`, `V606` AS `V606`, `V607` AS `V607`, `V608` AS `V608`, `V609` AS `V609`, `V610` AS `V610`, `V611` AS `V611`, `V612` AS `V612`, `V613` AS `V613`, `V614` AS `V614`, `V615` AS `V615`, `V616` AS `V616`, `V617` AS `V617`, `V618` AS `V618`, `V619` AS `V619`, `V620` AS `V620`, `V621` AS `V621`, `V622` AS `V622`, `V623` AS `V623`, `V624` AS `V624`, `V625` AS `V625`, `V626` AS `V626`, `V627` AS `V627`, `V628` AS `V628`, `V629` AS `V629`, `V630` AS `V630`, `V631` AS `V631`, `V632` AS `V632`, `V633` AS `V633`, `V634` AS `V634`, `V635` AS `V635`, `V636` AS `V636`, `V637` AS `V637`, `V638` AS `V638`, `V639` AS `V639`, `V640` AS `V640`, `V641` AS `V641`, `V642` AS `V642`, `V643` AS `V643`, `V644` AS `V644`, `V645` AS `V645`, `V646` AS `V646`, `V647` AS `V647`, `V648` AS `V648`, `V649` AS `V649`, `V650` AS `V650`, `V651` AS `V651`, `V652` AS `V652`, `V653` AS `V653`, `V654` AS `V654`, `V655` AS `V655`, `V656` AS `V656`, `V657` AS `V657`, `V658` AS `V658`, `V659` AS `V659`, `V660` AS `V660`, `V661` AS `V661`, `V662` AS `V662`, `V663` AS `V663`, `V664` AS `V664`, `V665` AS `V665`, `V666` AS `V666`, `V667` AS `V667`, `V668` AS `V668`, `V669` AS `V669`, `V670` AS `V670`, `V671` AS `V671`, `V672` AS `V672`, `V673` AS `V673`, `V674` AS `V674`, `V675` AS `V675`, `V676` AS `V676`, `V677` AS `V677`, `V678` AS `V678`, `V679` AS `V679`, `V680` AS `V680`, `V681` AS `V681`, `V682` AS `V682`, `V683` AS `V683`, `V684` AS `V684`, `V685` AS `V685`, `V686` AS `V686`, `V687` AS `V687`, `V688` AS `V688`, `V689` AS `V689`, `V690` AS `V690`, `V691` AS `V691`, `V692` AS `V692`, `V693` AS `V693`, `V694` AS `V694`, `V695` AS `V695`, `V696` AS `V696`, `V697` AS `V697`, `V698` AS `V698`, `V699` AS `V699`, `V700` AS `V700`, `V701` AS `V701`, `V702` AS `V702`, `V703` AS `V703`, `V704` AS `V704`, `V705` AS `V705`, `V706` AS `V706`, `V707` AS `V707`, `V708` AS `V708`, `V709` AS `V709`, `V710` AS `V710`, `V711` AS `V711`, `V712` AS `V712`, `V713` AS `V713`, `V714` AS `V714`, `V715` AS `V715`, `V716` AS `V716`, `V717` AS `V717`, `V718` AS `V718`, `V719` AS `V719`, `V720` AS `V720`, `V721` AS `V721`, `V722` AS `V722`, `V723` AS `V723`, `V724` AS `V724`, `V725` AS `V725`, `V726` AS `V726`, `V727` AS `V727`, `V728` AS `V728`, `V729` AS `V729`, `V730` AS `V730`, `V731` AS `V731`, `V732` AS `V732`, `V733` AS `V733`, `V734` AS `V734`, `V735` AS `V735`, `V736` AS `V736`, `V737` AS `V737`, `V738` AS `V738`, `V739` AS `V739`, `V740` AS `V740`, `V741` AS `V741`, `V742` AS `V742`, `V743` AS `V743`, `V744` AS `V744`, `V745` AS `V745`, `V746` AS `V746`, `V747` AS `V747`, `V748` AS `V748`, `V749` AS `V749`, `V750` AS `V750`, `V751` AS `V751`, `V752` AS `V752`, `V753` AS `V753`, `V754` AS `V754`, `V755` AS `V755`, `V756` AS `V756`, `V757` AS `V757`, `V758` AS `V758`, `V759` AS `V759`, `V760` AS `V760`, `V761` AS `V761`, `V762` AS `V762`, `V763` AS `V763`, `V764` AS `V764`, `V765` AS `V765`, `V766` AS `V766`, `V767` AS `V767`, `V768` AS `V768`, `V769` AS `V769`, `V770` AS `V770`, `V771` AS `V771`, `V772` AS `V772`, `V773` AS `V773`, `V774` AS `V774`, `V775` AS `V775`, `V776` AS `V776`, `V777` AS `V777`, `V778` AS `V778`, `V779` AS `V779`, `V780` AS `V780`, `V781` AS `V781`, `V782` AS `V782`, `V783` AS `V783`, `V784` AS `V784`, `V785` AS `V785`, `V786` AS `V786`, `V787` AS `V787`, `V788` AS `V788`, `V789` AS `V789`, `V790` AS `V790`, `V791` AS `V791`, `V792` AS `V792`, `V793` AS `V793`, `V794` AS `V794`, `V795` AS `V795`, `V796` AS `V796`, `V797` AS `V797`, `V798` AS `V798`, `V799` AS `V799`, `V800` AS `V800`, `V801` AS `V801`, `V802` AS `V802`, `V803` AS `V803`, `V804` AS `V804`, `V805` AS `V805`, `V806` AS `V806`, `V807` AS `V807`, `V808` AS `V808`, `V809` AS `V809`, `V810` AS `V810`, `V811` AS `V811`, `V812` AS `V812`, `V813` AS `V813`, `V814` AS `V814`, `V815` AS `V815`, `V816` AS `V816`, `V817` AS `V817`, `V818` AS `V818`, `V819` AS `V819`, `V820` AS `V820`, `V821` AS `V821`, `V822` AS `V822`, `V823` AS `V823`, `V824` AS `V824`, `V825` AS `V825`, `V826` AS `V826`, `V827` AS `V827`, `V828` AS `V828`, `V829` AS `V829`, `V830` AS `V830`, `V831` AS `V831`, `V832` AS `V832`, `V833` AS `V833`, `V834` AS `V834`, `V835` AS `V835`, `V836` AS `V836`, `V837` AS `V837`, `V838` AS `V838`, `V839` AS `V839`, `V840` AS `V840`, `V841` AS `V841`, `V842` AS `V842`, `V843` AS `V843`, `V844` AS `V844`, `V845` AS `V845`, `V846` AS `V846`, `V847` AS `V847`, `V848` AS `V848`, `V849` AS `V849`, `V850` AS `V850`, `V851` AS `V851`, `V852` AS `V852`, `V853` AS `V853`, `V854` AS `V854`, `V855` AS `V855`, `V856` AS `V856`, `V857` AS `V857`, `V858` AS `V858`, `V859` AS `V859`, `V860` AS `V860`, `V861` AS `V861`, `V862` AS `V862`, `V863` AS `V863`, `V864` AS `V864`, `V865` AS `V865`, `V866` AS `V866`, `V867` AS `V867`, `V868` AS `V868`, `V869` AS `V869`, `V870` AS `V870`, `V871` AS `V871`, `V872` AS `V872`, `V873` AS `V873`, `V874` AS `V874`, `V875` AS `V875`, `V876` AS `V876`, `V877` AS `V877`, `V878` AS `V878`, `V879` AS `V879`, `V880` AS `V880`, `V881` AS `V881`, `V882` AS `V882`, `V883` AS `V883`, `V884` AS `V884`, `V885` AS `V885`, `V886` AS `V886`, `V887` AS `V887`, `V888` AS `V888`, `V889` AS `V889`, `V890` AS `V890`, `V891` AS `V891`, `V892` AS `V892`, `V893` AS `V893`, `V894` AS `V894`, `V895` AS `V895`, `V896` AS `V896`, `V897` AS `V897`, `V898` AS `V898`, `V899` AS `V899`, `V900` AS `V900`, `V901` AS `V901`, `V902` AS `V902`, `V903` AS `V903`, `V904` AS `V904`, `V905` AS `V905`, `V906` AS `V906`, `V907` AS `V907`, `V908` AS `V908`, `V909` AS `V909`, `V910` AS `V910`, `V911` AS `V911`, `V912` AS `V912`, `V913` AS `V913`, `V914` AS `V914`, `V915` AS `V915`, `V916` AS `V916`, `V917` AS `V917`, `V918` AS `V918`, `V919` AS `V919`, `V920` AS `V920`, `V921` AS `V921`, `V922` AS `V922`, `V923` AS `V923`, `V924` AS `V924`, `V925` AS `V925`, `V926` AS `V926`, `V927` AS `V927`, `V928` AS `V928`, `V929` AS `V929`, `V930` AS `V930`, `V931` AS `V931`, `V932` AS `V932`, `V933` AS `V933`, `V934` AS `V934`, `V935` AS `V935`, `V936` AS `V936`, `V937` AS `V937`, `V938` AS `V938`, `V939` AS `V939`, `V940` AS `V940`, `V941` AS `V941`, `V942` AS `V942`, `V943` AS `V943`, `V944` AS `V944`, `V945` AS `V945`, `V946` AS `V946`, `V947` AS `V947`, `V948` AS `V948`, `V949` AS `V949`, `V950` AS `V950`, `V951` AS `V951`, `V952` AS `V952`, `V953` AS `V953`, `V954` AS `V954`, `V955` AS `V955`, `V956` AS `V956`, `V957` AS `V957`, `V958` AS `V958`, `V959` AS `V959`, `V960` AS `V960`, `V961` AS `V961`, `V962` AS `V962`, `V963` AS `V963`, `V964` AS `V964`, `V965` AS `V965`, `V966` AS `V966`, `V967` AS `V967`, `V968` AS `V968`, `V969` AS `V969`, `V970` AS `V970`, `V971` AS `V971`, `V972` AS `V972`, `V973` AS `V973`, `V974` AS `V974`, `V975` AS `V975`, `V976` AS `V976`, `V977` AS `V977`, `V978` AS `V978`, `V979` AS `V979`, `V980` AS `V980`, `V981` AS `V981`, `V982` AS `V982`, `V983` AS `V983`, `V984` AS `V984`, `V985` AS `V985`, `V986` AS `V986`, `V987` AS `V987`, `V988` AS `V988`, `V989` AS `V989`, `V990` AS `V990`, `V991` AS `V991`, `V992` AS `V992`, `V993` AS `V993`, `V994` AS `V994`, `V995` AS `V995`, `V996` AS `V996`, `V997` AS `V997`, `V998` AS `V998`, `V999` AS `V999`, `V1000` AS `V1000`
FROM (SELECT `S1`, `S1` + 0.92195445 * RANDN() AS `V1`, `S1` + 0.92195445 * RANDN() AS `V2`, `S1` + 0.92195445 * RANDN() AS `V3`, `S1` + 0.92195445 * RANDN() AS `V4`, `S1` + 0.92195445 * RANDN() AS `V5`, `S1` + 0.92195445 * RANDN() AS `V6`, `S1` + 0.92195445 * RANDN() AS `V7`, `S1` + 0.92195445 * RANDN() AS `V8`, `S1` + 0.92195445 * RANDN() AS `V9`, `S1` + 0.92195445 * RANDN() AS `V10`, `S1` + 0.92195445 * RANDN() AS `V11`, `S1` + 0.92195445 * RANDN() AS `V12`, `S1` + 0.92195445 * RANDN() AS `V13`, `S1` + 0.92195445 * RANDN() AS `V14`, `S1` + 0.92195445 * RANDN() AS `V15`, `S1` + 0.92195445 * RANDN() AS `V16`, `S1` + 0.92195445 * RANDN() AS `V17`, `S1` + 0.92195445 * RANDN() AS `V18`, `S1` + 0.92195445 * RANDN() AS `V19`, `S1` + 0.92195445 * RANDN() AS `V20`, `S1` + 0.92195445 * RANDN() AS `V21`, `S1` + 0.92195445 * RANDN() AS `V22`, `S1` + 0.92195445 * RANDN() AS `V23`, `S1` + 0.92195445 * RANDN() AS `V24`, `S1` + 0.92195445 * RANDN() AS `V25`, `S1` + 0.92195445 * RANDN() AS `V26`, `S1` + 0.92195445 * RANDN() AS `V27`, `S1` + 0.92195445 * RANDN() AS `V28`, `S1` + 0.92195445 * RANDN() AS `V29`, `S1` + 0.92195445 * RANDN() AS `V30`, `S1` + 0.92195445 * RANDN() AS `V31`, `S1` + 0.92195445 * RANDN() AS `V32`, `S1` + 0.92195445 * RANDN() AS `V33`, `S1` + 0.92195445 * RANDN() AS `V34`, `S1` + 0.92195445 * RANDN() AS `V35`, `S1` + 0.92195445 * RANDN() AS `V36`, `S1` + 0.92195445 * RANDN() AS `V37`, `S1` + 0.92195445 * RANDN() AS `V38`, `S1` + 0.92195445 * RANDN() AS `V39`, `S1` + 0.92195445 * RANDN() AS `V40`, `S1` + 0.92195445 * RANDN() AS `V41`, `S1` + 0.92195445 * RANDN() AS `V42`, `S1` + 0.92195445 * RANDN() AS `V43`, `S1` + 0.92195445 * RANDN() AS `V44`, `S1` + 0.92195445 * RANDN() AS `V45`, `S1` + 0.92195445 * RANDN() AS `V46`, `S1` + 0.92195445 * RANDN() AS `V47`, `S1` + 0.92195445 * RANDN() AS `V48`, `S1` + 0.92195445 * RANDN() AS `V49`, `S1` + 0.92195445 * RANDN() AS `V50`, `S1` + 0.92195445 * RANDN() AS `V51`, `S1` + 0.92195445 * RANDN() AS `V52`, `S1` + 0.92195445 * RANDN() AS `V53`, `S1` + 0.92195445 * RANDN() AS `V54`, `S1` + 0.92195445 * RANDN() AS `V55`, `S1` + 0.92195445 * RANDN() AS `V56`, `S1` + 0.92195445 * RANDN() AS `V57`, `S1` + 0.92195445 * RANDN() AS `V58`, `S1` + 0.92195445 * RANDN() AS `V59`, `S1` + 0.92195445 * RANDN() AS `V60`, `S1` + 0.92195445 * RANDN() AS `V61`, `S1` + 0.92195445 * RANDN() AS `V62`, `S1` + 0.92195445 * RANDN() AS `V63`, `S1` + 0.92195445 * RANDN() AS `V64`, `S1` + 0.92195445 * RANDN() AS `V65`, `S1` + 0.92195445 * RANDN() AS `V66`, `S1` + 0.92195445 * RANDN() AS `V67`, `S1` + 0.92195445 * RANDN() AS `V68`, `S1` + 0.92195445 * RANDN() AS `V69`, `S1` + 0.92195445 * RANDN() AS `V70`, `S1` + 0.92195445 * RANDN() AS `V71`, `S1` + 0.92195445 * RANDN() AS `V72`, `S1` + 0.92195445 * RANDN() AS `V73`, `S1` + 0.92195445 * RANDN() AS `V74`, `S1` + 0.92195445 * RANDN() AS `V75`, `S1` + 0.92195445 * RANDN() AS `V76`, `S1` + 0.92195445 * RANDN() AS `V77`, `S1` + 0.92195445 * RANDN() AS `V78`, `S1` + 0.92195445 * RANDN() AS `V79`, `S1` + 0.92195445 * RANDN() AS `V80`, `S1` + 0.92195445 * RANDN() AS `V81`, `S1` + 0.92195445 * RANDN() AS `V82`, `S1` + 0.92195445 * RANDN() AS `V83`, `S1` + 0.92195445 * RANDN() AS `V84`, `S1` + 0.92195445 * RANDN() AS `V85`, `S1` + 0.92195445 * RANDN() AS `V86`, `S1` + 0.92195445 * RANDN() AS `V87`, `S1` + 0.92195445 * RANDN() AS `V88`, `S1` + 0.92195445 * RANDN() AS `V89`, `S1` + 0.92195445 * RANDN() AS `V90`, `S1` + 0.92195445 * RANDN() AS `V91`, `S1` + 0.92195445 * RANDN() AS `V92`, `S1` + 0.92195445 * RANDN() AS `V93`, `S1` + 0.92195445 * RANDN() AS `V94`, `S1` + 0.92195445 * RANDN() AS `V95`, `S1` + 0.92195445 * RANDN() AS `V96`, `S1` + 0.92195445 * RANDN() AS `V97`, `S1` + 0.92195445 * RANDN() AS `V98`, `S1` + 0.92195445 * RANDN() AS `V99`, `S1` + 0.92195445 * RANDN() AS `V100`, `S1` + 0.92195445 * RANDN() AS `V101`, `S1` + 0.92195445 * RANDN() AS `V102`, `S1` + 0.92195445 * RANDN() AS `V103`, `S1` + 0.92195445 * RANDN() AS `V104`, `S1` + 0.92195445 * RANDN() AS `V105`, `S1` + 0.92195445 * RANDN() AS `V106`, `S1` + 0.92195445 * RANDN() AS `V107`, `S1` + 0.92195445 * RANDN() AS `V108`, `S1` + 0.92195445 * RANDN() AS `V109`, `S1` + 0.92195445 * RANDN() AS `V110`, `S1` + 0.92195445 * RANDN() AS `V111`, `S1` + 0.92195445 * RANDN() AS `V112`, `S1` + 0.92195445 * RANDN() AS `V113`, `S1` + 0.92195445 * RANDN() AS `V114`, `S1` + 0.92195445 * RANDN() AS `V115`, `S1` + 0.92195445 * RANDN() AS `V116`, `S1` + 0.92195445 * RANDN() AS `V117`, `S1` + 0.92195445 * RANDN() AS `V118`, `S1` + 0.92195445 * RANDN() AS `V119`, `S1` + 0.92195445 * RANDN() AS `V120`, `S1` + 0.92195445 * RANDN() AS `V121`, `S1` + 0.92195445 * RANDN() AS `V122`, `S1` + 0.92195445 * RANDN() AS `V123`, `S1` + 0.92195445 * RANDN() AS `V124`, `S1` + 0.92195445 * RANDN() AS `V125`, `S1` + 0.92195445 * RANDN() AS `V126`, `S1` + 0.92195445 * RANDN() AS `V127`, `S1` + 0.92195445 * RANDN() AS `V128`, `S1` + 0.92195445 * RANDN() AS `V129`, `S1` + 0.92195445 * RANDN() AS `V130`, `S1` + 0.92195445 * RANDN() AS `V131`, `S1` + 0.92195445 * RANDN() AS `V132`, `S1` + 0.92195445 * RANDN() AS `V133`, `S1` + 0.92195445 * RANDN() AS `V134`, `S1` + 0.92195445 * RANDN() AS `V135`, `S1` + 0.92195445 * RANDN() AS `V136`, `S1` + 0.92195445 * RANDN() AS `V137`, `S1` + 0.92195445 * RANDN() AS `V138`, `S1` + 0.92195445 * RANDN() AS `V139`, `S1` + 0.92195445 * RANDN() AS `V140`, `S1` + 0.92195445 * RANDN() AS `V141`, `S1` + 0.92195445 * RANDN() AS `V142`, `S1` + 0.92195445 * RANDN() AS `V143`, `S1` + 0.92195445 * RANDN() AS `V144`, `S1` + 0.92195445 * RANDN() AS `V145`, `S1` + 0.92195445 * RANDN() AS `V146`, `S1` + 0.92195445 * RANDN() AS `V147`, `S1` + 0.92195445 * RANDN() AS `V148`, `S1` + 0.92195445 * RANDN() AS `V149`, `S1` + 0.92195445 * RANDN() AS `V150`, `S1` + 0.92195445 * RANDN() AS `V151`, `S1` + 0.92195445 * RANDN() AS `V152`, `S1` + 0.92195445 * RANDN() AS `V153`, `S1` + 0.92195445 * RANDN() AS `V154`, `S1` + 0.92195445 * RANDN() AS `V155`, `S1` + 0.92195445 * RANDN() AS `V156`, `S1` + 0.92195445 * RANDN() AS `V157`, `S1` + 0.92195445 * RANDN() AS `V158`, `S1` + 0.92195445 * RANDN() AS `V159`, `S1` + 0.92195445 * RANDN() AS `V160`, `S1` + 0.92195445 * RANDN() AS `V161`, `S1` + 0.92195445 * RANDN() AS `V162`, `S1` + 0.92195445 * RANDN() AS `V163`, `S1` + 0.92195445 * RANDN() AS `V164`, `S1` + 0.92195445 * RANDN() AS `V165`, `S1` + 0.92195445 * RANDN() AS `V166`, `S1` + 0.92195445 * RANDN() AS `V167`, `S1` + 0.92195445 * RANDN() AS `V168`, `S1` + 0.92195445 * RANDN() AS `V169`, `S1` + 0.92195445 * RANDN() AS `V170`, `S1` + 0.92195445 * RANDN() AS `V171`, `S1` + 0.92195445 * RANDN() AS `V172`, `S1` + 0.92195445 * RANDN() AS `V173`, `S1` + 0.92195445 * RANDN() AS `V174`, `S1` + 0.92195445 * RANDN() AS `V175`, `S1` + 0.92195445 * RANDN() AS `V176`, `S1` + 0.92195445 * RANDN() AS `V177`, `S1` + 0.92195445 * RANDN() AS `V178`, `S1` + 0.92195445 * RANDN() AS `V179`, `S1` + 0.92195445 * RANDN() AS `V180`, `S1` + 0.92195445 * RANDN() AS `V181`, `S1` + 0.92195445 * RANDN() AS `V182`, `S1` + 0.92195445 * RANDN() AS `V183`, `S1` + 0.92195445 * RANDN() AS `V184`, `S1` + 0.92195445 * RANDN() AS `V185`, `S1` + 0.92195445 * RANDN() AS `V186`, `S1` + 0.92195445 * RANDN() AS `V187`, `S1` + 0.92195445 * RANDN() AS `V188`, `S1` + 0.92195445 * RANDN() AS `V189`, `S1` + 0.92195445 * RANDN() AS `V190`, `S1` + 0.92195445 * RANDN() AS `V191`, `S1` + 0.92195445 * RANDN() AS `V192`, `S1` + 0.92195445 * RANDN() AS `V193`, `S1` + 0.92195445 * RANDN() AS `V194`, `S1` + 0.92195445 * RANDN() AS `V195`, `S1` + 0.92195445 * RANDN() AS `V196`, `S1` + 0.92195445 * RANDN() AS `V197`, `S1` + 0.92195445 * RANDN() AS `V198`, `S1` + 0.92195445 * RANDN() AS `V199`, `S1` + 0.92195445 * RANDN() AS `V200`, `S1` + 0.92195445 * RANDN() AS `V201`, `S1` + 0.92195445 * RANDN() AS `V202`, `S1` + 0.92195445 * RANDN() AS `V203`, `S1` + 0.92195445 * RANDN() AS `V204`, `S1` + 0.92195445 * RANDN() AS `V205`, `S1` + 0.92195445 * RANDN() AS `V206`, `S1` + 0.92195445 * RANDN() AS `V207`, `S1` + 0.92195445 * RANDN() AS `V208`, `S1` + 0.92195445 * RANDN() AS `V209`, `S1` + 0.92195445 * RANDN() AS `V210`, `S1` + 0.92195445 * RANDN() AS `V211`, `S1` + 0.92195445 * RANDN() AS `V212`, `S1` + 0.92195445 * RANDN() AS `V213`, `S1` + 0.92195445 * RANDN() AS `V214`, `S1` + 0.92195445 * RANDN() AS `V215`, `S1` + 0.92195445 * RANDN() AS `V216`, `S1` + 0.92195445 * RANDN() AS `V217`, `S1` + 0.92195445 * RANDN() AS `V218`, `S1` + 0.92195445 * RANDN() AS `V219`, `S1` + 0.92195445 * RANDN() AS `V220`, `S1` + 0.92195445 * RANDN() AS `V221`, `S1` + 0.92195445 * RANDN() AS `V222`, `S1` + 0.92195445 * RANDN() AS `V223`, `S1` + 0.92195445 * RANDN() AS `V224`, `S1` + 0.92195445 * RANDN() AS `V225`, `S1` + 0.92195445 * RANDN() AS `V226`, `S1` + 0.92195445 * RANDN() AS `V227`, `S1` + 0.92195445 * RANDN() AS `V228`, `S1` + 0.92195445 * RANDN() AS `V229`, `S1` + 0.92195445 * RANDN() AS `V230`, `S1` + 0.92195445 * RANDN() AS `V231`, `S1` + 0.92195445 * RANDN() AS `V232`, `S1` + 0.92195445 * RANDN() AS `V233`, `S1` + 0.92195445 * RANDN() AS `V234`, `S1` + 0.92195445 * RANDN() AS `V235`, `S1` + 0.92195445 * RANDN() AS `V236`, `S1` + 0.92195445 * RANDN() AS `V237`, `S1` + 0.92195445 * RANDN() AS `V238`, `S1` + 0.92195445 * RANDN() AS `V239`, `S1` + 0.92195445 * RANDN() AS `V240`, `S1` + 0.92195445 * RANDN() AS `V241`, `S1` + 0.92195445 * RANDN() AS `V242`, `S1` + 0.92195445 * RANDN() AS `V243`, `S1` + 0.92195445 * RANDN() AS `V244`, `S1` + 0.92195445 * RANDN() AS `V245`, `S1` + 0.92195445 * RANDN() AS `V246`, `S1` + 0.92195445 * RANDN() AS `V247`, `S1` + 0.92195445 * RANDN() AS `V248`, `S1` + 0.92195445 * RANDN() AS `V249`, `S1` + 0.92195445 * RANDN() AS `V250`, `S1` + 0.92195445 * RANDN() AS `V251`, `S1` + 0.92195445 * RANDN() AS `V252`, `S1` + 0.92195445 * RANDN() AS `V253`, `S1` + 0.92195445 * RANDN() AS `V254`, `S1` + 0.92195445 * RANDN() AS `V255`, `S1` + 0.92195445 * RANDN() AS `V256`, `S1` + 0.92195445 * RANDN() AS `V257`, `S1` + 0.92195445 * RANDN() AS `V258`, `S1` + 0.92195445 * RANDN() AS `V259`, `S1` + 0.92195445 * RANDN() AS `V260`, `S1` + 0.92195445 * RANDN() AS `V261`, `S1` + 0.92195445 * RANDN() AS `V262`, `S1` + 0.92195445 * RANDN() AS `V263`, `S1` + 0.92195445 * RANDN() AS `V264`, `S1` + 0.92195445 * RANDN() AS `V265`, `S1` + 0.92195445 * RANDN() AS `V266`, `S1` + 0.92195445 * RANDN() AS `V267`, `S1` + 0.92195445 * RANDN() AS `V268`, `S1` + 0.92195445 * RANDN() AS `V269`, `S1` + 0.92195445 * RANDN() AS `V270`, `S1` + 0.92195445 * RANDN() AS `V271`, `S1` + 0.92195445 * RANDN() AS `V272`, `S1` + 0.92195445 * RANDN() AS `V273`, `S1` + 0.92195445 * RANDN() AS `V274`, `S1` + 0.92195445 * RANDN() AS `V275`, `S1` + 0.92195445 * RANDN() AS `V276`, `S1` + 0.92195445 * RANDN() AS `V277`, `S1` + 0.92195445 * RANDN() AS `V278`, `S1` + 0.92195445 * RANDN() AS `V279`, `S1` + 0.92195445 * RANDN() AS `V280`, `S1` + 0.92195445 * RANDN() AS `V281`, `S1` + 0.92195445 * RANDN() AS `V282`, `S1` + 0.92195445 * RANDN() AS `V283`, `S1` + 0.92195445 * RANDN() AS `V284`, `S1` + 0.92195445 * RANDN() AS `V285`, `S1` + 0.92195445 * RANDN() AS `V286`, `S1` + 0.92195445 * RANDN() AS `V287`, `S1` + 0.92195445 * RANDN() AS `V288`, `S1` + 0.92195445 * RANDN() AS `V289`, `S1` + 0.92195445 * RANDN() AS `V290`, `S1` + 0.92195445 * RANDN() AS `V291`, `S1` + 0.92195445 * RANDN() AS `V292`, `S1` + 0.92195445 * RANDN() AS `V293`, `S1` + 0.92195445 * RANDN() AS `V294`, `S1` + 0.92195445 * RANDN() AS `V295`, `S1` + 0.92195445 * RANDN() AS `V296`, `S1` + 0.92195445 * RANDN() AS `V297`, `S1` + 0.92195445 * RANDN() AS `V298`, `S1` + 0.92195445 * RANDN() AS `V299`, `S1` + 0.92195445 * RANDN() AS `V300`, `S1` + 0.92195445 * RANDN() AS `V301`, `S1` + 0.92195445 * RANDN() AS `V302`, `S1` + 0.92195445 * RANDN() AS `V303`, `S1` + 0.92195445 * RANDN() AS `V304`, `S1` + 0.92195445 * RANDN() AS `V305`, `S1` + 0.92195445 * RANDN() AS `V306`, `S1` + 0.92195445 * RANDN() AS `V307`, `S1` + 0.92195445 * RANDN() AS `V308`, `S1` + 0.92195445 * RANDN() AS `V309`, `S1` + 0.92195445 * RANDN() AS `V310`, `S1` + 0.92195445 * RANDN() AS `V311`, `S1` + 0.92195445 * RANDN() AS `V312`, `S1` + 0.92195445 * RANDN() AS `V313`, `S1` + 0.92195445 * RANDN() AS `V314`, `S1` + 0.92195445 * RANDN() AS `V315`, `S1` + 0.92195445 * RANDN() AS `V316`, `S1` + 0.92195445 * RANDN() AS `V317`, `S1` + 0.92195445 * RANDN() AS `V318`, `S1` + 0.92195445 * RANDN() AS `V319`, `S1` + 0.92195445 * RANDN() AS `V320`, `S1` + 0.92195445 * RANDN() AS `V321`, `S1` + 0.92195445 * RANDN() AS `V322`, `S1` + 0.92195445 * RANDN() AS `V323`, `S1` + 0.92195445 * RANDN() AS `V324`, `S1` + 0.92195445 * RANDN() AS `V325`, `S1` + 0.92195445 * RANDN() AS `V326`, `S1` + 0.92195445 * RANDN() AS `V327`, `S1` + 0.92195445 * RANDN() AS `V328`, `S1` + 0.92195445 * RANDN() AS `V329`, `S1` + 0.92195445 * RANDN() AS `V330`, `S1` + 0.92195445 * RANDN() AS `V331`, `S1` + 0.92195445 * RANDN() AS `V332`, `S1` + 0.92195445 * RANDN() AS `V333`, `S1` + 0.92195445 * RANDN() AS `V334`, `S1` + 0.92195445 * RANDN() AS `V335`, `S1` + 0.92195445 * RANDN() AS `V336`, `S1` + 0.92195445 * RANDN() AS `V337`, `S1` + 0.92195445 * RANDN() AS `V338`, `S1` + 0.92195445 * RANDN() AS `V339`, `S1` + 0.92195445 * RANDN() AS `V340`, `S1` + 0.92195445 * RANDN() AS `V341`, `S1` + 0.92195445 * RANDN() AS `V342`, `S1` + 0.92195445 * RANDN() AS `V343`, `S1` + 0.92195445 * RANDN() AS `V344`, `S1` + 0.92195445 * RANDN() AS `V345`, `S1` + 0.92195445 * RANDN() AS `V346`, `S1` + 0.92195445 * RANDN() AS `V347`, `S1` + 0.92195445 * RANDN() AS `V348`, `S1` + 0.92195445 * RANDN() AS `V349`, `S1` + 0.92195445 * RANDN() AS `V350`, `S1` + 0.92195445 * RANDN() AS `V351`, `S1` + 0.92195445 * RANDN() AS `V352`, `S1` + 0.92195445 * RANDN() AS `V353`, `S1` + 0.92195445 * RANDN() AS `V354`, `S1` + 0.92195445 * RANDN() AS `V355`, `S1` + 0.92195445 * RANDN() AS `V356`, `S1` + 0.92195445 * RANDN() AS `V357`, `S1` + 0.92195445 * RANDN() AS `V358`, `S1` + 0.92195445 * RANDN() AS `V359`, `S1` + 0.92195445 * RANDN() AS `V360`, `S1` + 0.92195445 * RANDN() AS `V361`, `S1` + 0.92195445 * RANDN() AS `V362`, `S1` + 0.92195445 * RANDN() AS `V363`, `S1` + 0.92195445 * RANDN() AS `V364`, `S1` + 0.92195445 * RANDN() AS `V365`, `S1` + 0.92195445 * RANDN() AS `V366`, `S1` + 0.92195445 * RANDN() AS `V367`, `S1` + 0.92195445 * RANDN() AS `V368`, `S1` + 0.92195445 * RANDN() AS `V369`, `S1` + 0.92195445 * RANDN() AS `V370`, `S1` + 0.92195445 * RANDN() AS `V371`, `S1` + 0.92195445 * RANDN() AS `V372`, `S1` + 0.92195445 * RANDN() AS `V373`, `S1` + 0.92195445 * RANDN() AS `V374`, `S1` + 0.92195445 * RANDN() AS `V375`, `S1` + 0.92195445 * RANDN() AS `V376`, `S1` + 0.92195445 * RANDN() AS `V377`, `S1` + 0.92195445 * RANDN() AS `V378`, `S1` + 0.92195445 * RANDN() AS `V379`, `S1` + 0.92195445 * RANDN() AS `V380`, `S1` + 0.92195445 * RANDN() AS `V381`, `S1` + 0.92195445 * RANDN() AS `V382`, `S1` + 0.92195445 * RANDN() AS `V383`, `S1` + 0.92195445 * RANDN() AS `V384`, `S1` + 0.92195445 * RANDN() AS `V385`, `S1` + 0.92195445 * RANDN() AS `V386`, `S1` + 0.92195445 * RANDN() AS `V387`, `S1` + 0.92195445 * RANDN() AS `V388`, `S1` + 0.92195445 * RANDN() AS `V389`, `S1` + 0.92195445 * RANDN() AS `V390`, `S1` + 0.92195445 * RANDN() AS `V391`, `S1` + 0.92195445 * RANDN() AS `V392`, `S1` + 0.92195445 * RANDN() AS `V393`, `S1` + 0.92195445 * RANDN() AS `V394`, `S1` + 0.92195445 * RANDN() AS `V395`, `S1` + 0.92195445 * RANDN() AS `V396`, `S1` + 0.92195445 * RANDN() AS `V397`, `S1` + 0.92195445 * RANDN() AS `V398`, `S1` + 0.92195445 * RANDN() AS `V399`, `S1` + 0.92195445 * RANDN() AS `V400`, `S1` + 0.92195445 * RANDN() AS `V401`, `S1` + 0.92195445 * RANDN() AS `V402`, `S1` + 0.92195445 * RANDN() AS `V403`, `S1` + 0.92195445 * RANDN() AS `V404`, `S1` + 0.92195445 * RANDN() AS `V405`, `S1` + 0.92195445 * RANDN() AS `V406`, `S1` + 0.92195445 * RANDN() AS `V407`, `S1` + 0.92195445 * RANDN() AS `V408`, `S1` + 0.92195445 * RANDN() AS `V409`, `S1` + 0.92195445 * RANDN() AS `V410`, `S1` + 0.92195445 * RANDN() AS `V411`, `S1` + 0.92195445 * RANDN() AS `V412`, `S1` + 0.92195445 * RANDN() AS `V413`, `S1` + 0.92195445 * RANDN() AS `V414`, `S1` + 0.92195445 * RANDN() AS `V415`, `S1` + 0.92195445 * RANDN() AS `V416`, `S1` + 0.92195445 * RANDN() AS `V417`, `S1` + 0.92195445 * RANDN() AS `V418`, `S1` + 0.92195445 * RANDN() AS `V419`, `S1` + 0.92195445 * RANDN() AS `V420`, `S1` + 0.92195445 * RANDN() AS `V421`, `S1` + 0.92195445 * RANDN() AS `V422`, `S1` + 0.92195445 * RANDN() AS `V423`, `S1` + 0.92195445 * RANDN() AS `V424`, `S1` + 0.92195445 * RANDN() AS `V425`, `S1` + 0.92195445 * RANDN() AS `V426`, `S1` + 0.92195445 * RANDN() AS `V427`, `S1` + 0.92195445 * RANDN() AS `V428`, `S1` + 0.92195445 * RANDN() AS `V429`, `S1` + 0.92195445 * RANDN() AS `V430`, `S1` + 0.92195445 * RANDN() AS `V431`, `S1` + 0.92195445 * RANDN() AS `V432`, `S1` + 0.92195445 * RANDN() AS `V433`, `S1` + 0.92195445 * RANDN() AS `V434`, `S1` + 0.92195445 * RANDN() AS `V435`, `S1` + 0.92195445 * RANDN() AS `V436`, `S1` + 0.92195445 * RANDN() AS `V437`, `S1` + 0.92195445 * RANDN() AS `V438`, `S1` + 0.92195445 * RANDN() AS `V439`, `S1` + 0.92195445 * RANDN() AS `V440`, `S1` + 0.92195445 * RANDN() AS `V441`, `S1` + 0.92195445 * RANDN() AS `V442`, `S1` + 0.92195445 * RANDN() AS `V443`, `S1` + 0.92195445 * RANDN() AS `V444`, `S1` + 0.92195445 * RANDN() AS `V445`, `S1` + 0.92195445 * RANDN() AS `V446`, `S1` + 0.92195445 * RANDN() AS `V447`, `S1` + 0.92195445 * RANDN() AS `V448`, `S1` + 0.92195445 * RANDN() AS `V449`, `S1` + 0.92195445 * RANDN() AS `V450`, `S1` + 0.92195445 * RANDN() AS `V451`, `S1` + 0.92195445 * RANDN() AS `V452`, `S1` + 0.92195445 * RANDN() AS `V453`, `S1` + 0.92195445 * RANDN() AS `V454`, `S1` + 0.92195445 * RANDN() AS `V455`, `S1` + 0.92195445 * RANDN() AS `V456`, `S1` + 0.92195445 * RANDN() AS `V457`, `S1` + 0.92195445 * RANDN() AS `V458`, `S1` + 0.92195445 * RANDN() AS `V459`, `S1` + 0.92195445 * RANDN() AS `V460`, `S1` + 0.92195445 * RANDN() AS `V461`, `S1` + 0.92195445 * RANDN() AS `V462`, `S1` + 0.92195445 * RANDN() AS `V463`, `S1` + 0.92195445 * RANDN() AS `V464`, `S1` + 0.92195445 * RANDN() AS `V465`, `S1` + 0.92195445 * RANDN() AS `V466`, `S1` + 0.92195445 * RANDN() AS `V467`, `S1` + 0.92195445 * RANDN() AS `V468`, `S1` + 0.92195445 * RANDN() AS `V469`, `S1` + 0.92195445 * RANDN() AS `V470`, `S1` + 0.92195445 * RANDN() AS `V471`, `S1` + 0.92195445 * RANDN() AS `V472`, `S1` + 0.92195445 * RANDN() AS `V473`, `S1` + 0.92195445 * RANDN() AS `V474`, `S1` + 0.92195445 * RANDN() AS `V475`, `S1` + 0.92195445 * RANDN() AS `V476`, `S1` + 0.92195445 * RANDN() AS `V477`, `S1` + 0.92195445 * RANDN() AS `V478`, `S1` + 0.92195445 * RANDN() AS `V479`, `S1` + 0.92195445 * RANDN() AS `V480`, `S1` + 0.92195445 * RANDN() AS `V481`, `S1` + 0.92195445 * RANDN() AS `V482`, `S1` + 0.92195445 * RANDN() AS `V483`, `S1` + 0.92195445 * RANDN() AS `V484`, `S1` + 0.92195445 * RANDN() AS `V485`, `S1` + 0.92195445 * RANDN() AS `V486`, `S1` + 0.92195445 * RANDN() AS `V487`, `S1` + 0.92195445 * RANDN() AS `V488`, `S1` + 0.92195445 * RANDN() AS `V489`, `S1` + 0.92195445 * RANDN() AS `V490`, `S1` + 0.92195445 * RANDN() AS `V491`, `S1` + 0.92195445 * RANDN() AS `V492`, `S1` + 0.92195445 * RANDN() AS `V493`, `S1` + 0.92195445 * RANDN() AS `V494`, `S1` + 0.92195445 * RANDN() AS `V495`, `S1` + 0.92195445 * RANDN() AS `V496`, `S1` + 0.92195445 * RANDN() AS `V497`, `S1` + 0.92195445 * RANDN() AS `V498`, `S1` + 0.92195445 * RANDN() AS `V499`, `S1` + 0.92195445 * RANDN() AS `V500`, `S1` + 0.92195445 * RANDN() AS `V501`, `S1` + 0.92195445 * RANDN() AS `V502`, `S1` + 0.92195445 * RANDN() AS `V503`, `S1` + 0.92195445 * RANDN() AS `V504`, `S1` + 0.92195445 * RANDN() AS `V505`, `S1` + 0.92195445 * RANDN() AS `V506`, `S1` + 0.92195445 * RANDN() AS `V507`, `S1` + 0.92195445 * RANDN() AS `V508`, `S1` + 0.92195445 * RANDN() AS `V509`, `S1` + 0.92195445 * RANDN() AS `V510`, `S1` + 0.92195445 * RANDN() AS `V511`, `S1` + 0.92195445 * RANDN() AS `V512`, `S1` + 0.92195445 * RANDN() AS `V513`, `S1` + 0.92195445 * RANDN() AS `V514`, `S1` + 0.92195445 * RANDN() AS `V515`, `S1` + 0.92195445 * RANDN() AS `V516`, `S1` + 0.92195445 * RANDN() AS `V517`, `S1` + 0.92195445 * RANDN() AS `V518`, `S1` + 0.92195445 * RANDN() AS `V519`, `S1` + 0.92195445 * RANDN() AS `V520`, `S1` + 0.92195445 * RANDN() AS `V521`, `S1` + 0.92195445 * RANDN() AS `V522`, `S1` + 0.92195445 * RANDN() AS `V523`, `S1` + 0.92195445 * RANDN() AS `V524`, `S1` + 0.92195445 * RANDN() AS `V525`, `S1` + 0.92195445 * RANDN() AS `V526`, `S1` + 0.92195445 * RANDN() AS `V527`, `S1` + 0.92195445 * RANDN() AS `V528`, `S1` + 0.92195445 * RANDN() AS `V529`, `S1` + 0.92195445 * RANDN() AS `V530`, `S1` + 0.92195445 * RANDN() AS `V531`, `S1` + 0.92195445 * RANDN() AS `V532`, `S1` + 0.92195445 * RANDN() AS `V533`, `S1` + 0.92195445 * RANDN() AS `V534`, `S1` + 0.92195445 * RANDN() AS `V535`, `S1` + 0.92195445 * RANDN() AS `V536`, `S1` + 0.92195445 * RANDN() AS `V537`, `S1` + 0.92195445 * RANDN() AS `V538`, `S1` + 0.92195445 * RANDN() AS `V539`, `S1` + 0.92195445 * RANDN() AS `V540`, `S1` + 0.92195445 * RANDN() AS `V541`, `S1` + 0.92195445 * RANDN() AS `V542`, `S1` + 0.92195445 * RANDN() AS `V543`, `S1` + 0.92195445 * RANDN() AS `V544`, `S1` + 0.92195445 * RANDN() AS `V545`, `S1` + 0.92195445 * RANDN() AS `V546`, `S1` + 0.92195445 * RANDN() AS `V547`, `S1` + 0.92195445 * RANDN() AS `V548`, `S1` + 0.92195445 * RANDN() AS `V549`, `S1` + 0.92195445 * RANDN() AS `V550`, `S1` + 0.92195445 * RANDN() AS `V551`, `S1` + 0.92195445 * RANDN() AS `V552`, `S1` + 0.92195445 * RANDN() AS `V553`, `S1` + 0.92195445 * RANDN() AS `V554`, `S1` + 0.92195445 * RANDN() AS `V555`, `S1` + 0.92195445 * RANDN() AS `V556`, `S1` + 0.92195445 * RANDN() AS `V557`, `S1` + 0.92195445 * RANDN() AS `V558`, `S1` + 0.92195445 * RANDN() AS `V559`, `S1` + 0.92195445 * RANDN() AS `V560`, `S1` + 0.92195445 * RANDN() AS `V561`, `S1` + 0.92195445 * RANDN() AS `V562`, `S1` + 0.92195445 * RANDN() AS `V563`, `S1` + 0.92195445 * RANDN() AS `V564`, `S1` + 0.92195445 * RANDN() AS `V565`, `S1` + 0.92195445 * RANDN() AS `V566`, `S1` + 0.92195445 * RANDN() AS `V567`, `S1` + 0.92195445 * RANDN() AS `V568`, `S1` + 0.92195445 * RANDN() AS `V569`, `S1` + 0.92195445 * RANDN() AS `V570`, `S1` + 0.92195445 * RANDN() AS `V571`, `S1` + 0.92195445 * RANDN() AS `V572`, `S1` + 0.92195445 * RANDN() AS `V573`, `S1` + 0.92195445 * RANDN() AS `V574`, `S1` + 0.92195445 * RANDN() AS `V575`, `S1` + 0.92195445 * RANDN() AS `V576`, `S1` + 0.92195445 * RANDN() AS `V577`, `S1` + 0.92195445 * RANDN() AS `V578`, `S1` + 0.92195445 * RANDN() AS `V579`, `S1` + 0.92195445 * RANDN() AS `V580`, `S1` + 0.92195445 * RANDN() AS `V581`, `S1` + 0.92195445 * RANDN() AS `V582`, `S1` + 0.92195445 * RANDN() AS `V583`, `S1` + 0.92195445 * RANDN() AS `V584`, `S1` + 0.92195445 * RANDN() AS `V585`, `S1` + 0.92195445 * RANDN() AS `V586`, `S1` + 0.92195445 * RANDN() AS `V587`, `S1` + 0.92195445 * RANDN() AS `V588`, `S1` + 0.92195445 * RANDN() AS `V589`, `S1` + 0.92195445 * RANDN() AS `V590`, `S1` + 0.92195445 * RANDN() AS `V591`, `S1` + 0.92195445 * RANDN() AS `V592`, `S1` + 0.92195445 * RANDN() AS `V593`, `S1` + 0.92195445 * RANDN() AS `V594`, `S1` + 0.92195445 * RANDN() AS `V595`, `S1` + 0.92195445 * RANDN() AS `V596`, `S1` + 0.92195445 * RANDN() AS `V597`, `S1` + 0.92195445 * RANDN() AS `V598`, `S1` + 0.92195445 * RANDN() AS `V599`, `S1` + 0.92195445 * RANDN() AS `V600`, `S1` + 0.92195445 * RANDN() AS `V601`, `S1` + 0.92195445 * RANDN() AS `V602`, `S1` + 0.92195445 * RANDN() AS `V603`, `S1` + 0.92195445 * RANDN() AS `V604`, `S1` + 0.92195445 * RANDN() AS `V605`, `S1` + 0.92195445 * RANDN() AS `V606`, `S1` + 0.92195445 * RANDN() AS `V607`, `S1` + 0.92195445 * RANDN() AS `V608`, `S1` + 0.92195445 * RANDN() AS `V609`, `S1` + 0.92195445 * RANDN() AS `V610`, `S1` + 0.92195445 * RANDN() AS `V611`, `S1` + 0.92195445 * RANDN() AS `V612`, `S1` + 0.92195445 * RANDN() AS `V613`, `S1` + 0.92195445 * RANDN() AS `V614`, `S1` + 0.92195445 * RANDN() AS `V615`, `S1` + 0.92195445 * RANDN() AS `V616`, `S1` + 0.92195445 * RANDN() AS `V617`, `S1` + 0.92195445 * RANDN() AS `V618`, `S1` + 0.92195445 * RANDN() AS `V619`, `S1` + 0.92195445 * RANDN() AS `V620`, `S1` + 0.92195445 * RANDN() AS `V621`, `S1` + 0.92195445 * RANDN() AS `V622`, `S1` + 0.92195445 * RANDN() AS `V623`, `S1` + 0.92195445 * RANDN() AS `V624`, `S1` + 0.92195445 * RANDN() AS `V625`, `S1` + 0.92195445 * RANDN() AS `V626`, `S1` + 0.92195445 * RANDN() AS `V627`, `S1` + 0.92195445 * RANDN() AS `V628`, `S1` + 0.92195445 * RANDN() AS `V629`, `S1` + 0.92195445 * RANDN() AS `V630`, `S1` + 0.92195445 * RANDN() AS `V631`, `S1` + 0.92195445 * RANDN() AS `V632`, `S1` + 0.92195445 * RANDN() AS `V633`, `S1` + 0.92195445 * RANDN() AS `V634`, `S1` + 0.92195445 * RANDN() AS `V635`, `S1` + 0.92195445 * RANDN() AS `V636`, `S1` + 0.92195445 * RANDN() AS `V637`, `S1` + 0.92195445 * RANDN() AS `V638`, `S1` + 0.92195445 * RANDN() AS `V639`, `S1` + 0.92195445 * RANDN() AS `V640`, `S1` + 0.92195445 * RANDN() AS `V641`, `S1` + 0.92195445 * RANDN() AS `V642`, `S1` + 0.92195445 * RANDN() AS `V643`, `S1` + 0.92195445 * RANDN() AS `V644`, `S1` + 0.92195445 * RANDN() AS `V645`, `S1` + 0.92195445 * RANDN() AS `V646`, `S1` + 0.92195445 * RANDN() AS `V647`, `S1` + 0.92195445 * RANDN() AS `V648`, `S1` + 0.92195445 * RANDN() AS `V649`, `S1` + 0.92195445 * RANDN() AS `V650`, `S1` + 0.92195445 * RANDN() AS `V651`, `S1` + 0.92195445 * RANDN() AS `V652`, `S1` + 0.92195445 * RANDN() AS `V653`, `S1` + 0.92195445 * RANDN() AS `V654`, `S1` + 0.92195445 * RANDN() AS `V655`, `S1` + 0.92195445 * RANDN() AS `V656`, `S1` + 0.92195445 * RANDN() AS `V657`, `S1` + 0.92195445 * RANDN() AS `V658`, `S1` + 0.92195445 * RANDN() AS `V659`, `S1` + 0.92195445 * RANDN() AS `V660`, `S1` + 0.92195445 * RANDN() AS `V661`, `S1` + 0.92195445 * RANDN() AS `V662`, `S1` + 0.92195445 * RANDN() AS `V663`, `S1` + 0.92195445 * RANDN() AS `V664`, `S1` + 0.92195445 * RANDN() AS `V665`, `S1` + 0.92195445 * RANDN() AS `V666`, `S1` + 0.92195445 * RANDN() AS `V667`, `S1` + 0.92195445 * RANDN() AS `V668`, `S1` + 0.92195445 * RANDN() AS `V669`, `S1` + 0.92195445 * RANDN() AS `V670`, `S1` + 0.92195445 * RANDN() AS `V671`, `S1` + 0.92195445 * RANDN() AS `V672`, `S1` + 0.92195445 * RANDN() AS `V673`, `S1` + 0.92195445 * RANDN() AS `V674`, `S1` + 0.92195445 * RANDN() AS `V675`, `S1` + 0.92195445 * RANDN() AS `V676`, `S1` + 0.92195445 * RANDN() AS `V677`, `S1` + 0.92195445 * RANDN() AS `V678`, `S1` + 0.92195445 * RANDN() AS `V679`, `S1` + 0.92195445 * RANDN() AS `V680`, `S1` + 0.92195445 * RANDN() AS `V681`, `S1` + 0.92195445 * RANDN() AS `V682`, `S1` + 0.92195445 * RANDN() AS `V683`, `S1` + 0.92195445 * RANDN() AS `V684`, `S1` + 0.92195445 * RANDN() AS `V685`, `S1` + 0.92195445 * RANDN() AS `V686`, `S1` + 0.92195445 * RANDN() AS `V687`, `S1` + 0.92195445 * RANDN() AS `V688`, `S1` + 0.92195445 * RANDN() AS `V689`, `S1` + 0.92195445 * RANDN() AS `V690`, `S1` + 0.92195445 * RANDN() AS `V691`, `S1` + 0.92195445 * RANDN() AS `V692`, `S1` + 0.92195445 * RANDN() AS `V693`, `S1` + 0.92195445 * RANDN() AS `V694`, `S1` + 0.92195445 * RANDN() AS `V695`, `S1` + 0.92195445 * RANDN() AS `V696`, `S1` + 0.92195445 * RANDN() AS `V697`, `S1` + 0.92195445 * RANDN() AS `V698`, `S1` + 0.92195445 * RANDN() AS `V699`, `S1` + 0.92195445 * RANDN() AS `V700`, `S1` + 0.92195445 * RANDN() AS `V701`, `S1` + 0.92195445 * RANDN() AS `V702`, `S1` + 0.92195445 * RANDN() AS `V703`, `S1` + 0.92195445 * RANDN() AS `V704`, `S1` + 0.92195445 * RANDN() AS `V705`, `S1` + 0.92195445 * RANDN() AS `V706`, `S1` + 0.92195445 * RANDN() AS `V707`, `S1` + 0.92195445 * RANDN() AS `V708`, `S1` + 0.92195445 * RANDN() AS `V709`, `S1` + 0.92195445 * RANDN() AS `V710`, `S1` + 0.92195445 * RANDN() AS `V711`, `S1` + 0.92195445 * RANDN() AS `V712`, `S1` + 0.92195445 * RANDN() AS `V713`, `S1` + 0.92195445 * RANDN() AS `V714`, `S1` + 0.92195445 * RANDN() AS `V715`, `S1` + 0.92195445 * RANDN() AS `V716`, `S1` + 0.92195445 * RANDN() AS `V717`, `S1` + 0.92195445 * RANDN() AS `V718`, `S1` + 0.92195445 * RANDN() AS `V719`, `S1` + 0.92195445 * RANDN() AS `V720`, `S1` + 0.92195445 * RANDN() AS `V721`, `S1` + 0.92195445 * RANDN() AS `V722`, `S1` + 0.92195445 * RANDN() AS `V723`, `S1` + 0.92195445 * RANDN() AS `V724`, `S1` + 0.92195445 * RANDN() AS `V725`, `S1` + 0.92195445 * RANDN() AS `V726`, `S1` + 0.92195445 * RANDN() AS `V727`, `S1` + 0.92195445 * RANDN() AS `V728`, `S1` + 0.92195445 * RANDN() AS `V729`, `S1` + 0.92195445 * RANDN() AS `V730`, `S1` + 0.92195445 * RANDN() AS `V731`, `S1` + 0.92195445 * RANDN() AS `V732`, `S1` + 0.92195445 * RANDN() AS `V733`, `S1` + 0.92195445 * RANDN() AS `V734`, `S1` + 0.92195445 * RANDN() AS `V735`, `S1` + 0.92195445 * RANDN() AS `V736`, `S1` + 0.92195445 * RANDN() AS `V737`, `S1` + 0.92195445 * RANDN() AS `V738`, `S1` + 0.92195445 * RANDN() AS `V739`, `S1` + 0.92195445 * RANDN() AS `V740`, `S1` + 0.92195445 * RANDN() AS `V741`, `S1` + 0.92195445 * RANDN() AS `V742`, `S1` + 0.92195445 * RANDN() AS `V743`, `S1` + 0.92195445 * RANDN() AS `V744`, `S1` + 0.92195445 * RANDN() AS `V745`, `S1` + 0.92195445 * RANDN() AS `V746`, `S1` + 0.92195445 * RANDN() AS `V747`, `S1` + 0.92195445 * RANDN() AS `V748`, `S1` + 0.92195445 * RANDN() AS `V749`, `S1` + 0.92195445 * RANDN() AS `V750`, `S1` + 0.92195445 * RANDN() AS `V751`, `S1` + 0.92195445 * RANDN() AS `V752`, `S1` + 0.92195445 * RANDN() AS `V753`, `S1` + 0.92195445 * RANDN() AS `V754`, `S1` + 0.92195445 * RANDN() AS `V755`, `S1` + 0.92195445 * RANDN() AS `V756`, `S1` + 0.92195445 * RANDN() AS `V757`, `S1` + 0.92195445 * RANDN() AS `V758`, `S1` + 0.92195445 * RANDN() AS `V759`, `S1` + 0.92195445 * RANDN() AS `V760`, `S1` + 0.92195445 * RANDN() AS `V761`, `S1` + 0.92195445 * RANDN() AS `V762`, `S1` + 0.92195445 * RANDN() AS `V763`, `S1` + 0.92195445 * RANDN() AS `V764`, `S1` + 0.92195445 * RANDN() AS `V765`, `S1` + 0.92195445 * RANDN() AS `V766`, `S1` + 0.92195445 * RANDN() AS `V767`, `S1` + 0.92195445 * RANDN() AS `V768`, `S1` + 0.92195445 * RANDN() AS `V769`, `S1` + 0.92195445 * RANDN() AS `V770`, `S1` + 0.92195445 * RANDN() AS `V771`, `S1` + 0.92195445 * RANDN() AS `V772`, `S1` + 0.92195445 * RANDN() AS `V773`, `S1` + 0.92195445 * RANDN() AS `V774`, `S1` + 0.92195445 * RANDN() AS `V775`, `S1` + 0.92195445 * RANDN() AS `V776`, `S1` + 0.92195445 * RANDN() AS `V777`, `S1` + 0.92195445 * RANDN() AS `V778`, `S1` + 0.92195445 * RANDN() AS `V779`, `S1` + 0.92195445 * RANDN() AS `V780`, `S1` + 0.92195445 * RANDN() AS `V781`, `S1` + 0.92195445 * RANDN() AS `V782`, `S1` + 0.92195445 * RANDN() AS `V783`, `S1` + 0.92195445 * RANDN() AS `V784`, `S1` + 0.92195445 * RANDN() AS `V785`, `S1` + 0.92195445 * RANDN() AS `V786`, `S1` + 0.92195445 * RANDN() AS `V787`, `S1` + 0.92195445 * RANDN() AS `V788`, `S1` + 0.92195445 * RANDN() AS `V789`, `S1` + 0.92195445 * RANDN() AS `V790`, `S1` + 0.92195445 * RANDN() AS `V791`, `S1` + 0.92195445 * RANDN() AS `V792`, `S1` + 0.92195445 * RANDN() AS `V793`, `S1` + 0.92195445 * RANDN() AS `V794`, `S1` + 0.92195445 * RANDN() AS `V795`, `S1` + 0.92195445 * RANDN() AS `V796`, `S1` + 0.92195445 * RANDN() AS `V797`, `S1` + 0.92195445 * RANDN() AS `V798`, `S1` + 0.92195445 * RANDN() AS `V799`, `S1` + 0.92195445 * RANDN() AS `V800`, `S1` + 0.92195445 * RANDN() AS `V801`, `S1` + 0.92195445 * RANDN() AS `V802`, `S1` + 0.92195445 * RANDN() AS `V803`, `S1` + 0.92195445 * RANDN() AS `V804`, `S1` + 0.92195445 * RANDN() AS `V805`, `S1` + 0.92195445 * RANDN() AS `V806`, `S1` + 0.92195445 * RANDN() AS `V807`, `S1` + 0.92195445 * RANDN() AS `V808`, `S1` + 0.92195445 * RANDN() AS `V809`, `S1` + 0.92195445 * RANDN() AS `V810`, `S1` + 0.92195445 * RANDN() AS `V811`, `S1` + 0.92195445 * RANDN() AS `V812`, `S1` + 0.92195445 * RANDN() AS `V813`, `S1` + 0.92195445 * RANDN() AS `V814`, `S1` + 0.92195445 * RANDN() AS `V815`, `S1` + 0.92195445 * RANDN() AS `V816`, `S1` + 0.92195445 * RANDN() AS `V817`, `S1` + 0.92195445 * RANDN() AS `V818`, `S1` + 0.92195445 * RANDN() AS `V819`, `S1` + 0.92195445 * RANDN() AS `V820`, `S1` + 0.92195445 * RANDN() AS `V821`, `S1` + 0.92195445 * RANDN() AS `V822`, `S1` + 0.92195445 * RANDN() AS `V823`, `S1` + 0.92195445 * RANDN() AS `V824`, `S1` + 0.92195445 * RANDN() AS `V825`, `S1` + 0.92195445 * RANDN() AS `V826`, `S1` + 0.92195445 * RANDN() AS `V827`, `S1` + 0.92195445 * RANDN() AS `V828`, `S1` + 0.92195445 * RANDN() AS `V829`, `S1` + 0.92195445 * RANDN() AS `V830`, `S1` + 0.92195445 * RANDN() AS `V831`, `S1` + 0.92195445 * RANDN() AS `V832`, `S1` + 0.92195445 * RANDN() AS `V833`, `S1` + 0.92195445 * RANDN() AS `V834`, `S1` + 0.92195445 * RANDN() AS `V835`, `S1` + 0.92195445 * RANDN() AS `V836`, `S1` + 0.92195445 * RANDN() AS `V837`, `S1` + 0.92195445 * RANDN() AS `V838`, `S1` + 0.92195445 * RANDN() AS `V839`, `S1` + 0.92195445 * RANDN() AS `V840`, `S1` + 0.92195445 * RANDN() AS `V841`, `S1` + 0.92195445 * RANDN() AS `V842`, `S1` + 0.92195445 * RANDN() AS `V843`, `S1` + 0.92195445 * RANDN() AS `V844`, `S1` + 0.92195445 * RANDN() AS `V845`, `S1` + 0.92195445 * RANDN() AS `V846`, `S1` + 0.92195445 * RANDN() AS `V847`, `S1` + 0.92195445 * RANDN() AS `V848`, `S1` + 0.92195445 * RANDN() AS `V849`, `S1` + 0.92195445 * RANDN() AS `V850`, `S1` + 0.92195445 * RANDN() AS `V851`, `S1` + 0.92195445 * RANDN() AS `V852`, `S1` + 0.92195445 * RANDN() AS `V853`, `S1` + 0.92195445 * RANDN() AS `V854`, `S1` + 0.92195445 * RANDN() AS `V855`, `S1` + 0.92195445 * RANDN() AS `V856`, `S1` + 0.92195445 * RANDN() AS `V857`, `S1` + 0.92195445 * RANDN() AS `V858`, `S1` + 0.92195445 * RANDN() AS `V859`, `S1` + 0.92195445 * RANDN() AS `V860`, `S1` + 0.92195445 * RANDN() AS `V861`, `S1` + 0.92195445 * RANDN() AS `V862`, `S1` + 0.92195445 * RANDN() AS `V863`, `S1` + 0.92195445 * RANDN() AS `V864`, `S1` + 0.92195445 * RANDN() AS `V865`, `S1` + 0.92195445 * RANDN() AS `V866`, `S1` + 0.92195445 * RANDN() AS `V867`, `S1` + 0.92195445 * RANDN() AS `V868`, `S1` + 0.92195445 * RANDN() AS `V869`, `S1` + 0.92195445 * RANDN() AS `V870`, `S1` + 0.92195445 * RANDN() AS `V871`, `S1` + 0.92195445 * RANDN() AS `V872`, `S1` + 0.92195445 * RANDN() AS `V873`, `S1` + 0.92195445 * RANDN() AS `V874`, `S1` + 0.92195445 * RANDN() AS `V875`, `S1` + 0.92195445 * RANDN() AS `V876`, `S1` + 0.92195445 * RANDN() AS `V877`, `S1` + 0.92195445 * RANDN() AS `V878`, `S1` + 0.92195445 * RANDN() AS `V879`, `S1` + 0.92195445 * RANDN() AS `V880`, `S1` + 0.92195445 * RANDN() AS `V881`, `S1` + 0.92195445 * RANDN() AS `V882`, `S1` + 0.92195445 * RANDN() AS `V883`, `S1` + 0.92195445 * RANDN() AS `V884`, `S1` + 0.92195445 * RANDN() AS `V885`, `S1` + 0.92195445 * RANDN() AS `V886`, `S1` + 0.92195445 * RANDN() AS `V887`, `S1` + 0.92195445 * RANDN() AS `V888`, `S1` + 0.92195445 * RANDN() AS `V889`, `S1` + 0.92195445 * RANDN() AS `V890`, `S1` + 0.92195445 * RANDN() AS `V891`, `S1` + 0.92195445 * RANDN() AS `V892`, `S1` + 0.92195445 * RANDN() AS `V893`, `S1` + 0.92195445 * RANDN() AS `V894`, `S1` + 0.92195445 * RANDN() AS `V895`, `S1` + 0.92195445 * RANDN() AS `V896`, `S1` + 0.92195445 * RANDN() AS `V897`, `S1` + 0.92195445 * RANDN() AS `V898`, `S1` + 0.92195445 * RANDN() AS `V899`, `S1` + 0.92195445 * RANDN() AS `V900`, `S1` + 0.92195445 * RANDN() AS `V901`, `S1` + 0.92195445 * RANDN() AS `V902`, `S1` + 0.92195445 * RANDN() AS `V903`, `S1` + 0.92195445 * RANDN() AS `V904`, `S1` + 0.92195445 * RANDN() AS `V905`, `S1` + 0.92195445 * RANDN() AS `V906`, `S1` + 0.92195445 * RANDN() AS `V907`, `S1` + 0.92195445 * RANDN() AS `V908`, `S1` + 0.92195445 * RANDN() AS `V909`, `S1` + 0.92195445 * RANDN() AS `V910`, `S1` + 0.92195445 * RANDN() AS `V911`, `S1` + 0.92195445 * RANDN() AS `V912`, `S1` + 0.92195445 * RANDN() AS `V913`, `S1` + 0.92195445 * RANDN() AS `V914`, `S1` + 0.92195445 * RANDN() AS `V915`, `S1` + 0.92195445 * RANDN() AS `V916`, `S1` + 0.92195445 * RANDN() AS `V917`, `S1` + 0.92195445 * RANDN() AS `V918`, `S1` + 0.92195445 * RANDN() AS `V919`, `S1` + 0.92195445 * RANDN() AS `V920`, `S1` + 0.92195445 * RANDN() AS `V921`, `S1` + 0.92195445 * RANDN() AS `V922`, `S1` + 0.92195445 * RANDN() AS `V923`, `S1` + 0.92195445 * RANDN() AS `V924`, `S1` + 0.92195445 * RANDN() AS `V925`, `S1` + 0.92195445 * RANDN() AS `V926`, `S1` + 0.92195445 * RANDN() AS `V927`, `S1` + 0.92195445 * RANDN() AS `V928`, `S1` + 0.92195445 * RANDN() AS `V929`, `S1` + 0.92195445 * RANDN() AS `V930`, `S1` + 0.92195445 * RANDN() AS `V931`, `S1` + 0.92195445 * RANDN() AS `V932`, `S1` + 0.92195445 * RANDN() AS `V933`, `S1` + 0.92195445 * RANDN() AS `V934`, `S1` + 0.92195445 * RANDN() AS `V935`, `S1` + 0.92195445 * RANDN() AS `V936`, `S1` + 0.92195445 * RANDN() AS `V937`, `S1` + 0.92195445 * RANDN() AS `V938`, `S1` + 0.92195445 * RANDN() AS `V939`, `S1` + 0.92195445 * RANDN() AS `V940`, `S1` + 0.92195445 * RANDN() AS `V941`, `S1` + 0.92195445 * RANDN() AS `V942`, `S1` + 0.92195445 * RANDN() AS `V943`, `S1` + 0.92195445 * RANDN() AS `V944`, `S1` + 0.92195445 * RANDN() AS `V945`, `S1` + 0.92195445 * RANDN() AS `V946`, `S1` + 0.92195445 * RANDN() AS `V947`, `S1` + 0.92195445 * RANDN() AS `V948`, `S1` + 0.92195445 * RANDN() AS `V949`, `S1` + 0.92195445 * RANDN() AS `V950`, `S1` + 0.92195445 * RANDN() AS `V951`, `S1` + 0.92195445 * RANDN() AS `V952`, `S1` + 0.92195445 * RANDN() AS `V953`, `S1` + 0.92195445 * RANDN() AS `V954`, `S1` + 0.92195445 * RANDN() AS `V955`, `S1` + 0.92195445 * RANDN() AS `V956`, `S1` + 0.92195445 * RANDN() AS `V957`, `S1` + 0.92195445 * RANDN() AS `V958`, `S1` + 0.92195445 * RANDN() AS `V959`, `S1` + 0.92195445 * RANDN() AS `V960`, `S1` + 0.92195445 * RANDN() AS `V961`, `S1` + 0.92195445 * RANDN() AS `V962`, `S1` + 0.92195445 * RANDN() AS `V963`, `S1` + 0.92195445 * RANDN() AS `V964`, `S1` + 0.92195445 * RANDN() AS `V965`, `S1` + 0.92195445 * RANDN() AS `V966`, `S1` + 0.92195445 * RANDN() AS `V967`, `S1` + 0.92195445 * RANDN() AS `V968`, `S1` + 0.92195445 * RANDN() AS `V969`, `S1` + 0.92195445 * RANDN() AS `V970`, `S1` + 0.92195445 * RANDN() AS `V971`, `S1` + 0.92195445 * RANDN() AS `V972`, `S1` + 0.92195445 * RANDN() AS `V973`, `S1` + 0.92195445 * RANDN() AS `V974`, `S1` + 0.92195445 * RANDN() AS `V975`, `S1` + 0.92195445 * RANDN() AS `V976`, `S1` + 0.92195445 * RANDN() AS `V977`, `S1` + 0.92195445 * RANDN() AS `V978`, `S1` + 0.92195445 * RANDN() AS `V979`, `S1` + 0.92195445 * RANDN() AS `V980`, `S1` + 0.92195445 * RANDN() AS `V981`, `S1` + 0.92195445 * RANDN() AS `V982`, `S1` + 0.92195445 * RANDN() AS `V983`, `S1` + 0.92195445 * RANDN() AS `V984`, `S1` + 0.92195445 * RANDN() AS `V985`, `S1` + 0.92195445 * RANDN() AS `V986`, `S1` + 0.92195445 * RANDN() AS `V987`, `S1` + 0.92195445 * RANDN() AS `V988`, `S1` + 0.92195445 * RANDN() AS `V989`, `S1` + 0.92195445 * RANDN() AS `V990`, `S1` + 0.92195445 * RANDN() AS `V991`, `S1` + 0.92195445 * RANDN() AS `V992`, `S1` + 0.92195445 * RANDN() AS `V993`, `S1` + 0.92195445 * RANDN() AS `V994`, `S1` + 0.92195445 * RANDN() AS `V995`, `S1` + 0.92195445 * RANDN() AS `V996`, `S1` + 0.92195445 * RANDN() AS `V997`, `S1` + 0.92195445 * RANDN() AS `V998`, `S1` + 0.92195445 * RANDN() AS `V999`, `S1` + 0.92195445 * RANDN() AS `V1000`
FROM `analyis_tbl`) `ooqztzgkyb`
17/12/21 18:03:37 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:51496 in memory (size: 7.2 KB, free: 2004.5 MB)
17/12/21 18:03:37 INFO ContextCleaner: Cleaned shuffle 1
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 69
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 68
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 67
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 66
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 65
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 64
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 63
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 62
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 61
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 60
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 59
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 58
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 51
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 50
17/12/21 18:03:37 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:51496 in memory (size: 4.6 KB, free: 2004.5 MB)
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 1
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 0
17/12/21 18:03:37 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:51496 in memory (size: 5.6 KB, free: 2004.5 MB)
17/12/21 18:03:37 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:51496 in memory (size: 3.7 KB, free: 2004.5 MB)
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 238
17/12/21 18:03:37 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:51496 in memory (size: 5.6 KB, free: 2004.5 MB)
17/12/21 18:03:37 INFO ContextCleaner: Cleaned accumulator 57
17/12/21 18:03:37 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:51496 in memory (size: 3.7 KB, free: 2004.5 MB)
17/12/21 18:03:38 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 18:03:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:03:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz7`
WHERE (0 = 1)
17/12/21 18:03:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:03:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 18:03:39 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 18:03:39 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/21 18:03:39 INFO DAGScheduler: Got job 3 (take at <unknown>:0) with 1 output partitions
17/12/21 18:03:39 INFO DAGScheduler: Final stage: ResultStage 8 (take at <unknown>:0)
17/12/21 18:03:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/12/21 18:03:39 INFO DAGScheduler: Missing parents: List()
17/12/21 18:03:39 INFO DAGScheduler: Submitting ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18), which has no missing parents
17/12/21 18:03:39 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 567.9 KB, free 2003.7 MB)
17/12/21 18:03:39 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 189.5 KB, free 2003.5 MB)
17/12/21 18:03:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:51496 (size: 189.5 KB, free: 2004.3 MB)
17/12/21 18:03:39 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/12/21 18:03:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18)
17/12/21 18:03:39 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/21 18:03:39 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5913 bytes)
17/12/21 18:03:39 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/12/21 18:03:39 INFO BlockManager: Found block rdd_12_0 locally
17/12/21 18:03:39 INFO CodeGenerator: Code generated in 18.736698 ms
17/12/21 18:03:39 INFO CodeGenerator: Code generated in 535.535461 ms
17/12/21 18:03:39 INFO CodeGenerator: Code generated in 127.286677 ms
17/12/21 18:06:32 INFO MemoryStore: Block rdd_31_0 stored as values in memory (estimated size 133.7 MB, free 1869.8 MB)
17/12/21 18:06:32 INFO BlockManagerInfo: Added rdd_31_0 in memory on 127.0.0.1:51496 (size: 133.7 MB, free: 1870.6 MB)
17/12/21 18:06:32 WARN Executor: 1 block locks were not released by TID = 8:
[rdd_31_0]
17/12/21 18:06:32 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 143298 bytes result sent to driver
17/12/21 18:06:32 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 173071 ms on localhost (executor driver) (1/1)
17/12/21 18:06:32 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/21 18:06:32 INFO DAGScheduler: ResultStage 8 (take at <unknown>:0) finished in 173.086 s
17/12/21 18:06:32 INFO DAGScheduler: Job 3 finished: take at <unknown>:0, took 173.114059 s
17/12/21 18:06:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:06:33 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1b204a263d8
17/12/21 18:06:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:06:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1b204a263d8` AS `zzz8`
WHERE (0 = 1)
17/12/21 18:06:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:06:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1b204a263d8`
17/12/21 18:06:33 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 18:06:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:06:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz9`
WHERE (0 = 1)
17/12/21 18:06:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:06:35 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.01) AS `V1`, (`V2` < 0.01) AS `V2`, (`V3` < 0.01) AS `V3`, (`V4` < 0.01) AS `V4`, (`V5` < 0.01) AS `V5`, (`V6` < 0.01) AS `V6`, (`V7` < 0.01) AS `V7`, (`V8` < 0.01) AS `V8`, (`V9` < 0.01) AS `V9`, (`V10` < 0.01) AS `V10`, (`V11` < 0.01) AS `V11`, (`V12` < 0.01) AS `V12`, (`V13` < 0.01) AS `V13`, (`V14` < 0.01) AS `V14`, (`V15` < 0.01) AS `V15`, (`V16` < 0.01) AS `V16`, (`V17` < 0.01) AS `V17`, (`V18` < 0.01) AS `V18`, (`V19` < 0.01) AS `V19`, (`V20` < 0.01) AS `V20`, (`V21` < 0.01) AS `V21`, (`V22` < 0.01) AS `V22`, (`V23` < 0.01) AS `V23`, (`V24` < 0.01) AS `V24`, (`V25` < 0.01) AS `V25`, (`V26` < 0.01) AS `V26`, (`V27` < 0.01) AS `V27`, (`V28` < 0.01) AS `V28`, (`V29` < 0.01) AS `V29`, (`V30` < 0.01) AS `V30`, (`V31` < 0.01) AS `V31`, (`V32` < 0.01) AS `V32`, (`V33` < 0.01) AS `V33`, (`V34` < 0.01) AS `V34`, (`V35` < 0.01) AS `V35`, (`V36` < 0.01) AS `V36`, (`V37` < 0.01) AS `V37`, (`V38` < 0.01) AS `V38`, (`V39` < 0.01) AS `V39`, (`V40` < 0.01) AS `V40`, (`V41` < 0.01) AS `V41`, (`V42` < 0.01) AS `V42`, (`V43` < 0.01) AS `V43`, (`V44` < 0.01) AS `V44`, (`V45` < 0.01) AS `V45`, (`V46` < 0.01) AS `V46`, (`V47` < 0.01) AS `V47`, (`V48` < 0.01) AS `V48`, (`V49` < 0.01) AS `V49`, (`V50` < 0.01) AS `V50`, (`V51` < 0.01) AS `V51`, (`V52` < 0.01) AS `V52`, (`V53` < 0.01) AS `V53`, (`V54` < 0.01) AS `V54`, (`V55` < 0.01) AS `V55`, (`V56` < 0.01) AS `V56`, (`V57` < 0.01) AS `V57`, (`V58` < 0.01) AS `V58`, (`V59` < 0.01) AS `V59`, (`V60` < 0.01) AS `V60`, (`V61` < 0.01) AS `V61`, (`V62` < 0.01) AS `V62`, (`V63` < 0.01) AS `V63`, (`V64` < 0.01) AS `V64`, (`V65` < 0.01) AS `V65`, (`V66` < 0.01) AS `V66`, (`V67` < 0.01) AS `V67`, (`V68` < 0.01) AS `V68`, (`V69` < 0.01) AS `V69`, (`V70` < 0.01) AS `V70`, (`V71` < 0.01) AS `V71`, (`V72` < 0.01) AS `V72`, (`V73` < 0.01) AS `V73`, (`V74` < 0.01) AS `V74`, (`V75` < 0.01) AS `V75`, (`V76` < 0.01) AS `V76`, (`V77` < 0.01) AS `V77`, (`V78` < 0.01) AS `V78`, (`V79` < 0.01) AS `V79`, (`V80` < 0.01) AS `V80`, (`V81` < 0.01) AS `V81`, (`V82` < 0.01) AS `V82`, (`V83` < 0.01) AS `V83`, (`V84` < 0.01) AS `V84`, (`V85` < 0.01) AS `V85`, (`V86` < 0.01) AS `V86`, (`V87` < 0.01) AS `V87`, (`V88` < 0.01) AS `V88`, (`V89` < 0.01) AS `V89`, (`V90` < 0.01) AS `V90`, (`V91` < 0.01) AS `V91`, (`V92` < 0.01) AS `V92`, (`V93` < 0.01) AS `V93`, (`V94` < 0.01) AS `V94`, (`V95` < 0.01) AS `V95`, (`V96` < 0.01) AS `V96`, (`V97` < 0.01) AS `V97`, (`V98` < 0.01) AS `V98`, (`V99` < 0.01) AS `V99`, (`V100` < 0.01) AS `V100`, (`V101` < 0.01) AS `V101`, (`V102` < 0.01) AS `V102`, (`V103` < 0.01) AS `V103`, (`V104` < 0.01) AS `V104`, (`V105` < 0.01) AS `V105`, (`V106` < 0.01) AS `V106`, (`V107` < 0.01) AS `V107`, (`V108` < 0.01) AS `V108`, (`V109` < 0.01) AS `V109`, (`V110` < 0.01) AS `V110`, (`V111` < 0.01) AS `V111`, (`V112` < 0.01) AS `V112`, (`V113` < 0.01) AS `V113`, (`V114` < 0.01) AS `V114`, (`V115` < 0.01) AS `V115`, (`V116` < 0.01) AS `V116`, (`V117` < 0.01) AS `V117`, (`V118` < 0.01) AS `V118`, (`V119` < 0.01) AS `V119`, (`V120` < 0.01) AS `V120`, (`V121` < 0.01) AS `V121`, (`V122` < 0.01) AS `V122`, (`V123` < 0.01) AS `V123`, (`V124` < 0.01) AS `V124`, (`V125` < 0.01) AS `V125`, (`V126` < 0.01) AS `V126`, (`V127` < 0.01) AS `V127`, (`V128` < 0.01) AS `V128`, (`V129` < 0.01) AS `V129`, (`V130` < 0.01) AS `V130`, (`V131` < 0.01) AS `V131`, (`V132` < 0.01) AS `V132`, (`V133` < 0.01) AS `V133`, (`V134` < 0.01) AS `V134`, (`V135` < 0.01) AS `V135`, (`V136` < 0.01) AS `V136`, (`V137` < 0.01) AS `V137`, (`V138` < 0.01) AS `V138`, (`V139` < 0.01) AS `V139`, (`V140` < 0.01) AS `V140`, (`V141` < 0.01) AS `V141`, (`V142` < 0.01) AS `V142`, (`V143` < 0.01) AS `V143`, (`V144` < 0.01) AS `V144`, (`V145` < 0.01) AS `V145`, (`V146` < 0.01) AS `V146`, (`V147` < 0.01) AS `V147`, (`V148` < 0.01) AS `V148`, (`V149` < 0.01) AS `V149`, (`V150` < 0.01) AS `V150`, (`V151` < 0.01) AS `V151`, (`V152` < 0.01) AS `V152`, (`V153` < 0.01) AS `V153`, (`V154` < 0.01) AS `V154`, (`V155` < 0.01) AS `V155`, (`V156` < 0.01) AS `V156`, (`V157` < 0.01) AS `V157`, (`V158` < 0.01) AS `V158`, (`V159` < 0.01) AS `V159`, (`V160` < 0.01) AS `V160`, (`V161` < 0.01) AS `V161`, (`V162` < 0.01) AS `V162`, (`V163` < 0.01) AS `V163`, (`V164` < 0.01) AS `V164`, (`V165` < 0.01) AS `V165`, (`V166` < 0.01) AS `V166`, (`V167` < 0.01) AS `V167`, (`V168` < 0.01) AS `V168`, (`V169` < 0.01) AS `V169`, (`V170` < 0.01) AS `V170`, (`V171` < 0.01) AS `V171`, (`V172` < 0.01) AS `V172`, (`V173` < 0.01) AS `V173`, (`V174` < 0.01) AS `V174`, (`V175` < 0.01) AS `V175`, (`V176` < 0.01) AS `V176`, (`V177` < 0.01) AS `V177`, (`V178` < 0.01) AS `V178`, (`V179` < 0.01) AS `V179`, (`V180` < 0.01) AS `V180`, (`V181` < 0.01) AS `V181`, (`V182` < 0.01) AS `V182`, (`V183` < 0.01) AS `V183`, (`V184` < 0.01) AS `V184`, (`V185` < 0.01) AS `V185`, (`V186` < 0.01) AS `V186`, (`V187` < 0.01) AS `V187`, (`V188` < 0.01) AS `V188`, (`V189` < 0.01) AS `V189`, (`V190` < 0.01) AS `V190`, (`V191` < 0.01) AS `V191`, (`V192` < 0.01) AS `V192`, (`V193` < 0.01) AS `V193`, (`V194` < 0.01) AS `V194`, (`V195` < 0.01) AS `V195`, (`V196` < 0.01) AS `V196`, (`V197` < 0.01) AS `V197`, (`V198` < 0.01) AS `V198`, (`V199` < 0.01) AS `V199`, (`V200` < 0.01) AS `V200`, (`V201` < 0.01) AS `V201`, (`V202` < 0.01) AS `V202`, (`V203` < 0.01) AS `V203`, (`V204` < 0.01) AS `V204`, (`V205` < 0.01) AS `V205`, (`V206` < 0.01) AS `V206`, (`V207` < 0.01) AS `V207`, (`V208` < 0.01) AS `V208`, (`V209` < 0.01) AS `V209`, (`V210` < 0.01) AS `V210`, (`V211` < 0.01) AS `V211`, (`V212` < 0.01) AS `V212`, (`V213` < 0.01) AS `V213`, (`V214` < 0.01) AS `V214`, (`V215` < 0.01) AS `V215`, (`V216` < 0.01) AS `V216`, (`V217` < 0.01) AS `V217`, (`V218` < 0.01) AS `V218`, (`V219` < 0.01) AS `V219`, (`V220` < 0.01) AS `V220`, (`V221` < 0.01) AS `V221`, (`V222` < 0.01) AS `V222`, (`V223` < 0.01) AS `V223`, (`V224` < 0.01) AS `V224`, (`V225` < 0.01) AS `V225`, (`V226` < 0.01) AS `V226`, (`V227` < 0.01) AS `V227`, (`V228` < 0.01) AS `V228`, (`V229` < 0.01) AS `V229`, (`V230` < 0.01) AS `V230`, (`V231` < 0.01) AS `V231`, (`V232` < 0.01) AS `V232`, (`V233` < 0.01) AS `V233`, (`V234` < 0.01) AS `V234`, (`V235` < 0.01) AS `V235`, (`V236` < 0.01) AS `V236`, (`V237` < 0.01) AS `V237`, (`V238` < 0.01) AS `V238`, (`V239` < 0.01) AS `V239`, (`V240` < 0.01) AS `V240`, (`V241` < 0.01) AS `V241`, (`V242` < 0.01) AS `V242`, (`V243` < 0.01) AS `V243`, (`V244` < 0.01) AS `V244`, (`V245` < 0.01) AS `V245`, (`V246` < 0.01) AS `V246`, (`V247` < 0.01) AS `V247`, (`V248` < 0.01) AS `V248`, (`V249` < 0.01) AS `V249`, (`V250` < 0.01) AS `V250`, (`V251` < 0.01) AS `V251`, (`V252` < 0.01) AS `V252`, (`V253` < 0.01) AS `V253`, (`V254` < 0.01) AS `V254`, (`V255` < 0.01) AS `V255`, (`V256` < 0.01) AS `V256`, (`V257` < 0.01) AS `V257`, (`V258` < 0.01) AS `V258`, (`V259` < 0.01) AS `V259`, (`V260` < 0.01) AS `V260`, (`V261` < 0.01) AS `V261`, (`V262` < 0.01) AS `V262`, (`V263` < 0.01) AS `V263`, (`V264` < 0.01) AS `V264`, (`V265` < 0.01) AS `V265`, (`V266` < 0.01) AS `V266`, (`V267` < 0.01) AS `V267`, (`V268` < 0.01) AS `V268`, (`V269` < 0.01) AS `V269`, (`V270` < 0.01) AS `V270`, (`V271` < 0.01) AS `V271`, (`V272` < 0.01) AS `V272`, (`V273` < 0.01) AS `V273`, (`V274` < 0.01) AS `V274`, (`V275` < 0.01) AS `V275`, (`V276` < 0.01) AS `V276`, (`V277` < 0.01) AS `V277`, (`V278` < 0.01) AS `V278`, (`V279` < 0.01) AS `V279`, (`V280` < 0.01) AS `V280`, (`V281` < 0.01) AS `V281`, (`V282` < 0.01) AS `V282`, (`V283` < 0.01) AS `V283`, (`V284` < 0.01) AS `V284`, (`V285` < 0.01) AS `V285`, (`V286` < 0.01) AS `V286`, (`V287` < 0.01) AS `V287`, (`V288` < 0.01) AS `V288`, (`V289` < 0.01) AS `V289`, (`V290` < 0.01) AS `V290`, (`V291` < 0.01) AS `V291`, (`V292` < 0.01) AS `V292`, (`V293` < 0.01) AS `V293`, (`V294` < 0.01) AS `V294`, (`V295` < 0.01) AS `V295`, (`V296` < 0.01) AS `V296`, (`V297` < 0.01) AS `V297`, (`V298` < 0.01) AS `V298`, (`V299` < 0.01) AS `V299`, (`V300` < 0.01) AS `V300`, (`V301` < 0.01) AS `V301`, (`V302` < 0.01) AS `V302`, (`V303` < 0.01) AS `V303`, (`V304` < 0.01) AS `V304`, (`V305` < 0.01) AS `V305`, (`V306` < 0.01) AS `V306`, (`V307` < 0.01) AS `V307`, (`V308` < 0.01) AS `V308`, (`V309` < 0.01) AS `V309`, (`V310` < 0.01) AS `V310`, (`V311` < 0.01) AS `V311`, (`V312` < 0.01) AS `V312`, (`V313` < 0.01) AS `V313`, (`V314` < 0.01) AS `V314`, (`V315` < 0.01) AS `V315`, (`V316` < 0.01) AS `V316`, (`V317` < 0.01) AS `V317`, (`V318` < 0.01) AS `V318`, (`V319` < 0.01) AS `V319`, (`V320` < 0.01) AS `V320`, (`V321` < 0.01) AS `V321`, (`V322` < 0.01) AS `V322`, (`V323` < 0.01) AS `V323`, (`V324` < 0.01) AS `V324`, (`V325` < 0.01) AS `V325`, (`V326` < 0.01) AS `V326`, (`V327` < 0.01) AS `V327`, (`V328` < 0.01) AS `V328`, (`V329` < 0.01) AS `V329`, (`V330` < 0.01) AS `V330`, (`V331` < 0.01) AS `V331`, (`V332` < 0.01) AS `V332`, (`V333` < 0.01) AS `V333`, (`V334` < 0.01) AS `V334`, (`V335` < 0.01) AS `V335`, (`V336` < 0.01) AS `V336`, (`V337` < 0.01) AS `V337`, (`V338` < 0.01) AS `V338`, (`V339` < 0.01) AS `V339`, (`V340` < 0.01) AS `V340`, (`V341` < 0.01) AS `V341`, (`V342` < 0.01) AS `V342`, (`V343` < 0.01) AS `V343`, (`V344` < 0.01) AS `V344`, (`V345` < 0.01) AS `V345`, (`V346` < 0.01) AS `V346`, (`V347` < 0.01) AS `V347`, (`V348` < 0.01) AS `V348`, (`V349` < 0.01) AS `V349`, (`V350` < 0.01) AS `V350`, (`V351` < 0.01) AS `V351`, (`V352` < 0.01) AS `V352`, (`V353` < 0.01) AS `V353`, (`V354` < 0.01) AS `V354`, (`V355` < 0.01) AS `V355`, (`V356` < 0.01) AS `V356`, (`V357` < 0.01) AS `V357`, (`V358` < 0.01) AS `V358`, (`V359` < 0.01) AS `V359`, (`V360` < 0.01) AS `V360`, (`V361` < 0.01) AS `V361`, (`V362` < 0.01) AS `V362`, (`V363` < 0.01) AS `V363`, (`V364` < 0.01) AS `V364`, (`V365` < 0.01) AS `V365`, (`V366` < 0.01) AS `V366`, (`V367` < 0.01) AS `V367`, (`V368` < 0.01) AS `V368`, (`V369` < 0.01) AS `V369`, (`V370` < 0.01) AS `V370`, (`V371` < 0.01) AS `V371`, (`V372` < 0.01) AS `V372`, (`V373` < 0.01) AS `V373`, (`V374` < 0.01) AS `V374`, (`V375` < 0.01) AS `V375`, (`V376` < 0.01) AS `V376`, (`V377` < 0.01) AS `V377`, (`V378` < 0.01) AS `V378`, (`V379` < 0.01) AS `V379`, (`V380` < 0.01) AS `V380`, (`V381` < 0.01) AS `V381`, (`V382` < 0.01) AS `V382`, (`V383` < 0.01) AS `V383`, (`V384` < 0.01) AS `V384`, (`V385` < 0.01) AS `V385`, (`V386` < 0.01) AS `V386`, (`V387` < 0.01) AS `V387`, (`V388` < 0.01) AS `V388`, (`V389` < 0.01) AS `V389`, (`V390` < 0.01) AS `V390`, (`V391` < 0.01) AS `V391`, (`V392` < 0.01) AS `V392`, (`V393` < 0.01) AS `V393`, (`V394` < 0.01) AS `V394`, (`V395` < 0.01) AS `V395`, (`V396` < 0.01) AS `V396`, (`V397` < 0.01) AS `V397`, (`V398` < 0.01) AS `V398`, (`V399` < 0.01) AS `V399`, (`V400` < 0.01) AS `V400`, (`V401` < 0.01) AS `V401`, (`V402` < 0.01) AS `V402`, (`V403` < 0.01) AS `V403`, (`V404` < 0.01) AS `V404`, (`V405` < 0.01) AS `V405`, (`V406` < 0.01) AS `V406`, (`V407` < 0.01) AS `V407`, (`V408` < 0.01) AS `V408`, (`V409` < 0.01) AS `V409`, (`V410` < 0.01) AS `V410`, (`V411` < 0.01) AS `V411`, (`V412` < 0.01) AS `V412`, (`V413` < 0.01) AS `V413`, (`V414` < 0.01) AS `V414`, (`V415` < 0.01) AS `V415`, (`V416` < 0.01) AS `V416`, (`V417` < 0.01) AS `V417`, (`V418` < 0.01) AS `V418`, (`V419` < 0.01) AS `V419`, (`V420` < 0.01) AS `V420`, (`V421` < 0.01) AS `V421`, (`V422` < 0.01) AS `V422`, (`V423` < 0.01) AS `V423`, (`V424` < 0.01) AS `V424`, (`V425` < 0.01) AS `V425`, (`V426` < 0.01) AS `V426`, (`V427` < 0.01) AS `V427`, (`V428` < 0.01) AS `V428`, (`V429` < 0.01) AS `V429`, (`V430` < 0.01) AS `V430`, (`V431` < 0.01) AS `V431`, (`V432` < 0.01) AS `V432`, (`V433` < 0.01) AS `V433`, (`V434` < 0.01) AS `V434`, (`V435` < 0.01) AS `V435`, (`V436` < 0.01) AS `V436`, (`V437` < 0.01) AS `V437`, (`V438` < 0.01) AS `V438`, (`V439` < 0.01) AS `V439`, (`V440` < 0.01) AS `V440`, (`V441` < 0.01) AS `V441`, (`V442` < 0.01) AS `V442`, (`V443` < 0.01) AS `V443`, (`V444` < 0.01) AS `V444`, (`V445` < 0.01) AS `V445`, (`V446` < 0.01) AS `V446`, (`V447` < 0.01) AS `V447`, (`V448` < 0.01) AS `V448`, (`V449` < 0.01) AS `V449`, (`V450` < 0.01) AS `V450`, (`V451` < 0.01) AS `V451`, (`V452` < 0.01) AS `V452`, (`V453` < 0.01) AS `V453`, (`V454` < 0.01) AS `V454`, (`V455` < 0.01) AS `V455`, (`V456` < 0.01) AS `V456`, (`V457` < 0.01) AS `V457`, (`V458` < 0.01) AS `V458`, (`V459` < 0.01) AS `V459`, (`V460` < 0.01) AS `V460`, (`V461` < 0.01) AS `V461`, (`V462` < 0.01) AS `V462`, (`V463` < 0.01) AS `V463`, (`V464` < 0.01) AS `V464`, (`V465` < 0.01) AS `V465`, (`V466` < 0.01) AS `V466`, (`V467` < 0.01) AS `V467`, (`V468` < 0.01) AS `V468`, (`V469` < 0.01) AS `V469`, (`V470` < 0.01) AS `V470`, (`V471` < 0.01) AS `V471`, (`V472` < 0.01) AS `V472`, (`V473` < 0.01) AS `V473`, (`V474` < 0.01) AS `V474`, (`V475` < 0.01) AS `V475`, (`V476` < 0.01) AS `V476`, (`V477` < 0.01) AS `V477`, (`V478` < 0.01) AS `V478`, (`V479` < 0.01) AS `V479`, (`V480` < 0.01) AS `V480`, (`V481` < 0.01) AS `V481`, (`V482` < 0.01) AS `V482`, (`V483` < 0.01) AS `V483`, (`V484` < 0.01) AS `V484`, (`V485` < 0.01) AS `V485`, (`V486` < 0.01) AS `V486`, (`V487` < 0.01) AS `V487`, (`V488` < 0.01) AS `V488`, (`V489` < 0.01) AS `V489`, (`V490` < 0.01) AS `V490`, (`V491` < 0.01) AS `V491`, (`V492` < 0.01) AS `V492`, (`V493` < 0.01) AS `V493`, (`V494` < 0.01) AS `V494`, (`V495` < 0.01) AS `V495`, (`V496` < 0.01) AS `V496`, (`V497` < 0.01) AS `V497`, (`V498` < 0.01) AS `V498`, (`V499` < 0.01) AS `V499`, (`V500` < 0.01) AS `V500`, (`V501` < 0.01) AS `V501`, (`V502` < 0.01) AS `V502`, (`V503` < 0.01) AS `V503`, (`V504` < 0.01) AS `V504`, (`V505` < 0.01) AS `V505`, (`V506` < 0.01) AS `V506`, (`V507` < 0.01) AS `V507`, (`V508` < 0.01) AS `V508`, (`V509` < 0.01) AS `V509`, (`V510` < 0.01) AS `V510`, (`V511` < 0.01) AS `V511`, (`V512` < 0.01) AS `V512`, (`V513` < 0.01) AS `V513`, (`V514` < 0.01) AS `V514`, (`V515` < 0.01) AS `V515`, (`V516` < 0.01) AS `V516`, (`V517` < 0.01) AS `V517`, (`V518` < 0.01) AS `V518`, (`V519` < 0.01) AS `V519`, (`V520` < 0.01) AS `V520`, (`V521` < 0.01) AS `V521`, (`V522` < 0.01) AS `V522`, (`V523` < 0.01) AS `V523`, (`V524` < 0.01) AS `V524`, (`V525` < 0.01) AS `V525`, (`V526` < 0.01) AS `V526`, (`V527` < 0.01) AS `V527`, (`V528` < 0.01) AS `V528`, (`V529` < 0.01) AS `V529`, (`V530` < 0.01) AS `V530`, (`V531` < 0.01) AS `V531`, (`V532` < 0.01) AS `V532`, (`V533` < 0.01) AS `V533`, (`V534` < 0.01) AS `V534`, (`V535` < 0.01) AS `V535`, (`V536` < 0.01) AS `V536`, (`V537` < 0.01) AS `V537`, (`V538` < 0.01) AS `V538`, (`V539` < 0.01) AS `V539`, (`V540` < 0.01) AS `V540`, (`V541` < 0.01) AS `V541`, (`V542` < 0.01) AS `V542`, (`V543` < 0.01) AS `V543`, (`V544` < 0.01) AS `V544`, (`V545` < 0.01) AS `V545`, (`V546` < 0.01) AS `V546`, (`V547` < 0.01) AS `V547`, (`V548` < 0.01) AS `V548`, (`V549` < 0.01) AS `V549`, (`V550` < 0.01) AS `V550`, (`V551` < 0.01) AS `V551`, (`V552` < 0.01) AS `V552`, (`V553` < 0.01) AS `V553`, (`V554` < 0.01) AS `V554`, (`V555` < 0.01) AS `V555`, (`V556` < 0.01) AS `V556`, (`V557` < 0.01) AS `V557`, (`V558` < 0.01) AS `V558`, (`V559` < 0.01) AS `V559`, (`V560` < 0.01) AS `V560`, (`V561` < 0.01) AS `V561`, (`V562` < 0.01) AS `V562`, (`V563` < 0.01) AS `V563`, (`V564` < 0.01) AS `V564`, (`V565` < 0.01) AS `V565`, (`V566` < 0.01) AS `V566`, (`V567` < 0.01) AS `V567`, (`V568` < 0.01) AS `V568`, (`V569` < 0.01) AS `V569`, (`V570` < 0.01) AS `V570`, (`V571` < 0.01) AS `V571`, (`V572` < 0.01) AS `V572`, (`V573` < 0.01) AS `V573`, (`V574` < 0.01) AS `V574`, (`V575` < 0.01) AS `V575`, (`V576` < 0.01) AS `V576`, (`V577` < 0.01) AS `V577`, (`V578` < 0.01) AS `V578`, (`V579` < 0.01) AS `V579`, (`V580` < 0.01) AS `V580`, (`V581` < 0.01) AS `V581`, (`V582` < 0.01) AS `V582`, (`V583` < 0.01) AS `V583`, (`V584` < 0.01) AS `V584`, (`V585` < 0.01) AS `V585`, (`V586` < 0.01) AS `V586`, (`V587` < 0.01) AS `V587`, (`V588` < 0.01) AS `V588`, (`V589` < 0.01) AS `V589`, (`V590` < 0.01) AS `V590`, (`V591` < 0.01) AS `V591`, (`V592` < 0.01) AS `V592`, (`V593` < 0.01) AS `V593`, (`V594` < 0.01) AS `V594`, (`V595` < 0.01) AS `V595`, (`V596` < 0.01) AS `V596`, (`V597` < 0.01) AS `V597`, (`V598` < 0.01) AS `V598`, (`V599` < 0.01) AS `V599`, (`V600` < 0.01) AS `V600`, (`V601` < 0.01) AS `V601`, (`V602` < 0.01) AS `V602`, (`V603` < 0.01) AS `V603`, (`V604` < 0.01) AS `V604`, (`V605` < 0.01) AS `V605`, (`V606` < 0.01) AS `V606`, (`V607` < 0.01) AS `V607`, (`V608` < 0.01) AS `V608`, (`V609` < 0.01) AS `V609`, (`V610` < 0.01) AS `V610`, (`V611` < 0.01) AS `V611`, (`V612` < 0.01) AS `V612`, (`V613` < 0.01) AS `V613`, (`V614` < 0.01) AS `V614`, (`V615` < 0.01) AS `V615`, (`V616` < 0.01) AS `V616`, (`V617` < 0.01) AS `V617`, (`V618` < 0.01) AS `V618`, (`V619` < 0.01) AS `V619`, (`V620` < 0.01) AS `V620`, (`V621` < 0.01) AS `V621`, (`V622` < 0.01) AS `V622`, (`V623` < 0.01) AS `V623`, (`V624` < 0.01) AS `V624`, (`V625` < 0.01) AS `V625`, (`V626` < 0.01) AS `V626`, (`V627` < 0.01) AS `V627`, (`V628` < 0.01) AS `V628`, (`V629` < 0.01) AS `V629`, (`V630` < 0.01) AS `V630`, (`V631` < 0.01) AS `V631`, (`V632` < 0.01) AS `V632`, (`V633` < 0.01) AS `V633`, (`V634` < 0.01) AS `V634`, (`V635` < 0.01) AS `V635`, (`V636` < 0.01) AS `V636`, (`V637` < 0.01) AS `V637`, (`V638` < 0.01) AS `V638`, (`V639` < 0.01) AS `V639`, (`V640` < 0.01) AS `V640`, (`V641` < 0.01) AS `V641`, (`V642` < 0.01) AS `V642`, (`V643` < 0.01) AS `V643`, (`V644` < 0.01) AS `V644`, (`V645` < 0.01) AS `V645`, (`V646` < 0.01) AS `V646`, (`V647` < 0.01) AS `V647`, (`V648` < 0.01) AS `V648`, (`V649` < 0.01) AS `V649`, (`V650` < 0.01) AS `V650`, (`V651` < 0.01) AS `V651`, (`V652` < 0.01) AS `V652`, (`V653` < 0.01) AS `V653`, (`V654` < 0.01) AS `V654`, (`V655` < 0.01) AS `V655`, (`V656` < 0.01) AS `V656`, (`V657` < 0.01) AS `V657`, (`V658` < 0.01) AS `V658`, (`V659` < 0.01) AS `V659`, (`V660` < 0.01) AS `V660`, (`V661` < 0.01) AS `V661`, (`V662` < 0.01) AS `V662`, (`V663` < 0.01) AS `V663`, (`V664` < 0.01) AS `V664`, (`V665` < 0.01) AS `V665`, (`V666` < 0.01) AS `V666`, (`V667` < 0.01) AS `V667`, (`V668` < 0.01) AS `V668`, (`V669` < 0.01) AS `V669`, (`V670` < 0.01) AS `V670`, (`V671` < 0.01) AS `V671`, (`V672` < 0.01) AS `V672`, (`V673` < 0.01) AS `V673`, (`V674` < 0.01) AS `V674`, (`V675` < 0.01) AS `V675`, (`V676` < 0.01) AS `V676`, (`V677` < 0.01) AS `V677`, (`V678` < 0.01) AS `V678`, (`V679` < 0.01) AS `V679`, (`V680` < 0.01) AS `V680`, (`V681` < 0.01) AS `V681`, (`V682` < 0.01) AS `V682`, (`V683` < 0.01) AS `V683`, (`V684` < 0.01) AS `V684`, (`V685` < 0.01) AS `V685`, (`V686` < 0.01) AS `V686`, (`V687` < 0.01) AS `V687`, (`V688` < 0.01) AS `V688`, (`V689` < 0.01) AS `V689`, (`V690` < 0.01) AS `V690`, (`V691` < 0.01) AS `V691`, (`V692` < 0.01) AS `V692`, (`V693` < 0.01) AS `V693`, (`V694` < 0.01) AS `V694`, (`V695` < 0.01) AS `V695`, (`V696` < 0.01) AS `V696`, (`V697` < 0.01) AS `V697`, (`V698` < 0.01) AS `V698`, (`V699` < 0.01) AS `V699`, (`V700` < 0.01) AS `V700`, (`V701` < 0.01) AS `V701`, (`V702` < 0.01) AS `V702`, (`V703` < 0.01) AS `V703`, (`V704` < 0.01) AS `V704`, (`V705` < 0.01) AS `V705`, (`V706` < 0.01) AS `V706`, (`V707` < 0.01) AS `V707`, (`V708` < 0.01) AS `V708`, (`V709` < 0.01) AS `V709`, (`V710` < 0.01) AS `V710`, (`V711` < 0.01) AS `V711`, (`V712` < 0.01) AS `V712`, (`V713` < 0.01) AS `V713`, (`V714` < 0.01) AS `V714`, (`V715` < 0.01) AS `V715`, (`V716` < 0.01) AS `V716`, (`V717` < 0.01) AS `V717`, (`V718` < 0.01) AS `V718`, (`V719` < 0.01) AS `V719`, (`V720` < 0.01) AS `V720`, (`V721` < 0.01) AS `V721`, (`V722` < 0.01) AS `V722`, (`V723` < 0.01) AS `V723`, (`V724` < 0.01) AS `V724`, (`V725` < 0.01) AS `V725`, (`V726` < 0.01) AS `V726`, (`V727` < 0.01) AS `V727`, (`V728` < 0.01) AS `V728`, (`V729` < 0.01) AS `V729`, (`V730` < 0.01) AS `V730`, (`V731` < 0.01) AS `V731`, (`V732` < 0.01) AS `V732`, (`V733` < 0.01) AS `V733`, (`V734` < 0.01) AS `V734`, (`V735` < 0.01) AS `V735`, (`V736` < 0.01) AS `V736`, (`V737` < 0.01) AS `V737`, (`V738` < 0.01) AS `V738`, (`V739` < 0.01) AS `V739`, (`V740` < 0.01) AS `V740`, (`V741` < 0.01) AS `V741`, (`V742` < 0.01) AS `V742`, (`V743` < 0.01) AS `V743`, (`V744` < 0.01) AS `V744`, (`V745` < 0.01) AS `V745`, (`V746` < 0.01) AS `V746`, (`V747` < 0.01) AS `V747`, (`V748` < 0.01) AS `V748`, (`V749` < 0.01) AS `V749`, (`V750` < 0.01) AS `V750`, (`V751` < 0.01) AS `V751`, (`V752` < 0.01) AS `V752`, (`V753` < 0.01) AS `V753`, (`V754` < 0.01) AS `V754`, (`V755` < 0.01) AS `V755`, (`V756` < 0.01) AS `V756`, (`V757` < 0.01) AS `V757`, (`V758` < 0.01) AS `V758`, (`V759` < 0.01) AS `V759`, (`V760` < 0.01) AS `V760`, (`V761` < 0.01) AS `V761`, (`V762` < 0.01) AS `V762`, (`V763` < 0.01) AS `V763`, (`V764` < 0.01) AS `V764`, (`V765` < 0.01) AS `V765`, (`V766` < 0.01) AS `V766`, (`V767` < 0.01) AS `V767`, (`V768` < 0.01) AS `V768`, (`V769` < 0.01) AS `V769`, (`V770` < 0.01) AS `V770`, (`V771` < 0.01) AS `V771`, (`V772` < 0.01) AS `V772`, (`V773` < 0.01) AS `V773`, (`V774` < 0.01) AS `V774`, (`V775` < 0.01) AS `V775`, (`V776` < 0.01) AS `V776`, (`V777` < 0.01) AS `V777`, (`V778` < 0.01) AS `V778`, (`V779` < 0.01) AS `V779`, (`V780` < 0.01) AS `V780`, (`V781` < 0.01) AS `V781`, (`V782` < 0.01) AS `V782`, (`V783` < 0.01) AS `V783`, (`V784` < 0.01) AS `V784`, (`V785` < 0.01) AS `V785`, (`V786` < 0.01) AS `V786`, (`V787` < 0.01) AS `V787`, (`V788` < 0.01) AS `V788`, (`V789` < 0.01) AS `V789`, (`V790` < 0.01) AS `V790`, (`V791` < 0.01) AS `V791`, (`V792` < 0.01) AS `V792`, (`V793` < 0.01) AS `V793`, (`V794` < 0.01) AS `V794`, (`V795` < 0.01) AS `V795`, (`V796` < 0.01) AS `V796`, (`V797` < 0.01) AS `V797`, (`V798` < 0.01) AS `V798`, (`V799` < 0.01) AS `V799`, (`V800` < 0.01) AS `V800`, (`V801` < 0.01) AS `V801`, (`V802` < 0.01) AS `V802`, (`V803` < 0.01) AS `V803`, (`V804` < 0.01) AS `V804`, (`V805` < 0.01) AS `V805`, (`V806` < 0.01) AS `V806`, (`V807` < 0.01) AS `V807`, (`V808` < 0.01) AS `V808`, (`V809` < 0.01) AS `V809`, (`V810` < 0.01) AS `V810`, (`V811` < 0.01) AS `V811`, (`V812` < 0.01) AS `V812`, (`V813` < 0.01) AS `V813`, (`V814` < 0.01) AS `V814`, (`V815` < 0.01) AS `V815`, (`V816` < 0.01) AS `V816`, (`V817` < 0.01) AS `V817`, (`V818` < 0.01) AS `V818`, (`V819` < 0.01) AS `V819`, (`V820` < 0.01) AS `V820`, (`V821` < 0.01) AS `V821`, (`V822` < 0.01) AS `V822`, (`V823` < 0.01) AS `V823`, (`V824` < 0.01) AS `V824`, (`V825` < 0.01) AS `V825`, (`V826` < 0.01) AS `V826`, (`V827` < 0.01) AS `V827`, (`V828` < 0.01) AS `V828`, (`V829` < 0.01) AS `V829`, (`V830` < 0.01) AS `V830`, (`V831` < 0.01) AS `V831`, (`V832` < 0.01) AS `V832`, (`V833` < 0.01) AS `V833`, (`V834` < 0.01) AS `V834`, (`V835` < 0.01) AS `V835`, (`V836` < 0.01) AS `V836`, (`V837` < 0.01) AS `V837`, (`V838` < 0.01) AS `V838`, (`V839` < 0.01) AS `V839`, (`V840` < 0.01) AS `V840`, (`V841` < 0.01) AS `V841`, (`V842` < 0.01) AS `V842`, (`V843` < 0.01) AS `V843`, (`V844` < 0.01) AS `V844`, (`V845` < 0.01) AS `V845`, (`V846` < 0.01) AS `V846`, (`V847` < 0.01) AS `V847`, (`V848` < 0.01) AS `V848`, (`V849` < 0.01) AS `V849`, (`V850` < 0.01) AS `V850`, (`V851` < 0.01) AS `V851`, (`V852` < 0.01) AS `V852`, (`V853` < 0.01) AS `V853`, (`V854` < 0.01) AS `V854`, (`V855` < 0.01) AS `V855`, (`V856` < 0.01) AS `V856`, (`V857` < 0.01) AS `V857`, (`V858` < 0.01) AS `V858`, (`V859` < 0.01) AS `V859`, (`V860` < 0.01) AS `V860`, (`V861` < 0.01) AS `V861`, (`V862` < 0.01) AS `V862`, (`V863` < 0.01) AS `V863`, (`V864` < 0.01) AS `V864`, (`V865` < 0.01) AS `V865`, (`V866` < 0.01) AS `V866`, (`V867` < 0.01) AS `V867`, (`V868` < 0.01) AS `V868`, (`V869` < 0.01) AS `V869`, (`V870` < 0.01) AS `V870`, (`V871` < 0.01) AS `V871`, (`V872` < 0.01) AS `V872`, (`V873` < 0.01) AS `V873`, (`V874` < 0.01) AS `V874`, (`V875` < 0.01) AS `V875`, (`V876` < 0.01) AS `V876`, (`V877` < 0.01) AS `V877`, (`V878` < 0.01) AS `V878`, (`V879` < 0.01) AS `V879`, (`V880` < 0.01) AS `V880`, (`V881` < 0.01) AS `V881`, (`V882` < 0.01) AS `V882`, (`V883` < 0.01) AS `V883`, (`V884` < 0.01) AS `V884`, (`V885` < 0.01) AS `V885`, (`V886` < 0.01) AS `V886`, (`V887` < 0.01) AS `V887`, (`V888` < 0.01) AS `V888`, (`V889` < 0.01) AS `V889`, (`V890` < 0.01) AS `V890`, (`V891` < 0.01) AS `V891`, (`V892` < 0.01) AS `V892`, (`V893` < 0.01) AS `V893`, (`V894` < 0.01) AS `V894`, (`V895` < 0.01) AS `V895`, (`V896` < 0.01) AS `V896`, (`V897` < 0.01) AS `V897`, (`V898` < 0.01) AS `V898`, (`V899` < 0.01) AS `V899`, (`V900` < 0.01) AS `V900`, (`V901` < 0.01) AS `V901`, (`V902` < 0.01) AS `V902`, (`V903` < 0.01) AS `V903`, (`V904` < 0.01) AS `V904`, (`V905` < 0.01) AS `V905`, (`V906` < 0.01) AS `V906`, (`V907` < 0.01) AS `V907`, (`V908` < 0.01) AS `V908`, (`V909` < 0.01) AS `V909`, (`V910` < 0.01) AS `V910`, (`V911` < 0.01) AS `V911`, (`V912` < 0.01) AS `V912`, (`V913` < 0.01) AS `V913`, (`V914` < 0.01) AS `V914`, (`V915` < 0.01) AS `V915`, (`V916` < 0.01) AS `V916`, (`V917` < 0.01) AS `V917`, (`V918` < 0.01) AS `V918`, (`V919` < 0.01) AS `V919`, (`V920` < 0.01) AS `V920`, (`V921` < 0.01) AS `V921`, (`V922` < 0.01) AS `V922`, (`V923` < 0.01) AS `V923`, (`V924` < 0.01) AS `V924`, (`V925` < 0.01) AS `V925`, (`V926` < 0.01) AS `V926`, (`V927` < 0.01) AS `V927`, (`V928` < 0.01) AS `V928`, (`V929` < 0.01) AS `V929`, (`V930` < 0.01) AS `V930`, (`V931` < 0.01) AS `V931`, (`V932` < 0.01) AS `V932`, (`V933` < 0.01) AS `V933`, (`V934` < 0.01) AS `V934`, (`V935` < 0.01) AS `V935`, (`V936` < 0.01) AS `V936`, (`V937` < 0.01) AS `V937`, (`V938` < 0.01) AS `V938`, (`V939` < 0.01) AS `V939`, (`V940` < 0.01) AS `V940`, (`V941` < 0.01) AS `V941`, (`V942` < 0.01) AS `V942`, (`V943` < 0.01) AS `V943`, (`V944` < 0.01) AS `V944`, (`V945` < 0.01) AS `V945`, (`V946` < 0.01) AS `V946`, (`V947` < 0.01) AS `V947`, (`V948` < 0.01) AS `V948`, (`V949` < 0.01) AS `V949`, (`V950` < 0.01) AS `V950`, (`V951` < 0.01) AS `V951`, (`V952` < 0.01) AS `V952`, (`V953` < 0.01) AS `V953`, (`V954` < 0.01) AS `V954`, (`V955` < 0.01) AS `V955`, (`V956` < 0.01) AS `V956`, (`V957` < 0.01) AS `V957`, (`V958` < 0.01) AS `V958`, (`V959` < 0.01) AS `V959`, (`V960` < 0.01) AS `V960`, (`V961` < 0.01) AS `V961`, (`V962` < 0.01) AS `V962`, (`V963` < 0.01) AS `V963`, (`V964` < 0.01) AS `V964`, (`V965` < 0.01) AS `V965`, (`V966` < 0.01) AS `V966`, (`V967` < 0.01) AS `V967`, (`V968` < 0.01) AS `V968`, (`V969` < 0.01) AS `V969`, (`V970` < 0.01) AS `V970`, (`V971` < 0.01) AS `V971`, (`V972` < 0.01) AS `V972`, (`V973` < 0.01) AS `V973`, (`V974` < 0.01) AS `V974`, (`V975` < 0.01) AS `V975`, (`V976` < 0.01) AS `V976`, (`V977` < 0.01) AS `V977`, (`V978` < 0.01) AS `V978`, (`V979` < 0.01) AS `V979`, (`V980` < 0.01) AS `V980`, (`V981` < 0.01) AS `V981`, (`V982` < 0.01) AS `V982`, (`V983` < 0.01) AS `V983`, (`V984` < 0.01) AS `V984`, (`V985` < 0.01) AS `V985`, (`V986` < 0.01) AS `V986`, (`V987` < 0.01) AS `V987`, (`V988` < 0.01) AS `V988`, (`V989` < 0.01) AS `V989`, (`V990` < 0.01) AS `V990`, (`V991` < 0.01) AS `V991`, (`V992` < 0.01) AS `V992`, (`V993` < 0.01) AS `V993`, (`V994` < 0.01) AS `V994`, (`V995` < 0.01) AS `V995`, (`V996` < 0.01) AS `V996`, (`V997` < 0.01) AS `V997`, (`V998` < 0.01) AS `V998`, (`V999` < 0.01) AS `V999`, (`V1000` < 0.01) AS `V1000`
FROM `analyis_tbl`
17/12/21 18:06:36 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 18:06:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:06:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz10`
WHERE (0 = 1)
17/12/21 18:06:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:06:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 18:06:36 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/12/21 18:06:37 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 18:06:37 INFO DAGScheduler: Got job 4 (collect at utils.scala:196) with 2 output partitions
17/12/21 18:06:37 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:196)
17/12/21 18:06:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
17/12/21 18:06:37 INFO DAGScheduler: Missing parents: List()
17/12/21 18:06:37 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196), which has no missing parents
17/12/21 18:06:37 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1064.2 KB, free 1868.7 MB)
17/12/21 18:06:37 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 279.6 KB, free 1868.5 MB)
17/12/21 18:06:37 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:51496 (size: 279.6 KB, free: 1870.4 MB)
17/12/21 18:06:37 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/12/21 18:06:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196)
17/12/21 18:06:37 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks
17/12/21 18:06:37 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5945 bytes)
17/12/21 18:06:37 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 5945 bytes)
17/12/21 18:06:37 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
17/12/21 18:06:37 INFO Executor: Running task 1.0 in stage 10.0 (TID 10)
17/12/21 18:06:37 INFO BlockManager: Found block rdd_12_1 locally
17/12/21 18:06:37 INFO BlockManager: Found block rdd_31_0 locally
17/12/21 18:06:37 INFO CodeGenerator: Code generated in 140.482374 ms
17/12/21 18:06:37 INFO CodeGenerator: Code generated in 319.032457 ms
17/12/21 18:06:40 WARN CodeGenerator: Error calculating stats of compiled class.
java.io.EOFException
	at java.io.DataInputStream.readFully(Unknown Source)
	at java.io.DataInputStream.readFully(Unknown Source)
	at org.codehaus.janino.util.ClassFile.loadAttribute(ClassFile.java:1509)
	at org.codehaus.janino.util.ClassFile.loadAttributes(ClassFile.java:644)
	at org.codehaus.janino.util.ClassFile.loadFields(ClassFile.java:623)
	at org.codehaus.janino.util.ClassFile.<init>(ClassFile.java:280)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anonfun$recordCompilationStats$1.apply(CodeGenerator.scala:967)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anonfun$recordCompilationStats$1.apply(CodeGenerator.scala:964)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.recordCompilationStats(CodeGenerator.scala:964)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(CodeGenerator.scala:936)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:998)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:995)
	at org.spark_project.guava.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)
	at org.spark_project.guava.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)
	at org.spark_project.guava.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)
	at org.spark_project.guava.cache.LocalCache$Segment.get(LocalCache.java:2257)
	at org.spark_project.guava.cache.LocalCache.get(LocalCache.java:4000)
	at org.spark_project.guava.cache.LocalCache.getOrLoad(LocalCache.java:4004)
	at org.spark_project.guava.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4874)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.compile(CodeGenerator.scala:890)
	at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:405)
	at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:359)
	at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:32)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:874)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.extractProjection$lzycompute(ExpressionEncoder.scala:266)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.extractProjection(ExpressionEncoder.scala:266)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:290)
	at org.apache.spark.sql.SparkSession$$anonfun$3.apply(SparkSession.scala:547)
	at org.apache.spark.sql.SparkSession$$anonfun$3.apply(SparkSession.scala:547)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:232)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/12/21 18:06:40 INFO CodeGenerator: Code generated in 2227.562726 ms
17/12/21 18:06:48 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 480719 bytes result sent to driver
17/12/21 18:06:48 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 11757 ms on localhost (executor driver) (1/2)
17/12/21 18:09:33 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:51496 in memory (size: 189.5 KB, free: 1870.5 MB)
17/12/21 18:09:35 INFO MemoryStore: Block rdd_31_1 stored as values in memory (estimated size 133.7 MB, free 1735.5 MB)
17/12/21 18:09:35 INFO BlockManagerInfo: Added rdd_31_1 in memory on 127.0.0.1:51496 (size: 133.7 MB, free: 1736.9 MB)
17/12/21 18:09:43 INFO Executor: Finished task 1.0 in stage 10.0 (TID 10). 485744 bytes result sent to driver
17/12/21 18:09:43 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 10) in 186405 ms on localhost (executor driver) (2/2)
17/12/21 18:09:43 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/21 18:09:43 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:196) finished in 186.405 s
17/12/21 18:09:43 INFO DAGScheduler: Job 4 finished: collect at utils.scala:196, took 186.420280 s
17/12/21 18:09:43 INFO CodeGenerator: Code generated in 77.194907 ms
17/12/21 18:09:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:09:47 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 18:09:47 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:09:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:09:47 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:09:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:09:47 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 18:09:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 18:09:47 INFO CodeGenerator: Code generated in 5.678061 ms
17/12/21 18:09:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:09:47 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 18:09:47 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:09:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:09:47 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:09:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:09:47 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 18:09:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 18:09:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:09:47 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 18:09:47 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:09:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:09:47 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:09:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:09:47 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 18:09:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 18:09:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:09:47 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 18:09:47 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:09:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:09:47 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:09:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:09:47 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 18:09:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 18:11:13 INFO SparkContext: Invoking stop() from shutdown hook
17/12/21 18:11:13 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/21 18:11:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/21 18:11:13 INFO MemoryStore: MemoryStore cleared
17/12/21 18:11:13 INFO BlockManager: BlockManager stopped
17/12/21 18:11:13 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/21 18:11:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/21 18:11:13 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-115ef8b1-ed82-49f0-8cc2-c7f74746f82c\userFiles-8c65ebda-ad5b-4c12-9316-71a40db91823
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-115ef8b1-ed82-49f0-8cc2-c7f74746f82c\userFiles-8c65ebda-ad5b-4c12-9316-71a40db91823
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/21 18:11:13 INFO SparkContext: Successfully stopped SparkContext
17/12/21 18:11:13 INFO ShutdownHookManager: Shutdown hook called
17/12/21 18:11:13 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-115ef8b1-ed82-49f0-8cc2-c7f74746f82c
17/12/21 18:11:13 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-115ef8b1-ed82-49f0-8cc2-c7f74746f82c
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-115ef8b1-ed82-49f0-8cc2-c7f74746f82c
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/21 18:11:13 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-115ef8b1-ed82-49f0-8cc2-c7f74746f82c\userFiles-8c65ebda-ad5b-4c12-9316-71a40db91823
17/12/21 18:11:13 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-115ef8b1-ed82-49f0-8cc2-c7f74746f82c\userFiles-8c65ebda-ad5b-4c12-9316-71a40db91823
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-115ef8b1-ed82-49f0-8cc2-c7f74746f82c\userFiles-8c65ebda-ad5b-4c12-9316-71a40db91823
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/21 18:11:23 INFO SparkContext: Running Spark version 2.1.0
17/12/21 18:11:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/21 18:11:24 INFO SecurityManager: Changing view acls to: conan
17/12/21 18:11:24 INFO SecurityManager: Changing modify acls to: conan
17/12/21 18:11:24 INFO SecurityManager: Changing view acls groups to: 
17/12/21 18:11:24 INFO SecurityManager: Changing modify acls groups to: 
17/12/21 18:11:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(conan); groups with view permissions: Set(); users  with modify permissions: Set(conan); groups with modify permissions: Set()
17/12/21 18:11:24 INFO Utils: Successfully started service 'sparkDriver' on port 51611.
17/12/21 18:11:24 INFO SparkEnv: Registering MapOutputTracker
17/12/21 18:11:24 INFO SparkEnv: Registering BlockManagerMaster
17/12/21 18:11:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/21 18:11:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/21 18:11:24 INFO DiskBlockManager: Created local directory at C:\Users\conan\AppData\Local\Temp\blockmgr-5301e3ab-236a-40bd-9899-7b70b0d1e026
17/12/21 18:11:24 INFO MemoryStore: MemoryStore started with capacity 2004.6 MB
17/12/21 18:11:24 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/21 18:11:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/21 18:11:24 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/21 18:11:24 INFO SparkContext: Added JAR file:/C:/Users/conan/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:51611/jars/sparklyr-2.1-2.11.jar with timestamp 1513879884971
17/12/21 18:11:25 INFO Executor: Starting executor ID driver on host localhost
17/12/21 18:11:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51632.
17/12/21 18:11:25 INFO NettyBlockTransferService: Server created on 127.0.0.1:51632
17/12/21 18:11:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/21 18:11:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51632, None)
17/12/21 18:11:25 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51632 with 2004.6 MB RAM, BlockManagerId(driver, 127.0.0.1, 51632, None)
17/12/21 18:11:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51632, None)
17/12/21 18:11:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51632, None)
17/12/21 18:11:25 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/21 18:11:25 INFO SharedState: Warehouse path is 'C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/21 18:11:25 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/21 18:11:26 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/21 18:11:26 INFO ObjectStore: ObjectStore, initialize called
17/12/21 18:11:26 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/21 18:11:26 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/21 18:11:27 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/21 18:11:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:11:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:11:29 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:11:29 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:11:29 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/21 18:11:29 INFO ObjectStore: Initialized ObjectStore
17/12/21 18:11:29 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/21 18:11:29 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/21 18:11:30 INFO HiveMetaStore: Added admin role in metastore
17/12/21 18:11:30 INFO HiveMetaStore: Added public role in metastore
17/12/21 18:11:30 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/21 18:11:30 INFO HiveMetaStore: 0: get_all_databases
17/12/21 18:11:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/21 18:11:30 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/21 18:11:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/21 18:11:30 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:11:30 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/Temp/feb50f05-3f8f-4fdb-a2c1-2fa299b7f646_resources
17/12/21 18:11:30 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/feb50f05-3f8f-4fdb-a2c1-2fa299b7f646
17/12/21 18:11:30 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/feb50f05-3f8f-4fdb-a2c1-2fa299b7f646
17/12/21 18:11:30 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/feb50f05-3f8f-4fdb-a2c1-2fa299b7f646/_tmp_space.db
17/12/21 18:11:30 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/21 18:11:30 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:11:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:11:30 INFO HiveMetaStore: 0: get_database: global_temp
17/12/21 18:11:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/21 18:11:30 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/21 18:11:30 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 18:11:32 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:11:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:11:32 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:11:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:11:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 18:11:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 18:11:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:11:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 18:11:38 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:11:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:11:38 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:11:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:11:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 18:11:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 18:11:38 INFO CodeGenerator: Code generated in 277.182144 ms
17/12/21 18:11:38 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 18:11:38 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/21 18:11:38 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/21 18:11:38 INFO DAGScheduler: Parents of final stage: List()
17/12/21 18:11:38 INFO DAGScheduler: Missing parents: List()
17/12/21 18:11:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/12/21 18:11:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 2004.6 MB)
17/12/21 18:11:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2004.6 MB)
17/12/21 18:11:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:51632 (size: 4.6 KB, free: 2004.6 MB)
17/12/21 18:11:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/21 18:11:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/12/21 18:11:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/21 18:11:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/21 18:11:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/21 18:11:39 INFO Executor: Fetching spark://127.0.0.1:51611/jars/sparklyr-2.1-2.11.jar with timestamp 1513879884971
17/12/21 18:11:39 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:51611 after 18 ms (0 ms spent in bootstraps)
17/12/21 18:11:39 INFO Utils: Fetching spark://127.0.0.1:51611/jars/sparklyr-2.1-2.11.jar to C:\Users\conan\AppData\Local\Temp\spark-54fc6593-f3d9-418b-ad4b-2b2f2a461dfb\userFiles-7d1ad9fb-60d9-411e-a62d-1526f15dee1f\fetchFileTemp7090222443528680378.tmp
17/12/21 18:11:39 INFO Executor: Adding file:/C:/Users/conan/AppData/Local/Temp/spark-54fc6593-f3d9-418b-ad4b-2b2f2a461dfb/userFiles-7d1ad9fb-60d9-411e-a62d-1526f15dee1f/sparklyr-2.1-2.11.jar to class loader
17/12/21 18:11:39 INFO CodeGenerator: Code generated in 14.334104 ms
17/12/21 18:11:39 INFO CodeGenerator: Code generated in 15.19008 ms
17/12/21 18:11:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/12/21 18:11:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 366 ms on localhost (executor driver) (1/1)
17/12/21 18:11:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/21 18:11:39 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.392 s
17/12/21 18:11:39 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.590036 s
17/12/21 18:11:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:11:39 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 18:11:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:11:39 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 18:11:39 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 18:11:39 INFO FileSourceStrategy: Pruning directories with: 
17/12/21 18:11:39 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/21 18:11:39 INFO FileSourceStrategy: Output Data Schema: struct<S1: double>
17/12/21 18:11:39 INFO FileSourceStrategy: Pushed Filters: 
17/12/21 18:11:39 INFO CodeGenerator: Code generated in 7.737011 ms
17/12/21 18:11:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.7 KB, free 2004.3 MB)
17/12/21 18:11:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2004.3 MB)
17/12/21 18:11:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:51632 (size: 24.0 KB, free: 2004.6 MB)
17/12/21 18:11:39 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/21 18:11:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/21 18:11:40 INFO CodeGenerator: Code generated in 10.576419 ms
17/12/21 18:11:40 INFO CodeGenerator: Code generated in 8.683983 ms
17/12/21 18:11:40 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 18:11:40 INFO DAGScheduler: Registering RDD 10 (sql at <unknown>:0)
17/12/21 18:11:40 INFO DAGScheduler: Registering RDD 15 (sql at <unknown>:0)
17/12/21 18:11:40 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/21 18:11:40 INFO DAGScheduler: Final stage: ResultStage 3 (sql at <unknown>:0)
17/12/21 18:11:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/12/21 18:11:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/12/21 18:11:40 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0), which has no missing parents
17/12/21 18:11:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.8 KB, free 2004.3 MB)
17/12/21 18:11:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KB, free 2004.3 MB)
17/12/21 18:11:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:51632 (size: 7.2 KB, free: 2004.6 MB)
17/12/21 18:11:40 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/21 18:11:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0)
17/12/21 18:11:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/21 18:11:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/21 18:11:40 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/21 18:11:40 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpEzPCXP/spark_serialize_b4b6732d6ed4e78ba65df5f88c4d1160a9f5b325857ab7dd3dcb86e68e85fa88.csv, range: 0-198278, partition values: [empty row]
17/12/21 18:11:40 INFO CodeGenerator: Code generated in 5.329555 ms
17/12/21 18:11:40 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1896 bytes result sent to driver
17/12/21 18:11:40 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.238 s
17/12/21 18:11:40 INFO DAGScheduler: looking for newly runnable stages
17/12/21 18:11:40 INFO DAGScheduler: running: Set()
17/12/21 18:11:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 238 ms on localhost (executor driver) (1/1)
17/12/21 18:11:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/21 18:11:40 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/12/21 18:11:40 INFO DAGScheduler: failed: Set()
17/12/21 18:11:40 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/21 18:11:40 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.9 KB, free 2004.2 MB)
17/12/21 18:11:40 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.6 KB, free 2004.2 MB)
17/12/21 18:11:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:51632 (size: 5.6 KB, free: 2004.6 MB)
17/12/21 18:11:40 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/21 18:11:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/21 18:11:40 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
17/12/21 18:11:40 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5942 bytes)
17/12/21 18:11:40 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5942 bytes)
17/12/21 18:11:40 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/21 18:11:40 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
17/12/21 18:11:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 18:11:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 18:11:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 18:11:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 18:11:40 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 39.3 KB, free 2004.2 MB)
17/12/21 18:11:40 INFO MemoryStore: Block rdd_12_1 stored as values in memory (estimated size 39.3 KB, free 2004.2 MB)
17/12/21 18:11:40 INFO BlockManagerInfo: Added rdd_12_0 in memory on 127.0.0.1:51632 (size: 39.3 KB, free: 2004.5 MB)
17/12/21 18:11:40 INFO BlockManagerInfo: Added rdd_12_1 in memory on 127.0.0.1:51632 (size: 39.3 KB, free: 2004.5 MB)
17/12/21 18:11:40 INFO CodeGenerator: Code generated in 3.433721 ms
17/12/21 18:11:40 INFO CodeGenerator: Code generated in 16.885418 ms
17/12/21 18:11:40 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 3241 bytes result sent to driver
17/12/21 18:11:40 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 3064 bytes result sent to driver
17/12/21 18:11:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 138 ms on localhost (executor driver) (1/2)
17/12/21 18:11:40 INFO DAGScheduler: ShuffleMapStage 2 (sql at <unknown>:0) finished in 0.138 s
17/12/21 18:11:40 INFO DAGScheduler: looking for newly runnable stages
17/12/21 18:11:40 INFO DAGScheduler: running: Set()
17/12/21 18:11:40 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/12/21 18:11:40 INFO DAGScheduler: failed: Set()
17/12/21 18:11:40 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
17/12/21 18:11:40 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 138 ms on localhost (executor driver) (2/2)
17/12/21 18:11:40 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/21 18:11:40 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 2004.2 MB)
17/12/21 18:11:40 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.2 MB)
17/12/21 18:11:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:51632 (size: 3.7 KB, free: 2004.5 MB)
17/12/21 18:11:40 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/21 18:11:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0)
17/12/21 18:11:40 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/21 18:11:40 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/21 18:11:40 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
17/12/21 18:11:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 18:11:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 18:11:40 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 1952 bytes result sent to driver
17/12/21 18:11:40 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
17/12/21 18:11:40 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/21 18:11:40 INFO DAGScheduler: ResultStage 3 (sql at <unknown>:0) finished in 0.007 s
17/12/21 18:11:40 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.451530 s
17/12/21 18:11:40 INFO CodeGenerator: Code generated in 6.807783 ms
17/12/21 18:11:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:11:40 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 50
17/12/21 18:11:40 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:51632 in memory (size: 7.2 KB, free: 2004.5 MB)
17/12/21 18:11:40 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:51632 in memory (size: 5.6 KB, free: 2004.5 MB)
17/12/21 18:11:40 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:51632 in memory (size: 3.7 KB, free: 2004.5 MB)
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 51
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 57
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 58
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 59
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 60
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 61
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 62
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 63
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 64
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 65
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 66
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 67
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 68
17/12/21 18:11:40 INFO ContextCleaner: Cleaned accumulator 69
17/12/21 18:11:40 INFO ContextCleaner: Cleaned shuffle 1
17/12/21 18:11:40 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 18:11:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/21 18:11:40 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:196)
17/12/21 18:11:40 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/12/21 18:11:40 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:196)
17/12/21 18:11:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/12/21 18:11:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/12/21 18:11:40 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
17/12/21 18:11:40 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.9 KB, free 2004.2 MB)
17/12/21 18:11:40 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.6 KB, free 2004.2 MB)
17/12/21 18:11:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:51632 (size: 5.6 KB, free: 2004.5 MB)
17/12/21 18:11:40 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/21 18:11:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196)
17/12/21 18:11:40 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
17/12/21 18:11:40 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5934 bytes)
17/12/21 18:11:40 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 5934 bytes)
17/12/21 18:11:40 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/21 18:11:40 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/12/21 18:11:40 INFO BlockManager: Found block rdd_12_0 locally
17/12/21 18:11:40 INFO BlockManager: Found block rdd_12_1 locally
17/12/21 18:11:40 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2127 bytes result sent to driver
17/12/21 18:11:40 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 1950 bytes result sent to driver
17/12/21 18:11:40 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 31 ms on localhost (executor driver) (1/2)
17/12/21 18:11:40 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:196) finished in 0.031 s
17/12/21 18:11:40 INFO DAGScheduler: looking for newly runnable stages
17/12/21 18:11:40 INFO DAGScheduler: running: Set()
17/12/21 18:11:40 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/12/21 18:11:40 INFO DAGScheduler: failed: Set()
17/12/21 18:11:40 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196), which has no missing parents
17/12/21 18:11:40 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 31 ms on localhost (executor driver) (2/2)
17/12/21 18:11:40 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/21 18:11:40 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 2004.2 MB)
17/12/21 18:11:40 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.2 MB)
17/12/21 18:11:40 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:51632 (size: 3.7 KB, free: 2004.5 MB)
17/12/21 18:11:40 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/12/21 18:11:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196)
17/12/21 18:11:40 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/21 18:11:40 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/21 18:11:40 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
17/12/21 18:11:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 18:11:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 18:11:40 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1963 bytes result sent to driver
17/12/21 18:11:40 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:196) finished in 0.021 s
17/12/21 18:11:40 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.057210 s
17/12/21 18:11:40 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 21 ms on localhost (executor driver) (1/1)
17/12/21 18:11:40 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/21 18:11:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:11:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz11`
WHERE (0 = 1)
17/12/21 18:11:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:11:43 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`, `V11` AS `V11`, `V12` AS `V12`, `V13` AS `V13`, `V14` AS `V14`, `V15` AS `V15`, `V16` AS `V16`, `V17` AS `V17`, `V18` AS `V18`, `V19` AS `V19`, `V20` AS `V20`, `V21` AS `V21`, `V22` AS `V22`, `V23` AS `V23`, `V24` AS `V24`, `V25` AS `V25`, `V26` AS `V26`, `V27` AS `V27`, `V28` AS `V28`, `V29` AS `V29`, `V30` AS `V30`, `V31` AS `V31`, `V32` AS `V32`, `V33` AS `V33`, `V34` AS `V34`, `V35` AS `V35`, `V36` AS `V36`, `V37` AS `V37`, `V38` AS `V38`, `V39` AS `V39`, `V40` AS `V40`, `V41` AS `V41`, `V42` AS `V42`, `V43` AS `V43`, `V44` AS `V44`, `V45` AS `V45`, `V46` AS `V46`, `V47` AS `V47`, `V48` AS `V48`, `V49` AS `V49`, `V50` AS `V50`, `V51` AS `V51`, `V52` AS `V52`, `V53` AS `V53`, `V54` AS `V54`, `V55` AS `V55`, `V56` AS `V56`, `V57` AS `V57`, `V58` AS `V58`, `V59` AS `V59`, `V60` AS `V60`, `V61` AS `V61`, `V62` AS `V62`, `V63` AS `V63`, `V64` AS `V64`, `V65` AS `V65`, `V66` AS `V66`, `V67` AS `V67`, `V68` AS `V68`, `V69` AS `V69`, `V70` AS `V70`, `V71` AS `V71`, `V72` AS `V72`, `V73` AS `V73`, `V74` AS `V74`, `V75` AS `V75`, `V76` AS `V76`, `V77` AS `V77`, `V78` AS `V78`, `V79` AS `V79`, `V80` AS `V80`, `V81` AS `V81`, `V82` AS `V82`, `V83` AS `V83`, `V84` AS `V84`, `V85` AS `V85`, `V86` AS `V86`, `V87` AS `V87`, `V88` AS `V88`, `V89` AS `V89`, `V90` AS `V90`, `V91` AS `V91`, `V92` AS `V92`, `V93` AS `V93`, `V94` AS `V94`, `V95` AS `V95`, `V96` AS `V96`, `V97` AS `V97`, `V98` AS `V98`, `V99` AS `V99`, `V100` AS `V100`, `V101` AS `V101`, `V102` AS `V102`, `V103` AS `V103`, `V104` AS `V104`, `V105` AS `V105`, `V106` AS `V106`, `V107` AS `V107`, `V108` AS `V108`, `V109` AS `V109`, `V110` AS `V110`, `V111` AS `V111`, `V112` AS `V112`, `V113` AS `V113`, `V114` AS `V114`, `V115` AS `V115`, `V116` AS `V116`, `V117` AS `V117`, `V118` AS `V118`, `V119` AS `V119`, `V120` AS `V120`, `V121` AS `V121`, `V122` AS `V122`, `V123` AS `V123`, `V124` AS `V124`, `V125` AS `V125`, `V126` AS `V126`, `V127` AS `V127`, `V128` AS `V128`, `V129` AS `V129`, `V130` AS `V130`, `V131` AS `V131`, `V132` AS `V132`, `V133` AS `V133`, `V134` AS `V134`, `V135` AS `V135`, `V136` AS `V136`, `V137` AS `V137`, `V138` AS `V138`, `V139` AS `V139`, `V140` AS `V140`, `V141` AS `V141`, `V142` AS `V142`, `V143` AS `V143`, `V144` AS `V144`, `V145` AS `V145`, `V146` AS `V146`, `V147` AS `V147`, `V148` AS `V148`, `V149` AS `V149`, `V150` AS `V150`, `V151` AS `V151`, `V152` AS `V152`, `V153` AS `V153`, `V154` AS `V154`, `V155` AS `V155`, `V156` AS `V156`, `V157` AS `V157`, `V158` AS `V158`, `V159` AS `V159`, `V160` AS `V160`, `V161` AS `V161`, `V162` AS `V162`, `V163` AS `V163`, `V164` AS `V164`, `V165` AS `V165`, `V166` AS `V166`, `V167` AS `V167`, `V168` AS `V168`, `V169` AS `V169`, `V170` AS `V170`, `V171` AS `V171`, `V172` AS `V172`, `V173` AS `V173`, `V174` AS `V174`, `V175` AS `V175`, `V176` AS `V176`, `V177` AS `V177`, `V178` AS `V178`, `V179` AS `V179`, `V180` AS `V180`, `V181` AS `V181`, `V182` AS `V182`, `V183` AS `V183`, `V184` AS `V184`, `V185` AS `V185`, `V186` AS `V186`, `V187` AS `V187`, `V188` AS `V188`, `V189` AS `V189`, `V190` AS `V190`, `V191` AS `V191`, `V192` AS `V192`, `V193` AS `V193`, `V194` AS `V194`, `V195` AS `V195`, `V196` AS `V196`, `V197` AS `V197`, `V198` AS `V198`, `V199` AS `V199`, `V200` AS `V200`, `V201` AS `V201`, `V202` AS `V202`, `V203` AS `V203`, `V204` AS `V204`, `V205` AS `V205`, `V206` AS `V206`, `V207` AS `V207`, `V208` AS `V208`, `V209` AS `V209`, `V210` AS `V210`, `V211` AS `V211`, `V212` AS `V212`, `V213` AS `V213`, `V214` AS `V214`, `V215` AS `V215`, `V216` AS `V216`, `V217` AS `V217`, `V218` AS `V218`, `V219` AS `V219`, `V220` AS `V220`, `V221` AS `V221`, `V222` AS `V222`, `V223` AS `V223`, `V224` AS `V224`, `V225` AS `V225`, `V226` AS `V226`, `V227` AS `V227`, `V228` AS `V228`, `V229` AS `V229`, `V230` AS `V230`, `V231` AS `V231`, `V232` AS `V232`, `V233` AS `V233`, `V234` AS `V234`, `V235` AS `V235`, `V236` AS `V236`, `V237` AS `V237`, `V238` AS `V238`, `V239` AS `V239`, `V240` AS `V240`, `V241` AS `V241`, `V242` AS `V242`, `V243` AS `V243`, `V244` AS `V244`, `V245` AS `V245`, `V246` AS `V246`, `V247` AS `V247`, `V248` AS `V248`, `V249` AS `V249`, `V250` AS `V250`, `V251` AS `V251`, `V252` AS `V252`, `V253` AS `V253`, `V254` AS `V254`, `V255` AS `V255`, `V256` AS `V256`, `V257` AS `V257`, `V258` AS `V258`, `V259` AS `V259`, `V260` AS `V260`, `V261` AS `V261`, `V262` AS `V262`, `V263` AS `V263`, `V264` AS `V264`, `V265` AS `V265`, `V266` AS `V266`, `V267` AS `V267`, `V268` AS `V268`, `V269` AS `V269`, `V270` AS `V270`, `V271` AS `V271`, `V272` AS `V272`, `V273` AS `V273`, `V274` AS `V274`, `V275` AS `V275`, `V276` AS `V276`, `V277` AS `V277`, `V278` AS `V278`, `V279` AS `V279`, `V280` AS `V280`, `V281` AS `V281`, `V282` AS `V282`, `V283` AS `V283`, `V284` AS `V284`, `V285` AS `V285`, `V286` AS `V286`, `V287` AS `V287`, `V288` AS `V288`, `V289` AS `V289`, `V290` AS `V290`, `V291` AS `V291`, `V292` AS `V292`, `V293` AS `V293`, `V294` AS `V294`, `V295` AS `V295`, `V296` AS `V296`, `V297` AS `V297`, `V298` AS `V298`, `V299` AS `V299`, `V300` AS `V300`, `V301` AS `V301`, `V302` AS `V302`, `V303` AS `V303`, `V304` AS `V304`, `V305` AS `V305`, `V306` AS `V306`, `V307` AS `V307`, `V308` AS `V308`, `V309` AS `V309`, `V310` AS `V310`, `V311` AS `V311`, `V312` AS `V312`, `V313` AS `V313`, `V314` AS `V314`, `V315` AS `V315`, `V316` AS `V316`, `V317` AS `V317`, `V318` AS `V318`, `V319` AS `V319`, `V320` AS `V320`, `V321` AS `V321`, `V322` AS `V322`, `V323` AS `V323`, `V324` AS `V324`, `V325` AS `V325`, `V326` AS `V326`, `V327` AS `V327`, `V328` AS `V328`, `V329` AS `V329`, `V330` AS `V330`, `V331` AS `V331`, `V332` AS `V332`, `V333` AS `V333`, `V334` AS `V334`, `V335` AS `V335`, `V336` AS `V336`, `V337` AS `V337`, `V338` AS `V338`, `V339` AS `V339`, `V340` AS `V340`, `V341` AS `V341`, `V342` AS `V342`, `V343` AS `V343`, `V344` AS `V344`, `V345` AS `V345`, `V346` AS `V346`, `V347` AS `V347`, `V348` AS `V348`, `V349` AS `V349`, `V350` AS `V350`, `V351` AS `V351`, `V352` AS `V352`, `V353` AS `V353`, `V354` AS `V354`, `V355` AS `V355`, `V356` AS `V356`, `V357` AS `V357`, `V358` AS `V358`, `V359` AS `V359`, `V360` AS `V360`, `V361` AS `V361`, `V362` AS `V362`, `V363` AS `V363`, `V364` AS `V364`, `V365` AS `V365`, `V366` AS `V366`, `V367` AS `V367`, `V368` AS `V368`, `V369` AS `V369`, `V370` AS `V370`, `V371` AS `V371`, `V372` AS `V372`, `V373` AS `V373`, `V374` AS `V374`, `V375` AS `V375`, `V376` AS `V376`, `V377` AS `V377`, `V378` AS `V378`, `V379` AS `V379`, `V380` AS `V380`, `V381` AS `V381`, `V382` AS `V382`, `V383` AS `V383`, `V384` AS `V384`, `V385` AS `V385`, `V386` AS `V386`, `V387` AS `V387`, `V388` AS `V388`, `V389` AS `V389`, `V390` AS `V390`, `V391` AS `V391`, `V392` AS `V392`, `V393` AS `V393`, `V394` AS `V394`, `V395` AS `V395`, `V396` AS `V396`, `V397` AS `V397`, `V398` AS `V398`, `V399` AS `V399`, `V400` AS `V400`, `V401` AS `V401`, `V402` AS `V402`, `V403` AS `V403`, `V404` AS `V404`, `V405` AS `V405`, `V406` AS `V406`, `V407` AS `V407`, `V408` AS `V408`, `V409` AS `V409`, `V410` AS `V410`, `V411` AS `V411`, `V412` AS `V412`, `V413` AS `V413`, `V414` AS `V414`, `V415` AS `V415`, `V416` AS `V416`, `V417` AS `V417`, `V418` AS `V418`, `V419` AS `V419`, `V420` AS `V420`, `V421` AS `V421`, `V422` AS `V422`, `V423` AS `V423`, `V424` AS `V424`, `V425` AS `V425`, `V426` AS `V426`, `V427` AS `V427`, `V428` AS `V428`, `V429` AS `V429`, `V430` AS `V430`, `V431` AS `V431`, `V432` AS `V432`, `V433` AS `V433`, `V434` AS `V434`, `V435` AS `V435`, `V436` AS `V436`, `V437` AS `V437`, `V438` AS `V438`, `V439` AS `V439`, `V440` AS `V440`, `V441` AS `V441`, `V442` AS `V442`, `V443` AS `V443`, `V444` AS `V444`, `V445` AS `V445`, `V446` AS `V446`, `V447` AS `V447`, `V448` AS `V448`, `V449` AS `V449`, `V450` AS `V450`, `V451` AS `V451`, `V452` AS `V452`, `V453` AS `V453`, `V454` AS `V454`, `V455` AS `V455`, `V456` AS `V456`, `V457` AS `V457`, `V458` AS `V458`, `V459` AS `V459`, `V460` AS `V460`, `V461` AS `V461`, `V462` AS `V462`, `V463` AS `V463`, `V464` AS `V464`, `V465` AS `V465`, `V466` AS `V466`, `V467` AS `V467`, `V468` AS `V468`, `V469` AS `V469`, `V470` AS `V470`, `V471` AS `V471`, `V472` AS `V472`, `V473` AS `V473`, `V474` AS `V474`, `V475` AS `V475`, `V476` AS `V476`, `V477` AS `V477`, `V478` AS `V478`, `V479` AS `V479`, `V480` AS `V480`, `V481` AS `V481`, `V482` AS `V482`, `V483` AS `V483`, `V484` AS `V484`, `V485` AS `V485`, `V486` AS `V486`, `V487` AS `V487`, `V488` AS `V488`, `V489` AS `V489`, `V490` AS `V490`, `V491` AS `V491`, `V492` AS `V492`, `V493` AS `V493`, `V494` AS `V494`, `V495` AS `V495`, `V496` AS `V496`, `V497` AS `V497`, `V498` AS `V498`, `V499` AS `V499`, `V500` AS `V500`, `V501` AS `V501`, `V502` AS `V502`, `V503` AS `V503`, `V504` AS `V504`, `V505` AS `V505`, `V506` AS `V506`, `V507` AS `V507`, `V508` AS `V508`, `V509` AS `V509`, `V510` AS `V510`, `V511` AS `V511`, `V512` AS `V512`, `V513` AS `V513`, `V514` AS `V514`, `V515` AS `V515`, `V516` AS `V516`, `V517` AS `V517`, `V518` AS `V518`, `V519` AS `V519`, `V520` AS `V520`, `V521` AS `V521`, `V522` AS `V522`, `V523` AS `V523`, `V524` AS `V524`, `V525` AS `V525`, `V526` AS `V526`, `V527` AS `V527`, `V528` AS `V528`, `V529` AS `V529`, `V530` AS `V530`, `V531` AS `V531`, `V532` AS `V532`, `V533` AS `V533`, `V534` AS `V534`, `V535` AS `V535`, `V536` AS `V536`, `V537` AS `V537`, `V538` AS `V538`, `V539` AS `V539`, `V540` AS `V540`, `V541` AS `V541`, `V542` AS `V542`, `V543` AS `V543`, `V544` AS `V544`, `V545` AS `V545`, `V546` AS `V546`, `V547` AS `V547`, `V548` AS `V548`, `V549` AS `V549`, `V550` AS `V550`, `V551` AS `V551`, `V552` AS `V552`, `V553` AS `V553`, `V554` AS `V554`, `V555` AS `V555`, `V556` AS `V556`, `V557` AS `V557`, `V558` AS `V558`, `V559` AS `V559`, `V560` AS `V560`, `V561` AS `V561`, `V562` AS `V562`, `V563` AS `V563`, `V564` AS `V564`, `V565` AS `V565`, `V566` AS `V566`, `V567` AS `V567`, `V568` AS `V568`, `V569` AS `V569`, `V570` AS `V570`, `V571` AS `V571`, `V572` AS `V572`, `V573` AS `V573`, `V574` AS `V574`, `V575` AS `V575`, `V576` AS `V576`, `V577` AS `V577`, `V578` AS `V578`, `V579` AS `V579`, `V580` AS `V580`, `V581` AS `V581`, `V582` AS `V582`, `V583` AS `V583`, `V584` AS `V584`, `V585` AS `V585`, `V586` AS `V586`, `V587` AS `V587`, `V588` AS `V588`, `V589` AS `V589`, `V590` AS `V590`, `V591` AS `V591`, `V592` AS `V592`, `V593` AS `V593`, `V594` AS `V594`, `V595` AS `V595`, `V596` AS `V596`, `V597` AS `V597`, `V598` AS `V598`, `V599` AS `V599`, `V600` AS `V600`, `V601` AS `V601`, `V602` AS `V602`, `V603` AS `V603`, `V604` AS `V604`, `V605` AS `V605`, `V606` AS `V606`, `V607` AS `V607`, `V608` AS `V608`, `V609` AS `V609`, `V610` AS `V610`, `V611` AS `V611`, `V612` AS `V612`, `V613` AS `V613`, `V614` AS `V614`, `V615` AS `V615`, `V616` AS `V616`, `V617` AS `V617`, `V618` AS `V618`, `V619` AS `V619`, `V620` AS `V620`, `V621` AS `V621`, `V622` AS `V622`, `V623` AS `V623`, `V624` AS `V624`, `V625` AS `V625`, `V626` AS `V626`, `V627` AS `V627`, `V628` AS `V628`, `V629` AS `V629`, `V630` AS `V630`, `V631` AS `V631`, `V632` AS `V632`, `V633` AS `V633`, `V634` AS `V634`, `V635` AS `V635`, `V636` AS `V636`, `V637` AS `V637`, `V638` AS `V638`, `V639` AS `V639`, `V640` AS `V640`, `V641` AS `V641`, `V642` AS `V642`, `V643` AS `V643`, `V644` AS `V644`, `V645` AS `V645`, `V646` AS `V646`, `V647` AS `V647`, `V648` AS `V648`, `V649` AS `V649`, `V650` AS `V650`, `V651` AS `V651`, `V652` AS `V652`, `V653` AS `V653`, `V654` AS `V654`, `V655` AS `V655`, `V656` AS `V656`, `V657` AS `V657`, `V658` AS `V658`, `V659` AS `V659`, `V660` AS `V660`, `V661` AS `V661`, `V662` AS `V662`, `V663` AS `V663`, `V664` AS `V664`, `V665` AS `V665`, `V666` AS `V666`, `V667` AS `V667`, `V668` AS `V668`, `V669` AS `V669`, `V670` AS `V670`, `V671` AS `V671`, `V672` AS `V672`, `V673` AS `V673`, `V674` AS `V674`, `V675` AS `V675`, `V676` AS `V676`, `V677` AS `V677`, `V678` AS `V678`, `V679` AS `V679`, `V680` AS `V680`, `V681` AS `V681`, `V682` AS `V682`, `V683` AS `V683`, `V684` AS `V684`, `V685` AS `V685`, `V686` AS `V686`, `V687` AS `V687`, `V688` AS `V688`, `V689` AS `V689`, `V690` AS `V690`, `V691` AS `V691`, `V692` AS `V692`, `V693` AS `V693`, `V694` AS `V694`, `V695` AS `V695`, `V696` AS `V696`, `V697` AS `V697`, `V698` AS `V698`, `V699` AS `V699`, `V700` AS `V700`, `V701` AS `V701`, `V702` AS `V702`, `V703` AS `V703`, `V704` AS `V704`, `V705` AS `V705`, `V706` AS `V706`, `V707` AS `V707`, `V708` AS `V708`, `V709` AS `V709`, `V710` AS `V710`, `V711` AS `V711`, `V712` AS `V712`, `V713` AS `V713`, `V714` AS `V714`, `V715` AS `V715`, `V716` AS `V716`, `V717` AS `V717`, `V718` AS `V718`, `V719` AS `V719`, `V720` AS `V720`, `V721` AS `V721`, `V722` AS `V722`, `V723` AS `V723`, `V724` AS `V724`, `V725` AS `V725`, `V726` AS `V726`, `V727` AS `V727`, `V728` AS `V728`, `V729` AS `V729`, `V730` AS `V730`, `V731` AS `V731`, `V732` AS `V732`, `V733` AS `V733`, `V734` AS `V734`, `V735` AS `V735`, `V736` AS `V736`, `V737` AS `V737`, `V738` AS `V738`, `V739` AS `V739`, `V740` AS `V740`, `V741` AS `V741`, `V742` AS `V742`, `V743` AS `V743`, `V744` AS `V744`, `V745` AS `V745`, `V746` AS `V746`, `V747` AS `V747`, `V748` AS `V748`, `V749` AS `V749`, `V750` AS `V750`, `V751` AS `V751`, `V752` AS `V752`, `V753` AS `V753`, `V754` AS `V754`, `V755` AS `V755`, `V756` AS `V756`, `V757` AS `V757`, `V758` AS `V758`, `V759` AS `V759`, `V760` AS `V760`, `V761` AS `V761`, `V762` AS `V762`, `V763` AS `V763`, `V764` AS `V764`, `V765` AS `V765`, `V766` AS `V766`, `V767` AS `V767`, `V768` AS `V768`, `V769` AS `V769`, `V770` AS `V770`, `V771` AS `V771`, `V772` AS `V772`, `V773` AS `V773`, `V774` AS `V774`, `V775` AS `V775`, `V776` AS `V776`, `V777` AS `V777`, `V778` AS `V778`, `V779` AS `V779`, `V780` AS `V780`, `V781` AS `V781`, `V782` AS `V782`, `V783` AS `V783`, `V784` AS `V784`, `V785` AS `V785`, `V786` AS `V786`, `V787` AS `V787`, `V788` AS `V788`, `V789` AS `V789`, `V790` AS `V790`, `V791` AS `V791`, `V792` AS `V792`, `V793` AS `V793`, `V794` AS `V794`, `V795` AS `V795`, `V796` AS `V796`, `V797` AS `V797`, `V798` AS `V798`, `V799` AS `V799`, `V800` AS `V800`, `V801` AS `V801`, `V802` AS `V802`, `V803` AS `V803`, `V804` AS `V804`, `V805` AS `V805`, `V806` AS `V806`, `V807` AS `V807`, `V808` AS `V808`, `V809` AS `V809`, `V810` AS `V810`, `V811` AS `V811`, `V812` AS `V812`, `V813` AS `V813`, `V814` AS `V814`, `V815` AS `V815`, `V816` AS `V816`, `V817` AS `V817`, `V818` AS `V818`, `V819` AS `V819`, `V820` AS `V820`, `V821` AS `V821`, `V822` AS `V822`, `V823` AS `V823`, `V824` AS `V824`, `V825` AS `V825`, `V826` AS `V826`, `V827` AS `V827`, `V828` AS `V828`, `V829` AS `V829`, `V830` AS `V830`, `V831` AS `V831`, `V832` AS `V832`, `V833` AS `V833`, `V834` AS `V834`, `V835` AS `V835`, `V836` AS `V836`, `V837` AS `V837`, `V838` AS `V838`, `V839` AS `V839`, `V840` AS `V840`, `V841` AS `V841`, `V842` AS `V842`, `V843` AS `V843`, `V844` AS `V844`, `V845` AS `V845`, `V846` AS `V846`, `V847` AS `V847`, `V848` AS `V848`, `V849` AS `V849`, `V850` AS `V850`, `V851` AS `V851`, `V852` AS `V852`, `V853` AS `V853`, `V854` AS `V854`, `V855` AS `V855`, `V856` AS `V856`, `V857` AS `V857`, `V858` AS `V858`, `V859` AS `V859`, `V860` AS `V860`, `V861` AS `V861`, `V862` AS `V862`, `V863` AS `V863`, `V864` AS `V864`, `V865` AS `V865`, `V866` AS `V866`, `V867` AS `V867`, `V868` AS `V868`, `V869` AS `V869`, `V870` AS `V870`, `V871` AS `V871`, `V872` AS `V872`, `V873` AS `V873`, `V874` AS `V874`, `V875` AS `V875`, `V876` AS `V876`, `V877` AS `V877`, `V878` AS `V878`, `V879` AS `V879`, `V880` AS `V880`, `V881` AS `V881`, `V882` AS `V882`, `V883` AS `V883`, `V884` AS `V884`, `V885` AS `V885`, `V886` AS `V886`, `V887` AS `V887`, `V888` AS `V888`, `V889` AS `V889`, `V890` AS `V890`, `V891` AS `V891`, `V892` AS `V892`, `V893` AS `V893`, `V894` AS `V894`, `V895` AS `V895`, `V896` AS `V896`, `V897` AS `V897`, `V898` AS `V898`, `V899` AS `V899`, `V900` AS `V900`, `V901` AS `V901`, `V902` AS `V902`, `V903` AS `V903`, `V904` AS `V904`, `V905` AS `V905`, `V906` AS `V906`, `V907` AS `V907`, `V908` AS `V908`, `V909` AS `V909`, `V910` AS `V910`, `V911` AS `V911`, `V912` AS `V912`, `V913` AS `V913`, `V914` AS `V914`, `V915` AS `V915`, `V916` AS `V916`, `V917` AS `V917`, `V918` AS `V918`, `V919` AS `V919`, `V920` AS `V920`, `V921` AS `V921`, `V922` AS `V922`, `V923` AS `V923`, `V924` AS `V924`, `V925` AS `V925`, `V926` AS `V926`, `V927` AS `V927`, `V928` AS `V928`, `V929` AS `V929`, `V930` AS `V930`, `V931` AS `V931`, `V932` AS `V932`, `V933` AS `V933`, `V934` AS `V934`, `V935` AS `V935`, `V936` AS `V936`, `V937` AS `V937`, `V938` AS `V938`, `V939` AS `V939`, `V940` AS `V940`, `V941` AS `V941`, `V942` AS `V942`, `V943` AS `V943`, `V944` AS `V944`, `V945` AS `V945`, `V946` AS `V946`, `V947` AS `V947`, `V948` AS `V948`, `V949` AS `V949`, `V950` AS `V950`, `V951` AS `V951`, `V952` AS `V952`, `V953` AS `V953`, `V954` AS `V954`, `V955` AS `V955`, `V956` AS `V956`, `V957` AS `V957`, `V958` AS `V958`, `V959` AS `V959`, `V960` AS `V960`, `V961` AS `V961`, `V962` AS `V962`, `V963` AS `V963`, `V964` AS `V964`, `V965` AS `V965`, `V966` AS `V966`, `V967` AS `V967`, `V968` AS `V968`, `V969` AS `V969`, `V970` AS `V970`, `V971` AS `V971`, `V972` AS `V972`, `V973` AS `V973`, `V974` AS `V974`, `V975` AS `V975`, `V976` AS `V976`, `V977` AS `V977`, `V978` AS `V978`, `V979` AS `V979`, `V980` AS `V980`, `V981` AS `V981`, `V982` AS `V982`, `V983` AS `V983`, `V984` AS `V984`, `V985` AS `V985`, `V986` AS `V986`, `V987` AS `V987`, `V988` AS `V988`, `V989` AS `V989`, `V990` AS `V990`, `V991` AS `V991`, `V992` AS `V992`, `V993` AS `V993`, `V994` AS `V994`, `V995` AS `V995`, `V996` AS `V996`, `V997` AS `V997`, `V998` AS `V998`, `V999` AS `V999`, `V1000` AS `V1000`
FROM (SELECT `S1`, `S1` + 0.9797959 * RANDN() AS `V1`, `S1` + 0.9797959 * RANDN() AS `V2`, `S1` + 0.9797959 * RANDN() AS `V3`, `S1` + 0.9797959 * RANDN() AS `V4`, `S1` + 0.9797959 * RANDN() AS `V5`, `S1` + 0.9797959 * RANDN() AS `V6`, `S1` + 0.9797959 * RANDN() AS `V7`, `S1` + 0.9797959 * RANDN() AS `V8`, `S1` + 0.9797959 * RANDN() AS `V9`, `S1` + 0.9797959 * RANDN() AS `V10`, `S1` + 0.9797959 * RANDN() AS `V11`, `S1` + 0.9797959 * RANDN() AS `V12`, `S1` + 0.9797959 * RANDN() AS `V13`, `S1` + 0.9797959 * RANDN() AS `V14`, `S1` + 0.9797959 * RANDN() AS `V15`, `S1` + 0.9797959 * RANDN() AS `V16`, `S1` + 0.9797959 * RANDN() AS `V17`, `S1` + 0.9797959 * RANDN() AS `V18`, `S1` + 0.9797959 * RANDN() AS `V19`, `S1` + 0.9797959 * RANDN() AS `V20`, `S1` + 0.9797959 * RANDN() AS `V21`, `S1` + 0.9797959 * RANDN() AS `V22`, `S1` + 0.9797959 * RANDN() AS `V23`, `S1` + 0.9797959 * RANDN() AS `V24`, `S1` + 0.9797959 * RANDN() AS `V25`, `S1` + 0.9797959 * RANDN() AS `V26`, `S1` + 0.9797959 * RANDN() AS `V27`, `S1` + 0.9797959 * RANDN() AS `V28`, `S1` + 0.9797959 * RANDN() AS `V29`, `S1` + 0.9797959 * RANDN() AS `V30`, `S1` + 0.9797959 * RANDN() AS `V31`, `S1` + 0.9797959 * RANDN() AS `V32`, `S1` + 0.9797959 * RANDN() AS `V33`, `S1` + 0.9797959 * RANDN() AS `V34`, `S1` + 0.9797959 * RANDN() AS `V35`, `S1` + 0.9797959 * RANDN() AS `V36`, `S1` + 0.9797959 * RANDN() AS `V37`, `S1` + 0.9797959 * RANDN() AS `V38`, `S1` + 0.9797959 * RANDN() AS `V39`, `S1` + 0.9797959 * RANDN() AS `V40`, `S1` + 0.9797959 * RANDN() AS `V41`, `S1` + 0.9797959 * RANDN() AS `V42`, `S1` + 0.9797959 * RANDN() AS `V43`, `S1` + 0.9797959 * RANDN() AS `V44`, `S1` + 0.9797959 * RANDN() AS `V45`, `S1` + 0.9797959 * RANDN() AS `V46`, `S1` + 0.9797959 * RANDN() AS `V47`, `S1` + 0.9797959 * RANDN() AS `V48`, `S1` + 0.9797959 * RANDN() AS `V49`, `S1` + 0.9797959 * RANDN() AS `V50`, `S1` + 0.9797959 * RANDN() AS `V51`, `S1` + 0.9797959 * RANDN() AS `V52`, `S1` + 0.9797959 * RANDN() AS `V53`, `S1` + 0.9797959 * RANDN() AS `V54`, `S1` + 0.9797959 * RANDN() AS `V55`, `S1` + 0.9797959 * RANDN() AS `V56`, `S1` + 0.9797959 * RANDN() AS `V57`, `S1` + 0.9797959 * RANDN() AS `V58`, `S1` + 0.9797959 * RANDN() AS `V59`, `S1` + 0.9797959 * RANDN() AS `V60`, `S1` + 0.9797959 * RANDN() AS `V61`, `S1` + 0.9797959 * RANDN() AS `V62`, `S1` + 0.9797959 * RANDN() AS `V63`, `S1` + 0.9797959 * RANDN() AS `V64`, `S1` + 0.9797959 * RANDN() AS `V65`, `S1` + 0.9797959 * RANDN() AS `V66`, `S1` + 0.9797959 * RANDN() AS `V67`, `S1` + 0.9797959 * RANDN() AS `V68`, `S1` + 0.9797959 * RANDN() AS `V69`, `S1` + 0.9797959 * RANDN() AS `V70`, `S1` + 0.9797959 * RANDN() AS `V71`, `S1` + 0.9797959 * RANDN() AS `V72`, `S1` + 0.9797959 * RANDN() AS `V73`, `S1` + 0.9797959 * RANDN() AS `V74`, `S1` + 0.9797959 * RANDN() AS `V75`, `S1` + 0.9797959 * RANDN() AS `V76`, `S1` + 0.9797959 * RANDN() AS `V77`, `S1` + 0.9797959 * RANDN() AS `V78`, `S1` + 0.9797959 * RANDN() AS `V79`, `S1` + 0.9797959 * RANDN() AS `V80`, `S1` + 0.9797959 * RANDN() AS `V81`, `S1` + 0.9797959 * RANDN() AS `V82`, `S1` + 0.9797959 * RANDN() AS `V83`, `S1` + 0.9797959 * RANDN() AS `V84`, `S1` + 0.9797959 * RANDN() AS `V85`, `S1` + 0.9797959 * RANDN() AS `V86`, `S1` + 0.9797959 * RANDN() AS `V87`, `S1` + 0.9797959 * RANDN() AS `V88`, `S1` + 0.9797959 * RANDN() AS `V89`, `S1` + 0.9797959 * RANDN() AS `V90`, `S1` + 0.9797959 * RANDN() AS `V91`, `S1` + 0.9797959 * RANDN() AS `V92`, `S1` + 0.9797959 * RANDN() AS `V93`, `S1` + 0.9797959 * RANDN() AS `V94`, `S1` + 0.9797959 * RANDN() AS `V95`, `S1` + 0.9797959 * RANDN() AS `V96`, `S1` + 0.9797959 * RANDN() AS `V97`, `S1` + 0.9797959 * RANDN() AS `V98`, `S1` + 0.9797959 * RANDN() AS `V99`, `S1` + 0.9797959 * RANDN() AS `V100`, `S1` + 0.9797959 * RANDN() AS `V101`, `S1` + 0.9797959 * RANDN() AS `V102`, `S1` + 0.9797959 * RANDN() AS `V103`, `S1` + 0.9797959 * RANDN() AS `V104`, `S1` + 0.9797959 * RANDN() AS `V105`, `S1` + 0.9797959 * RANDN() AS `V106`, `S1` + 0.9797959 * RANDN() AS `V107`, `S1` + 0.9797959 * RANDN() AS `V108`, `S1` + 0.9797959 * RANDN() AS `V109`, `S1` + 0.9797959 * RANDN() AS `V110`, `S1` + 0.9797959 * RANDN() AS `V111`, `S1` + 0.9797959 * RANDN() AS `V112`, `S1` + 0.9797959 * RANDN() AS `V113`, `S1` + 0.9797959 * RANDN() AS `V114`, `S1` + 0.9797959 * RANDN() AS `V115`, `S1` + 0.9797959 * RANDN() AS `V116`, `S1` + 0.9797959 * RANDN() AS `V117`, `S1` + 0.9797959 * RANDN() AS `V118`, `S1` + 0.9797959 * RANDN() AS `V119`, `S1` + 0.9797959 * RANDN() AS `V120`, `S1` + 0.9797959 * RANDN() AS `V121`, `S1` + 0.9797959 * RANDN() AS `V122`, `S1` + 0.9797959 * RANDN() AS `V123`, `S1` + 0.9797959 * RANDN() AS `V124`, `S1` + 0.9797959 * RANDN() AS `V125`, `S1` + 0.9797959 * RANDN() AS `V126`, `S1` + 0.9797959 * RANDN() AS `V127`, `S1` + 0.9797959 * RANDN() AS `V128`, `S1` + 0.9797959 * RANDN() AS `V129`, `S1` + 0.9797959 * RANDN() AS `V130`, `S1` + 0.9797959 * RANDN() AS `V131`, `S1` + 0.9797959 * RANDN() AS `V132`, `S1` + 0.9797959 * RANDN() AS `V133`, `S1` + 0.9797959 * RANDN() AS `V134`, `S1` + 0.9797959 * RANDN() AS `V135`, `S1` + 0.9797959 * RANDN() AS `V136`, `S1` + 0.9797959 * RANDN() AS `V137`, `S1` + 0.9797959 * RANDN() AS `V138`, `S1` + 0.9797959 * RANDN() AS `V139`, `S1` + 0.9797959 * RANDN() AS `V140`, `S1` + 0.9797959 * RANDN() AS `V141`, `S1` + 0.9797959 * RANDN() AS `V142`, `S1` + 0.9797959 * RANDN() AS `V143`, `S1` + 0.9797959 * RANDN() AS `V144`, `S1` + 0.9797959 * RANDN() AS `V145`, `S1` + 0.9797959 * RANDN() AS `V146`, `S1` + 0.9797959 * RANDN() AS `V147`, `S1` + 0.9797959 * RANDN() AS `V148`, `S1` + 0.9797959 * RANDN() AS `V149`, `S1` + 0.9797959 * RANDN() AS `V150`, `S1` + 0.9797959 * RANDN() AS `V151`, `S1` + 0.9797959 * RANDN() AS `V152`, `S1` + 0.9797959 * RANDN() AS `V153`, `S1` + 0.9797959 * RANDN() AS `V154`, `S1` + 0.9797959 * RANDN() AS `V155`, `S1` + 0.9797959 * RANDN() AS `V156`, `S1` + 0.9797959 * RANDN() AS `V157`, `S1` + 0.9797959 * RANDN() AS `V158`, `S1` + 0.9797959 * RANDN() AS `V159`, `S1` + 0.9797959 * RANDN() AS `V160`, `S1` + 0.9797959 * RANDN() AS `V161`, `S1` + 0.9797959 * RANDN() AS `V162`, `S1` + 0.9797959 * RANDN() AS `V163`, `S1` + 0.9797959 * RANDN() AS `V164`, `S1` + 0.9797959 * RANDN() AS `V165`, `S1` + 0.9797959 * RANDN() AS `V166`, `S1` + 0.9797959 * RANDN() AS `V167`, `S1` + 0.9797959 * RANDN() AS `V168`, `S1` + 0.9797959 * RANDN() AS `V169`, `S1` + 0.9797959 * RANDN() AS `V170`, `S1` + 0.9797959 * RANDN() AS `V171`, `S1` + 0.9797959 * RANDN() AS `V172`, `S1` + 0.9797959 * RANDN() AS `V173`, `S1` + 0.9797959 * RANDN() AS `V174`, `S1` + 0.9797959 * RANDN() AS `V175`, `S1` + 0.9797959 * RANDN() AS `V176`, `S1` + 0.9797959 * RANDN() AS `V177`, `S1` + 0.9797959 * RANDN() AS `V178`, `S1` + 0.9797959 * RANDN() AS `V179`, `S1` + 0.9797959 * RANDN() AS `V180`, `S1` + 0.9797959 * RANDN() AS `V181`, `S1` + 0.9797959 * RANDN() AS `V182`, `S1` + 0.9797959 * RANDN() AS `V183`, `S1` + 0.9797959 * RANDN() AS `V184`, `S1` + 0.9797959 * RANDN() AS `V185`, `S1` + 0.9797959 * RANDN() AS `V186`, `S1` + 0.9797959 * RANDN() AS `V187`, `S1` + 0.9797959 * RANDN() AS `V188`, `S1` + 0.9797959 * RANDN() AS `V189`, `S1` + 0.9797959 * RANDN() AS `V190`, `S1` + 0.9797959 * RANDN() AS `V191`, `S1` + 0.9797959 * RANDN() AS `V192`, `S1` + 0.9797959 * RANDN() AS `V193`, `S1` + 0.9797959 * RANDN() AS `V194`, `S1` + 0.9797959 * RANDN() AS `V195`, `S1` + 0.9797959 * RANDN() AS `V196`, `S1` + 0.9797959 * RANDN() AS `V197`, `S1` + 0.9797959 * RANDN() AS `V198`, `S1` + 0.9797959 * RANDN() AS `V199`, `S1` + 0.9797959 * RANDN() AS `V200`, `S1` + 0.9797959 * RANDN() AS `V201`, `S1` + 0.9797959 * RANDN() AS `V202`, `S1` + 0.9797959 * RANDN() AS `V203`, `S1` + 0.9797959 * RANDN() AS `V204`, `S1` + 0.9797959 * RANDN() AS `V205`, `S1` + 0.9797959 * RANDN() AS `V206`, `S1` + 0.9797959 * RANDN() AS `V207`, `S1` + 0.9797959 * RANDN() AS `V208`, `S1` + 0.9797959 * RANDN() AS `V209`, `S1` + 0.9797959 * RANDN() AS `V210`, `S1` + 0.9797959 * RANDN() AS `V211`, `S1` + 0.9797959 * RANDN() AS `V212`, `S1` + 0.9797959 * RANDN() AS `V213`, `S1` + 0.9797959 * RANDN() AS `V214`, `S1` + 0.9797959 * RANDN() AS `V215`, `S1` + 0.9797959 * RANDN() AS `V216`, `S1` + 0.9797959 * RANDN() AS `V217`, `S1` + 0.9797959 * RANDN() AS `V218`, `S1` + 0.9797959 * RANDN() AS `V219`, `S1` + 0.9797959 * RANDN() AS `V220`, `S1` + 0.9797959 * RANDN() AS `V221`, `S1` + 0.9797959 * RANDN() AS `V222`, `S1` + 0.9797959 * RANDN() AS `V223`, `S1` + 0.9797959 * RANDN() AS `V224`, `S1` + 0.9797959 * RANDN() AS `V225`, `S1` + 0.9797959 * RANDN() AS `V226`, `S1` + 0.9797959 * RANDN() AS `V227`, `S1` + 0.9797959 * RANDN() AS `V228`, `S1` + 0.9797959 * RANDN() AS `V229`, `S1` + 0.9797959 * RANDN() AS `V230`, `S1` + 0.9797959 * RANDN() AS `V231`, `S1` + 0.9797959 * RANDN() AS `V232`, `S1` + 0.9797959 * RANDN() AS `V233`, `S1` + 0.9797959 * RANDN() AS `V234`, `S1` + 0.9797959 * RANDN() AS `V235`, `S1` + 0.9797959 * RANDN() AS `V236`, `S1` + 0.9797959 * RANDN() AS `V237`, `S1` + 0.9797959 * RANDN() AS `V238`, `S1` + 0.9797959 * RANDN() AS `V239`, `S1` + 0.9797959 * RANDN() AS `V240`, `S1` + 0.9797959 * RANDN() AS `V241`, `S1` + 0.9797959 * RANDN() AS `V242`, `S1` + 0.9797959 * RANDN() AS `V243`, `S1` + 0.9797959 * RANDN() AS `V244`, `S1` + 0.9797959 * RANDN() AS `V245`, `S1` + 0.9797959 * RANDN() AS `V246`, `S1` + 0.9797959 * RANDN() AS `V247`, `S1` + 0.9797959 * RANDN() AS `V248`, `S1` + 0.9797959 * RANDN() AS `V249`, `S1` + 0.9797959 * RANDN() AS `V250`, `S1` + 0.9797959 * RANDN() AS `V251`, `S1` + 0.9797959 * RANDN() AS `V252`, `S1` + 0.9797959 * RANDN() AS `V253`, `S1` + 0.9797959 * RANDN() AS `V254`, `S1` + 0.9797959 * RANDN() AS `V255`, `S1` + 0.9797959 * RANDN() AS `V256`, `S1` + 0.9797959 * RANDN() AS `V257`, `S1` + 0.9797959 * RANDN() AS `V258`, `S1` + 0.9797959 * RANDN() AS `V259`, `S1` + 0.9797959 * RANDN() AS `V260`, `S1` + 0.9797959 * RANDN() AS `V261`, `S1` + 0.9797959 * RANDN() AS `V262`, `S1` + 0.9797959 * RANDN() AS `V263`, `S1` + 0.9797959 * RANDN() AS `V264`, `S1` + 0.9797959 * RANDN() AS `V265`, `S1` + 0.9797959 * RANDN() AS `V266`, `S1` + 0.9797959 * RANDN() AS `V267`, `S1` + 0.9797959 * RANDN() AS `V268`, `S1` + 0.9797959 * RANDN() AS `V269`, `S1` + 0.9797959 * RANDN() AS `V270`, `S1` + 0.9797959 * RANDN() AS `V271`, `S1` + 0.9797959 * RANDN() AS `V272`, `S1` + 0.9797959 * RANDN() AS `V273`, `S1` + 0.9797959 * RANDN() AS `V274`, `S1` + 0.9797959 * RANDN() AS `V275`, `S1` + 0.9797959 * RANDN() AS `V276`, `S1` + 0.9797959 * RANDN() AS `V277`, `S1` + 0.9797959 * RANDN() AS `V278`, `S1` + 0.9797959 * RANDN() AS `V279`, `S1` + 0.9797959 * RANDN() AS `V280`, `S1` + 0.9797959 * RANDN() AS `V281`, `S1` + 0.9797959 * RANDN() AS `V282`, `S1` + 0.9797959 * RANDN() AS `V283`, `S1` + 0.9797959 * RANDN() AS `V284`, `S1` + 0.9797959 * RANDN() AS `V285`, `S1` + 0.9797959 * RANDN() AS `V286`, `S1` + 0.9797959 * RANDN() AS `V287`, `S1` + 0.9797959 * RANDN() AS `V288`, `S1` + 0.9797959 * RANDN() AS `V289`, `S1` + 0.9797959 * RANDN() AS `V290`, `S1` + 0.9797959 * RANDN() AS `V291`, `S1` + 0.9797959 * RANDN() AS `V292`, `S1` + 0.9797959 * RANDN() AS `V293`, `S1` + 0.9797959 * RANDN() AS `V294`, `S1` + 0.9797959 * RANDN() AS `V295`, `S1` + 0.9797959 * RANDN() AS `V296`, `S1` + 0.9797959 * RANDN() AS `V297`, `S1` + 0.9797959 * RANDN() AS `V298`, `S1` + 0.9797959 * RANDN() AS `V299`, `S1` + 0.9797959 * RANDN() AS `V300`, `S1` + 0.9797959 * RANDN() AS `V301`, `S1` + 0.9797959 * RANDN() AS `V302`, `S1` + 0.9797959 * RANDN() AS `V303`, `S1` + 0.9797959 * RANDN() AS `V304`, `S1` + 0.9797959 * RANDN() AS `V305`, `S1` + 0.9797959 * RANDN() AS `V306`, `S1` + 0.9797959 * RANDN() AS `V307`, `S1` + 0.9797959 * RANDN() AS `V308`, `S1` + 0.9797959 * RANDN() AS `V309`, `S1` + 0.9797959 * RANDN() AS `V310`, `S1` + 0.9797959 * RANDN() AS `V311`, `S1` + 0.9797959 * RANDN() AS `V312`, `S1` + 0.9797959 * RANDN() AS `V313`, `S1` + 0.9797959 * RANDN() AS `V314`, `S1` + 0.9797959 * RANDN() AS `V315`, `S1` + 0.9797959 * RANDN() AS `V316`, `S1` + 0.9797959 * RANDN() AS `V317`, `S1` + 0.9797959 * RANDN() AS `V318`, `S1` + 0.9797959 * RANDN() AS `V319`, `S1` + 0.9797959 * RANDN() AS `V320`, `S1` + 0.9797959 * RANDN() AS `V321`, `S1` + 0.9797959 * RANDN() AS `V322`, `S1` + 0.9797959 * RANDN() AS `V323`, `S1` + 0.9797959 * RANDN() AS `V324`, `S1` + 0.9797959 * RANDN() AS `V325`, `S1` + 0.9797959 * RANDN() AS `V326`, `S1` + 0.9797959 * RANDN() AS `V327`, `S1` + 0.9797959 * RANDN() AS `V328`, `S1` + 0.9797959 * RANDN() AS `V329`, `S1` + 0.9797959 * RANDN() AS `V330`, `S1` + 0.9797959 * RANDN() AS `V331`, `S1` + 0.9797959 * RANDN() AS `V332`, `S1` + 0.9797959 * RANDN() AS `V333`, `S1` + 0.9797959 * RANDN() AS `V334`, `S1` + 0.9797959 * RANDN() AS `V335`, `S1` + 0.9797959 * RANDN() AS `V336`, `S1` + 0.9797959 * RANDN() AS `V337`, `S1` + 0.9797959 * RANDN() AS `V338`, `S1` + 0.9797959 * RANDN() AS `V339`, `S1` + 0.9797959 * RANDN() AS `V340`, `S1` + 0.9797959 * RANDN() AS `V341`, `S1` + 0.9797959 * RANDN() AS `V342`, `S1` + 0.9797959 * RANDN() AS `V343`, `S1` + 0.9797959 * RANDN() AS `V344`, `S1` + 0.9797959 * RANDN() AS `V345`, `S1` + 0.9797959 * RANDN() AS `V346`, `S1` + 0.9797959 * RANDN() AS `V347`, `S1` + 0.9797959 * RANDN() AS `V348`, `S1` + 0.9797959 * RANDN() AS `V349`, `S1` + 0.9797959 * RANDN() AS `V350`, `S1` + 0.9797959 * RANDN() AS `V351`, `S1` + 0.9797959 * RANDN() AS `V352`, `S1` + 0.9797959 * RANDN() AS `V353`, `S1` + 0.9797959 * RANDN() AS `V354`, `S1` + 0.9797959 * RANDN() AS `V355`, `S1` + 0.9797959 * RANDN() AS `V356`, `S1` + 0.9797959 * RANDN() AS `V357`, `S1` + 0.9797959 * RANDN() AS `V358`, `S1` + 0.9797959 * RANDN() AS `V359`, `S1` + 0.9797959 * RANDN() AS `V360`, `S1` + 0.9797959 * RANDN() AS `V361`, `S1` + 0.9797959 * RANDN() AS `V362`, `S1` + 0.9797959 * RANDN() AS `V363`, `S1` + 0.9797959 * RANDN() AS `V364`, `S1` + 0.9797959 * RANDN() AS `V365`, `S1` + 0.9797959 * RANDN() AS `V366`, `S1` + 0.9797959 * RANDN() AS `V367`, `S1` + 0.9797959 * RANDN() AS `V368`, `S1` + 0.9797959 * RANDN() AS `V369`, `S1` + 0.9797959 * RANDN() AS `V370`, `S1` + 0.9797959 * RANDN() AS `V371`, `S1` + 0.9797959 * RANDN() AS `V372`, `S1` + 0.9797959 * RANDN() AS `V373`, `S1` + 0.9797959 * RANDN() AS `V374`, `S1` + 0.9797959 * RANDN() AS `V375`, `S1` + 0.9797959 * RANDN() AS `V376`, `S1` + 0.9797959 * RANDN() AS `V377`, `S1` + 0.9797959 * RANDN() AS `V378`, `S1` + 0.9797959 * RANDN() AS `V379`, `S1` + 0.9797959 * RANDN() AS `V380`, `S1` + 0.9797959 * RANDN() AS `V381`, `S1` + 0.9797959 * RANDN() AS `V382`, `S1` + 0.9797959 * RANDN() AS `V383`, `S1` + 0.9797959 * RANDN() AS `V384`, `S1` + 0.9797959 * RANDN() AS `V385`, `S1` + 0.9797959 * RANDN() AS `V386`, `S1` + 0.9797959 * RANDN() AS `V387`, `S1` + 0.9797959 * RANDN() AS `V388`, `S1` + 0.9797959 * RANDN() AS `V389`, `S1` + 0.9797959 * RANDN() AS `V390`, `S1` + 0.9797959 * RANDN() AS `V391`, `S1` + 0.9797959 * RANDN() AS `V392`, `S1` + 0.9797959 * RANDN() AS `V393`, `S1` + 0.9797959 * RANDN() AS `V394`, `S1` + 0.9797959 * RANDN() AS `V395`, `S1` + 0.9797959 * RANDN() AS `V396`, `S1` + 0.9797959 * RANDN() AS `V397`, `S1` + 0.9797959 * RANDN() AS `V398`, `S1` + 0.9797959 * RANDN() AS `V399`, `S1` + 0.9797959 * RANDN() AS `V400`, `S1` + 0.9797959 * RANDN() AS `V401`, `S1` + 0.9797959 * RANDN() AS `V402`, `S1` + 0.9797959 * RANDN() AS `V403`, `S1` + 0.9797959 * RANDN() AS `V404`, `S1` + 0.9797959 * RANDN() AS `V405`, `S1` + 0.9797959 * RANDN() AS `V406`, `S1` + 0.9797959 * RANDN() AS `V407`, `S1` + 0.9797959 * RANDN() AS `V408`, `S1` + 0.9797959 * RANDN() AS `V409`, `S1` + 0.9797959 * RANDN() AS `V410`, `S1` + 0.9797959 * RANDN() AS `V411`, `S1` + 0.9797959 * RANDN() AS `V412`, `S1` + 0.9797959 * RANDN() AS `V413`, `S1` + 0.9797959 * RANDN() AS `V414`, `S1` + 0.9797959 * RANDN() AS `V415`, `S1` + 0.9797959 * RANDN() AS `V416`, `S1` + 0.9797959 * RANDN() AS `V417`, `S1` + 0.9797959 * RANDN() AS `V418`, `S1` + 0.9797959 * RANDN() AS `V419`, `S1` + 0.9797959 * RANDN() AS `V420`, `S1` + 0.9797959 * RANDN() AS `V421`, `S1` + 0.9797959 * RANDN() AS `V422`, `S1` + 0.9797959 * RANDN() AS `V423`, `S1` + 0.9797959 * RANDN() AS `V424`, `S1` + 0.9797959 * RANDN() AS `V425`, `S1` + 0.9797959 * RANDN() AS `V426`, `S1` + 0.9797959 * RANDN() AS `V427`, `S1` + 0.9797959 * RANDN() AS `V428`, `S1` + 0.9797959 * RANDN() AS `V429`, `S1` + 0.9797959 * RANDN() AS `V430`, `S1` + 0.9797959 * RANDN() AS `V431`, `S1` + 0.9797959 * RANDN() AS `V432`, `S1` + 0.9797959 * RANDN() AS `V433`, `S1` + 0.9797959 * RANDN() AS `V434`, `S1` + 0.9797959 * RANDN() AS `V435`, `S1` + 0.9797959 * RANDN() AS `V436`, `S1` + 0.9797959 * RANDN() AS `V437`, `S1` + 0.9797959 * RANDN() AS `V438`, `S1` + 0.9797959 * RANDN() AS `V439`, `S1` + 0.9797959 * RANDN() AS `V440`, `S1` + 0.9797959 * RANDN() AS `V441`, `S1` + 0.9797959 * RANDN() AS `V442`, `S1` + 0.9797959 * RANDN() AS `V443`, `S1` + 0.9797959 * RANDN() AS `V444`, `S1` + 0.9797959 * RANDN() AS `V445`, `S1` + 0.9797959 * RANDN() AS `V446`, `S1` + 0.9797959 * RANDN() AS `V447`, `S1` + 0.9797959 * RANDN() AS `V448`, `S1` + 0.9797959 * RANDN() AS `V449`, `S1` + 0.9797959 * RANDN() AS `V450`, `S1` + 0.9797959 * RANDN() AS `V451`, `S1` + 0.9797959 * RANDN() AS `V452`, `S1` + 0.9797959 * RANDN() AS `V453`, `S1` + 0.9797959 * RANDN() AS `V454`, `S1` + 0.9797959 * RANDN() AS `V455`, `S1` + 0.9797959 * RANDN() AS `V456`, `S1` + 0.9797959 * RANDN() AS `V457`, `S1` + 0.9797959 * RANDN() AS `V458`, `S1` + 0.9797959 * RANDN() AS `V459`, `S1` + 0.9797959 * RANDN() AS `V460`, `S1` + 0.9797959 * RANDN() AS `V461`, `S1` + 0.9797959 * RANDN() AS `V462`, `S1` + 0.9797959 * RANDN() AS `V463`, `S1` + 0.9797959 * RANDN() AS `V464`, `S1` + 0.9797959 * RANDN() AS `V465`, `S1` + 0.9797959 * RANDN() AS `V466`, `S1` + 0.9797959 * RANDN() AS `V467`, `S1` + 0.9797959 * RANDN() AS `V468`, `S1` + 0.9797959 * RANDN() AS `V469`, `S1` + 0.9797959 * RANDN() AS `V470`, `S1` + 0.9797959 * RANDN() AS `V471`, `S1` + 0.9797959 * RANDN() AS `V472`, `S1` + 0.9797959 * RANDN() AS `V473`, `S1` + 0.9797959 * RANDN() AS `V474`, `S1` + 0.9797959 * RANDN() AS `V475`, `S1` + 0.9797959 * RANDN() AS `V476`, `S1` + 0.9797959 * RANDN() AS `V477`, `S1` + 0.9797959 * RANDN() AS `V478`, `S1` + 0.9797959 * RANDN() AS `V479`, `S1` + 0.9797959 * RANDN() AS `V480`, `S1` + 0.9797959 * RANDN() AS `V481`, `S1` + 0.9797959 * RANDN() AS `V482`, `S1` + 0.9797959 * RANDN() AS `V483`, `S1` + 0.9797959 * RANDN() AS `V484`, `S1` + 0.9797959 * RANDN() AS `V485`, `S1` + 0.9797959 * RANDN() AS `V486`, `S1` + 0.9797959 * RANDN() AS `V487`, `S1` + 0.9797959 * RANDN() AS `V488`, `S1` + 0.9797959 * RANDN() AS `V489`, `S1` + 0.9797959 * RANDN() AS `V490`, `S1` + 0.9797959 * RANDN() AS `V491`, `S1` + 0.9797959 * RANDN() AS `V492`, `S1` + 0.9797959 * RANDN() AS `V493`, `S1` + 0.9797959 * RANDN() AS `V494`, `S1` + 0.9797959 * RANDN() AS `V495`, `S1` + 0.9797959 * RANDN() AS `V496`, `S1` + 0.9797959 * RANDN() AS `V497`, `S1` + 0.9797959 * RANDN() AS `V498`, `S1` + 0.9797959 * RANDN() AS `V499`, `S1` + 0.9797959 * RANDN() AS `V500`, `S1` + 0.9797959 * RANDN() AS `V501`, `S1` + 0.9797959 * RANDN() AS `V502`, `S1` + 0.9797959 * RANDN() AS `V503`, `S1` + 0.9797959 * RANDN() AS `V504`, `S1` + 0.9797959 * RANDN() AS `V505`, `S1` + 0.9797959 * RANDN() AS `V506`, `S1` + 0.9797959 * RANDN() AS `V507`, `S1` + 0.9797959 * RANDN() AS `V508`, `S1` + 0.9797959 * RANDN() AS `V509`, `S1` + 0.9797959 * RANDN() AS `V510`, `S1` + 0.9797959 * RANDN() AS `V511`, `S1` + 0.9797959 * RANDN() AS `V512`, `S1` + 0.9797959 * RANDN() AS `V513`, `S1` + 0.9797959 * RANDN() AS `V514`, `S1` + 0.9797959 * RANDN() AS `V515`, `S1` + 0.9797959 * RANDN() AS `V516`, `S1` + 0.9797959 * RANDN() AS `V517`, `S1` + 0.9797959 * RANDN() AS `V518`, `S1` + 0.9797959 * RANDN() AS `V519`, `S1` + 0.9797959 * RANDN() AS `V520`, `S1` + 0.9797959 * RANDN() AS `V521`, `S1` + 0.9797959 * RANDN() AS `V522`, `S1` + 0.9797959 * RANDN() AS `V523`, `S1` + 0.9797959 * RANDN() AS `V524`, `S1` + 0.9797959 * RANDN() AS `V525`, `S1` + 0.9797959 * RANDN() AS `V526`, `S1` + 0.9797959 * RANDN() AS `V527`, `S1` + 0.9797959 * RANDN() AS `V528`, `S1` + 0.9797959 * RANDN() AS `V529`, `S1` + 0.9797959 * RANDN() AS `V530`, `S1` + 0.9797959 * RANDN() AS `V531`, `S1` + 0.9797959 * RANDN() AS `V532`, `S1` + 0.9797959 * RANDN() AS `V533`, `S1` + 0.9797959 * RANDN() AS `V534`, `S1` + 0.9797959 * RANDN() AS `V535`, `S1` + 0.9797959 * RANDN() AS `V536`, `S1` + 0.9797959 * RANDN() AS `V537`, `S1` + 0.9797959 * RANDN() AS `V538`, `S1` + 0.9797959 * RANDN() AS `V539`, `S1` + 0.9797959 * RANDN() AS `V540`, `S1` + 0.9797959 * RANDN() AS `V541`, `S1` + 0.9797959 * RANDN() AS `V542`, `S1` + 0.9797959 * RANDN() AS `V543`, `S1` + 0.9797959 * RANDN() AS `V544`, `S1` + 0.9797959 * RANDN() AS `V545`, `S1` + 0.9797959 * RANDN() AS `V546`, `S1` + 0.9797959 * RANDN() AS `V547`, `S1` + 0.9797959 * RANDN() AS `V548`, `S1` + 0.9797959 * RANDN() AS `V549`, `S1` + 0.9797959 * RANDN() AS `V550`, `S1` + 0.9797959 * RANDN() AS `V551`, `S1` + 0.9797959 * RANDN() AS `V552`, `S1` + 0.9797959 * RANDN() AS `V553`, `S1` + 0.9797959 * RANDN() AS `V554`, `S1` + 0.9797959 * RANDN() AS `V555`, `S1` + 0.9797959 * RANDN() AS `V556`, `S1` + 0.9797959 * RANDN() AS `V557`, `S1` + 0.9797959 * RANDN() AS `V558`, `S1` + 0.9797959 * RANDN() AS `V559`, `S1` + 0.9797959 * RANDN() AS `V560`, `S1` + 0.9797959 * RANDN() AS `V561`, `S1` + 0.9797959 * RANDN() AS `V562`, `S1` + 0.9797959 * RANDN() AS `V563`, `S1` + 0.9797959 * RANDN() AS `V564`, `S1` + 0.9797959 * RANDN() AS `V565`, `S1` + 0.9797959 * RANDN() AS `V566`, `S1` + 0.9797959 * RANDN() AS `V567`, `S1` + 0.9797959 * RANDN() AS `V568`, `S1` + 0.9797959 * RANDN() AS `V569`, `S1` + 0.9797959 * RANDN() AS `V570`, `S1` + 0.9797959 * RANDN() AS `V571`, `S1` + 0.9797959 * RANDN() AS `V572`, `S1` + 0.9797959 * RANDN() AS `V573`, `S1` + 0.9797959 * RANDN() AS `V574`, `S1` + 0.9797959 * RANDN() AS `V575`, `S1` + 0.9797959 * RANDN() AS `V576`, `S1` + 0.9797959 * RANDN() AS `V577`, `S1` + 0.9797959 * RANDN() AS `V578`, `S1` + 0.9797959 * RANDN() AS `V579`, `S1` + 0.9797959 * RANDN() AS `V580`, `S1` + 0.9797959 * RANDN() AS `V581`, `S1` + 0.9797959 * RANDN() AS `V582`, `S1` + 0.9797959 * RANDN() AS `V583`, `S1` + 0.9797959 * RANDN() AS `V584`, `S1` + 0.9797959 * RANDN() AS `V585`, `S1` + 0.9797959 * RANDN() AS `V586`, `S1` + 0.9797959 * RANDN() AS `V587`, `S1` + 0.9797959 * RANDN() AS `V588`, `S1` + 0.9797959 * RANDN() AS `V589`, `S1` + 0.9797959 * RANDN() AS `V590`, `S1` + 0.9797959 * RANDN() AS `V591`, `S1` + 0.9797959 * RANDN() AS `V592`, `S1` + 0.9797959 * RANDN() AS `V593`, `S1` + 0.9797959 * RANDN() AS `V594`, `S1` + 0.9797959 * RANDN() AS `V595`, `S1` + 0.9797959 * RANDN() AS `V596`, `S1` + 0.9797959 * RANDN() AS `V597`, `S1` + 0.9797959 * RANDN() AS `V598`, `S1` + 0.9797959 * RANDN() AS `V599`, `S1` + 0.9797959 * RANDN() AS `V600`, `S1` + 0.9797959 * RANDN() AS `V601`, `S1` + 0.9797959 * RANDN() AS `V602`, `S1` + 0.9797959 * RANDN() AS `V603`, `S1` + 0.9797959 * RANDN() AS `V604`, `S1` + 0.9797959 * RANDN() AS `V605`, `S1` + 0.9797959 * RANDN() AS `V606`, `S1` + 0.9797959 * RANDN() AS `V607`, `S1` + 0.9797959 * RANDN() AS `V608`, `S1` + 0.9797959 * RANDN() AS `V609`, `S1` + 0.9797959 * RANDN() AS `V610`, `S1` + 0.9797959 * RANDN() AS `V611`, `S1` + 0.9797959 * RANDN() AS `V612`, `S1` + 0.9797959 * RANDN() AS `V613`, `S1` + 0.9797959 * RANDN() AS `V614`, `S1` + 0.9797959 * RANDN() AS `V615`, `S1` + 0.9797959 * RANDN() AS `V616`, `S1` + 0.9797959 * RANDN() AS `V617`, `S1` + 0.9797959 * RANDN() AS `V618`, `S1` + 0.9797959 * RANDN() AS `V619`, `S1` + 0.9797959 * RANDN() AS `V620`, `S1` + 0.9797959 * RANDN() AS `V621`, `S1` + 0.9797959 * RANDN() AS `V622`, `S1` + 0.9797959 * RANDN() AS `V623`, `S1` + 0.9797959 * RANDN() AS `V624`, `S1` + 0.9797959 * RANDN() AS `V625`, `S1` + 0.9797959 * RANDN() AS `V626`, `S1` + 0.9797959 * RANDN() AS `V627`, `S1` + 0.9797959 * RANDN() AS `V628`, `S1` + 0.9797959 * RANDN() AS `V629`, `S1` + 0.9797959 * RANDN() AS `V630`, `S1` + 0.9797959 * RANDN() AS `V631`, `S1` + 0.9797959 * RANDN() AS `V632`, `S1` + 0.9797959 * RANDN() AS `V633`, `S1` + 0.9797959 * RANDN() AS `V634`, `S1` + 0.9797959 * RANDN() AS `V635`, `S1` + 0.9797959 * RANDN() AS `V636`, `S1` + 0.9797959 * RANDN() AS `V637`, `S1` + 0.9797959 * RANDN() AS `V638`, `S1` + 0.9797959 * RANDN() AS `V639`, `S1` + 0.9797959 * RANDN() AS `V640`, `S1` + 0.9797959 * RANDN() AS `V641`, `S1` + 0.9797959 * RANDN() AS `V642`, `S1` + 0.9797959 * RANDN() AS `V643`, `S1` + 0.9797959 * RANDN() AS `V644`, `S1` + 0.9797959 * RANDN() AS `V645`, `S1` + 0.9797959 * RANDN() AS `V646`, `S1` + 0.9797959 * RANDN() AS `V647`, `S1` + 0.9797959 * RANDN() AS `V648`, `S1` + 0.9797959 * RANDN() AS `V649`, `S1` + 0.9797959 * RANDN() AS `V650`, `S1` + 0.9797959 * RANDN() AS `V651`, `S1` + 0.9797959 * RANDN() AS `V652`, `S1` + 0.9797959 * RANDN() AS `V653`, `S1` + 0.9797959 * RANDN() AS `V654`, `S1` + 0.9797959 * RANDN() AS `V655`, `S1` + 0.9797959 * RANDN() AS `V656`, `S1` + 0.9797959 * RANDN() AS `V657`, `S1` + 0.9797959 * RANDN() AS `V658`, `S1` + 0.9797959 * RANDN() AS `V659`, `S1` + 0.9797959 * RANDN() AS `V660`, `S1` + 0.9797959 * RANDN() AS `V661`, `S1` + 0.9797959 * RANDN() AS `V662`, `S1` + 0.9797959 * RANDN() AS `V663`, `S1` + 0.9797959 * RANDN() AS `V664`, `S1` + 0.9797959 * RANDN() AS `V665`, `S1` + 0.9797959 * RANDN() AS `V666`, `S1` + 0.9797959 * RANDN() AS `V667`, `S1` + 0.9797959 * RANDN() AS `V668`, `S1` + 0.9797959 * RANDN() AS `V669`, `S1` + 0.9797959 * RANDN() AS `V670`, `S1` + 0.9797959 * RANDN() AS `V671`, `S1` + 0.9797959 * RANDN() AS `V672`, `S1` + 0.9797959 * RANDN() AS `V673`, `S1` + 0.9797959 * RANDN() AS `V674`, `S1` + 0.9797959 * RANDN() AS `V675`, `S1` + 0.9797959 * RANDN() AS `V676`, `S1` + 0.9797959 * RANDN() AS `V677`, `S1` + 0.9797959 * RANDN() AS `V678`, `S1` + 0.9797959 * RANDN() AS `V679`, `S1` + 0.9797959 * RANDN() AS `V680`, `S1` + 0.9797959 * RANDN() AS `V681`, `S1` + 0.9797959 * RANDN() AS `V682`, `S1` + 0.9797959 * RANDN() AS `V683`, `S1` + 0.9797959 * RANDN() AS `V684`, `S1` + 0.9797959 * RANDN() AS `V685`, `S1` + 0.9797959 * RANDN() AS `V686`, `S1` + 0.9797959 * RANDN() AS `V687`, `S1` + 0.9797959 * RANDN() AS `V688`, `S1` + 0.9797959 * RANDN() AS `V689`, `S1` + 0.9797959 * RANDN() AS `V690`, `S1` + 0.9797959 * RANDN() AS `V691`, `S1` + 0.9797959 * RANDN() AS `V692`, `S1` + 0.9797959 * RANDN() AS `V693`, `S1` + 0.9797959 * RANDN() AS `V694`, `S1` + 0.9797959 * RANDN() AS `V695`, `S1` + 0.9797959 * RANDN() AS `V696`, `S1` + 0.9797959 * RANDN() AS `V697`, `S1` + 0.9797959 * RANDN() AS `V698`, `S1` + 0.9797959 * RANDN() AS `V699`, `S1` + 0.9797959 * RANDN() AS `V700`, `S1` + 0.9797959 * RANDN() AS `V701`, `S1` + 0.9797959 * RANDN() AS `V702`, `S1` + 0.9797959 * RANDN() AS `V703`, `S1` + 0.9797959 * RANDN() AS `V704`, `S1` + 0.9797959 * RANDN() AS `V705`, `S1` + 0.9797959 * RANDN() AS `V706`, `S1` + 0.9797959 * RANDN() AS `V707`, `S1` + 0.9797959 * RANDN() AS `V708`, `S1` + 0.9797959 * RANDN() AS `V709`, `S1` + 0.9797959 * RANDN() AS `V710`, `S1` + 0.9797959 * RANDN() AS `V711`, `S1` + 0.9797959 * RANDN() AS `V712`, `S1` + 0.9797959 * RANDN() AS `V713`, `S1` + 0.9797959 * RANDN() AS `V714`, `S1` + 0.9797959 * RANDN() AS `V715`, `S1` + 0.9797959 * RANDN() AS `V716`, `S1` + 0.9797959 * RANDN() AS `V717`, `S1` + 0.9797959 * RANDN() AS `V718`, `S1` + 0.9797959 * RANDN() AS `V719`, `S1` + 0.9797959 * RANDN() AS `V720`, `S1` + 0.9797959 * RANDN() AS `V721`, `S1` + 0.9797959 * RANDN() AS `V722`, `S1` + 0.9797959 * RANDN() AS `V723`, `S1` + 0.9797959 * RANDN() AS `V724`, `S1` + 0.9797959 * RANDN() AS `V725`, `S1` + 0.9797959 * RANDN() AS `V726`, `S1` + 0.9797959 * RANDN() AS `V727`, `S1` + 0.9797959 * RANDN() AS `V728`, `S1` + 0.9797959 * RANDN() AS `V729`, `S1` + 0.9797959 * RANDN() AS `V730`, `S1` + 0.9797959 * RANDN() AS `V731`, `S1` + 0.9797959 * RANDN() AS `V732`, `S1` + 0.9797959 * RANDN() AS `V733`, `S1` + 0.9797959 * RANDN() AS `V734`, `S1` + 0.9797959 * RANDN() AS `V735`, `S1` + 0.9797959 * RANDN() AS `V736`, `S1` + 0.9797959 * RANDN() AS `V737`, `S1` + 0.9797959 * RANDN() AS `V738`, `S1` + 0.9797959 * RANDN() AS `V739`, `S1` + 0.9797959 * RANDN() AS `V740`, `S1` + 0.9797959 * RANDN() AS `V741`, `S1` + 0.9797959 * RANDN() AS `V742`, `S1` + 0.9797959 * RANDN() AS `V743`, `S1` + 0.9797959 * RANDN() AS `V744`, `S1` + 0.9797959 * RANDN() AS `V745`, `S1` + 0.9797959 * RANDN() AS `V746`, `S1` + 0.9797959 * RANDN() AS `V747`, `S1` + 0.9797959 * RANDN() AS `V748`, `S1` + 0.9797959 * RANDN() AS `V749`, `S1` + 0.9797959 * RANDN() AS `V750`, `S1` + 0.9797959 * RANDN() AS `V751`, `S1` + 0.9797959 * RANDN() AS `V752`, `S1` + 0.9797959 * RANDN() AS `V753`, `S1` + 0.9797959 * RANDN() AS `V754`, `S1` + 0.9797959 * RANDN() AS `V755`, `S1` + 0.9797959 * RANDN() AS `V756`, `S1` + 0.9797959 * RANDN() AS `V757`, `S1` + 0.9797959 * RANDN() AS `V758`, `S1` + 0.9797959 * RANDN() AS `V759`, `S1` + 0.9797959 * RANDN() AS `V760`, `S1` + 0.9797959 * RANDN() AS `V761`, `S1` + 0.9797959 * RANDN() AS `V762`, `S1` + 0.9797959 * RANDN() AS `V763`, `S1` + 0.9797959 * RANDN() AS `V764`, `S1` + 0.9797959 * RANDN() AS `V765`, `S1` + 0.9797959 * RANDN() AS `V766`, `S1` + 0.9797959 * RANDN() AS `V767`, `S1` + 0.9797959 * RANDN() AS `V768`, `S1` + 0.9797959 * RANDN() AS `V769`, `S1` + 0.9797959 * RANDN() AS `V770`, `S1` + 0.9797959 * RANDN() AS `V771`, `S1` + 0.9797959 * RANDN() AS `V772`, `S1` + 0.9797959 * RANDN() AS `V773`, `S1` + 0.9797959 * RANDN() AS `V774`, `S1` + 0.9797959 * RANDN() AS `V775`, `S1` + 0.9797959 * RANDN() AS `V776`, `S1` + 0.9797959 * RANDN() AS `V777`, `S1` + 0.9797959 * RANDN() AS `V778`, `S1` + 0.9797959 * RANDN() AS `V779`, `S1` + 0.9797959 * RANDN() AS `V780`, `S1` + 0.9797959 * RANDN() AS `V781`, `S1` + 0.9797959 * RANDN() AS `V782`, `S1` + 0.9797959 * RANDN() AS `V783`, `S1` + 0.9797959 * RANDN() AS `V784`, `S1` + 0.9797959 * RANDN() AS `V785`, `S1` + 0.9797959 * RANDN() AS `V786`, `S1` + 0.9797959 * RANDN() AS `V787`, `S1` + 0.9797959 * RANDN() AS `V788`, `S1` + 0.9797959 * RANDN() AS `V789`, `S1` + 0.9797959 * RANDN() AS `V790`, `S1` + 0.9797959 * RANDN() AS `V791`, `S1` + 0.9797959 * RANDN() AS `V792`, `S1` + 0.9797959 * RANDN() AS `V793`, `S1` + 0.9797959 * RANDN() AS `V794`, `S1` + 0.9797959 * RANDN() AS `V795`, `S1` + 0.9797959 * RANDN() AS `V796`, `S1` + 0.9797959 * RANDN() AS `V797`, `S1` + 0.9797959 * RANDN() AS `V798`, `S1` + 0.9797959 * RANDN() AS `V799`, `S1` + 0.9797959 * RANDN() AS `V800`, `S1` + 0.9797959 * RANDN() AS `V801`, `S1` + 0.9797959 * RANDN() AS `V802`, `S1` + 0.9797959 * RANDN() AS `V803`, `S1` + 0.9797959 * RANDN() AS `V804`, `S1` + 0.9797959 * RANDN() AS `V805`, `S1` + 0.9797959 * RANDN() AS `V806`, `S1` + 0.9797959 * RANDN() AS `V807`, `S1` + 0.9797959 * RANDN() AS `V808`, `S1` + 0.9797959 * RANDN() AS `V809`, `S1` + 0.9797959 * RANDN() AS `V810`, `S1` + 0.9797959 * RANDN() AS `V811`, `S1` + 0.9797959 * RANDN() AS `V812`, `S1` + 0.9797959 * RANDN() AS `V813`, `S1` + 0.9797959 * RANDN() AS `V814`, `S1` + 0.9797959 * RANDN() AS `V815`, `S1` + 0.9797959 * RANDN() AS `V816`, `S1` + 0.9797959 * RANDN() AS `V817`, `S1` + 0.9797959 * RANDN() AS `V818`, `S1` + 0.9797959 * RANDN() AS `V819`, `S1` + 0.9797959 * RANDN() AS `V820`, `S1` + 0.9797959 * RANDN() AS `V821`, `S1` + 0.9797959 * RANDN() AS `V822`, `S1` + 0.9797959 * RANDN() AS `V823`, `S1` + 0.9797959 * RANDN() AS `V824`, `S1` + 0.9797959 * RANDN() AS `V825`, `S1` + 0.9797959 * RANDN() AS `V826`, `S1` + 0.9797959 * RANDN() AS `V827`, `S1` + 0.9797959 * RANDN() AS `V828`, `S1` + 0.9797959 * RANDN() AS `V829`, `S1` + 0.9797959 * RANDN() AS `V830`, `S1` + 0.9797959 * RANDN() AS `V831`, `S1` + 0.9797959 * RANDN() AS `V832`, `S1` + 0.9797959 * RANDN() AS `V833`, `S1` + 0.9797959 * RANDN() AS `V834`, `S1` + 0.9797959 * RANDN() AS `V835`, `S1` + 0.9797959 * RANDN() AS `V836`, `S1` + 0.9797959 * RANDN() AS `V837`, `S1` + 0.9797959 * RANDN() AS `V838`, `S1` + 0.9797959 * RANDN() AS `V839`, `S1` + 0.9797959 * RANDN() AS `V840`, `S1` + 0.9797959 * RANDN() AS `V841`, `S1` + 0.9797959 * RANDN() AS `V842`, `S1` + 0.9797959 * RANDN() AS `V843`, `S1` + 0.9797959 * RANDN() AS `V844`, `S1` + 0.9797959 * RANDN() AS `V845`, `S1` + 0.9797959 * RANDN() AS `V846`, `S1` + 0.9797959 * RANDN() AS `V847`, `S1` + 0.9797959 * RANDN() AS `V848`, `S1` + 0.9797959 * RANDN() AS `V849`, `S1` + 0.9797959 * RANDN() AS `V850`, `S1` + 0.9797959 * RANDN() AS `V851`, `S1` + 0.9797959 * RANDN() AS `V852`, `S1` + 0.9797959 * RANDN() AS `V853`, `S1` + 0.9797959 * RANDN() AS `V854`, `S1` + 0.9797959 * RANDN() AS `V855`, `S1` + 0.9797959 * RANDN() AS `V856`, `S1` + 0.9797959 * RANDN() AS `V857`, `S1` + 0.9797959 * RANDN() AS `V858`, `S1` + 0.9797959 * RANDN() AS `V859`, `S1` + 0.9797959 * RANDN() AS `V860`, `S1` + 0.9797959 * RANDN() AS `V861`, `S1` + 0.9797959 * RANDN() AS `V862`, `S1` + 0.9797959 * RANDN() AS `V863`, `S1` + 0.9797959 * RANDN() AS `V864`, `S1` + 0.9797959 * RANDN() AS `V865`, `S1` + 0.9797959 * RANDN() AS `V866`, `S1` + 0.9797959 * RANDN() AS `V867`, `S1` + 0.9797959 * RANDN() AS `V868`, `S1` + 0.9797959 * RANDN() AS `V869`, `S1` + 0.9797959 * RANDN() AS `V870`, `S1` + 0.9797959 * RANDN() AS `V871`, `S1` + 0.9797959 * RANDN() AS `V872`, `S1` + 0.9797959 * RANDN() AS `V873`, `S1` + 0.9797959 * RANDN() AS `V874`, `S1` + 0.9797959 * RANDN() AS `V875`, `S1` + 0.9797959 * RANDN() AS `V876`, `S1` + 0.9797959 * RANDN() AS `V877`, `S1` + 0.9797959 * RANDN() AS `V878`, `S1` + 0.9797959 * RANDN() AS `V879`, `S1` + 0.9797959 * RANDN() AS `V880`, `S1` + 0.9797959 * RANDN() AS `V881`, `S1` + 0.9797959 * RANDN() AS `V882`, `S1` + 0.9797959 * RANDN() AS `V883`, `S1` + 0.9797959 * RANDN() AS `V884`, `S1` + 0.9797959 * RANDN() AS `V885`, `S1` + 0.9797959 * RANDN() AS `V886`, `S1` + 0.9797959 * RANDN() AS `V887`, `S1` + 0.9797959 * RANDN() AS `V888`, `S1` + 0.9797959 * RANDN() AS `V889`, `S1` + 0.9797959 * RANDN() AS `V890`, `S1` + 0.9797959 * RANDN() AS `V891`, `S1` + 0.9797959 * RANDN() AS `V892`, `S1` + 0.9797959 * RANDN() AS `V893`, `S1` + 0.9797959 * RANDN() AS `V894`, `S1` + 0.9797959 * RANDN() AS `V895`, `S1` + 0.9797959 * RANDN() AS `V896`, `S1` + 0.9797959 * RANDN() AS `V897`, `S1` + 0.9797959 * RANDN() AS `V898`, `S1` + 0.9797959 * RANDN() AS `V899`, `S1` + 0.9797959 * RANDN() AS `V900`, `S1` + 0.9797959 * RANDN() AS `V901`, `S1` + 0.9797959 * RANDN() AS `V902`, `S1` + 0.9797959 * RANDN() AS `V903`, `S1` + 0.9797959 * RANDN() AS `V904`, `S1` + 0.9797959 * RANDN() AS `V905`, `S1` + 0.9797959 * RANDN() AS `V906`, `S1` + 0.9797959 * RANDN() AS `V907`, `S1` + 0.9797959 * RANDN() AS `V908`, `S1` + 0.9797959 * RANDN() AS `V909`, `S1` + 0.9797959 * RANDN() AS `V910`, `S1` + 0.9797959 * RANDN() AS `V911`, `S1` + 0.9797959 * RANDN() AS `V912`, `S1` + 0.9797959 * RANDN() AS `V913`, `S1` + 0.9797959 * RANDN() AS `V914`, `S1` + 0.9797959 * RANDN() AS `V915`, `S1` + 0.9797959 * RANDN() AS `V916`, `S1` + 0.9797959 * RANDN() AS `V917`, `S1` + 0.9797959 * RANDN() AS `V918`, `S1` + 0.9797959 * RANDN() AS `V919`, `S1` + 0.9797959 * RANDN() AS `V920`, `S1` + 0.9797959 * RANDN() AS `V921`, `S1` + 0.9797959 * RANDN() AS `V922`, `S1` + 0.9797959 * RANDN() AS `V923`, `S1` + 0.9797959 * RANDN() AS `V924`, `S1` + 0.9797959 * RANDN() AS `V925`, `S1` + 0.9797959 * RANDN() AS `V926`, `S1` + 0.9797959 * RANDN() AS `V927`, `S1` + 0.9797959 * RANDN() AS `V928`, `S1` + 0.9797959 * RANDN() AS `V929`, `S1` + 0.9797959 * RANDN() AS `V930`, `S1` + 0.9797959 * RANDN() AS `V931`, `S1` + 0.9797959 * RANDN() AS `V932`, `S1` + 0.9797959 * RANDN() AS `V933`, `S1` + 0.9797959 * RANDN() AS `V934`, `S1` + 0.9797959 * RANDN() AS `V935`, `S1` + 0.9797959 * RANDN() AS `V936`, `S1` + 0.9797959 * RANDN() AS `V937`, `S1` + 0.9797959 * RANDN() AS `V938`, `S1` + 0.9797959 * RANDN() AS `V939`, `S1` + 0.9797959 * RANDN() AS `V940`, `S1` + 0.9797959 * RANDN() AS `V941`, `S1` + 0.9797959 * RANDN() AS `V942`, `S1` + 0.9797959 * RANDN() AS `V943`, `S1` + 0.9797959 * RANDN() AS `V944`, `S1` + 0.9797959 * RANDN() AS `V945`, `S1` + 0.9797959 * RANDN() AS `V946`, `S1` + 0.9797959 * RANDN() AS `V947`, `S1` + 0.9797959 * RANDN() AS `V948`, `S1` + 0.9797959 * RANDN() AS `V949`, `S1` + 0.9797959 * RANDN() AS `V950`, `S1` + 0.9797959 * RANDN() AS `V951`, `S1` + 0.9797959 * RANDN() AS `V952`, `S1` + 0.9797959 * RANDN() AS `V953`, `S1` + 0.9797959 * RANDN() AS `V954`, `S1` + 0.9797959 * RANDN() AS `V955`, `S1` + 0.9797959 * RANDN() AS `V956`, `S1` + 0.9797959 * RANDN() AS `V957`, `S1` + 0.9797959 * RANDN() AS `V958`, `S1` + 0.9797959 * RANDN() AS `V959`, `S1` + 0.9797959 * RANDN() AS `V960`, `S1` + 0.9797959 * RANDN() AS `V961`, `S1` + 0.9797959 * RANDN() AS `V962`, `S1` + 0.9797959 * RANDN() AS `V963`, `S1` + 0.9797959 * RANDN() AS `V964`, `S1` + 0.9797959 * RANDN() AS `V965`, `S1` + 0.9797959 * RANDN() AS `V966`, `S1` + 0.9797959 * RANDN() AS `V967`, `S1` + 0.9797959 * RANDN() AS `V968`, `S1` + 0.9797959 * RANDN() AS `V969`, `S1` + 0.9797959 * RANDN() AS `V970`, `S1` + 0.9797959 * RANDN() AS `V971`, `S1` + 0.9797959 * RANDN() AS `V972`, `S1` + 0.9797959 * RANDN() AS `V973`, `S1` + 0.9797959 * RANDN() AS `V974`, `S1` + 0.9797959 * RANDN() AS `V975`, `S1` + 0.9797959 * RANDN() AS `V976`, `S1` + 0.9797959 * RANDN() AS `V977`, `S1` + 0.9797959 * RANDN() AS `V978`, `S1` + 0.9797959 * RANDN() AS `V979`, `S1` + 0.9797959 * RANDN() AS `V980`, `S1` + 0.9797959 * RANDN() AS `V981`, `S1` + 0.9797959 * RANDN() AS `V982`, `S1` + 0.9797959 * RANDN() AS `V983`, `S1` + 0.9797959 * RANDN() AS `V984`, `S1` + 0.9797959 * RANDN() AS `V985`, `S1` + 0.9797959 * RANDN() AS `V986`, `S1` + 0.9797959 * RANDN() AS `V987`, `S1` + 0.9797959 * RANDN() AS `V988`, `S1` + 0.9797959 * RANDN() AS `V989`, `S1` + 0.9797959 * RANDN() AS `V990`, `S1` + 0.9797959 * RANDN() AS `V991`, `S1` + 0.9797959 * RANDN() AS `V992`, `S1` + 0.9797959 * RANDN() AS `V993`, `S1` + 0.9797959 * RANDN() AS `V994`, `S1` + 0.9797959 * RANDN() AS `V995`, `S1` + 0.9797959 * RANDN() AS `V996`, `S1` + 0.9797959 * RANDN() AS `V997`, `S1` + 0.9797959 * RANDN() AS `V998`, `S1` + 0.9797959 * RANDN() AS `V999`, `S1` + 0.9797959 * RANDN() AS `V1000`
FROM `analyis_tbl`) `ggnjjmdvxm`
17/12/21 18:11:44 INFO ContextCleaner: Cleaned accumulator 238
17/12/21 18:11:44 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:51632 in memory (size: 5.6 KB, free: 2004.5 MB)
17/12/21 18:11:44 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:51632 in memory (size: 3.7 KB, free: 2004.5 MB)
17/12/21 18:11:44 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:51632 in memory (size: 4.6 KB, free: 2004.5 MB)
17/12/21 18:11:44 INFO ContextCleaner: Cleaned accumulator 1
17/12/21 18:11:44 INFO ContextCleaner: Cleaned accumulator 0
17/12/21 18:11:45 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 18:11:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:11:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz12`
WHERE (0 = 1)
17/12/21 18:11:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:11:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 18:11:46 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 18:11:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/21 18:11:46 INFO DAGScheduler: Got job 3 (take at <unknown>:0) with 1 output partitions
17/12/21 18:11:46 INFO DAGScheduler: Final stage: ResultStage 8 (take at <unknown>:0)
17/12/21 18:11:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/12/21 18:11:46 INFO DAGScheduler: Missing parents: List()
17/12/21 18:11:46 INFO DAGScheduler: Submitting ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18), which has no missing parents
17/12/21 18:11:46 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 567.9 KB, free 2003.7 MB)
17/12/21 18:11:46 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 189.3 KB, free 2003.5 MB)
17/12/21 18:11:46 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:51632 (size: 189.3 KB, free: 2004.3 MB)
17/12/21 18:11:46 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/12/21 18:11:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18)
17/12/21 18:11:46 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/21 18:11:46 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5913 bytes)
17/12/21 18:11:46 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/12/21 18:11:46 INFO BlockManager: Found block rdd_12_0 locally
17/12/21 18:11:46 INFO CodeGenerator: Code generated in 19.099553 ms
17/12/21 18:11:47 INFO CodeGenerator: Code generated in 559.931341 ms
17/12/21 18:11:47 INFO CodeGenerator: Code generated in 119.928003 ms
17/12/21 18:14:37 INFO MemoryStore: Block rdd_31_0 stored as values in memory (estimated size 133.7 MB, free 1869.8 MB)
17/12/21 18:14:37 INFO BlockManagerInfo: Added rdd_31_0 in memory on 127.0.0.1:51632 (size: 133.7 MB, free: 1870.6 MB)
17/12/21 18:14:37 WARN Executor: 1 block locks were not released by TID = 8:
[rdd_31_0]
17/12/21 18:14:37 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 143298 bytes result sent to driver
17/12/21 18:14:37 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 170415 ms on localhost (executor driver) (1/1)
17/12/21 18:14:37 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/21 18:14:37 INFO DAGScheduler: ResultStage 8 (take at <unknown>:0) finished in 170.416 s
17/12/21 18:14:37 INFO DAGScheduler: Job 3 finished: take at <unknown>:0, took 170.450846 s
17/12/21 18:14:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:14:38 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1b203f1851cd
17/12/21 18:14:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:14:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1b203f1851cd` AS `zzz13`
WHERE (0 = 1)
17/12/21 18:14:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:14:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1b203f1851cd`
17/12/21 18:14:38 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 18:14:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:14:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz14`
WHERE (0 = 1)
17/12/21 18:14:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:14:40 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.03) AS `V1`, (`V2` < 0.03) AS `V2`, (`V3` < 0.03) AS `V3`, (`V4` < 0.03) AS `V4`, (`V5` < 0.03) AS `V5`, (`V6` < 0.03) AS `V6`, (`V7` < 0.03) AS `V7`, (`V8` < 0.03) AS `V8`, (`V9` < 0.03) AS `V9`, (`V10` < 0.03) AS `V10`, (`V11` < 0.03) AS `V11`, (`V12` < 0.03) AS `V12`, (`V13` < 0.03) AS `V13`, (`V14` < 0.03) AS `V14`, (`V15` < 0.03) AS `V15`, (`V16` < 0.03) AS `V16`, (`V17` < 0.03) AS `V17`, (`V18` < 0.03) AS `V18`, (`V19` < 0.03) AS `V19`, (`V20` < 0.03) AS `V20`, (`V21` < 0.03) AS `V21`, (`V22` < 0.03) AS `V22`, (`V23` < 0.03) AS `V23`, (`V24` < 0.03) AS `V24`, (`V25` < 0.03) AS `V25`, (`V26` < 0.03) AS `V26`, (`V27` < 0.03) AS `V27`, (`V28` < 0.03) AS `V28`, (`V29` < 0.03) AS `V29`, (`V30` < 0.03) AS `V30`, (`V31` < 0.03) AS `V31`, (`V32` < 0.03) AS `V32`, (`V33` < 0.03) AS `V33`, (`V34` < 0.03) AS `V34`, (`V35` < 0.03) AS `V35`, (`V36` < 0.03) AS `V36`, (`V37` < 0.03) AS `V37`, (`V38` < 0.03) AS `V38`, (`V39` < 0.03) AS `V39`, (`V40` < 0.03) AS `V40`, (`V41` < 0.03) AS `V41`, (`V42` < 0.03) AS `V42`, (`V43` < 0.03) AS `V43`, (`V44` < 0.03) AS `V44`, (`V45` < 0.03) AS `V45`, (`V46` < 0.03) AS `V46`, (`V47` < 0.03) AS `V47`, (`V48` < 0.03) AS `V48`, (`V49` < 0.03) AS `V49`, (`V50` < 0.03) AS `V50`, (`V51` < 0.03) AS `V51`, (`V52` < 0.03) AS `V52`, (`V53` < 0.03) AS `V53`, (`V54` < 0.03) AS `V54`, (`V55` < 0.03) AS `V55`, (`V56` < 0.03) AS `V56`, (`V57` < 0.03) AS `V57`, (`V58` < 0.03) AS `V58`, (`V59` < 0.03) AS `V59`, (`V60` < 0.03) AS `V60`, (`V61` < 0.03) AS `V61`, (`V62` < 0.03) AS `V62`, (`V63` < 0.03) AS `V63`, (`V64` < 0.03) AS `V64`, (`V65` < 0.03) AS `V65`, (`V66` < 0.03) AS `V66`, (`V67` < 0.03) AS `V67`, (`V68` < 0.03) AS `V68`, (`V69` < 0.03) AS `V69`, (`V70` < 0.03) AS `V70`, (`V71` < 0.03) AS `V71`, (`V72` < 0.03) AS `V72`, (`V73` < 0.03) AS `V73`, (`V74` < 0.03) AS `V74`, (`V75` < 0.03) AS `V75`, (`V76` < 0.03) AS `V76`, (`V77` < 0.03) AS `V77`, (`V78` < 0.03) AS `V78`, (`V79` < 0.03) AS `V79`, (`V80` < 0.03) AS `V80`, (`V81` < 0.03) AS `V81`, (`V82` < 0.03) AS `V82`, (`V83` < 0.03) AS `V83`, (`V84` < 0.03) AS `V84`, (`V85` < 0.03) AS `V85`, (`V86` < 0.03) AS `V86`, (`V87` < 0.03) AS `V87`, (`V88` < 0.03) AS `V88`, (`V89` < 0.03) AS `V89`, (`V90` < 0.03) AS `V90`, (`V91` < 0.03) AS `V91`, (`V92` < 0.03) AS `V92`, (`V93` < 0.03) AS `V93`, (`V94` < 0.03) AS `V94`, (`V95` < 0.03) AS `V95`, (`V96` < 0.03) AS `V96`, (`V97` < 0.03) AS `V97`, (`V98` < 0.03) AS `V98`, (`V99` < 0.03) AS `V99`, (`V100` < 0.03) AS `V100`, (`V101` < 0.03) AS `V101`, (`V102` < 0.03) AS `V102`, (`V103` < 0.03) AS `V103`, (`V104` < 0.03) AS `V104`, (`V105` < 0.03) AS `V105`, (`V106` < 0.03) AS `V106`, (`V107` < 0.03) AS `V107`, (`V108` < 0.03) AS `V108`, (`V109` < 0.03) AS `V109`, (`V110` < 0.03) AS `V110`, (`V111` < 0.03) AS `V111`, (`V112` < 0.03) AS `V112`, (`V113` < 0.03) AS `V113`, (`V114` < 0.03) AS `V114`, (`V115` < 0.03) AS `V115`, (`V116` < 0.03) AS `V116`, (`V117` < 0.03) AS `V117`, (`V118` < 0.03) AS `V118`, (`V119` < 0.03) AS `V119`, (`V120` < 0.03) AS `V120`, (`V121` < 0.03) AS `V121`, (`V122` < 0.03) AS `V122`, (`V123` < 0.03) AS `V123`, (`V124` < 0.03) AS `V124`, (`V125` < 0.03) AS `V125`, (`V126` < 0.03) AS `V126`, (`V127` < 0.03) AS `V127`, (`V128` < 0.03) AS `V128`, (`V129` < 0.03) AS `V129`, (`V130` < 0.03) AS `V130`, (`V131` < 0.03) AS `V131`, (`V132` < 0.03) AS `V132`, (`V133` < 0.03) AS `V133`, (`V134` < 0.03) AS `V134`, (`V135` < 0.03) AS `V135`, (`V136` < 0.03) AS `V136`, (`V137` < 0.03) AS `V137`, (`V138` < 0.03) AS `V138`, (`V139` < 0.03) AS `V139`, (`V140` < 0.03) AS `V140`, (`V141` < 0.03) AS `V141`, (`V142` < 0.03) AS `V142`, (`V143` < 0.03) AS `V143`, (`V144` < 0.03) AS `V144`, (`V145` < 0.03) AS `V145`, (`V146` < 0.03) AS `V146`, (`V147` < 0.03) AS `V147`, (`V148` < 0.03) AS `V148`, (`V149` < 0.03) AS `V149`, (`V150` < 0.03) AS `V150`, (`V151` < 0.03) AS `V151`, (`V152` < 0.03) AS `V152`, (`V153` < 0.03) AS `V153`, (`V154` < 0.03) AS `V154`, (`V155` < 0.03) AS `V155`, (`V156` < 0.03) AS `V156`, (`V157` < 0.03) AS `V157`, (`V158` < 0.03) AS `V158`, (`V159` < 0.03) AS `V159`, (`V160` < 0.03) AS `V160`, (`V161` < 0.03) AS `V161`, (`V162` < 0.03) AS `V162`, (`V163` < 0.03) AS `V163`, (`V164` < 0.03) AS `V164`, (`V165` < 0.03) AS `V165`, (`V166` < 0.03) AS `V166`, (`V167` < 0.03) AS `V167`, (`V168` < 0.03) AS `V168`, (`V169` < 0.03) AS `V169`, (`V170` < 0.03) AS `V170`, (`V171` < 0.03) AS `V171`, (`V172` < 0.03) AS `V172`, (`V173` < 0.03) AS `V173`, (`V174` < 0.03) AS `V174`, (`V175` < 0.03) AS `V175`, (`V176` < 0.03) AS `V176`, (`V177` < 0.03) AS `V177`, (`V178` < 0.03) AS `V178`, (`V179` < 0.03) AS `V179`, (`V180` < 0.03) AS `V180`, (`V181` < 0.03) AS `V181`, (`V182` < 0.03) AS `V182`, (`V183` < 0.03) AS `V183`, (`V184` < 0.03) AS `V184`, (`V185` < 0.03) AS `V185`, (`V186` < 0.03) AS `V186`, (`V187` < 0.03) AS `V187`, (`V188` < 0.03) AS `V188`, (`V189` < 0.03) AS `V189`, (`V190` < 0.03) AS `V190`, (`V191` < 0.03) AS `V191`, (`V192` < 0.03) AS `V192`, (`V193` < 0.03) AS `V193`, (`V194` < 0.03) AS `V194`, (`V195` < 0.03) AS `V195`, (`V196` < 0.03) AS `V196`, (`V197` < 0.03) AS `V197`, (`V198` < 0.03) AS `V198`, (`V199` < 0.03) AS `V199`, (`V200` < 0.03) AS `V200`, (`V201` < 0.03) AS `V201`, (`V202` < 0.03) AS `V202`, (`V203` < 0.03) AS `V203`, (`V204` < 0.03) AS `V204`, (`V205` < 0.03) AS `V205`, (`V206` < 0.03) AS `V206`, (`V207` < 0.03) AS `V207`, (`V208` < 0.03) AS `V208`, (`V209` < 0.03) AS `V209`, (`V210` < 0.03) AS `V210`, (`V211` < 0.03) AS `V211`, (`V212` < 0.03) AS `V212`, (`V213` < 0.03) AS `V213`, (`V214` < 0.03) AS `V214`, (`V215` < 0.03) AS `V215`, (`V216` < 0.03) AS `V216`, (`V217` < 0.03) AS `V217`, (`V218` < 0.03) AS `V218`, (`V219` < 0.03) AS `V219`, (`V220` < 0.03) AS `V220`, (`V221` < 0.03) AS `V221`, (`V222` < 0.03) AS `V222`, (`V223` < 0.03) AS `V223`, (`V224` < 0.03) AS `V224`, (`V225` < 0.03) AS `V225`, (`V226` < 0.03) AS `V226`, (`V227` < 0.03) AS `V227`, (`V228` < 0.03) AS `V228`, (`V229` < 0.03) AS `V229`, (`V230` < 0.03) AS `V230`, (`V231` < 0.03) AS `V231`, (`V232` < 0.03) AS `V232`, (`V233` < 0.03) AS `V233`, (`V234` < 0.03) AS `V234`, (`V235` < 0.03) AS `V235`, (`V236` < 0.03) AS `V236`, (`V237` < 0.03) AS `V237`, (`V238` < 0.03) AS `V238`, (`V239` < 0.03) AS `V239`, (`V240` < 0.03) AS `V240`, (`V241` < 0.03) AS `V241`, (`V242` < 0.03) AS `V242`, (`V243` < 0.03) AS `V243`, (`V244` < 0.03) AS `V244`, (`V245` < 0.03) AS `V245`, (`V246` < 0.03) AS `V246`, (`V247` < 0.03) AS `V247`, (`V248` < 0.03) AS `V248`, (`V249` < 0.03) AS `V249`, (`V250` < 0.03) AS `V250`, (`V251` < 0.03) AS `V251`, (`V252` < 0.03) AS `V252`, (`V253` < 0.03) AS `V253`, (`V254` < 0.03) AS `V254`, (`V255` < 0.03) AS `V255`, (`V256` < 0.03) AS `V256`, (`V257` < 0.03) AS `V257`, (`V258` < 0.03) AS `V258`, (`V259` < 0.03) AS `V259`, (`V260` < 0.03) AS `V260`, (`V261` < 0.03) AS `V261`, (`V262` < 0.03) AS `V262`, (`V263` < 0.03) AS `V263`, (`V264` < 0.03) AS `V264`, (`V265` < 0.03) AS `V265`, (`V266` < 0.03) AS `V266`, (`V267` < 0.03) AS `V267`, (`V268` < 0.03) AS `V268`, (`V269` < 0.03) AS `V269`, (`V270` < 0.03) AS `V270`, (`V271` < 0.03) AS `V271`, (`V272` < 0.03) AS `V272`, (`V273` < 0.03) AS `V273`, (`V274` < 0.03) AS `V274`, (`V275` < 0.03) AS `V275`, (`V276` < 0.03) AS `V276`, (`V277` < 0.03) AS `V277`, (`V278` < 0.03) AS `V278`, (`V279` < 0.03) AS `V279`, (`V280` < 0.03) AS `V280`, (`V281` < 0.03) AS `V281`, (`V282` < 0.03) AS `V282`, (`V283` < 0.03) AS `V283`, (`V284` < 0.03) AS `V284`, (`V285` < 0.03) AS `V285`, (`V286` < 0.03) AS `V286`, (`V287` < 0.03) AS `V287`, (`V288` < 0.03) AS `V288`, (`V289` < 0.03) AS `V289`, (`V290` < 0.03) AS `V290`, (`V291` < 0.03) AS `V291`, (`V292` < 0.03) AS `V292`, (`V293` < 0.03) AS `V293`, (`V294` < 0.03) AS `V294`, (`V295` < 0.03) AS `V295`, (`V296` < 0.03) AS `V296`, (`V297` < 0.03) AS `V297`, (`V298` < 0.03) AS `V298`, (`V299` < 0.03) AS `V299`, (`V300` < 0.03) AS `V300`, (`V301` < 0.03) AS `V301`, (`V302` < 0.03) AS `V302`, (`V303` < 0.03) AS `V303`, (`V304` < 0.03) AS `V304`, (`V305` < 0.03) AS `V305`, (`V306` < 0.03) AS `V306`, (`V307` < 0.03) AS `V307`, (`V308` < 0.03) AS `V308`, (`V309` < 0.03) AS `V309`, (`V310` < 0.03) AS `V310`, (`V311` < 0.03) AS `V311`, (`V312` < 0.03) AS `V312`, (`V313` < 0.03) AS `V313`, (`V314` < 0.03) AS `V314`, (`V315` < 0.03) AS `V315`, (`V316` < 0.03) AS `V316`, (`V317` < 0.03) AS `V317`, (`V318` < 0.03) AS `V318`, (`V319` < 0.03) AS `V319`, (`V320` < 0.03) AS `V320`, (`V321` < 0.03) AS `V321`, (`V322` < 0.03) AS `V322`, (`V323` < 0.03) AS `V323`, (`V324` < 0.03) AS `V324`, (`V325` < 0.03) AS `V325`, (`V326` < 0.03) AS `V326`, (`V327` < 0.03) AS `V327`, (`V328` < 0.03) AS `V328`, (`V329` < 0.03) AS `V329`, (`V330` < 0.03) AS `V330`, (`V331` < 0.03) AS `V331`, (`V332` < 0.03) AS `V332`, (`V333` < 0.03) AS `V333`, (`V334` < 0.03) AS `V334`, (`V335` < 0.03) AS `V335`, (`V336` < 0.03) AS `V336`, (`V337` < 0.03) AS `V337`, (`V338` < 0.03) AS `V338`, (`V339` < 0.03) AS `V339`, (`V340` < 0.03) AS `V340`, (`V341` < 0.03) AS `V341`, (`V342` < 0.03) AS `V342`, (`V343` < 0.03) AS `V343`, (`V344` < 0.03) AS `V344`, (`V345` < 0.03) AS `V345`, (`V346` < 0.03) AS `V346`, (`V347` < 0.03) AS `V347`, (`V348` < 0.03) AS `V348`, (`V349` < 0.03) AS `V349`, (`V350` < 0.03) AS `V350`, (`V351` < 0.03) AS `V351`, (`V352` < 0.03) AS `V352`, (`V353` < 0.03) AS `V353`, (`V354` < 0.03) AS `V354`, (`V355` < 0.03) AS `V355`, (`V356` < 0.03) AS `V356`, (`V357` < 0.03) AS `V357`, (`V358` < 0.03) AS `V358`, (`V359` < 0.03) AS `V359`, (`V360` < 0.03) AS `V360`, (`V361` < 0.03) AS `V361`, (`V362` < 0.03) AS `V362`, (`V363` < 0.03) AS `V363`, (`V364` < 0.03) AS `V364`, (`V365` < 0.03) AS `V365`, (`V366` < 0.03) AS `V366`, (`V367` < 0.03) AS `V367`, (`V368` < 0.03) AS `V368`, (`V369` < 0.03) AS `V369`, (`V370` < 0.03) AS `V370`, (`V371` < 0.03) AS `V371`, (`V372` < 0.03) AS `V372`, (`V373` < 0.03) AS `V373`, (`V374` < 0.03) AS `V374`, (`V375` < 0.03) AS `V375`, (`V376` < 0.03) AS `V376`, (`V377` < 0.03) AS `V377`, (`V378` < 0.03) AS `V378`, (`V379` < 0.03) AS `V379`, (`V380` < 0.03) AS `V380`, (`V381` < 0.03) AS `V381`, (`V382` < 0.03) AS `V382`, (`V383` < 0.03) AS `V383`, (`V384` < 0.03) AS `V384`, (`V385` < 0.03) AS `V385`, (`V386` < 0.03) AS `V386`, (`V387` < 0.03) AS `V387`, (`V388` < 0.03) AS `V388`, (`V389` < 0.03) AS `V389`, (`V390` < 0.03) AS `V390`, (`V391` < 0.03) AS `V391`, (`V392` < 0.03) AS `V392`, (`V393` < 0.03) AS `V393`, (`V394` < 0.03) AS `V394`, (`V395` < 0.03) AS `V395`, (`V396` < 0.03) AS `V396`, (`V397` < 0.03) AS `V397`, (`V398` < 0.03) AS `V398`, (`V399` < 0.03) AS `V399`, (`V400` < 0.03) AS `V400`, (`V401` < 0.03) AS `V401`, (`V402` < 0.03) AS `V402`, (`V403` < 0.03) AS `V403`, (`V404` < 0.03) AS `V404`, (`V405` < 0.03) AS `V405`, (`V406` < 0.03) AS `V406`, (`V407` < 0.03) AS `V407`, (`V408` < 0.03) AS `V408`, (`V409` < 0.03) AS `V409`, (`V410` < 0.03) AS `V410`, (`V411` < 0.03) AS `V411`, (`V412` < 0.03) AS `V412`, (`V413` < 0.03) AS `V413`, (`V414` < 0.03) AS `V414`, (`V415` < 0.03) AS `V415`, (`V416` < 0.03) AS `V416`, (`V417` < 0.03) AS `V417`, (`V418` < 0.03) AS `V418`, (`V419` < 0.03) AS `V419`, (`V420` < 0.03) AS `V420`, (`V421` < 0.03) AS `V421`, (`V422` < 0.03) AS `V422`, (`V423` < 0.03) AS `V423`, (`V424` < 0.03) AS `V424`, (`V425` < 0.03) AS `V425`, (`V426` < 0.03) AS `V426`, (`V427` < 0.03) AS `V427`, (`V428` < 0.03) AS `V428`, (`V429` < 0.03) AS `V429`, (`V430` < 0.03) AS `V430`, (`V431` < 0.03) AS `V431`, (`V432` < 0.03) AS `V432`, (`V433` < 0.03) AS `V433`, (`V434` < 0.03) AS `V434`, (`V435` < 0.03) AS `V435`, (`V436` < 0.03) AS `V436`, (`V437` < 0.03) AS `V437`, (`V438` < 0.03) AS `V438`, (`V439` < 0.03) AS `V439`, (`V440` < 0.03) AS `V440`, (`V441` < 0.03) AS `V441`, (`V442` < 0.03) AS `V442`, (`V443` < 0.03) AS `V443`, (`V444` < 0.03) AS `V444`, (`V445` < 0.03) AS `V445`, (`V446` < 0.03) AS `V446`, (`V447` < 0.03) AS `V447`, (`V448` < 0.03) AS `V448`, (`V449` < 0.03) AS `V449`, (`V450` < 0.03) AS `V450`, (`V451` < 0.03) AS `V451`, (`V452` < 0.03) AS `V452`, (`V453` < 0.03) AS `V453`, (`V454` < 0.03) AS `V454`, (`V455` < 0.03) AS `V455`, (`V456` < 0.03) AS `V456`, (`V457` < 0.03) AS `V457`, (`V458` < 0.03) AS `V458`, (`V459` < 0.03) AS `V459`, (`V460` < 0.03) AS `V460`, (`V461` < 0.03) AS `V461`, (`V462` < 0.03) AS `V462`, (`V463` < 0.03) AS `V463`, (`V464` < 0.03) AS `V464`, (`V465` < 0.03) AS `V465`, (`V466` < 0.03) AS `V466`, (`V467` < 0.03) AS `V467`, (`V468` < 0.03) AS `V468`, (`V469` < 0.03) AS `V469`, (`V470` < 0.03) AS `V470`, (`V471` < 0.03) AS `V471`, (`V472` < 0.03) AS `V472`, (`V473` < 0.03) AS `V473`, (`V474` < 0.03) AS `V474`, (`V475` < 0.03) AS `V475`, (`V476` < 0.03) AS `V476`, (`V477` < 0.03) AS `V477`, (`V478` < 0.03) AS `V478`, (`V479` < 0.03) AS `V479`, (`V480` < 0.03) AS `V480`, (`V481` < 0.03) AS `V481`, (`V482` < 0.03) AS `V482`, (`V483` < 0.03) AS `V483`, (`V484` < 0.03) AS `V484`, (`V485` < 0.03) AS `V485`, (`V486` < 0.03) AS `V486`, (`V487` < 0.03) AS `V487`, (`V488` < 0.03) AS `V488`, (`V489` < 0.03) AS `V489`, (`V490` < 0.03) AS `V490`, (`V491` < 0.03) AS `V491`, (`V492` < 0.03) AS `V492`, (`V493` < 0.03) AS `V493`, (`V494` < 0.03) AS `V494`, (`V495` < 0.03) AS `V495`, (`V496` < 0.03) AS `V496`, (`V497` < 0.03) AS `V497`, (`V498` < 0.03) AS `V498`, (`V499` < 0.03) AS `V499`, (`V500` < 0.03) AS `V500`, (`V501` < 0.03) AS `V501`, (`V502` < 0.03) AS `V502`, (`V503` < 0.03) AS `V503`, (`V504` < 0.03) AS `V504`, (`V505` < 0.03) AS `V505`, (`V506` < 0.03) AS `V506`, (`V507` < 0.03) AS `V507`, (`V508` < 0.03) AS `V508`, (`V509` < 0.03) AS `V509`, (`V510` < 0.03) AS `V510`, (`V511` < 0.03) AS `V511`, (`V512` < 0.03) AS `V512`, (`V513` < 0.03) AS `V513`, (`V514` < 0.03) AS `V514`, (`V515` < 0.03) AS `V515`, (`V516` < 0.03) AS `V516`, (`V517` < 0.03) AS `V517`, (`V518` < 0.03) AS `V518`, (`V519` < 0.03) AS `V519`, (`V520` < 0.03) AS `V520`, (`V521` < 0.03) AS `V521`, (`V522` < 0.03) AS `V522`, (`V523` < 0.03) AS `V523`, (`V524` < 0.03) AS `V524`, (`V525` < 0.03) AS `V525`, (`V526` < 0.03) AS `V526`, (`V527` < 0.03) AS `V527`, (`V528` < 0.03) AS `V528`, (`V529` < 0.03) AS `V529`, (`V530` < 0.03) AS `V530`, (`V531` < 0.03) AS `V531`, (`V532` < 0.03) AS `V532`, (`V533` < 0.03) AS `V533`, (`V534` < 0.03) AS `V534`, (`V535` < 0.03) AS `V535`, (`V536` < 0.03) AS `V536`, (`V537` < 0.03) AS `V537`, (`V538` < 0.03) AS `V538`, (`V539` < 0.03) AS `V539`, (`V540` < 0.03) AS `V540`, (`V541` < 0.03) AS `V541`, (`V542` < 0.03) AS `V542`, (`V543` < 0.03) AS `V543`, (`V544` < 0.03) AS `V544`, (`V545` < 0.03) AS `V545`, (`V546` < 0.03) AS `V546`, (`V547` < 0.03) AS `V547`, (`V548` < 0.03) AS `V548`, (`V549` < 0.03) AS `V549`, (`V550` < 0.03) AS `V550`, (`V551` < 0.03) AS `V551`, (`V552` < 0.03) AS `V552`, (`V553` < 0.03) AS `V553`, (`V554` < 0.03) AS `V554`, (`V555` < 0.03) AS `V555`, (`V556` < 0.03) AS `V556`, (`V557` < 0.03) AS `V557`, (`V558` < 0.03) AS `V558`, (`V559` < 0.03) AS `V559`, (`V560` < 0.03) AS `V560`, (`V561` < 0.03) AS `V561`, (`V562` < 0.03) AS `V562`, (`V563` < 0.03) AS `V563`, (`V564` < 0.03) AS `V564`, (`V565` < 0.03) AS `V565`, (`V566` < 0.03) AS `V566`, (`V567` < 0.03) AS `V567`, (`V568` < 0.03) AS `V568`, (`V569` < 0.03) AS `V569`, (`V570` < 0.03) AS `V570`, (`V571` < 0.03) AS `V571`, (`V572` < 0.03) AS `V572`, (`V573` < 0.03) AS `V573`, (`V574` < 0.03) AS `V574`, (`V575` < 0.03) AS `V575`, (`V576` < 0.03) AS `V576`, (`V577` < 0.03) AS `V577`, (`V578` < 0.03) AS `V578`, (`V579` < 0.03) AS `V579`, (`V580` < 0.03) AS `V580`, (`V581` < 0.03) AS `V581`, (`V582` < 0.03) AS `V582`, (`V583` < 0.03) AS `V583`, (`V584` < 0.03) AS `V584`, (`V585` < 0.03) AS `V585`, (`V586` < 0.03) AS `V586`, (`V587` < 0.03) AS `V587`, (`V588` < 0.03) AS `V588`, (`V589` < 0.03) AS `V589`, (`V590` < 0.03) AS `V590`, (`V591` < 0.03) AS `V591`, (`V592` < 0.03) AS `V592`, (`V593` < 0.03) AS `V593`, (`V594` < 0.03) AS `V594`, (`V595` < 0.03) AS `V595`, (`V596` < 0.03) AS `V596`, (`V597` < 0.03) AS `V597`, (`V598` < 0.03) AS `V598`, (`V599` < 0.03) AS `V599`, (`V600` < 0.03) AS `V600`, (`V601` < 0.03) AS `V601`, (`V602` < 0.03) AS `V602`, (`V603` < 0.03) AS `V603`, (`V604` < 0.03) AS `V604`, (`V605` < 0.03) AS `V605`, (`V606` < 0.03) AS `V606`, (`V607` < 0.03) AS `V607`, (`V608` < 0.03) AS `V608`, (`V609` < 0.03) AS `V609`, (`V610` < 0.03) AS `V610`, (`V611` < 0.03) AS `V611`, (`V612` < 0.03) AS `V612`, (`V613` < 0.03) AS `V613`, (`V614` < 0.03) AS `V614`, (`V615` < 0.03) AS `V615`, (`V616` < 0.03) AS `V616`, (`V617` < 0.03) AS `V617`, (`V618` < 0.03) AS `V618`, (`V619` < 0.03) AS `V619`, (`V620` < 0.03) AS `V620`, (`V621` < 0.03) AS `V621`, (`V622` < 0.03) AS `V622`, (`V623` < 0.03) AS `V623`, (`V624` < 0.03) AS `V624`, (`V625` < 0.03) AS `V625`, (`V626` < 0.03) AS `V626`, (`V627` < 0.03) AS `V627`, (`V628` < 0.03) AS `V628`, (`V629` < 0.03) AS `V629`, (`V630` < 0.03) AS `V630`, (`V631` < 0.03) AS `V631`, (`V632` < 0.03) AS `V632`, (`V633` < 0.03) AS `V633`, (`V634` < 0.03) AS `V634`, (`V635` < 0.03) AS `V635`, (`V636` < 0.03) AS `V636`, (`V637` < 0.03) AS `V637`, (`V638` < 0.03) AS `V638`, (`V639` < 0.03) AS `V639`, (`V640` < 0.03) AS `V640`, (`V641` < 0.03) AS `V641`, (`V642` < 0.03) AS `V642`, (`V643` < 0.03) AS `V643`, (`V644` < 0.03) AS `V644`, (`V645` < 0.03) AS `V645`, (`V646` < 0.03) AS `V646`, (`V647` < 0.03) AS `V647`, (`V648` < 0.03) AS `V648`, (`V649` < 0.03) AS `V649`, (`V650` < 0.03) AS `V650`, (`V651` < 0.03) AS `V651`, (`V652` < 0.03) AS `V652`, (`V653` < 0.03) AS `V653`, (`V654` < 0.03) AS `V654`, (`V655` < 0.03) AS `V655`, (`V656` < 0.03) AS `V656`, (`V657` < 0.03) AS `V657`, (`V658` < 0.03) AS `V658`, (`V659` < 0.03) AS `V659`, (`V660` < 0.03) AS `V660`, (`V661` < 0.03) AS `V661`, (`V662` < 0.03) AS `V662`, (`V663` < 0.03) AS `V663`, (`V664` < 0.03) AS `V664`, (`V665` < 0.03) AS `V665`, (`V666` < 0.03) AS `V666`, (`V667` < 0.03) AS `V667`, (`V668` < 0.03) AS `V668`, (`V669` < 0.03) AS `V669`, (`V670` < 0.03) AS `V670`, (`V671` < 0.03) AS `V671`, (`V672` < 0.03) AS `V672`, (`V673` < 0.03) AS `V673`, (`V674` < 0.03) AS `V674`, (`V675` < 0.03) AS `V675`, (`V676` < 0.03) AS `V676`, (`V677` < 0.03) AS `V677`, (`V678` < 0.03) AS `V678`, (`V679` < 0.03) AS `V679`, (`V680` < 0.03) AS `V680`, (`V681` < 0.03) AS `V681`, (`V682` < 0.03) AS `V682`, (`V683` < 0.03) AS `V683`, (`V684` < 0.03) AS `V684`, (`V685` < 0.03) AS `V685`, (`V686` < 0.03) AS `V686`, (`V687` < 0.03) AS `V687`, (`V688` < 0.03) AS `V688`, (`V689` < 0.03) AS `V689`, (`V690` < 0.03) AS `V690`, (`V691` < 0.03) AS `V691`, (`V692` < 0.03) AS `V692`, (`V693` < 0.03) AS `V693`, (`V694` < 0.03) AS `V694`, (`V695` < 0.03) AS `V695`, (`V696` < 0.03) AS `V696`, (`V697` < 0.03) AS `V697`, (`V698` < 0.03) AS `V698`, (`V699` < 0.03) AS `V699`, (`V700` < 0.03) AS `V700`, (`V701` < 0.03) AS `V701`, (`V702` < 0.03) AS `V702`, (`V703` < 0.03) AS `V703`, (`V704` < 0.03) AS `V704`, (`V705` < 0.03) AS `V705`, (`V706` < 0.03) AS `V706`, (`V707` < 0.03) AS `V707`, (`V708` < 0.03) AS `V708`, (`V709` < 0.03) AS `V709`, (`V710` < 0.03) AS `V710`, (`V711` < 0.03) AS `V711`, (`V712` < 0.03) AS `V712`, (`V713` < 0.03) AS `V713`, (`V714` < 0.03) AS `V714`, (`V715` < 0.03) AS `V715`, (`V716` < 0.03) AS `V716`, (`V717` < 0.03) AS `V717`, (`V718` < 0.03) AS `V718`, (`V719` < 0.03) AS `V719`, (`V720` < 0.03) AS `V720`, (`V721` < 0.03) AS `V721`, (`V722` < 0.03) AS `V722`, (`V723` < 0.03) AS `V723`, (`V724` < 0.03) AS `V724`, (`V725` < 0.03) AS `V725`, (`V726` < 0.03) AS `V726`, (`V727` < 0.03) AS `V727`, (`V728` < 0.03) AS `V728`, (`V729` < 0.03) AS `V729`, (`V730` < 0.03) AS `V730`, (`V731` < 0.03) AS `V731`, (`V732` < 0.03) AS `V732`, (`V733` < 0.03) AS `V733`, (`V734` < 0.03) AS `V734`, (`V735` < 0.03) AS `V735`, (`V736` < 0.03) AS `V736`, (`V737` < 0.03) AS `V737`, (`V738` < 0.03) AS `V738`, (`V739` < 0.03) AS `V739`, (`V740` < 0.03) AS `V740`, (`V741` < 0.03) AS `V741`, (`V742` < 0.03) AS `V742`, (`V743` < 0.03) AS `V743`, (`V744` < 0.03) AS `V744`, (`V745` < 0.03) AS `V745`, (`V746` < 0.03) AS `V746`, (`V747` < 0.03) AS `V747`, (`V748` < 0.03) AS `V748`, (`V749` < 0.03) AS `V749`, (`V750` < 0.03) AS `V750`, (`V751` < 0.03) AS `V751`, (`V752` < 0.03) AS `V752`, (`V753` < 0.03) AS `V753`, (`V754` < 0.03) AS `V754`, (`V755` < 0.03) AS `V755`, (`V756` < 0.03) AS `V756`, (`V757` < 0.03) AS `V757`, (`V758` < 0.03) AS `V758`, (`V759` < 0.03) AS `V759`, (`V760` < 0.03) AS `V760`, (`V761` < 0.03) AS `V761`, (`V762` < 0.03) AS `V762`, (`V763` < 0.03) AS `V763`, (`V764` < 0.03) AS `V764`, (`V765` < 0.03) AS `V765`, (`V766` < 0.03) AS `V766`, (`V767` < 0.03) AS `V767`, (`V768` < 0.03) AS `V768`, (`V769` < 0.03) AS `V769`, (`V770` < 0.03) AS `V770`, (`V771` < 0.03) AS `V771`, (`V772` < 0.03) AS `V772`, (`V773` < 0.03) AS `V773`, (`V774` < 0.03) AS `V774`, (`V775` < 0.03) AS `V775`, (`V776` < 0.03) AS `V776`, (`V777` < 0.03) AS `V777`, (`V778` < 0.03) AS `V778`, (`V779` < 0.03) AS `V779`, (`V780` < 0.03) AS `V780`, (`V781` < 0.03) AS `V781`, (`V782` < 0.03) AS `V782`, (`V783` < 0.03) AS `V783`, (`V784` < 0.03) AS `V784`, (`V785` < 0.03) AS `V785`, (`V786` < 0.03) AS `V786`, (`V787` < 0.03) AS `V787`, (`V788` < 0.03) AS `V788`, (`V789` < 0.03) AS `V789`, (`V790` < 0.03) AS `V790`, (`V791` < 0.03) AS `V791`, (`V792` < 0.03) AS `V792`, (`V793` < 0.03) AS `V793`, (`V794` < 0.03) AS `V794`, (`V795` < 0.03) AS `V795`, (`V796` < 0.03) AS `V796`, (`V797` < 0.03) AS `V797`, (`V798` < 0.03) AS `V798`, (`V799` < 0.03) AS `V799`, (`V800` < 0.03) AS `V800`, (`V801` < 0.03) AS `V801`, (`V802` < 0.03) AS `V802`, (`V803` < 0.03) AS `V803`, (`V804` < 0.03) AS `V804`, (`V805` < 0.03) AS `V805`, (`V806` < 0.03) AS `V806`, (`V807` < 0.03) AS `V807`, (`V808` < 0.03) AS `V808`, (`V809` < 0.03) AS `V809`, (`V810` < 0.03) AS `V810`, (`V811` < 0.03) AS `V811`, (`V812` < 0.03) AS `V812`, (`V813` < 0.03) AS `V813`, (`V814` < 0.03) AS `V814`, (`V815` < 0.03) AS `V815`, (`V816` < 0.03) AS `V816`, (`V817` < 0.03) AS `V817`, (`V818` < 0.03) AS `V818`, (`V819` < 0.03) AS `V819`, (`V820` < 0.03) AS `V820`, (`V821` < 0.03) AS `V821`, (`V822` < 0.03) AS `V822`, (`V823` < 0.03) AS `V823`, (`V824` < 0.03) AS `V824`, (`V825` < 0.03) AS `V825`, (`V826` < 0.03) AS `V826`, (`V827` < 0.03) AS `V827`, (`V828` < 0.03) AS `V828`, (`V829` < 0.03) AS `V829`, (`V830` < 0.03) AS `V830`, (`V831` < 0.03) AS `V831`, (`V832` < 0.03) AS `V832`, (`V833` < 0.03) AS `V833`, (`V834` < 0.03) AS `V834`, (`V835` < 0.03) AS `V835`, (`V836` < 0.03) AS `V836`, (`V837` < 0.03) AS `V837`, (`V838` < 0.03) AS `V838`, (`V839` < 0.03) AS `V839`, (`V840` < 0.03) AS `V840`, (`V841` < 0.03) AS `V841`, (`V842` < 0.03) AS `V842`, (`V843` < 0.03) AS `V843`, (`V844` < 0.03) AS `V844`, (`V845` < 0.03) AS `V845`, (`V846` < 0.03) AS `V846`, (`V847` < 0.03) AS `V847`, (`V848` < 0.03) AS `V848`, (`V849` < 0.03) AS `V849`, (`V850` < 0.03) AS `V850`, (`V851` < 0.03) AS `V851`, (`V852` < 0.03) AS `V852`, (`V853` < 0.03) AS `V853`, (`V854` < 0.03) AS `V854`, (`V855` < 0.03) AS `V855`, (`V856` < 0.03) AS `V856`, (`V857` < 0.03) AS `V857`, (`V858` < 0.03) AS `V858`, (`V859` < 0.03) AS `V859`, (`V860` < 0.03) AS `V860`, (`V861` < 0.03) AS `V861`, (`V862` < 0.03) AS `V862`, (`V863` < 0.03) AS `V863`, (`V864` < 0.03) AS `V864`, (`V865` < 0.03) AS `V865`, (`V866` < 0.03) AS `V866`, (`V867` < 0.03) AS `V867`, (`V868` < 0.03) AS `V868`, (`V869` < 0.03) AS `V869`, (`V870` < 0.03) AS `V870`, (`V871` < 0.03) AS `V871`, (`V872` < 0.03) AS `V872`, (`V873` < 0.03) AS `V873`, (`V874` < 0.03) AS `V874`, (`V875` < 0.03) AS `V875`, (`V876` < 0.03) AS `V876`, (`V877` < 0.03) AS `V877`, (`V878` < 0.03) AS `V878`, (`V879` < 0.03) AS `V879`, (`V880` < 0.03) AS `V880`, (`V881` < 0.03) AS `V881`, (`V882` < 0.03) AS `V882`, (`V883` < 0.03) AS `V883`, (`V884` < 0.03) AS `V884`, (`V885` < 0.03) AS `V885`, (`V886` < 0.03) AS `V886`, (`V887` < 0.03) AS `V887`, (`V888` < 0.03) AS `V888`, (`V889` < 0.03) AS `V889`, (`V890` < 0.03) AS `V890`, (`V891` < 0.03) AS `V891`, (`V892` < 0.03) AS `V892`, (`V893` < 0.03) AS `V893`, (`V894` < 0.03) AS `V894`, (`V895` < 0.03) AS `V895`, (`V896` < 0.03) AS `V896`, (`V897` < 0.03) AS `V897`, (`V898` < 0.03) AS `V898`, (`V899` < 0.03) AS `V899`, (`V900` < 0.03) AS `V900`, (`V901` < 0.03) AS `V901`, (`V902` < 0.03) AS `V902`, (`V903` < 0.03) AS `V903`, (`V904` < 0.03) AS `V904`, (`V905` < 0.03) AS `V905`, (`V906` < 0.03) AS `V906`, (`V907` < 0.03) AS `V907`, (`V908` < 0.03) AS `V908`, (`V909` < 0.03) AS `V909`, (`V910` < 0.03) AS `V910`, (`V911` < 0.03) AS `V911`, (`V912` < 0.03) AS `V912`, (`V913` < 0.03) AS `V913`, (`V914` < 0.03) AS `V914`, (`V915` < 0.03) AS `V915`, (`V916` < 0.03) AS `V916`, (`V917` < 0.03) AS `V917`, (`V918` < 0.03) AS `V918`, (`V919` < 0.03) AS `V919`, (`V920` < 0.03) AS `V920`, (`V921` < 0.03) AS `V921`, (`V922` < 0.03) AS `V922`, (`V923` < 0.03) AS `V923`, (`V924` < 0.03) AS `V924`, (`V925` < 0.03) AS `V925`, (`V926` < 0.03) AS `V926`, (`V927` < 0.03) AS `V927`, (`V928` < 0.03) AS `V928`, (`V929` < 0.03) AS `V929`, (`V930` < 0.03) AS `V930`, (`V931` < 0.03) AS `V931`, (`V932` < 0.03) AS `V932`, (`V933` < 0.03) AS `V933`, (`V934` < 0.03) AS `V934`, (`V935` < 0.03) AS `V935`, (`V936` < 0.03) AS `V936`, (`V937` < 0.03) AS `V937`, (`V938` < 0.03) AS `V938`, (`V939` < 0.03) AS `V939`, (`V940` < 0.03) AS `V940`, (`V941` < 0.03) AS `V941`, (`V942` < 0.03) AS `V942`, (`V943` < 0.03) AS `V943`, (`V944` < 0.03) AS `V944`, (`V945` < 0.03) AS `V945`, (`V946` < 0.03) AS `V946`, (`V947` < 0.03) AS `V947`, (`V948` < 0.03) AS `V948`, (`V949` < 0.03) AS `V949`, (`V950` < 0.03) AS `V950`, (`V951` < 0.03) AS `V951`, (`V952` < 0.03) AS `V952`, (`V953` < 0.03) AS `V953`, (`V954` < 0.03) AS `V954`, (`V955` < 0.03) AS `V955`, (`V956` < 0.03) AS `V956`, (`V957` < 0.03) AS `V957`, (`V958` < 0.03) AS `V958`, (`V959` < 0.03) AS `V959`, (`V960` < 0.03) AS `V960`, (`V961` < 0.03) AS `V961`, (`V962` < 0.03) AS `V962`, (`V963` < 0.03) AS `V963`, (`V964` < 0.03) AS `V964`, (`V965` < 0.03) AS `V965`, (`V966` < 0.03) AS `V966`, (`V967` < 0.03) AS `V967`, (`V968` < 0.03) AS `V968`, (`V969` < 0.03) AS `V969`, (`V970` < 0.03) AS `V970`, (`V971` < 0.03) AS `V971`, (`V972` < 0.03) AS `V972`, (`V973` < 0.03) AS `V973`, (`V974` < 0.03) AS `V974`, (`V975` < 0.03) AS `V975`, (`V976` < 0.03) AS `V976`, (`V977` < 0.03) AS `V977`, (`V978` < 0.03) AS `V978`, (`V979` < 0.03) AS `V979`, (`V980` < 0.03) AS `V980`, (`V981` < 0.03) AS `V981`, (`V982` < 0.03) AS `V982`, (`V983` < 0.03) AS `V983`, (`V984` < 0.03) AS `V984`, (`V985` < 0.03) AS `V985`, (`V986` < 0.03) AS `V986`, (`V987` < 0.03) AS `V987`, (`V988` < 0.03) AS `V988`, (`V989` < 0.03) AS `V989`, (`V990` < 0.03) AS `V990`, (`V991` < 0.03) AS `V991`, (`V992` < 0.03) AS `V992`, (`V993` < 0.03) AS `V993`, (`V994` < 0.03) AS `V994`, (`V995` < 0.03) AS `V995`, (`V996` < 0.03) AS `V996`, (`V997` < 0.03) AS `V997`, (`V998` < 0.03) AS `V998`, (`V999` < 0.03) AS `V999`, (`V1000` < 0.03) AS `V1000`
FROM `analyis_tbl`
17/12/21 18:14:41 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 18:14:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:14:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz15`
WHERE (0 = 1)
17/12/21 18:14:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:14:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 18:14:42 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/12/21 18:14:42 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 18:14:42 INFO DAGScheduler: Got job 4 (collect at utils.scala:196) with 2 output partitions
17/12/21 18:14:42 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:196)
17/12/21 18:14:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
17/12/21 18:14:42 INFO DAGScheduler: Missing parents: List()
17/12/21 18:14:42 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196), which has no missing parents
17/12/21 18:14:42 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1064.2 KB, free 1868.7 MB)
17/12/21 18:14:42 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 279.5 KB, free 1868.5 MB)
17/12/21 18:14:42 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:51632 (size: 279.5 KB, free: 1870.4 MB)
17/12/21 18:14:42 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/12/21 18:14:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196)
17/12/21 18:14:42 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks
17/12/21 18:14:42 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5945 bytes)
17/12/21 18:14:42 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 5945 bytes)
17/12/21 18:14:42 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
17/12/21 18:14:42 INFO Executor: Running task 1.0 in stage 10.0 (TID 10)
17/12/21 18:14:42 INFO BlockManager: Found block rdd_31_0 locally
17/12/21 18:14:42 INFO BlockManager: Found block rdd_12_1 locally
17/12/21 18:14:42 INFO CodeGenerator: Code generated in 141.906987 ms
17/12/21 18:14:42 INFO CodeGenerator: Code generated in 277.792314 ms
17/12/21 18:14:44 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:51632 in memory (size: 189.3 KB, free: 1870.5 MB)
17/12/21 18:14:47 WARN CodeGenerator: Error calculating stats of compiled class.
java.io.EOFException
	at java.io.DataInputStream.readFully(Unknown Source)
	at java.io.DataInputStream.readFully(Unknown Source)
	at org.codehaus.janino.util.ClassFile.loadAttribute(ClassFile.java:1509)
	at org.codehaus.janino.util.ClassFile.loadAttributes(ClassFile.java:644)
	at org.codehaus.janino.util.ClassFile.loadFields(ClassFile.java:623)
	at org.codehaus.janino.util.ClassFile.<init>(ClassFile.java:280)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anonfun$recordCompilationStats$1.apply(CodeGenerator.scala:967)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anonfun$recordCompilationStats$1.apply(CodeGenerator.scala:964)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.recordCompilationStats(CodeGenerator.scala:964)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(CodeGenerator.scala:936)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:998)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:995)
	at org.spark_project.guava.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)
	at org.spark_project.guava.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)
	at org.spark_project.guava.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)
	at org.spark_project.guava.cache.LocalCache$Segment.get(LocalCache.java:2257)
	at org.spark_project.guava.cache.LocalCache.get(LocalCache.java:4000)
	at org.spark_project.guava.cache.LocalCache.getOrLoad(LocalCache.java:4004)
	at org.spark_project.guava.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4874)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.compile(CodeGenerator.scala:890)
	at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:405)
	at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:359)
	at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:32)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:874)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.extractProjection$lzycompute(ExpressionEncoder.scala:266)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.extractProjection(ExpressionEncoder.scala:266)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:290)
	at org.apache.spark.sql.SparkSession$$anonfun$3.apply(SparkSession.scala:547)
	at org.apache.spark.sql.SparkSession$$anonfun$3.apply(SparkSession.scala:547)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:232)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/12/21 18:14:47 INFO CodeGenerator: Code generated in 2673.292834 ms
17/12/21 18:14:55 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 1012454 bytes result sent to driver
17/12/21 18:14:55 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 13031 ms on localhost (executor driver) (1/2)
17/12/21 18:17:39 INFO MemoryStore: Block rdd_31_1 stored as values in memory (estimated size 133.7 MB, free 1735.5 MB)
17/12/21 18:17:39 INFO BlockManagerInfo: Added rdd_31_1 in memory on 127.0.0.1:51632 (size: 133.7 MB, free: 1736.9 MB)
17/12/21 18:17:46 INFO Executor: Finished task 1.0 in stage 10.0 (TID 10). 1006892 bytes result sent to driver
17/12/21 18:17:46 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 10) in 183928 ms on localhost (executor driver) (2/2)
17/12/21 18:17:46 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/21 18:17:46 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:196) finished in 183.929 s
17/12/21 18:17:46 INFO DAGScheduler: Job 4 finished: collect at utils.scala:196, took 183.957381 s
17/12/21 18:17:46 INFO CodeGenerator: Code generated in 82.462159 ms
17/12/21 18:17:49 INFO SparkContext: Invoking stop() from shutdown hook
17/12/21 18:17:49 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/21 18:17:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/21 18:17:50 INFO MemoryStore: MemoryStore cleared
17/12/21 18:17:50 INFO BlockManager: BlockManager stopped
17/12/21 18:17:50 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/21 18:17:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/21 18:17:50 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-54fc6593-f3d9-418b-ad4b-2b2f2a461dfb\userFiles-7d1ad9fb-60d9-411e-a62d-1526f15dee1f
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-54fc6593-f3d9-418b-ad4b-2b2f2a461dfb\userFiles-7d1ad9fb-60d9-411e-a62d-1526f15dee1f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/21 18:17:50 INFO SparkContext: Successfully stopped SparkContext
17/12/21 18:17:50 INFO ShutdownHookManager: Shutdown hook called
17/12/21 18:17:50 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-54fc6593-f3d9-418b-ad4b-2b2f2a461dfb
17/12/21 18:17:50 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-54fc6593-f3d9-418b-ad4b-2b2f2a461dfb
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-54fc6593-f3d9-418b-ad4b-2b2f2a461dfb
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/21 18:17:50 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-54fc6593-f3d9-418b-ad4b-2b2f2a461dfb\userFiles-7d1ad9fb-60d9-411e-a62d-1526f15dee1f
17/12/21 18:17:50 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-54fc6593-f3d9-418b-ad4b-2b2f2a461dfb\userFiles-7d1ad9fb-60d9-411e-a62d-1526f15dee1f
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-54fc6593-f3d9-418b-ad4b-2b2f2a461dfb\userFiles-7d1ad9fb-60d9-411e-a62d-1526f15dee1f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/21 18:54:15 INFO SparkContext: Running Spark version 2.1.0
17/12/21 18:54:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/21 18:54:16 INFO SecurityManager: Changing view acls to: conan
17/12/21 18:54:16 INFO SecurityManager: Changing modify acls to: conan
17/12/21 18:54:16 INFO SecurityManager: Changing view acls groups to: 
17/12/21 18:54:16 INFO SecurityManager: Changing modify acls groups to: 
17/12/21 18:54:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(conan); groups with view permissions: Set(); users  with modify permissions: Set(conan); groups with modify permissions: Set()
17/12/21 18:54:16 INFO Utils: Successfully started service 'sparkDriver' on port 52086.
17/12/21 18:54:16 INFO SparkEnv: Registering MapOutputTracker
17/12/21 18:54:16 INFO SparkEnv: Registering BlockManagerMaster
17/12/21 18:54:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/21 18:54:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/21 18:54:16 INFO DiskBlockManager: Created local directory at C:\Users\conan\AppData\Local\Temp\blockmgr-e331fe10-9128-4dd8-9685-55f29a95dec6
17/12/21 18:54:16 INFO MemoryStore: MemoryStore started with capacity 2004.6 MB
17/12/21 18:54:16 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/21 18:54:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/21 18:54:16 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/21 18:54:16 INFO SparkContext: Added JAR file:/C:/Users/conan/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:52086/jars/sparklyr-2.1-2.11.jar with timestamp 1513882456806
17/12/21 18:54:16 INFO Executor: Starting executor ID driver on host localhost
17/12/21 18:54:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52107.
17/12/21 18:54:16 INFO NettyBlockTransferService: Server created on 127.0.0.1:52107
17/12/21 18:54:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/21 18:54:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 52107, None)
17/12/21 18:54:16 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:52107 with 2004.6 MB RAM, BlockManagerId(driver, 127.0.0.1, 52107, None)
17/12/21 18:54:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 52107, None)
17/12/21 18:54:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 52107, None)
17/12/21 18:54:17 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/21 18:54:17 INFO SharedState: Warehouse path is 'C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/21 18:54:17 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/21 18:54:18 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/21 18:54:18 INFO ObjectStore: ObjectStore, initialize called
17/12/21 18:54:18 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/21 18:54:18 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/21 18:54:19 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/21 18:54:20 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:54:20 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:54:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:54:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:54:21 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/21 18:54:21 INFO ObjectStore: Initialized ObjectStore
17/12/21 18:54:21 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/21 18:54:21 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/21 18:54:21 INFO HiveMetaStore: Added admin role in metastore
17/12/21 18:54:21 INFO HiveMetaStore: Added public role in metastore
17/12/21 18:54:21 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/21 18:54:22 INFO HiveMetaStore: 0: get_all_databases
17/12/21 18:54:22 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/21 18:54:22 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/21 18:54:22 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/21 18:54:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/21 18:54:22 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/Temp/ce2e8eaf-2627-4b23-a9f5-aa4177cfffdb_resources
17/12/21 18:54:22 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/ce2e8eaf-2627-4b23-a9f5-aa4177cfffdb
17/12/21 18:54:22 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/ce2e8eaf-2627-4b23-a9f5-aa4177cfffdb
17/12/21 18:54:22 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/ce2e8eaf-2627-4b23-a9f5-aa4177cfffdb/_tmp_space.db
17/12/21 18:54:22 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/21 18:54:22 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:54:22 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:54:22 INFO HiveMetaStore: 0: get_database: global_temp
17/12/21 18:54:22 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/21 18:54:22 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/21 18:54:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 18:54:24 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:54:24 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:54:24 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:54:24 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:54:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 18:54:24 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 18:54:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:28 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 18:54:28 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:54:28 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:54:28 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:54:28 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:54:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 18:54:28 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 18:54:28 INFO CodeGenerator: Code generated in 253.872942 ms
17/12/21 18:54:28 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/21 18:54:28 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/21 18:54:28 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/21 18:54:28 INFO DAGScheduler: Parents of final stage: List()
17/12/21 18:54:28 INFO DAGScheduler: Missing parents: List()
17/12/21 18:54:28 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/12/21 18:54:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 2004.6 MB)
17/12/21 18:54:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2004.6 MB)
17/12/21 18:54:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:52107 (size: 4.6 KB, free: 2004.6 MB)
17/12/21 18:54:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/21 18:54:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/12/21 18:54:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/21 18:54:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/21 18:54:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/21 18:54:29 INFO Executor: Fetching spark://127.0.0.1:52086/jars/sparklyr-2.1-2.11.jar with timestamp 1513882456806
17/12/21 18:54:29 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:52086 after 17 ms (0 ms spent in bootstraps)
17/12/21 18:54:29 INFO Utils: Fetching spark://127.0.0.1:52086/jars/sparklyr-2.1-2.11.jar to C:\Users\conan\AppData\Local\Temp\spark-a0eaf712-d894-44ac-83bd-29df618402b6\userFiles-87b8969d-bdfe-4251-a1da-5ea56e52560d\fetchFileTemp1939389235832709817.tmp
17/12/21 18:54:29 INFO Executor: Adding file:/C:/Users/conan/AppData/Local/Temp/spark-a0eaf712-d894-44ac-83bd-29df618402b6/userFiles-87b8969d-bdfe-4251-a1da-5ea56e52560d/sparklyr-2.1-2.11.jar to class loader
17/12/21 18:54:29 INFO CodeGenerator: Code generated in 12.975568 ms
17/12/21 18:54:29 INFO CodeGenerator: Code generated in 12.442046 ms
17/12/21 18:54:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/12/21 18:54:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 348 ms on localhost (executor driver) (1/1)
17/12/21 18:54:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/21 18:54:30 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.367 s
17/12/21 18:54:30 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 1.365628 s
17/12/21 18:54:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:30 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 18:54:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:30 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/21 18:54:30 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:52107 in memory (size: 4.6 KB, free: 2004.6 MB)
17/12/21 18:54:30 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/21 18:54:30 INFO FileSourceStrategy: Pruning directories with: 
17/12/21 18:54:30 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/21 18:54:30 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double, S4: double, S5: double ... 8 more fields>
17/12/21 18:54:30 INFO FileSourceStrategy: Pushed Filters: 
17/12/21 18:54:30 INFO CodeGenerator: Code generated in 6.376586 ms
17/12/21 18:54:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.7 KB, free 2004.3 MB)
17/12/21 18:54:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2004.3 MB)
17/12/21 18:54:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:52107 (size: 24.0 KB, free: 2004.6 MB)
17/12/21 18:54:30 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/21 18:54:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/21 18:54:30 INFO CodeGenerator: Code generated in 15.613348 ms
17/12/21 18:54:30 INFO CodeGenerator: Code generated in 10.530731 ms
17/12/21 18:54:30 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/21 18:54:30 INFO DAGScheduler: Registering RDD 10 (sql at <unknown>:0)
17/12/21 18:54:30 INFO DAGScheduler: Registering RDD 15 (sql at <unknown>:0)
17/12/21 18:54:30 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/21 18:54:30 INFO DAGScheduler: Final stage: ResultStage 3 (sql at <unknown>:0)
17/12/21 18:54:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/12/21 18:54:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/12/21 18:54:30 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0), which has no missing parents
17/12/21 18:54:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.1 KB, free 2004.3 MB)
17/12/21 18:54:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.5 KB, free 2004.3 MB)
17/12/21 18:54:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:52107 (size: 7.5 KB, free: 2004.6 MB)
17/12/21 18:54:30 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/21 18:54:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0)
17/12/21 18:54:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/21 18:54:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/21 18:54:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/21 18:54:30 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp4iNYtw/spark_serialize_061dd0605a9f93b7858f34ab27e213771c18d031b13651953f45d986339548e9.csv, range: 0-187032, partition values: [empty row]
17/12/21 18:54:30 INFO CodeGenerator: Code generated in 9.772926 ms
17/12/21 18:54:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1632 bytes result sent to driver
17/12/21 18:54:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 185 ms on localhost (executor driver) (1/1)
17/12/21 18:54:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/21 18:54:30 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.185 s
17/12/21 18:54:30 INFO DAGScheduler: looking for newly runnable stages
17/12/21 18:54:31 INFO DAGScheduler: running: Set()
17/12/21 18:54:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/12/21 18:54:31 INFO DAGScheduler: failed: Set()
17/12/21 18:54:31 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/21 18:54:31 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.3 KB, free 2004.3 MB)
17/12/21 18:54:31 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2004.2 MB)
17/12/21 18:54:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:52107 (size: 6.9 KB, free: 2004.6 MB)
17/12/21 18:54:31 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/21 18:54:31 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/21 18:54:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
17/12/21 18:54:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5942 bytes)
17/12/21 18:54:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5942 bytes)
17/12/21 18:54:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/21 18:54:31 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
17/12/21 18:54:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 18:54:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/21 18:54:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 18:54:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 18:54:31 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 40.5 KB, free 2004.2 MB)
17/12/21 18:54:31 INFO MemoryStore: Block rdd_12_1 stored as values in memory (estimated size 40.5 KB, free 2004.2 MB)
17/12/21 18:54:31 INFO BlockManagerInfo: Added rdd_12_0 in memory on 127.0.0.1:52107 (size: 40.5 KB, free: 2004.5 MB)
17/12/21 18:54:31 INFO BlockManagerInfo: Added rdd_12_1 in memory on 127.0.0.1:52107 (size: 40.5 KB, free: 2004.5 MB)
17/12/21 18:54:31 INFO CodeGenerator: Code generated in 4.964811 ms
17/12/21 18:54:31 INFO CodeGenerator: Code generated in 16.81028 ms
17/12/21 18:54:31 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 3151 bytes result sent to driver
17/12/21 18:54:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 3241 bytes result sent to driver
17/12/21 18:54:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 154 ms on localhost (executor driver) (1/2)
17/12/21 18:54:31 INFO DAGScheduler: ShuffleMapStage 2 (sql at <unknown>:0) finished in 0.154 s
17/12/21 18:54:31 INFO DAGScheduler: looking for newly runnable stages
17/12/21 18:54:31 INFO DAGScheduler: running: Set()
17/12/21 18:54:31 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/12/21 18:54:31 INFO DAGScheduler: failed: Set()
17/12/21 18:54:31 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
17/12/21 18:54:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 154 ms on localhost (executor driver) (2/2)
17/12/21 18:54:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/21 18:54:31 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 2004.2 MB)
17/12/21 18:54:31 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.2 MB)
17/12/21 18:54:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:52107 (size: 3.7 KB, free: 2004.5 MB)
17/12/21 18:54:31 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/21 18:54:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0)
17/12/21 18:54:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/21 18:54:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/21 18:54:31 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
17/12/21 18:54:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 18:54:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 18:54:31 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 1707 bytes result sent to driver
17/12/21 18:54:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 0 ms on localhost (executor driver) (1/1)
17/12/21 18:54:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/21 18:54:31 INFO DAGScheduler: ResultStage 3 (sql at <unknown>:0) finished in 0.000 s
17/12/21 18:54:31 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.406323 s
17/12/21 18:54:31 INFO CodeGenerator: Code generated in 5.234026 ms
17/12/21 18:54:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:31 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/21 18:54:31 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 18:54:31 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/21 18:54:31 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:196)
17/12/21 18:54:31 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/12/21 18:54:31 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:196)
17/12/21 18:54:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/12/21 18:54:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/12/21 18:54:31 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
17/12/21 18:54:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 15.3 KB, free 2004.1 MB)
17/12/21 18:54:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2004.1 MB)
17/12/21 18:54:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:52107 (size: 6.9 KB, free: 2004.5 MB)
17/12/21 18:54:31 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/21 18:54:31 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196)
17/12/21 18:54:31 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
17/12/21 18:54:31 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5934 bytes)
17/12/21 18:54:31 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 5934 bytes)
17/12/21 18:54:31 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/21 18:54:31 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/12/21 18:54:31 INFO BlockManager: Found block rdd_12_1 locally
17/12/21 18:54:31 INFO BlockManager: Found block rdd_12_0 locally
17/12/21 18:54:31 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1871 bytes result sent to driver
17/12/21 18:54:31 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 21 ms on localhost (executor driver) (1/2)
17/12/21 18:54:31 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 2048 bytes result sent to driver
17/12/21 18:54:31 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 21 ms on localhost (executor driver) (2/2)
17/12/21 18:54:31 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:196) finished in 0.021 s
17/12/21 18:54:31 INFO DAGScheduler: looking for newly runnable stages
17/12/21 18:54:31 INFO DAGScheduler: running: Set()
17/12/21 18:54:31 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/12/21 18:54:31 INFO DAGScheduler: failed: Set()
17/12/21 18:54:31 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196), which has no missing parents
17/12/21 18:54:31 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 2004.1 MB)
17/12/21 18:54:31 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/21 18:54:31 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.1 MB)
17/12/21 18:54:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:52107 (size: 3.7 KB, free: 2004.5 MB)
17/12/21 18:54:31 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/12/21 18:54:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196)
17/12/21 18:54:31 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/21 18:54:31 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/21 18:54:31 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
17/12/21 18:54:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/21 18:54:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/21 18:54:31 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1707 bytes result sent to driver
17/12/21 18:54:31 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:196) finished in 0.000 s
17/12/21 18:54:31 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.055605 s
17/12/21 18:54:31 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 0 ms on localhost (executor driver) (1/1)
17/12/21 18:54:31 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/21 18:54:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz1`
WHERE (0 = 1)
17/12/21 18:54:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:31 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S6` + 0.89442719 * RANDN() AS `V1`, `S10` + 0.91104336 * RANDN() AS `V2`, `S2` + 0.9486833 * RANDN() AS `V3`, `S10` + 0.91104336 * RANDN() AS `V4`, `S5` + 0.92195445 * RANDN() AS `V5`, `S9` + 0.91104336 * RANDN() AS `V6`, `S2` + 0.9486833 * RANDN() AS `V7`, `S5` + 0.92195445 * RANDN() AS `V8`, `S7` + 0.94339811 * RANDN() AS `V9`, `S4` + 0.94339811 * RANDN() AS `V10`
FROM `analyis_tbl`) `lgytsvteyw`
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 1
17/12/21 18:54:31 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:52107 in memory (size: 6.9 KB, free: 2004.5 MB)
17/12/21 18:54:31 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:52107 in memory (size: 3.7 KB, free: 2004.5 MB)
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 50
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 51
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 57
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 58
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 59
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 60
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 61
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 62
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 63
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 64
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 65
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 66
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 67
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 68
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 69
17/12/21 18:54:31 INFO ContextCleaner: Cleaned shuffle 1
17/12/21 18:54:31 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:52107 in memory (size: 7.5 KB, free: 2004.5 MB)
17/12/21 18:54:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:52107 in memory (size: 6.9 KB, free: 2004.5 MB)
17/12/21 18:54:31 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:52107 in memory (size: 3.7 KB, free: 2004.5 MB)
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 238
17/12/21 18:54:31 INFO ContextCleaner: Cleaned accumulator 0
17/12/21 18:54:31 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 18:54:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz2`
WHERE (0 = 1)
17/12/21 18:54:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 18:54:32 INFO CodeGenerator: Code generated in 21.205699 ms
17/12/21 18:54:32 INFO SparkContext: Starting job: take at <unknown>:0
17/12/21 18:54:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/21 18:54:32 INFO DAGScheduler: Got job 3 (take at <unknown>:0) with 1 output partitions
17/12/21 18:54:32 INFO DAGScheduler: Final stage: ResultStage 8 (take at <unknown>:0)
17/12/21 18:54:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/12/21 18:54:32 INFO DAGScheduler: Missing parents: List()
17/12/21 18:54:32 INFO DAGScheduler: Submitting ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18), which has no missing parents
17/12/21 18:54:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 188.5 KB, free 2004.0 MB)
17/12/21 18:54:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 112.8 KB, free 2003.9 MB)
17/12/21 18:54:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:52107 (size: 112.8 KB, free: 2004.4 MB)
17/12/21 18:54:32 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/12/21 18:54:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18)
17/12/21 18:54:32 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/21 18:54:32 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5913 bytes)
17/12/21 18:54:32 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/12/21 18:54:32 INFO BlockManager: Found block rdd_12_0 locally
17/12/21 18:54:32 INFO CodeGenerator: Code generated in 21.456413 ms
17/12/21 18:54:32 INFO CodeGenerator: Code generated in 11.320253 ms
17/12/21 18:54:33 INFO MemoryStore: Block rdd_31_0 stored as values in memory (estimated size 154.3 KB, free 2003.8 MB)
17/12/21 18:54:33 INFO BlockManagerInfo: Added rdd_31_0 in memory on 127.0.0.1:52107 (size: 154.3 KB, free: 2004.2 MB)
17/12/21 18:54:33 WARN Executor: 1 block locks were not released by TID = 8:
[rdd_31_0]
17/12/21 18:54:33 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 4042 bytes result sent to driver
17/12/21 18:54:33 INFO DAGScheduler: ResultStage 8 (take at <unknown>:0) finished in 1.140 s
17/12/21 18:54:33 INFO DAGScheduler: Job 3 finished: take at <unknown>:0, took 1.159586 s
17/12/21 18:54:33 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 1139 ms on localhost (executor driver) (1/1)
17/12/21 18:54:33 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/21 18:54:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:33 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29a43e4235ec
17/12/21 18:54:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29a43e4235ec` AS `zzz3`
WHERE (0 = 1)
17/12/21 18:54:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29a43e4235ec`
17/12/21 18:54:33 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 18:54:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz4`
WHERE (0 = 1)
17/12/21 18:54:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:33 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.0045) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0185) AS `V3`, (`V4` < 0.0055) AS `V4`, (`V5` < 0.0055) AS `V5`, (`V6` < 0.009) AS `V6`, (`V7` < 0.0138) AS `V7`, (`V8` < 0.026) AS `V8`, (`V9` < 0.0018) AS `V9`, (`V10` < 0.0013) AS `V10`
FROM `analyis_tbl`
17/12/21 18:54:33 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/21 18:54:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz5`
WHERE (0 = 1)
17/12/21 18:54:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/21 18:54:33 INFO CodeGenerator: Code generated in 19.350266 ms
17/12/21 18:54:33 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/21 18:54:33 INFO DAGScheduler: Got job 4 (collect at utils.scala:196) with 2 output partitions
17/12/21 18:54:33 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:196)
17/12/21 18:54:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
17/12/21 18:54:33 INFO DAGScheduler: Missing parents: List()
17/12/21 18:54:33 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196), which has no missing parents
17/12/21 18:54:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 201.3 KB, free 2003.6 MB)
17/12/21 18:54:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 117.5 KB, free 2003.5 MB)
17/12/21 18:54:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:52107 (size: 117.5 KB, free: 2004.1 MB)
17/12/21 18:54:33 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/12/21 18:54:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196)
17/12/21 18:54:33 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks
17/12/21 18:54:33 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5945 bytes)
17/12/21 18:54:33 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 5945 bytes)
17/12/21 18:54:33 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
17/12/21 18:54:33 INFO Executor: Running task 1.0 in stage 10.0 (TID 10)
17/12/21 18:54:33 INFO BlockManager: Found block rdd_31_0 locally
17/12/21 18:54:33 INFO BlockManager: Found block rdd_12_1 locally
17/12/21 18:54:33 INFO CodeGenerator: Code generated in 91.243937 ms
17/12/21 18:54:33 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 2529 bytes result sent to driver
17/12/21 18:54:33 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 199 ms on localhost (executor driver) (1/2)
17/12/21 18:54:34 INFO MemoryStore: Block rdd_31_1 stored as values in memory (estimated size 154.3 KB, free 2003.3 MB)
17/12/21 18:54:34 INFO BlockManagerInfo: Added rdd_31_1 in memory on 127.0.0.1:52107 (size: 154.3 KB, free: 2004.0 MB)
17/12/21 18:54:34 INFO Executor: Finished task 1.0 in stage 10.0 (TID 10). 3264 bytes result sent to driver
17/12/21 18:54:34 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:196) finished in 1.257 s
17/12/21 18:54:34 INFO DAGScheduler: Job 4 finished: collect at utils.scala:196, took 1.272894 s
17/12/21 18:54:34 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 10) in 1254 ms on localhost (executor driver) (2/2)
17/12/21 18:54:34 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/21 18:54:34 INFO CodeGenerator: Code generated in 9.347393 ms
17/12/21 18:54:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 18:54:36 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:54:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:54:36 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:54:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:54:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 18:54:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 18:54:36 INFO CodeGenerator: Code generated in 8.154615 ms
17/12/21 18:54:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 18:54:36 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:54:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:54:36 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:54:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:54:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 18:54:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 18:54:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 18:54:36 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:54:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:54:36 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:54:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:54:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 18:54:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 18:54:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/21 18:54:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/21 18:54:36 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:54:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:54:36 INFO HiveMetaStore: 0: get_database: default
17/12/21 18:54:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/21 18:54:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/21 18:54:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/21 19:24:17 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:52107 in memory (size: 117.5 KB, free: 2004.1 MB)
17/12/21 19:24:17 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:52107 in memory (size: 112.8 KB, free: 2004.2 MB)
17/12/21 19:39:14 INFO SparkContext: Invoking stop() from shutdown hook
17/12/21 19:39:14 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/21 19:39:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/21 19:39:14 INFO MemoryStore: MemoryStore cleared
17/12/21 19:39:14 INFO BlockManager: BlockManager stopped
17/12/21 19:39:14 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/21 19:39:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/21 19:39:14 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-a0eaf712-d894-44ac-83bd-29df618402b6\userFiles-87b8969d-bdfe-4251-a1da-5ea56e52560d
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-a0eaf712-d894-44ac-83bd-29df618402b6\userFiles-87b8969d-bdfe-4251-a1da-5ea56e52560d
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/21 19:39:14 INFO SparkContext: Successfully stopped SparkContext
17/12/21 19:39:14 INFO ShutdownHookManager: Shutdown hook called
17/12/21 19:39:14 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-a0eaf712-d894-44ac-83bd-29df618402b6\userFiles-87b8969d-bdfe-4251-a1da-5ea56e52560d
17/12/21 19:39:14 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-a0eaf712-d894-44ac-83bd-29df618402b6\userFiles-87b8969d-bdfe-4251-a1da-5ea56e52560d
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-a0eaf712-d894-44ac-83bd-29df618402b6\userFiles-87b8969d-bdfe-4251-a1da-5ea56e52560d
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/21 19:39:14 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-a0eaf712-d894-44ac-83bd-29df618402b6
17/12/21 19:39:14 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-a0eaf712-d894-44ac-83bd-29df618402b6
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-a0eaf712-d894-44ac-83bd-29df618402b6
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
