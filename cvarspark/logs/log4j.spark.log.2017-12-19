17/12/19 00:52:28 WARN NettyRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@6410fa10,BlockManagerId(driver, 127.0.0.1, 65214, None))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 14 more
17/12/19 11:36:40 WARN NettyRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@6410fa10,BlockManagerId(driver, 127.0.0.1, 65214, None))] in 2 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 14 more
17/12/19 11:36:54 WARN NettyRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@6410fa10,BlockManagerId(driver, 127.0.0.1, 65214, None))] in 3 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 14 more
17/12/19 11:36:54 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@6410fa10,BlockManagerId(driver, 127.0.0.1, 65214, None))]
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:119)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	... 13 more
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 14 more
17/12/19 11:37:04 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
17/12/19 11:37:04 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
17/12/19 11:37:04 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
17/12/19 11:51:23 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:65214 in memory (size: 277.0 KB, free: 1737.2 MB)
17/12/19 12:02:08 INFO SparkContext: Invoking stop() from shutdown hook
17/12/19 12:02:08 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/19 12:02:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/19 12:02:08 INFO MemoryStore: MemoryStore cleared
17/12/19 12:02:08 INFO BlockManager: BlockManager stopped
17/12/19 12:02:08 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/19 12:02:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/19 12:02:08 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-5e2f84a6-3ab9-49d6-97f7-f64197721f9a\userFiles-88a1b984-79b0-40aa-86cc-3113fe64d811
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-5e2f84a6-3ab9-49d6-97f7-f64197721f9a\userFiles-88a1b984-79b0-40aa-86cc-3113fe64d811
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 12:02:08 INFO SparkContext: Successfully stopped SparkContext
17/12/19 12:02:08 INFO ShutdownHookManager: Shutdown hook called
17/12/19 12:02:08 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-5e2f84a6-3ab9-49d6-97f7-f64197721f9a\userFiles-88a1b984-79b0-40aa-86cc-3113fe64d811
17/12/19 12:02:08 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-5e2f84a6-3ab9-49d6-97f7-f64197721f9a\userFiles-88a1b984-79b0-40aa-86cc-3113fe64d811
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-5e2f84a6-3ab9-49d6-97f7-f64197721f9a\userFiles-88a1b984-79b0-40aa-86cc-3113fe64d811
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 12:02:08 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-5e2f84a6-3ab9-49d6-97f7-f64197721f9a
17/12/19 12:02:08 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-5e2f84a6-3ab9-49d6-97f7-f64197721f9a
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-5e2f84a6-3ab9-49d6-97f7-f64197721f9a
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 12:02:43 INFO SparkContext: Running Spark version 2.1.0
17/12/19 12:02:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/19 12:02:44 INFO SecurityManager: Changing view acls to: conan
17/12/19 12:02:44 INFO SecurityManager: Changing modify acls to: conan
17/12/19 12:02:44 INFO SecurityManager: Changing view acls groups to: 
17/12/19 12:02:44 INFO SecurityManager: Changing modify acls groups to: 
17/12/19 12:02:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(conan); groups with view permissions: Set(); users  with modify permissions: Set(conan); groups with modify permissions: Set()
17/12/19 12:02:44 INFO Utils: Successfully started service 'sparkDriver' on port 50890.
17/12/19 12:02:44 INFO SparkEnv: Registering MapOutputTracker
17/12/19 12:02:44 INFO SparkEnv: Registering BlockManagerMaster
17/12/19 12:02:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/19 12:02:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/19 12:02:44 INFO DiskBlockManager: Created local directory at C:\Users\conan\AppData\Local\Temp\blockmgr-8c7aeaa5-b1f9-42bd-96ce-118e8a7e3bbd
17/12/19 12:02:44 INFO MemoryStore: MemoryStore started with capacity 2004.6 MB
17/12/19 12:02:44 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/19 12:02:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/19 12:02:44 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/19 12:02:44 INFO SparkContext: Added JAR file:/C:/Users/conan/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:50890/jars/sparklyr-2.1-2.11.jar with timestamp 1513684964721
17/12/19 12:02:44 INFO Executor: Starting executor ID driver on host localhost
17/12/19 12:02:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50912.
17/12/19 12:02:44 INFO NettyBlockTransferService: Server created on 127.0.0.1:50912
17/12/19 12:02:44 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/19 12:02:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 50912, None)
17/12/19 12:02:44 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:50912 with 2004.6 MB RAM, BlockManagerId(driver, 127.0.0.1, 50912, None)
17/12/19 12:02:44 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 50912, None)
17/12/19 12:02:44 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 50912, None)
17/12/19 12:02:48 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/19 12:02:48 INFO SharedState: Warehouse path is 'C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/19 12:02:48 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/19 12:02:49 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/19 12:02:49 INFO ObjectStore: ObjectStore, initialize called
17/12/19 12:02:49 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/19 12:02:49 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/19 12:02:50 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/19 12:02:51 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 12:02:51 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 12:02:52 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 12:02:52 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 12:02:52 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/19 12:02:52 INFO ObjectStore: Initialized ObjectStore
17/12/19 12:02:52 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/19 12:02:52 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/19 12:02:52 INFO HiveMetaStore: Added admin role in metastore
17/12/19 12:02:52 INFO HiveMetaStore: Added public role in metastore
17/12/19 12:02:52 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/19 12:02:53 INFO HiveMetaStore: 0: get_all_databases
17/12/19 12:02:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/19 12:02:53 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/19 12:02:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/19 12:02:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 12:02:53 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/Temp/2570fcd4-55bb-4b95-ada2-8feb73f66bc9_resources
17/12/19 12:02:53 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/2570fcd4-55bb-4b95-ada2-8feb73f66bc9
17/12/19 12:02:53 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/2570fcd4-55bb-4b95-ada2-8feb73f66bc9
17/12/19 12:02:53 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/2570fcd4-55bb-4b95-ada2-8feb73f66bc9/_tmp_space.db
17/12/19 12:02:53 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/19 12:02:53 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:02:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:02:53 INFO HiveMetaStore: 0: get_database: global_temp
17/12/19 12:02:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/19 12:02:53 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/19 12:02:54 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ae89797607
17/12/19 12:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:02:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ae89797607` AS `zzz64`
WHERE (0 = 1)
17/12/19 12:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:02:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ae89797607`
17/12/19 12:02:55 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 12:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:02:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz65`
WHERE (0 = 1)
17/12/19 12:02:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:02:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 12:02:55 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 12:02:55 INFO DAGScheduler: Got job 0 (take at <unknown>:0) with 1 output partitions
17/12/19 12:02:55 INFO DAGScheduler: Final stage: ResultStage 0 (take at <unknown>:0)
17/12/19 12:02:55 INFO DAGScheduler: Parents of final stage: List()
17/12/19 12:02:55 INFO DAGScheduler: Missing parents: List()
17/12/19 12:02:55 INFO DAGScheduler: Submitting ResultStage 0 (WorkerRDD[9] at RDD at rdd.scala:18), which has no missing parents
17/12/19 12:02:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 297.3 KB, free 2004.3 MB)
17/12/19 12:02:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 134.6 KB, free 2004.2 MB)
17/12/19 12:02:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:50912 (size: 134.6 KB, free: 2004.5 MB)
17/12/19 12:02:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/19 12:02:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (WorkerRDD[9] at RDD at rdd.scala:18)
17/12/19 12:02:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/19 12:02:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6011 bytes)
17/12/19 12:02:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/19 12:02:56 INFO Executor: Fetching spark://127.0.0.1:50890/jars/sparklyr-2.1-2.11.jar with timestamp 1513684964721
17/12/19 12:02:56 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:50890 after 57 ms (0 ms spent in bootstraps)
17/12/19 12:02:56 INFO Utils: Fetching spark://127.0.0.1:50890/jars/sparklyr-2.1-2.11.jar to C:\Users\conan\AppData\Local\Temp\spark-c119635a-4731-404d-ab4c-1100d3917dd8\userFiles-3ea19ebe-3841-4208-90af-234e6621c0a0\fetchFileTemp1169045412524781932.tmp
17/12/19 12:02:56 INFO Executor: Adding file:/C:/Users/conan/AppData/Local/Temp/spark-c119635a-4731-404d-ab4c-1100d3917dd8/userFiles-3ea19ebe-3841-4208-90af-234e6621c0a0/sparklyr-2.1-2.11.jar to class loader
17/12/19 12:02:57 INFO CodeGenerator: Code generated in 266.838894 ms
17/12/19 12:02:57 INFO CodeGenerator: Code generated in 8.847105 ms
17/12/19 12:02:57 INFO CodeGenerator: Code generated in 9.38176 ms
17/12/19 12:02:58 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 80.0 B, free 2004.2 MB)
17/12/19 12:02:58 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:50912 (size: 80.0 B, free: 2004.5 MB)
17/12/19 12:02:58 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2087 bytes result sent to driver
17/12/19 12:02:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2244 ms on localhost (executor driver) (1/1)
17/12/19 12:02:58 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/19 12:02:58 INFO DAGScheduler: ResultStage 0 (take at <unknown>:0) finished in 2.268 s
17/12/19 12:02:58 INFO DAGScheduler: Job 0 finished: take at <unknown>:0, took 3.220037 s
17/12/19 12:02:58 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 12:02:58 INFO DAGScheduler: Got job 1 (take at <unknown>:0) with 1 output partitions
17/12/19 12:02:58 INFO DAGScheduler: Final stage: ResultStage 1 (take at <unknown>:0)
17/12/19 12:02:58 INFO DAGScheduler: Parents of final stage: List()
17/12/19 12:02:58 INFO DAGScheduler: Missing parents: List()
17/12/19 12:02:58 INFO DAGScheduler: Submitting ResultStage 1 (WorkerRDD[9] at RDD at rdd.scala:18), which has no missing parents
17/12/19 12:02:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 297.3 KB, free 2003.9 MB)
17/12/19 12:02:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 134.6 KB, free 2003.8 MB)
17/12/19 12:02:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:50912 (size: 134.6 KB, free: 2004.3 MB)
17/12/19 12:02:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/12/19 12:02:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (WorkerRDD[9] at RDD at rdd.scala:18)
17/12/19 12:02:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/19 12:02:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 6011 bytes)
17/12/19 12:02:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/19 12:02:59 INFO MemoryStore: Block rdd_9_1 stored as values in memory (estimated size 80.0 B, free 2003.8 MB)
17/12/19 12:02:59 INFO BlockManagerInfo: Added rdd_9_1 in memory on 127.0.0.1:50912 (size: 80.0 B, free: 2004.3 MB)
17/12/19 12:02:59 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2008 bytes result sent to driver
17/12/19 12:02:59 INFO DAGScheduler: ResultStage 1 (take at <unknown>:0) finished in 0.880 s
17/12/19 12:02:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 880 ms on localhost (executor driver) (1/1)
17/12/19 12:02:59 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/19 12:02:59 INFO DAGScheduler: Job 1 finished: take at <unknown>:0, took 0.894654 s
17/12/19 12:02:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:02:59 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ae87c906297
17/12/19 12:02:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:02:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ae87c906297` AS `zzz66`
WHERE (0 = 1)
17/12/19 12:02:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:02:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ae87c906297`
LIMIT 10
17/12/19 12:02:59 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 12:02:59 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/12/19 12:02:59 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:196)
17/12/19 12:02:59 INFO DAGScheduler: Parents of final stage: List()
17/12/19 12:02:59 INFO DAGScheduler: Missing parents: List()
17/12/19 12:02:59 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at collect at utils.scala:196), which has no missing parents
17/12/19 12:02:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 299.1 KB, free 2003.5 MB)
17/12/19 12:02:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 135.7 KB, free 2003.3 MB)
17/12/19 12:02:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:50912 (size: 135.7 KB, free: 2004.2 MB)
17/12/19 12:02:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/19 12:02:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at collect at utils.scala:196)
17/12/19 12:02:59 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/12/19 12:02:59 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5959 bytes)
17/12/19 12:02:59 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/19 12:02:59 INFO BlockManager: Found block rdd_9_0 locally
17/12/19 12:02:59 INFO CodeGenerator: Code generated in 7.383223 ms
17/12/19 12:02:59 INFO CodeGenerator: Code generated in 15.893903 ms
17/12/19 12:02:59 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1405 bytes result sent to driver
17/12/19 12:02:59 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:196) finished in 0.044 s
17/12/19 12:02:59 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.060398 s
17/12/19 12:02:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 44 ms on localhost (executor driver) (1/1)
17/12/19 12:02:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/19 12:02:59 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 12:02:59 INFO DAGScheduler: Got job 3 (collect at utils.scala:196) with 1 output partitions
17/12/19 12:02:59 INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:196)
17/12/19 12:02:59 INFO DAGScheduler: Parents of final stage: List()
17/12/19 12:02:59 INFO DAGScheduler: Missing parents: List()
17/12/19 12:02:59 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[13] at collect at utils.scala:196), which has no missing parents
17/12/19 12:02:59 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 299.1 KB, free 2003.0 MB)
17/12/19 12:02:59 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 135.7 KB, free 2002.9 MB)
17/12/19 12:02:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:50912 (size: 135.7 KB, free: 2004.1 MB)
17/12/19 12:02:59 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/19 12:02:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at collect at utils.scala:196)
17/12/19 12:02:59 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/19 12:02:59 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 5959 bytes)
17/12/19 12:02:59 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/12/19 12:02:59 INFO BlockManager: Found block rdd_9_1 locally
17/12/19 12:02:59 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1070 bytes result sent to driver
17/12/19 12:02:59 INFO DAGScheduler: ResultStage 3 (collect at utils.scala:196) finished in 0.000 s
17/12/19 12:02:59 INFO DAGScheduler: Job 3 finished: collect at utils.scala:196, took 0.030339 s
17/12/19 12:02:59 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 0 ms on localhost (executor driver) (1/1)
17/12/19 12:02:59 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/19 12:02:59 INFO CodeGenerator: Code generated in 7.634692 ms
17/12/19 12:03:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:03:02 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`, `V11` AS `V11`, `V12` AS `V12`, `V13` AS `V13`, `V14` AS `V14`, `V15` AS `V15`, `V16` AS `V16`, `V17` AS `V17`, `V18` AS `V18`, `V19` AS `V19`, `V20` AS `V20`, `V21` AS `V21`, `V22` AS `V22`, `V23` AS `V23`, `V24` AS `V24`, `V25` AS `V25`, `V26` AS `V26`, `V27` AS `V27`, `V28` AS `V28`, `V29` AS `V29`, `V30` AS `V30`, `V31` AS `V31`, `V32` AS `V32`, `V33` AS `V33`, `V34` AS `V34`, `V35` AS `V35`, `V36` AS `V36`, `V37` AS `V37`, `V38` AS `V38`, `V39` AS `V39`, `V40` AS `V40`, `V41` AS `V41`, `V42` AS `V42`, `V43` AS `V43`, `V44` AS `V44`, `V45` AS `V45`, `V46` AS `V46`, `V47` AS `V47`, `V48` AS `V48`, `V49` AS `V49`, `V50` AS `V50`, `V51` AS `V51`, `V52` AS `V52`, `V53` AS `V53`, `V54` AS `V54`, `V55` AS `V55`, `V56` AS `V56`, `V57` AS `V57`, `V58` AS `V58`, `V59` AS `V59`, `V60` AS `V60`, `V61` AS `V61`, `V62` AS `V62`, `V63` AS `V63`, `V64` AS `V64`, `V65` AS `V65`, `V66` AS `V66`, `V67` AS `V67`, `V68` AS `V68`, `V69` AS `V69`, `V70` AS `V70`, `V71` AS `V71`, `V72` AS `V72`, `V73` AS `V73`, `V74` AS `V74`, `V75` AS `V75`, `V76` AS `V76`, `V77` AS `V77`, `V78` AS `V78`, `V79` AS `V79`, `V80` AS `V80`, `V81` AS `V81`, `V82` AS `V82`, `V83` AS `V83`, `V84` AS `V84`, `V85` AS `V85`, `V86` AS `V86`, `V87` AS `V87`, `V88` AS `V88`, `V89` AS `V89`, `V90` AS `V90`, `V91` AS `V91`, `V92` AS `V92`, `V93` AS `V93`, `V94` AS `V94`, `V95` AS `V95`, `V96` AS `V96`, `V97` AS `V97`, `V98` AS `V98`, `V99` AS `V99`, `V100` AS `V100`, `V101` AS `V101`, `V102` AS `V102`, `V103` AS `V103`, `V104` AS `V104`, `V105` AS `V105`, `V106` AS `V106`, `V107` AS `V107`, `V108` AS `V108`, `V109` AS `V109`, `V110` AS `V110`, `V111` AS `V111`, `V112` AS `V112`, `V113` AS `V113`, `V114` AS `V114`, `V115` AS `V115`, `V116` AS `V116`, `V117` AS `V117`, `V118` AS `V118`, `V119` AS `V119`, `V120` AS `V120`, `V121` AS `V121`, `V122` AS `V122`, `V123` AS `V123`, `V124` AS `V124`, `V125` AS `V125`, `V126` AS `V126`, `V127` AS `V127`, `V128` AS `V128`, `V129` AS `V129`, `V130` AS `V130`, `V131` AS `V131`, `V132` AS `V132`, `V133` AS `V133`, `V134` AS `V134`, `V135` AS `V135`, `V136` AS `V136`, `V137` AS `V137`, `V138` AS `V138`, `V139` AS `V139`, `V140` AS `V140`, `V141` AS `V141`, `V142` AS `V142`, `V143` AS `V143`, `V144` AS `V144`, `V145` AS `V145`, `V146` AS `V146`, `V147` AS `V147`, `V148` AS `V148`, `V149` AS `V149`, `V150` AS `V150`, `V151` AS `V151`, `V152` AS `V152`, `V153` AS `V153`, `V154` AS `V154`, `V155` AS `V155`, `V156` AS `V156`, `V157` AS `V157`, `V158` AS `V158`, `V159` AS `V159`, `V160` AS `V160`, `V161` AS `V161`, `V162` AS `V162`, `V163` AS `V163`, `V164` AS `V164`, `V165` AS `V165`, `V166` AS `V166`, `V167` AS `V167`, `V168` AS `V168`, `V169` AS `V169`, `V170` AS `V170`, `V171` AS `V171`, `V172` AS `V172`, `V173` AS `V173`, `V174` AS `V174`, `V175` AS `V175`, `V176` AS `V176`, `V177` AS `V177`, `V178` AS `V178`, `V179` AS `V179`, `V180` AS `V180`, `V181` AS `V181`, `V182` AS `V182`, `V183` AS `V183`, `V184` AS `V184`, `V185` AS `V185`, `V186` AS `V186`, `V187` AS `V187`, `V188` AS `V188`, `V189` AS `V189`, `V190` AS `V190`, `V191` AS `V191`, `V192` AS `V192`, `V193` AS `V193`, `V194` AS `V194`, `V195` AS `V195`, `V196` AS `V196`, `V197` AS `V197`, `V198` AS `V198`, `V199` AS `V199`, `V200` AS `V200`, `V201` AS `V201`, `V202` AS `V202`, `V203` AS `V203`, `V204` AS `V204`, `V205` AS `V205`, `V206` AS `V206`, `V207` AS `V207`, `V208` AS `V208`, `V209` AS `V209`, `V210` AS `V210`, `V211` AS `V211`, `V212` AS `V212`, `V213` AS `V213`, `V214` AS `V214`, `V215` AS `V215`, `V216` AS `V216`, `V217` AS `V217`, `V218` AS `V218`, `V219` AS `V219`, `V220` AS `V220`, `V221` AS `V221`, `V222` AS `V222`, `V223` AS `V223`, `V224` AS `V224`, `V225` AS `V225`, `V226` AS `V226`, `V227` AS `V227`, `V228` AS `V228`, `V229` AS `V229`, `V230` AS `V230`, `V231` AS `V231`, `V232` AS `V232`, `V233` AS `V233`, `V234` AS `V234`, `V235` AS `V235`, `V236` AS `V236`, `V237` AS `V237`, `V238` AS `V238`, `V239` AS `V239`, `V240` AS `V240`, `V241` AS `V241`, `V242` AS `V242`, `V243` AS `V243`, `V244` AS `V244`, `V245` AS `V245`, `V246` AS `V246`, `V247` AS `V247`, `V248` AS `V248`, `V249` AS `V249`, `V250` AS `V250`, `V251` AS `V251`, `V252` AS `V252`, `V253` AS `V253`, `V254` AS `V254`, `V255` AS `V255`, `V256` AS `V256`, `V257` AS `V257`, `V258` AS `V258`, `V259` AS `V259`, `V260` AS `V260`, `V261` AS `V261`, `V262` AS `V262`, `V263` AS `V263`, `V264` AS `V264`, `V265` AS `V265`, `V266` AS `V266`, `V267` AS `V267`, `V268` AS `V268`, `V269` AS `V269`, `V270` AS `V270`, `V271` AS `V271`, `V272` AS `V272`, `V273` AS `V273`, `V274` AS `V274`, `V275` AS `V275`, `V276` AS `V276`, `V277` AS `V277`, `V278` AS `V278`, `V279` AS `V279`, `V280` AS `V280`, `V281` AS `V281`, `V282` AS `V282`, `V283` AS `V283`, `V284` AS `V284`, `V285` AS `V285`, `V286` AS `V286`, `V287` AS `V287`, `V288` AS `V288`, `V289` AS `V289`, `V290` AS `V290`, `V291` AS `V291`, `V292` AS `V292`, `V293` AS `V293`, `V294` AS `V294`, `V295` AS `V295`, `V296` AS `V296`, `V297` AS `V297`, `V298` AS `V298`, `V299` AS `V299`, `V300` AS `V300`, `V301` AS `V301`, `V302` AS `V302`, `V303` AS `V303`, `V304` AS `V304`, `V305` AS `V305`, `V306` AS `V306`, `V307` AS `V307`, `V308` AS `V308`, `V309` AS `V309`, `V310` AS `V310`, `V311` AS `V311`, `V312` AS `V312`, `V313` AS `V313`, `V314` AS `V314`, `V315` AS `V315`, `V316` AS `V316`, `V317` AS `V317`, `V318` AS `V318`, `V319` AS `V319`, `V320` AS `V320`, `V321` AS `V321`, `V322` AS `V322`, `V323` AS `V323`, `V324` AS `V324`, `V325` AS `V325`, `V326` AS `V326`, `V327` AS `V327`, `V328` AS `V328`, `V329` AS `V329`, `V330` AS `V330`, `V331` AS `V331`, `V332` AS `V332`, `V333` AS `V333`, `V334` AS `V334`, `V335` AS `V335`, `V336` AS `V336`, `V337` AS `V337`, `V338` AS `V338`, `V339` AS `V339`, `V340` AS `V340`, `V341` AS `V341`, `V342` AS `V342`, `V343` AS `V343`, `V344` AS `V344`, `V345` AS `V345`, `V346` AS `V346`, `V347` AS `V347`, `V348` AS `V348`, `V349` AS `V349`, `V350` AS `V350`, `V351` AS `V351`, `V352` AS `V352`, `V353` AS `V353`, `V354` AS `V354`, `V355` AS `V355`, `V356` AS `V356`, `V357` AS `V357`, `V358` AS `V358`, `V359` AS `V359`, `V360` AS `V360`, `V361` AS `V361`, `V362` AS `V362`, `V363` AS `V363`, `V364` AS `V364`, `V365` AS `V365`, `V366` AS `V366`, `V367` AS `V367`, `V368` AS `V368`, `V369` AS `V369`, `V370` AS `V370`, `V371` AS `V371`, `V372` AS `V372`, `V373` AS `V373`, `V374` AS `V374`, `V375` AS `V375`, `V376` AS `V376`, `V377` AS `V377`, `V378` AS `V378`, `V379` AS `V379`, `V380` AS `V380`, `V381` AS `V381`, `V382` AS `V382`, `V383` AS `V383`, `V384` AS `V384`, `V385` AS `V385`, `V386` AS `V386`, `V387` AS `V387`, `V388` AS `V388`, `V389` AS `V389`, `V390` AS `V390`, `V391` AS `V391`, `V392` AS `V392`, `V393` AS `V393`, `V394` AS `V394`, `V395` AS `V395`, `V396` AS `V396`, `V397` AS `V397`, `V398` AS `V398`, `V399` AS `V399`, `V400` AS `V400`, `V401` AS `V401`, `V402` AS `V402`, `V403` AS `V403`, `V404` AS `V404`, `V405` AS `V405`, `V406` AS `V406`, `V407` AS `V407`, `V408` AS `V408`, `V409` AS `V409`, `V410` AS `V410`, `V411` AS `V411`, `V412` AS `V412`, `V413` AS `V413`, `V414` AS `V414`, `V415` AS `V415`, `V416` AS `V416`, `V417` AS `V417`, `V418` AS `V418`, `V419` AS `V419`, `V420` AS `V420`, `V421` AS `V421`, `V422` AS `V422`, `V423` AS `V423`, `V424` AS `V424`, `V425` AS `V425`, `V426` AS `V426`, `V427` AS `V427`, `V428` AS `V428`, `V429` AS `V429`, `V430` AS `V430`, `V431` AS `V431`, `V432` AS `V432`, `V433` AS `V433`, `V434` AS `V434`, `V435` AS `V435`, `V436` AS `V436`, `V437` AS `V437`, `V438` AS `V438`, `V439` AS `V439`, `V440` AS `V440`, `V441` AS `V441`, `V442` AS `V442`, `V443` AS `V443`, `V444` AS `V444`, `V445` AS `V445`, `V446` AS `V446`, `V447` AS `V447`, `V448` AS `V448`, `V449` AS `V449`, `V450` AS `V450`, `V451` AS `V451`, `V452` AS `V452`, `V453` AS `V453`, `V454` AS `V454`, `V455` AS `V455`, `V456` AS `V456`, `V457` AS `V457`, `V458` AS `V458`, `V459` AS `V459`, `V460` AS `V460`, `V461` AS `V461`, `V462` AS `V462`, `V463` AS `V463`, `V464` AS `V464`, `V465` AS `V465`, `V466` AS `V466`, `V467` AS `V467`, `V468` AS `V468`, `V469` AS `V469`, `V470` AS `V470`, `V471` AS `V471`, `V472` AS `V472`, `V473` AS `V473`, `V474` AS `V474`, `V475` AS `V475`, `V476` AS `V476`, `V477` AS `V477`, `V478` AS `V478`, `V479` AS `V479`, `V480` AS `V480`, `V481` AS `V481`, `V482` AS `V482`, `V483` AS `V483`, `V484` AS `V484`, `V485` AS `V485`, `V486` AS `V486`, `V487` AS `V487`, `V488` AS `V488`, `V489` AS `V489`, `V490` AS `V490`, `V491` AS `V491`, `V492` AS `V492`, `V493` AS `V493`, `V494` AS `V494`, `V495` AS `V495`, `V496` AS `V496`, `V497` AS `V497`, `V498` AS `V498`, `V499` AS `V499`, `V500` AS `V500`, `V501` AS `V501`, `V502` AS `V502`, `V503` AS `V503`, `V504` AS `V504`, `V505` AS `V505`, `V506` AS `V506`, `V507` AS `V507`, `V508` AS `V508`, `V509` AS `V509`, `V510` AS `V510`, `V511` AS `V511`, `V512` AS `V512`, `V513` AS `V513`, `V514` AS `V514`, `V515` AS `V515`, `V516` AS `V516`, `V517` AS `V517`, `V518` AS `V518`, `V519` AS `V519`, `V520` AS `V520`, `V521` AS `V521`, `V522` AS `V522`, `V523` AS `V523`, `V524` AS `V524`, `V525` AS `V525`, `V526` AS `V526`, `V527` AS `V527`, `V528` AS `V528`, `V529` AS `V529`, `V530` AS `V530`, `V531` AS `V531`, `V532` AS `V532`, `V533` AS `V533`, `V534` AS `V534`, `V535` AS `V535`, `V536` AS `V536`, `V537` AS `V537`, `V538` AS `V538`, `V539` AS `V539`, `V540` AS `V540`, `V541` AS `V541`, `V542` AS `V542`, `V543` AS `V543`, `V544` AS `V544`, `V545` AS `V545`, `V546` AS `V546`, `V547` AS `V547`, `V548` AS `V548`, `V549` AS `V549`, `V550` AS `V550`, `V551` AS `V551`, `V552` AS `V552`, `V553` AS `V553`, `V554` AS `V554`, `V555` AS `V555`, `V556` AS `V556`, `V557` AS `V557`, `V558` AS `V558`, `V559` AS `V559`, `V560` AS `V560`, `V561` AS `V561`, `V562` AS `V562`, `V563` AS `V563`, `V564` AS `V564`, `V565` AS `V565`, `V566` AS `V566`, `V567` AS `V567`, `V568` AS `V568`, `V569` AS `V569`, `V570` AS `V570`, `V571` AS `V571`, `V572` AS `V572`, `V573` AS `V573`, `V574` AS `V574`, `V575` AS `V575`, `V576` AS `V576`, `V577` AS `V577`, `V578` AS `V578`, `V579` AS `V579`, `V580` AS `V580`, `V581` AS `V581`, `V582` AS `V582`, `V583` AS `V583`, `V584` AS `V584`, `V585` AS `V585`, `V586` AS `V586`, `V587` AS `V587`, `V588` AS `V588`, `V589` AS `V589`, `V590` AS `V590`, `V591` AS `V591`, `V592` AS `V592`, `V593` AS `V593`, `V594` AS `V594`, `V595` AS `V595`, `V596` AS `V596`, `V597` AS `V597`, `V598` AS `V598`, `V599` AS `V599`, `V600` AS `V600`, `V601` AS `V601`, `V602` AS `V602`, `V603` AS `V603`, `V604` AS `V604`, `V605` AS `V605`, `V606` AS `V606`, `V607` AS `V607`, `V608` AS `V608`, `V609` AS `V609`, `V610` AS `V610`, `V611` AS `V611`, `V612` AS `V612`, `V613` AS `V613`, `V614` AS `V614`, `V615` AS `V615`, `V616` AS `V616`, `V617` AS `V617`, `V618` AS `V618`, `V619` AS `V619`, `V620` AS `V620`, `V621` AS `V621`, `V622` AS `V622`, `V623` AS `V623`, `V624` AS `V624`, `V625` AS `V625`, `V626` AS `V626`, `V627` AS `V627`, `V628` AS `V628`, `V629` AS `V629`, `V630` AS `V630`, `V631` AS `V631`, `V632` AS `V632`, `V633` AS `V633`, `V634` AS `V634`, `V635` AS `V635`, `V636` AS `V636`, `V637` AS `V637`, `V638` AS `V638`, `V639` AS `V639`, `V640` AS `V640`, `V641` AS `V641`, `V642` AS `V642`, `V643` AS `V643`, `V644` AS `V644`, `V645` AS `V645`, `V646` AS `V646`, `V647` AS `V647`, `V648` AS `V648`, `V649` AS `V649`, `V650` AS `V650`, `V651` AS `V651`, `V652` AS `V652`, `V653` AS `V653`, `V654` AS `V654`, `V655` AS `V655`, `V656` AS `V656`, `V657` AS `V657`, `V658` AS `V658`, `V659` AS `V659`, `V660` AS `V660`, `V661` AS `V661`, `V662` AS `V662`, `V663` AS `V663`, `V664` AS `V664`, `V665` AS `V665`, `V666` AS `V666`, `V667` AS `V667`, `V668` AS `V668`, `V669` AS `V669`, `V670` AS `V670`, `V671` AS `V671`, `V672` AS `V672`, `V673` AS `V673`, `V674` AS `V674`, `V675` AS `V675`, `V676` AS `V676`, `V677` AS `V677`, `V678` AS `V678`, `V679` AS `V679`, `V680` AS `V680`, `V681` AS `V681`, `V682` AS `V682`, `V683` AS `V683`, `V684` AS `V684`, `V685` AS `V685`, `V686` AS `V686`, `V687` AS `V687`, `V688` AS `V688`, `V689` AS `V689`, `V690` AS `V690`, `V691` AS `V691`, `V692` AS `V692`, `V693` AS `V693`, `V694` AS `V694`, `V695` AS `V695`, `V696` AS `V696`, `V697` AS `V697`, `V698` AS `V698`, `V699` AS `V699`, `V700` AS `V700`, `V701` AS `V701`, `V702` AS `V702`, `V703` AS `V703`, `V704` AS `V704`, `V705` AS `V705`, `V706` AS `V706`, `V707` AS `V707`, `V708` AS `V708`, `V709` AS `V709`, `V710` AS `V710`, `V711` AS `V711`, `V712` AS `V712`, `V713` AS `V713`, `V714` AS `V714`, `V715` AS `V715`, `V716` AS `V716`, `V717` AS `V717`, `V718` AS `V718`, `V719` AS `V719`, `V720` AS `V720`, `V721` AS `V721`, `V722` AS `V722`, `V723` AS `V723`, `V724` AS `V724`, `V725` AS `V725`, `V726` AS `V726`, `V727` AS `V727`, `V728` AS `V728`, `V729` AS `V729`, `V730` AS `V730`, `V731` AS `V731`, `V732` AS `V732`, `V733` AS `V733`, `V734` AS `V734`, `V735` AS `V735`, `V736` AS `V736`, `V737` AS `V737`, `V738` AS `V738`, `V739` AS `V739`, `V740` AS `V740`, `V741` AS `V741`, `V742` AS `V742`, `V743` AS `V743`, `V744` AS `V744`, `V745` AS `V745`, `V746` AS `V746`, `V747` AS `V747`, `V748` AS `V748`, `V749` AS `V749`, `V750` AS `V750`, `V751` AS `V751`, `V752` AS `V752`, `V753` AS `V753`, `V754` AS `V754`, `V755` AS `V755`, `V756` AS `V756`, `V757` AS `V757`, `V758` AS `V758`, `V759` AS `V759`, `V760` AS `V760`, `V761` AS `V761`, `V762` AS `V762`, `V763` AS `V763`, `V764` AS `V764`, `V765` AS `V765`, `V766` AS `V766`, `V767` AS `V767`, `V768` AS `V768`, `V769` AS `V769`, `V770` AS `V770`, `V771` AS `V771`, `V772` AS `V772`, `V773` AS `V773`, `V774` AS `V774`, `V775` AS `V775`, `V776` AS `V776`, `V777` AS `V777`, `V778` AS `V778`, `V779` AS `V779`, `V780` AS `V780`, `V781` AS `V781`, `V782` AS `V782`, `V783` AS `V783`, `V784` AS `V784`, `V785` AS `V785`, `V786` AS `V786`, `V787` AS `V787`, `V788` AS `V788`, `V789` AS `V789`, `V790` AS `V790`, `V791` AS `V791`, `V792` AS `V792`, `V793` AS `V793`, `V794` AS `V794`, `V795` AS `V795`, `V796` AS `V796`, `V797` AS `V797`, `V798` AS `V798`, `V799` AS `V799`, `V800` AS `V800`, `V801` AS `V801`, `V802` AS `V802`, `V803` AS `V803`, `V804` AS `V804`, `V805` AS `V805`, `V806` AS `V806`, `V807` AS `V807`, `V808` AS `V808`, `V809` AS `V809`, `V810` AS `V810`, `V811` AS `V811`, `V812` AS `V812`, `V813` AS `V813`, `V814` AS `V814`, `V815` AS `V815`, `V816` AS `V816`, `V817` AS `V817`, `V818` AS `V818`, `V819` AS `V819`, `V820` AS `V820`, `V821` AS `V821`, `V822` AS `V822`, `V823` AS `V823`, `V824` AS `V824`, `V825` AS `V825`, `V826` AS `V826`, `V827` AS `V827`, `V828` AS `V828`, `V829` AS `V829`, `V830` AS `V830`, `V831` AS `V831`, `V832` AS `V832`, `V833` AS `V833`, `V834` AS `V834`, `V835` AS `V835`, `V836` AS `V836`, `V837` AS `V837`, `V838` AS `V838`, `V839` AS `V839`, `V840` AS `V840`, `V841` AS `V841`, `V842` AS `V842`, `V843` AS `V843`, `V844` AS `V844`, `V845` AS `V845`, `V846` AS `V846`, `V847` AS `V847`, `V848` AS `V848`, `V849` AS `V849`, `V850` AS `V850`, `V851` AS `V851`, `V852` AS `V852`, `V853` AS `V853`, `V854` AS `V854`, `V855` AS `V855`, `V856` AS `V856`, `V857` AS `V857`, `V858` AS `V858`, `V859` AS `V859`, `V860` AS `V860`, `V861` AS `V861`, `V862` AS `V862`, `V863` AS `V863`, `V864` AS `V864`, `V865` AS `V865`, `V866` AS `V866`, `V867` AS `V867`, `V868` AS `V868`, `V869` AS `V869`, `V870` AS `V870`, `V871` AS `V871`, `V872` AS `V872`, `V873` AS `V873`, `V874` AS `V874`, `V875` AS `V875`, `V876` AS `V876`, `V877` AS `V877`, `V878` AS `V878`, `V879` AS `V879`, `V880` AS `V880`, `V881` AS `V881`, `V882` AS `V882`, `V883` AS `V883`, `V884` AS `V884`, `V885` AS `V885`, `V886` AS `V886`, `V887` AS `V887`, `V888` AS `V888`, `V889` AS `V889`, `V890` AS `V890`, `V891` AS `V891`, `V892` AS `V892`, `V893` AS `V893`, `V894` AS `V894`, `V895` AS `V895`, `V896` AS `V896`, `V897` AS `V897`, `V898` AS `V898`, `V899` AS `V899`, `V900` AS `V900`, `V901` AS `V901`, `V902` AS `V902`, `V903` AS `V903`, `V904` AS `V904`, `V905` AS `V905`, `V906` AS `V906`, `V907` AS `V907`, `V908` AS `V908`, `V909` AS `V909`, `V910` AS `V910`, `V911` AS `V911`, `V912` AS `V912`, `V913` AS `V913`, `V914` AS `V914`, `V915` AS `V915`, `V916` AS `V916`, `V917` AS `V917`, `V918` AS `V918`, `V919` AS `V919`, `V920` AS `V920`, `V921` AS `V921`, `V922` AS `V922`, `V923` AS `V923`, `V924` AS `V924`, `V925` AS `V925`, `V926` AS `V926`, `V927` AS `V927`, `V928` AS `V928`, `V929` AS `V929`, `V930` AS `V930`, `V931` AS `V931`, `V932` AS `V932`, `V933` AS `V933`, `V934` AS `V934`, `V935` AS `V935`, `V936` AS `V936`, `V937` AS `V937`, `V938` AS `V938`, `V939` AS `V939`, `V940` AS `V940`, `V941` AS `V941`, `V942` AS `V942`, `V943` AS `V943`, `V944` AS `V944`, `V945` AS `V945`, `V946` AS `V946`, `V947` AS `V947`, `V948` AS `V948`, `V949` AS `V949`, `V950` AS `V950`, `V951` AS `V951`, `V952` AS `V952`, `V953` AS `V953`, `V954` AS `V954`, `V955` AS `V955`, `V956` AS `V956`, `V957` AS `V957`, `V958` AS `V958`, `V959` AS `V959`, `V960` AS `V960`, `V961` AS `V961`, `V962` AS `V962`, `V963` AS `V963`, `V964` AS `V964`, `V965` AS `V965`, `V966` AS `V966`, `V967` AS `V967`, `V968` AS `V968`, `V969` AS `V969`, `V970` AS `V970`, `V971` AS `V971`, `V972` AS `V972`, `V973` AS `V973`, `V974` AS `V974`, `V975` AS `V975`, `V976` AS `V976`, `V977` AS `V977`, `V978` AS `V978`, `V979` AS `V979`, `V980` AS `V980`, `V981` AS `V981`, `V982` AS `V982`, `V983` AS `V983`, `V984` AS `V984`, `V985` AS `V985`, `V986` AS `V986`, `V987` AS `V987`, `V988` AS `V988`, `V989` AS `V989`, `V990` AS `V990`, `V991` AS `V991`, `V992` AS `V992`, `V993` AS `V993`, `V994` AS `V994`, `V995` AS `V995`, `V996` AS `V996`, `V997` AS `V997`, `V998` AS `V998`, `V999` AS `V999`, `V1000` AS `V1000`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S9` + 0.92736185 * RANDN() AS `V1`, `S7` + 0.92736185 * RANDN() AS `V2`, `S10` + 0.93273791 * RANDN() AS `V3`, `S5` + 0.90553851 * RANDN() AS `V4`, `S3` + 0.92195445 * RANDN() AS `V5`, `S7` + 0.92736185 * RANDN() AS `V6`, `S4` + 0.91104336 * RANDN() AS `V7`, `S9` + 0.92736185 * RANDN() AS `V8`, `S10` + 0.93273791 * RANDN() AS `V9`, `S5` + 0.90553851 * RANDN() AS `V10`, `S2` + 0.92195445 * RANDN() AS `V11`, `S5` + 0.90553851 * RANDN() AS `V12`, `S6` + 0.92736185 * RANDN() AS `V13`, `S9` + 0.92736185 * RANDN() AS `V14`, `S1` + 0.93808315 * RANDN() AS `V15`, `S2` + 0.92195445 * RANDN() AS `V16`, `S9` + 0.92736185 * RANDN() AS `V17`, `S3` + 0.92195445 * RANDN() AS `V18`, `S4` + 0.91104336 * RANDN() AS `V19`, `S9` + 0.92736185 * RANDN() AS `V20`, `S5` + 0.90553851 * RANDN() AS `V21`, `S5` + 0.90553851 * RANDN() AS `V22`, `S10` + 0.93273791 * RANDN() AS `V23`, `S3` + 0.92195445 * RANDN() AS `V24`, `S3` + 0.92195445 * RANDN() AS `V25`, `S5` + 0.90553851 * RANDN() AS `V26`, `S7` + 0.92736185 * RANDN() AS `V27`, `S5` + 0.90553851 * RANDN() AS `V28`, `S5` + 0.90553851 * RANDN() AS `V29`, `S10` + 0.93273791 * RANDN() AS `V30`, `S2` + 0.92195445 * RANDN() AS `V31`, `S4` + 0.91104336 * RANDN() AS `V32`, `S10` + 0.93273791 * RANDN() AS `V33`, `S10` + 0.93273791 * RANDN() AS `V34`, `S10` + 0.93273791 * RANDN() AS `V35`, `S1` + 0.93808315 * RANDN() AS `V36`, `S9` + 0.92736185 * RANDN() AS `V37`, `S7` + 0.92736185 * RANDN() AS `V38`, `S1` + 0.93808315 * RANDN() AS `V39`, `S1` + 0.93808315 * RANDN() AS `V40`, `S5` + 0.90553851 * RANDN() AS `V41`, `S6` + 0.92736185 * RANDN() AS `V42`, `S1` + 0.93808315 * RANDN() AS `V43`, `S7` + 0.92736185 * RANDN() AS `V44`, `S6` + 0.92736185 * RANDN() AS `V45`, `S2` + 0.92195445 * RANDN() AS `V46`, `S3` + 0.92195445 * RANDN() AS `V47`, `S6` + 0.92736185 * RANDN() AS `V48`, `S6` + 0.92736185 * RANDN() AS `V49`, `S6` + 0.92736185 * RANDN() AS `V50`, `S2` + 0.92195445 * RANDN() AS `V51`, `S4` + 0.91104336 * RANDN() AS `V52`, `S2` + 0.92195445 * RANDN() AS `V53`, `S8` + 0.94339811 * RANDN() AS `V54`, `S7` + 0.92736185 * RANDN() AS `V55`, `S2` + 0.92195445 * RANDN() AS `V56`, `S7` + 0.92736185 * RANDN() AS `V57`, `S8` + 0.94339811 * RANDN() AS `V58`, `S2` + 0.92195445 * RANDN() AS `V59`, `S3` + 0.92195445 * RANDN() AS `V60`, `S5` + 0.90553851 * RANDN() AS `V61`, `S6` + 0.92736185 * RANDN() AS `V62`, `S3` + 0.92195445 * RANDN() AS `V63`, `S9` + 0.92736185 * RANDN() AS `V64`, `S3` + 0.92195445 * RANDN() AS `V65`, `S8` + 0.94339811 * RANDN() AS `V66`, `S6` + 0.92736185 * RANDN() AS `V67`, `S6` + 0.92736185 * RANDN() AS `V68`, `S6` + 0.92736185 * RANDN() AS `V69`, `S4` + 0.91104336 * RANDN() AS `V70`, `S4` + 0.91104336 * RANDN() AS `V71`, `S9` + 0.92736185 * RANDN() AS `V72`, `S7` + 0.92736185 * RANDN() AS `V73`, `S10` + 0.93273791 * RANDN() AS `V74`, `S7` + 0.92736185 * RANDN() AS `V75`, `S1` + 0.93808315 * RANDN() AS `V76`, `S7` + 0.92736185 * RANDN() AS `V77`, `S3` + 0.92195445 * RANDN() AS `V78`, `S4` + 0.91104336 * RANDN() AS `V79`, `S8` + 0.94339811 * RANDN() AS `V80`, `S10` + 0.93273791 * RANDN() AS `V81`, `S2` + 0.92195445 * RANDN() AS `V82`, `S6` + 0.92736185 * RANDN() AS `V83`, `S8` + 0.94339811 * RANDN() AS `V84`, `S10` + 0.93273791 * RANDN() AS `V85`, `S3` + 0.92195445 * RANDN() AS `V86`, `S8` + 0.94339811 * RANDN() AS `V87`, `S6` + 0.92736185 * RANDN() AS `V88`, `S7` + 0.92736185 * RANDN() AS `V89`, `S9` + 0.92736185 * RANDN() AS `V90`, `S5` + 0.90553851 * RANDN() AS `V91`, `S4` + 0.91104336 * RANDN() AS `V92`, `S8` + 0.94339811 * RANDN() AS `V93`, `S4` + 0.91104336 * RANDN() AS `V94`, `S1` + 0.93808315 * RANDN() AS `V95`, `S8` + 0.94339811 * RANDN() AS `V96`, `S4` + 0.91104336 * RANDN() AS `V97`, `S6` + 0.92736185 * RANDN() AS `V98`, `S7` + 0.92736185 * RANDN() AS `V99`, `S10` + 0.93273791 * RANDN() AS `V100`, `S2` + 0.92195445 * RANDN() AS `V101`, `S2` + 0.92195445 * RANDN() AS `V102`, `S1` + 0.93808315 * RANDN() AS `V103`, `S5` + 0.90553851 * RANDN() AS `V104`, `S3` + 0.92195445 * RANDN() AS `V105`, `S2` + 0.92195445 * RANDN() AS `V106`, `S7` + 0.92736185 * RANDN() AS `V107`, `S5` + 0.90553851 * RANDN() AS `V108`, `S3` + 0.92195445 * RANDN() AS `V109`, `S10` + 0.93273791 * RANDN() AS `V110`, `S2` + 0.92195445 * RANDN() AS `V111`, `S2` + 0.92195445 * RANDN() AS `V112`, `S10` + 0.93273791 * RANDN() AS `V113`, `S5` + 0.90553851 * RANDN() AS `V114`, `S2` + 0.92195445 * RANDN() AS `V115`, `S9` + 0.92736185 * RANDN() AS `V116`, `S6` + 0.92736185 * RANDN() AS `V117`, `S10` + 0.93273791 * RANDN() AS `V118`, `S1` + 0.93808315 * RANDN() AS `V119`, `S6` + 0.92736185 * RANDN() AS `V120`, `S1` + 0.93808315 * RANDN() AS `V121`, `S4` + 0.91104336 * RANDN() AS `V122`, `S6` + 0.92736185 * RANDN() AS `V123`, `S10` + 0.93273791 * RANDN() AS `V124`, `S9` + 0.92736185 * RANDN() AS `V125`, `S5` + 0.90553851 * RANDN() AS `V126`, `S5` + 0.90553851 * RANDN() AS `V127`, `S7` + 0.92736185 * RANDN() AS `V128`, `S7` + 0.92736185 * RANDN() AS `V129`, `S8` + 0.94339811 * RANDN() AS `V130`, `S7` + 0.92736185 * RANDN() AS `V131`, `S2` + 0.92195445 * RANDN() AS `V132`, `S4` + 0.91104336 * RANDN() AS `V133`, `S3` + 0.92195445 * RANDN() AS `V134`, `S7` + 0.92736185 * RANDN() AS `V135`, `S9` + 0.92736185 * RANDN() AS `V136`, `S9` + 0.92736185 * RANDN() AS `V137`, `S8` + 0.94339811 * RANDN() AS `V138`, `S1` + 0.93808315 * RANDN() AS `V139`, `S3` + 0.92195445 * RANDN() AS `V140`, `S2` + 0.92195445 * RANDN() AS `V141`, `S6` + 0.92736185 * RANDN() AS `V142`, `S4` + 0.91104336 * RANDN() AS `V143`, `S1` + 0.93808315 * RANDN() AS `V144`, `S4` + 0.91104336 * RANDN() AS `V145`, `S4` + 0.91104336 * RANDN() AS `V146`, `S1` + 0.93808315 * RANDN() AS `V147`, `S10` + 0.93273791 * RANDN() AS `V148`, `S7` + 0.92736185 * RANDN() AS `V149`, `S9` + 0.92736185 * RANDN() AS `V150`, `S7` + 0.92736185 * RANDN() AS `V151`, `S9` + 0.92736185 * RANDN() AS `V152`, `S5` + 0.90553851 * RANDN() AS `V153`, `S5` + 0.90553851 * RANDN() AS `V154`, `S3` + 0.92195445 * RANDN() AS `V155`, `S5` + 0.90553851 * RANDN() AS `V156`, `S7` + 0.92736185 * RANDN() AS `V157`, `S2` + 0.92195445 * RANDN() AS `V158`, `S3` + 0.92195445 * RANDN() AS `V159`, `S4` + 0.91104336 * RANDN() AS `V160`, `S8` + 0.94339811 * RANDN() AS `V161`, `S6` + 0.92736185 * RANDN() AS `V162`, `S5` + 0.90553851 * RANDN() AS `V163`, `S10` + 0.93273791 * RANDN() AS `V164`, `S2` + 0.92195445 * RANDN() AS `V165`, `S3` + 0.92195445 * RANDN() AS `V166`, `S5` + 0.90553851 * RANDN() AS `V167`, `S4` + 0.91104336 * RANDN() AS `V168`, `S4` + 0.91104336 * RANDN() AS `V169`, `S5` + 0.90553851 * RANDN() AS `V170`, `S7` + 0.92736185 * RANDN() AS `V171`, `S3` + 0.92195445 * RANDN() AS `V172`, `S8` + 0.94339811 * RANDN() AS `V173`, `S3` + 0.92195445 * RANDN() AS `V174`, `S10` + 0.93273791 * RANDN() AS `V175`, `S2` + 0.92195445 * RANDN() AS `V176`, `S5` + 0.90553851 * RANDN() AS `V177`, `S3` + 0.92195445 * RANDN() AS `V178`, `S2` + 0.92195445 * RANDN() AS `V179`, `S5` + 0.90553851 * RANDN() AS `V180`, `S5` + 0.90553851 * RANDN() AS `V181`, `S1` + 0.93808315 * RANDN() AS `V182`, `S5` + 0.90553851 * RANDN() AS `V183`, `S4` + 0.91104336 * RANDN() AS `V184`, `S9` + 0.92736185 * RANDN() AS `V185`, `S5` + 0.90553851 * RANDN() AS `V186`, `S3` + 0.92195445 * RANDN() AS `V187`, `S9` + 0.92736185 * RANDN() AS `V188`, `S6` + 0.92736185 * RANDN() AS `V189`, `S2` + 0.92195445 * RANDN() AS `V190`, `S8` + 0.94339811 * RANDN() AS `V191`, `S3` + 0.92195445 * RANDN() AS `V192`, `S6` + 0.92736185 * RANDN() AS `V193`, `S7` + 0.92736185 * RANDN() AS `V194`, `S6` + 0.92736185 * RANDN() AS `V195`, `S3` + 0.92195445 * RANDN() AS `V196`, `S1` + 0.93808315 * RANDN() AS `V197`, `S3` + 0.92195445 * RANDN() AS `V198`, `S6` + 0.92736185 * RANDN() AS `V199`, `S5` + 0.90553851 * RANDN() AS `V200`, `S1` + 0.93808315 * RANDN() AS `V201`, `S8` + 0.94339811 * RANDN() AS `V202`, `S4` + 0.91104336 * RANDN() AS `V203`, `S6` + 0.92736185 * RANDN() AS `V204`, `S2` + 0.92195445 * RANDN() AS `V205`, `S2` + 0.92195445 * RANDN() AS `V206`, `S8` + 0.94339811 * RANDN() AS `V207`, `S5` + 0.90553851 * RANDN() AS `V208`, `S7` + 0.92736185 * RANDN() AS `V209`, `S9` + 0.92736185 * RANDN() AS `V210`, `S1` + 0.93808315 * RANDN() AS `V211`, `S1` + 0.93808315 * RANDN() AS `V212`, `S1` + 0.93808315 * RANDN() AS `V213`, `S5` + 0.90553851 * RANDN() AS `V214`, `S3` + 0.92195445 * RANDN() AS `V215`, `S6` + 0.92736185 * RANDN() AS `V216`, `S8` + 0.94339811 * RANDN() AS `V217`, `S5` + 0.90553851 * RANDN() AS `V218`, `S5` + 0.90553851 * RANDN() AS `V219`, `S8` + 0.94339811 * RANDN() AS `V220`, `S2` + 0.92195445 * RANDN() AS `V221`, `S1` + 0.93808315 * RANDN() AS `V222`, `S4` + 0.91104336 * RANDN() AS `V223`, `S9` + 0.92736185 * RANDN() AS `V224`, `S6` + 0.92736185 * RANDN() AS `V225`, `S7` + 0.92736185 * RANDN() AS `V226`, `S10` + 0.93273791 * RANDN() AS `V227`, `S5` + 0.90553851 * RANDN() AS `V228`, `S4` + 0.91104336 * RANDN() AS `V229`, `S5` + 0.90553851 * RANDN() AS `V230`, `S8` + 0.94339811 * RANDN() AS `V231`, `S1` + 0.93808315 * RANDN() AS `V232`, `S2` + 0.92195445 * RANDN() AS `V233`, `S9` + 0.92736185 * RANDN() AS `V234`, `S8` + 0.94339811 * RANDN() AS `V235`, `S8` + 0.94339811 * RANDN() AS `V236`, `S6` + 0.92736185 * RANDN() AS `V237`, `S5` + 0.90553851 * RANDN() AS `V238`, `S10` + 0.93273791 * RANDN() AS `V239`, `S4` + 0.91104336 * RANDN() AS `V240`, `S9` + 0.92736185 * RANDN() AS `V241`, `S9` + 0.92736185 * RANDN() AS `V242`, `S3` + 0.92195445 * RANDN() AS `V243`, `S3` + 0.92195445 * RANDN() AS `V244`, `S2` + 0.92195445 * RANDN() AS `V245`, `S3` + 0.92195445 * RANDN() AS `V246`, `S1` + 0.93808315 * RANDN() AS `V247`, `S9` + 0.92736185 * RANDN() AS `V248`, `S10` + 0.93273791 * RANDN() AS `V249`, `S6` + 0.92736185 * RANDN() AS `V250`, `S10` + 0.93273791 * RANDN() AS `V251`, `S4` + 0.91104336 * RANDN() AS `V252`, `S5` + 0.90553851 * RANDN() AS `V253`, `S4` + 0.91104336 * RANDN() AS `V254`, `S4` + 0.91104336 * RANDN() AS `V255`, `S5` + 0.90553851 * RANDN() AS `V256`, `S2` + 0.92195445 * RANDN() AS `V257`, `S7` + 0.92736185 * RANDN() AS `V258`, `S10` + 0.93273791 * RANDN() AS `V259`, `S3` + 0.92195445 * RANDN() AS `V260`, `S2` + 0.92195445 * RANDN() AS `V261`, `S2` + 0.92195445 * RANDN() AS `V262`, `S2` + 0.92195445 * RANDN() AS `V263`, `S7` + 0.92736185 * RANDN() AS `V264`, `S9` + 0.92736185 * RANDN() AS `V265`, `S1` + 0.93808315 * RANDN() AS `V266`, `S5` + 0.90553851 * RANDN() AS `V267`, `S7` + 0.92736185 * RANDN() AS `V268`, `S8` + 0.94339811 * RANDN() AS `V269`, `S6` + 0.92736185 * RANDN() AS `V270`, `S6` + 0.92736185 * RANDN() AS `V271`, `S9` + 0.92736185 * RANDN() AS `V272`, `S6` + 0.92736185 * RANDN() AS `V273`, `S7` + 0.92736185 * RANDN() AS `V274`, `S8` + 0.94339811 * RANDN() AS `V275`, `S8` + 0.94339811 * RANDN() AS `V276`, `S6` + 0.92736185 * RANDN() AS `V277`, `S9` + 0.92736185 * RANDN() AS `V278`, `S9` + 0.92736185 * RANDN() AS `V279`, `S8` + 0.94339811 * RANDN() AS `V280`, `S2` + 0.92195445 * RANDN() AS `V281`, `S4` + 0.91104336 * RANDN() AS `V282`, `S1` + 0.93808315 * RANDN() AS `V283`, `S4` + 0.91104336 * RANDN() AS `V284`, `S1` + 0.93808315 * RANDN() AS `V285`, `S8` + 0.94339811 * RANDN() AS `V286`, `S7` + 0.92736185 * RANDN() AS `V287`, `S4` + 0.91104336 * RANDN() AS `V288`, `S3` + 0.92195445 * RANDN() AS `V289`, `S1` + 0.93808315 * RANDN() AS `V290`, `S8` + 0.94339811 * RANDN() AS `V291`, `S1` + 0.93808315 * RANDN() AS `V292`, `S2` + 0.92195445 * RANDN() AS `V293`, `S10` + 0.93273791 * RANDN() AS `V294`, `S4` + 0.91104336 * RANDN() AS `V295`, `S4` + 0.91104336 * RANDN() AS `V296`, `S7` + 0.92736185 * RANDN() AS `V297`, `S4` + 0.91104336 * RANDN() AS `V298`, `S10` + 0.93273791 * RANDN() AS `V299`, `S8` + 0.94339811 * RANDN() AS `V300`, `S9` + 0.92736185 * RANDN() AS `V301`, `S8` + 0.94339811 * RANDN() AS `V302`, `S4` + 0.91104336 * RANDN() AS `V303`, `S2` + 0.92195445 * RANDN() AS `V304`, `S2` + 0.92195445 * RANDN() AS `V305`, `S8` + 0.94339811 * RANDN() AS `V306`, `S2` + 0.92195445 * RANDN() AS `V307`, `S1` + 0.93808315 * RANDN() AS `V308`, `S3` + 0.92195445 * RANDN() AS `V309`, `S6` + 0.92736185 * RANDN() AS `V310`, `S8` + 0.94339811 * RANDN() AS `V311`, `S1` + 0.93808315 * RANDN() AS `V312`, `S2` + 0.92195445 * RANDN() AS `V313`, `S1` + 0.93808315 * RANDN() AS `V314`, `S2` + 0.92195445 * RANDN() AS `V315`, `S10` + 0.93273791 * RANDN() AS `V316`, `S4` + 0.91104336 * RANDN() AS `V317`, `S4` + 0.91104336 * RANDN() AS `V318`, `S4` + 0.91104336 * RANDN() AS `V319`, `S3` + 0.92195445 * RANDN() AS `V320`, `S6` + 0.92736185 * RANDN() AS `V321`, `S6` + 0.92736185 * RANDN() AS `V322`, `S10` + 0.93273791 * RANDN() AS `V323`, `S5` + 0.90553851 * RANDN() AS `V324`, `S4` + 0.91104336 * RANDN() AS `V325`, `S9` + 0.92736185 * RANDN() AS `V326`, `S8` + 0.94339811 * RANDN() AS `V327`, `S4` + 0.91104336 * RANDN() AS `V328`, `S9` + 0.92736185 * RANDN() AS `V329`, `S2` + 0.92195445 * RANDN() AS `V330`, `S8` + 0.94339811 * RANDN() AS `V331`, `S10` + 0.93273791 * RANDN() AS `V332`, `S8` + 0.94339811 * RANDN() AS `V333`, `S9` + 0.92736185 * RANDN() AS `V334`, `S4` + 0.91104336 * RANDN() AS `V335`, `S1` + 0.93808315 * RANDN() AS `V336`, `S4` + 0.91104336 * RANDN() AS `V337`, `S5` + 0.90553851 * RANDN() AS `V338`, `S8` + 0.94339811 * RANDN() AS `V339`, `S1` + 0.93808315 * RANDN() AS `V340`, `S3` + 0.92195445 * RANDN() AS `V341`, `S6` + 0.92736185 * RANDN() AS `V342`, `S9` + 0.92736185 * RANDN() AS `V343`, `S2` + 0.92195445 * RANDN() AS `V344`, `S2` + 0.92195445 * RANDN() AS `V345`, `S3` + 0.92195445 * RANDN() AS `V346`, `S1` + 0.93808315 * RANDN() AS `V347`, `S2` + 0.92195445 * RANDN() AS `V348`, `S4` + 0.91104336 * RANDN() AS `V349`, `S4` + 0.91104336 * RANDN() AS `V350`, `S6` + 0.92736185 * RANDN() AS `V351`, `S5` + 0.90553851 * RANDN() AS `V352`, `S10` + 0.93273791 * RANDN() AS `V353`, `S4` + 0.91104336 * RANDN() AS `V354`, `S8` + 0.94339811 * RANDN() AS `V355`, `S1` + 0.93808315 * RANDN() AS `V356`, `S4` + 0.91104336 * RANDN() AS `V357`, `S8` + 0.94339811 * RANDN() AS `V358`, `S3` + 0.92195445 * RANDN() AS `V359`, `S5` + 0.90553851 * RANDN() AS `V360`, `S1` + 0.93808315 * RANDN() AS `V361`, `S5` + 0.90553851 * RANDN() AS `V362`, `S3` + 0.92195445 * RANDN() AS `V363`, `S8` + 0.94339811 * RANDN() AS `V364`, `S6` + 0.92736185 * RANDN() AS `V365`, `S10` + 0.93273791 * RANDN() AS `V366`, `S4` + 0.91104336 * RANDN() AS `V367`, `S4` + 0.91104336 * RANDN() AS `V368`, `S8` + 0.94339811 * RANDN() AS `V369`, `S6` + 0.92736185 * RANDN() AS `V370`, `S3` + 0.92195445 * RANDN() AS `V371`, `S1` + 0.93808315 * RANDN() AS `V372`, `S8` + 0.94339811 * RANDN() AS `V373`, `S5` + 0.90553851 * RANDN() AS `V374`, `S9` + 0.92736185 * RANDN() AS `V375`, `S9` + 0.92736185 * RANDN() AS `V376`, `S4` + 0.91104336 * RANDN() AS `V377`, `S9` + 0.92736185 * RANDN() AS `V378`, `S8` + 0.94339811 * RANDN() AS `V379`, `S10` + 0.93273791 * RANDN() AS `V380`, `S1` + 0.93808315 * RANDN() AS `V381`, `S4` + 0.91104336 * RANDN() AS `V382`, `S2` + 0.92195445 * RANDN() AS `V383`, `S6` + 0.92736185 * RANDN() AS `V384`, `S10` + 0.93273791 * RANDN() AS `V385`, `S1` + 0.93808315 * RANDN() AS `V386`, `S4` + 0.91104336 * RANDN() AS `V387`, `S2` + 0.92195445 * RANDN() AS `V388`, `S10` + 0.93273791 * RANDN() AS `V389`, `S7` + 0.92736185 * RANDN() AS `V390`, `S6` + 0.92736185 * RANDN() AS `V391`, `S8` + 0.94339811 * RANDN() AS `V392`, `S9` + 0.92736185 * RANDN() AS `V393`, `S7` + 0.92736185 * RANDN() AS `V394`, `S8` + 0.94339811 * RANDN() AS `V395`, `S2` + 0.92195445 * RANDN() AS `V396`, `S7` + 0.92736185 * RANDN() AS `V397`, `S1` + 0.93808315 * RANDN() AS `V398`, `S10` + 0.93273791 * RANDN() AS `V399`, `S2` + 0.92195445 * RANDN() AS `V400`, `S8` + 0.94339811 * RANDN() AS `V401`, `S6` + 0.92736185 * RANDN() AS `V402`, `S5` + 0.90553851 * RANDN() AS `V403`, `S8` + 0.94339811 * RANDN() AS `V404`, `S3` + 0.92195445 * RANDN() AS `V405`, `S9` + 0.92736185 * RANDN() AS `V406`, `S10` + 0.93273791 * RANDN() AS `V407`, `S3` + 0.92195445 * RANDN() AS `V408`, `S10` + 0.93273791 * RANDN() AS `V409`, `S6` + 0.92736185 * RANDN() AS `V410`, `S3` + 0.92195445 * RANDN() AS `V411`, `S3` + 0.92195445 * RANDN() AS `V412`, `S8` + 0.94339811 * RANDN() AS `V413`, `S5` + 0.90553851 * RANDN() AS `V414`, `S5` + 0.90553851 * RANDN() AS `V415`, `S7` + 0.92736185 * RANDN() AS `V416`, `S8` + 0.94339811 * RANDN() AS `V417`, `S5` + 0.90553851 * RANDN() AS `V418`, `S5` + 0.90553851 * RANDN() AS `V419`, `S1` + 0.93808315 * RANDN() AS `V420`, `S2` + 0.92195445 * RANDN() AS `V421`, `S3` + 0.92195445 * RANDN() AS `V422`, `S3` + 0.92195445 * RANDN() AS `V423`, `S5` + 0.90553851 * RANDN() AS `V424`, `S4` + 0.91104336 * RANDN() AS `V425`, `S10` + 0.93273791 * RANDN() AS `V426`, `S1` + 0.93808315 * RANDN() AS `V427`, `S3` + 0.92195445 * RANDN() AS `V428`, `S10` + 0.93273791 * RANDN() AS `V429`, `S5` + 0.90553851 * RANDN() AS `V430`, `S6` + 0.92736185 * RANDN() AS `V431`, `S9` + 0.92736185 * RANDN() AS `V432`, `S8` + 0.94339811 * RANDN() AS `V433`, `S7` + 0.92736185 * RANDN() AS `V434`, `S1` + 0.93808315 * RANDN() AS `V435`, `S5` + 0.90553851 * RANDN() AS `V436`, `S7` + 0.92736185 * RANDN() AS `V437`, `S4` + 0.91104336 * RANDN() AS `V438`, `S9` + 0.92736185 * RANDN() AS `V439`, `S9` + 0.92736185 * RANDN() AS `V440`, `S9` + 0.92736185 * RANDN() AS `V441`, `S2` + 0.92195445 * RANDN() AS `V442`, `S5` + 0.90553851 * RANDN() AS `V443`, `S9` + 0.92736185 * RANDN() AS `V444`, `S7` + 0.92736185 * RANDN() AS `V445`, `S8` + 0.94339811 * RANDN() AS `V446`, `S8` + 0.94339811 * RANDN() AS `V447`, `S4` + 0.91104336 * RANDN() AS `V448`, `S9` + 0.92736185 * RANDN() AS `V449`, `S2` + 0.92195445 * RANDN() AS `V450`, `S2` + 0.92195445 * RANDN() AS `V451`, `S5` + 0.90553851 * RANDN() AS `V452`, `S9` + 0.92736185 * RANDN() AS `V453`, `S2` + 0.92195445 * RANDN() AS `V454`, `S9` + 0.92736185 * RANDN() AS `V455`, `S9` + 0.92736185 * RANDN() AS `V456`, `S6` + 0.92736185 * RANDN() AS `V457`, `S3` + 0.92195445 * RANDN() AS `V458`, `S1` + 0.93808315 * RANDN() AS `V459`, `S7` + 0.92736185 * RANDN() AS `V460`, `S3` + 0.92195445 * RANDN() AS `V461`, `S8` + 0.94339811 * RANDN() AS `V462`, `S9` + 0.92736185 * RANDN() AS `V463`, `S9` + 0.92736185 * RANDN() AS `V464`, `S9` + 0.92736185 * RANDN() AS `V465`, `S1` + 0.93808315 * RANDN() AS `V466`, `S2` + 0.92195445 * RANDN() AS `V467`, `S8` + 0.94339811 * RANDN() AS `V468`, `S7` + 0.92736185 * RANDN() AS `V469`, `S8` + 0.94339811 * RANDN() AS `V470`, `S10` + 0.93273791 * RANDN() AS `V471`, `S8` + 0.94339811 * RANDN() AS `V472`, `S2` + 0.92195445 * RANDN() AS `V473`, `S7` + 0.92736185 * RANDN() AS `V474`, `S3` + 0.92195445 * RANDN() AS `V475`, `S4` + 0.91104336 * RANDN() AS `V476`, `S5` + 0.90553851 * RANDN() AS `V477`, `S5` + 0.90553851 * RANDN() AS `V478`, `S10` + 0.93273791 * RANDN() AS `V479`, `S9` + 0.92736185 * RANDN() AS `V480`, `S1` + 0.93808315 * RANDN() AS `V481`, `S1` + 0.93808315 * RANDN() AS `V482`, `S5` + 0.90553851 * RANDN() AS `V483`, `S7` + 0.92736185 * RANDN() AS `V484`, `S4` + 0.91104336 * RANDN() AS `V485`, `S7` + 0.92736185 * RANDN() AS `V486`, `S9` + 0.92736185 * RANDN() AS `V487`, `S9` + 0.92736185 * RANDN() AS `V488`, `S4` + 0.91104336 * RANDN() AS `V489`, `S8` + 0.94339811 * RANDN() AS `V490`, `S10` + 0.93273791 * RANDN() AS `V491`, `S2` + 0.92195445 * RANDN() AS `V492`, `S8` + 0.94339811 * RANDN() AS `V493`, `S9` + 0.92736185 * RANDN() AS `V494`, `S6` + 0.92736185 * RANDN() AS `V495`, `S1` + 0.93808315 * RANDN() AS `V496`, `S10` + 0.93273791 * RANDN() AS `V497`, `S2` + 0.92195445 * RANDN() AS `V498`, `S9` + 0.92736185 * RANDN() AS `V499`, `S6` + 0.92736185 * RANDN() AS `V500`, `S4` + 0.91104336 * RANDN() AS `V501`, `S8` + 0.94339811 * RANDN() AS `V502`, `S9` + 0.92736185 * RANDN() AS `V503`, `S8` + 0.94339811 * RANDN() AS `V504`, `S7` + 0.92736185 * RANDN() AS `V505`, `S8` + 0.94339811 * RANDN() AS `V506`, `S4` + 0.91104336 * RANDN() AS `V507`, `S8` + 0.94339811 * RANDN() AS `V508`, `S8` + 0.94339811 * RANDN() AS `V509`, `S6` + 0.92736185 * RANDN() AS `V510`, `S2` + 0.92195445 * RANDN() AS `V511`, `S1` + 0.93808315 * RANDN() AS `V512`, `S5` + 0.90553851 * RANDN() AS `V513`, `S7` + 0.92736185 * RANDN() AS `V514`, `S3` + 0.92195445 * RANDN() AS `V515`, `S2` + 0.92195445 * RANDN() AS `V516`, `S10` + 0.93273791 * RANDN() AS `V517`, `S6` + 0.92736185 * RANDN() AS `V518`, `S1` + 0.93808315 * RANDN() AS `V519`, `S1` + 0.93808315 * RANDN() AS `V520`, `S10` + 0.93273791 * RANDN() AS `V521`, `S2` + 0.92195445 * RANDN() AS `V522`, `S4` + 0.91104336 * RANDN() AS `V523`, `S4` + 0.91104336 * RANDN() AS `V524`, `S2` + 0.92195445 * RANDN() AS `V525`, `S7` + 0.92736185 * RANDN() AS `V526`, `S9` + 0.92736185 * RANDN() AS `V527`, `S1` + 0.93808315 * RANDN() AS `V528`, `S5` + 0.90553851 * RANDN() AS `V529`, `S8` + 0.94339811 * RANDN() AS `V530`, `S5` + 0.90553851 * RANDN() AS `V531`, `S9` + 0.92736185 * RANDN() AS `V532`, `S3` + 0.92195445 * RANDN() AS `V533`, `S3` + 0.92195445 * RANDN() AS `V534`, `S1` + 0.93808315 * RANDN() AS `V535`, `S7` + 0.92736185 * RANDN() AS `V536`, `S3` + 0.92195445 * RANDN() AS `V537`, `S8` + 0.94339811 * RANDN() AS `V538`, `S8` + 0.94339811 * RANDN() AS `V539`, `S10` + 0.93273791 * RANDN() AS `V540`, `S9` + 0.92736185 * RANDN() AS `V541`, `S6` + 0.92736185 * RANDN() AS `V542`, `S10` + 0.93273791 * RANDN() AS `V543`, `S4` + 0.91104336 * RANDN() AS `V544`, `S2` + 0.92195445 * RANDN() AS `V545`, `S5` + 0.90553851 * RANDN() AS `V546`, `S2` + 0.92195445 * RANDN() AS `V547`, `S9` + 0.92736185 * RANDN() AS `V548`, `S3` + 0.92195445 * RANDN() AS `V549`, `S9` + 0.92736185 * RANDN() AS `V550`, `S1` + 0.93808315 * RANDN() AS `V551`, `S1` + 0.93808315 * RANDN() AS `V552`, `S8` + 0.94339811 * RANDN() AS `V553`, `S6` + 0.92736185 * RANDN() AS `V554`, `S8` + 0.94339811 * RANDN() AS `V555`, `S1` + 0.93808315 * RANDN() AS `V556`, `S7` + 0.92736185 * RANDN() AS `V557`, `S6` + 0.92736185 * RANDN() AS `V558`, `S4` + 0.91104336 * RANDN() AS `V559`, `S9` + 0.92736185 * RANDN() AS `V560`, `S3` + 0.92195445 * RANDN() AS `V561`, `S2` + 0.92195445 * RANDN() AS `V562`, `S2` + 0.92195445 * RANDN() AS `V563`, `S5` + 0.90553851 * RANDN() AS `V564`, `S9` + 0.92736185 * RANDN() AS `V565`, `S9` + 0.92736185 * RANDN() AS `V566`, `S2` + 0.92195445 * RANDN() AS `V567`, `S3` + 0.92195445 * RANDN() AS `V568`, `S4` + 0.91104336 * RANDN() AS `V569`, `S9` + 0.92736185 * RANDN() AS `V570`, `S1` + 0.93808315 * RANDN() AS `V571`, `S2` + 0.92195445 * RANDN() AS `V572`, `S8` + 0.94339811 * RANDN() AS `V573`, `S6` + 0.92736185 * RANDN() AS `V574`, `S4` + 0.91104336 * RANDN() AS `V575`, `S3` + 0.92195445 * RANDN() AS `V576`, `S10` + 0.93273791 * RANDN() AS `V577`, `S7` + 0.92736185 * RANDN() AS `V578`, `S5` + 0.90553851 * RANDN() AS `V579`, `S6` + 0.92736185 * RANDN() AS `V580`, `S8` + 0.94339811 * RANDN() AS `V581`, `S2` + 0.92195445 * RANDN() AS `V582`, `S1` + 0.93808315 * RANDN() AS `V583`, `S3` + 0.92195445 * RANDN() AS `V584`, `S10` + 0.93273791 * RANDN() AS `V585`, `S7` + 0.92736185 * RANDN() AS `V586`, `S9` + 0.92736185 * RANDN() AS `V587`, `S10` + 0.93273791 * RANDN() AS `V588`, `S9` + 0.92736185 * RANDN() AS `V589`, `S7` + 0.92736185 * RANDN() AS `V590`, `S7` + 0.92736185 * RANDN() AS `V591`, `S4` + 0.91104336 * RANDN() AS `V592`, `S9` + 0.92736185 * RANDN() AS `V593`, `S7` + 0.92736185 * RANDN() AS `V594`, `S9` + 0.92736185 * RANDN() AS `V595`, `S10` + 0.93273791 * RANDN() AS `V596`, `S4` + 0.91104336 * RANDN() AS `V597`, `S2` + 0.92195445 * RANDN() AS `V598`, `S9` + 0.92736185 * RANDN() AS `V599`, `S9` + 0.92736185 * RANDN() AS `V600`, `S9` + 0.92736185 * RANDN() AS `V601`, `S7` + 0.92736185 * RANDN() AS `V602`, `S3` + 0.92195445 * RANDN() AS `V603`, `S5` + 0.90553851 * RANDN() AS `V604`, `S10` + 0.93273791 * RANDN() AS `V605`, `S1` + 0.93808315 * RANDN() AS `V606`, `S6` + 0.92736185 * RANDN() AS `V607`, `S1` + 0.93808315 * RANDN() AS `V608`, `S4` + 0.91104336 * RANDN() AS `V609`, `S10` + 0.93273791 * RANDN() AS `V610`, `S6` + 0.92736185 * RANDN() AS `V611`, `S4` + 0.91104336 * RANDN() AS `V612`, `S3` + 0.92195445 * RANDN() AS `V613`, `S9` + 0.92736185 * RANDN() AS `V614`, `S10` + 0.93273791 * RANDN() AS `V615`, `S7` + 0.92736185 * RANDN() AS `V616`, `S8` + 0.94339811 * RANDN() AS `V617`, `S2` + 0.92195445 * RANDN() AS `V618`, `S1` + 0.93808315 * RANDN() AS `V619`, `S3` + 0.92195445 * RANDN() AS `V620`, `S3` + 0.92195445 * RANDN() AS `V621`, `S2` + 0.92195445 * RANDN() AS `V622`, `S2` + 0.92195445 * RANDN() AS `V623`, `S8` + 0.94339811 * RANDN() AS `V624`, `S3` + 0.92195445 * RANDN() AS `V625`, `S10` + 0.93273791 * RANDN() AS `V626`, `S7` + 0.92736185 * RANDN() AS `V627`, `S5` + 0.90553851 * RANDN() AS `V628`, `S10` + 0.93273791 * RANDN() AS `V629`, `S6` + 0.92736185 * RANDN() AS `V630`, `S9` + 0.92736185 * RANDN() AS `V631`, `S2` + 0.92195445 * RANDN() AS `V632`, `S4` + 0.91104336 * RANDN() AS `V633`, `S9` + 0.92736185 * RANDN() AS `V634`, `S1` + 0.93808315 * RANDN() AS `V635`, `S3` + 0.92195445 * RANDN() AS `V636`, `S1` + 0.93808315 * RANDN() AS `V637`, `S3` + 0.92195445 * RANDN() AS `V638`, `S3` + 0.92195445 * RANDN() AS `V639`, `S9` + 0.92736185 * RANDN() AS `V640`, `S8` + 0.94339811 * RANDN() AS `V641`, `S10` + 0.93273791 * RANDN() AS `V642`, `S7` + 0.92736185 * RANDN() AS `V643`, `S8` + 0.94339811 * RANDN() AS `V644`, `S3` + 0.92195445 * RANDN() AS `V645`, `S9` + 0.92736185 * RANDN() AS `V646`, `S6` + 0.92736185 * RANDN() AS `V647`, `S9` + 0.92736185 * RANDN() AS `V648`, `S3` + 0.92195445 * RANDN() AS `V649`, `S9` + 0.92736185 * RANDN() AS `V650`, `S3` + 0.92195445 * RANDN() AS `V651`, `S10` + 0.93273791 * RANDN() AS `V652`, `S8` + 0.94339811 * RANDN() AS `V653`, `S2` + 0.92195445 * RANDN() AS `V654`, `S5` + 0.90553851 * RANDN() AS `V655`, `S5` + 0.90553851 * RANDN() AS `V656`, `S1` + 0.93808315 * RANDN() AS `V657`, `S9` + 0.92736185 * RANDN() AS `V658`, `S8` + 0.94339811 * RANDN() AS `V659`, `S7` + 0.92736185 * RANDN() AS `V660`, `S4` + 0.91104336 * RANDN() AS `V661`, `S9` + 0.92736185 * RANDN() AS `V662`, `S5` + 0.90553851 * RANDN() AS `V663`, `S10` + 0.93273791 * RANDN() AS `V664`, `S1` + 0.93808315 * RANDN() AS `V665`, `S10` + 0.93273791 * RANDN() AS `V666`, `S2` + 0.92195445 * RANDN() AS `V667`, `S5` + 0.90553851 * RANDN() AS `V668`, `S2` + 0.92195445 * RANDN() AS `V669`, `S6` + 0.92736185 * RANDN() AS `V670`, `S6` + 0.92736185 * RANDN() AS `V671`, `S1` + 0.93808315 * RANDN() AS `V672`, `S6` + 0.92736185 * RANDN() AS `V673`, `S4` + 0.91104336 * RANDN() AS `V674`, `S5` + 0.90553851 * RANDN() AS `V675`, `S9` + 0.92736185 * RANDN() AS `V676`, `S10` + 0.93273791 * RANDN() AS `V677`, `S7` + 0.92736185 * RANDN() AS `V678`, `S4` + 0.91104336 * RANDN() AS `V679`, `S7` + 0.92736185 * RANDN() AS `V680`, `S1` + 0.93808315 * RANDN() AS `V681`, `S4` + 0.91104336 * RANDN() AS `V682`, `S10` + 0.93273791 * RANDN() AS `V683`, `S4` + 0.91104336 * RANDN() AS `V684`, `S9` + 0.92736185 * RANDN() AS `V685`, `S7` + 0.92736185 * RANDN() AS `V686`, `S6` + 0.92736185 * RANDN() AS `V687`, `S4` + 0.91104336 * RANDN() AS `V688`, `S3` + 0.92195445 * RANDN() AS `V689`, `S3` + 0.92195445 * RANDN() AS `V690`, `S7` + 0.92736185 * RANDN() AS `V691`, `S4` + 0.91104336 * RANDN() AS `V692`, `S7` + 0.92736185 * RANDN() AS `V693`, `S5` + 0.90553851 * RANDN() AS `V694`, `S3` + 0.92195445 * RANDN() AS `V695`, `S6` + 0.92736185 * RANDN() AS `V696`, `S3` + 0.92195445 * RANDN() AS `V697`, `S9` + 0.92736185 * RANDN() AS `V698`, `S4` + 0.91104336 * RANDN() AS `V699`, `S7` + 0.92736185 * RANDN() AS `V700`, `S8` + 0.94339811 * RANDN() AS `V701`, `S5` + 0.90553851 * RANDN() AS `V702`, `S7` + 0.92736185 * RANDN() AS `V703`, `S9` + 0.92736185 * RANDN() AS `V704`, `S8` + 0.94339811 * RANDN() AS `V705`, `S7` + 0.92736185 * RANDN() AS `V706`, `S9` + 0.92736185 * RANDN() AS `V707`, `S10` + 0.93273791 * RANDN() AS `V708`, `S2` + 0.92195445 * RANDN() AS `V709`, `S4` + 0.91104336 * RANDN() AS `V710`, `S5` + 0.90553851 * RANDN() AS `V711`, `S6` + 0.92736185 * RANDN() AS `V712`, `S7` + 0.92736185 * RANDN() AS `V713`, `S10` + 0.93273791 * RANDN() AS `V714`, `S1` + 0.93808315 * RANDN() AS `V715`, `S10` + 0.93273791 * RANDN() AS `V716`, `S1` + 0.93808315 * RANDN() AS `V717`, `S5` + 0.90553851 * RANDN() AS `V718`, `S8` + 0.94339811 * RANDN() AS `V719`, `S10` + 0.93273791 * RANDN() AS `V720`, `S1` + 0.93808315 * RANDN() AS `V721`, `S1` + 0.93808315 * RANDN() AS `V722`, `S8` + 0.94339811 * RANDN() AS `V723`, `S6` + 0.92736185 * RANDN() AS `V724`, `S6` + 0.92736185 * RANDN() AS `V725`, `S4` + 0.91104336 * RANDN() AS `V726`, `S4` + 0.91104336 * RANDN() AS `V727`, `S7` + 0.92736185 * RANDN() AS `V728`, `S2` + 0.92195445 * RANDN() AS `V729`, `S2` + 0.92195445 * RANDN() AS `V730`, `S6` + 0.92736185 * RANDN() AS `V731`, `S8` + 0.94339811 * RANDN() AS `V732`, `S1` + 0.93808315 * RANDN() AS `V733`, `S8` + 0.94339811 * RANDN() AS `V734`, `S1` + 0.93808315 * RANDN() AS `V735`, `S10` + 0.93273791 * RANDN() AS `V736`, `S3` + 0.92195445 * RANDN() AS `V737`, `S2` + 0.92195445 * RANDN() AS `V738`, `S4` + 0.91104336 * RANDN() AS `V739`, `S6` + 0.92736185 * RANDN() AS `V740`, `S8` + 0.94339811 * RANDN() AS `V741`, `S4` + 0.91104336 * RANDN() AS `V742`, `S9` + 0.92736185 * RANDN() AS `V743`, `S7` + 0.92736185 * RANDN() AS `V744`, `S5` + 0.90553851 * RANDN() AS `V745`, `S3` + 0.92195445 * RANDN() AS `V746`, `S8` + 0.94339811 * RANDN() AS `V747`, `S1` + 0.93808315 * RANDN() AS `V748`, `S6` + 0.92736185 * RANDN() AS `V749`, `S9` + 0.92736185 * RANDN() AS `V750`, `S3` + 0.92195445 * RANDN() AS `V751`, `S4` + 0.91104336 * RANDN() AS `V752`, `S6` + 0.92736185 * RANDN() AS `V753`, `S5` + 0.90553851 * RANDN() AS `V754`, `S2` + 0.92195445 * RANDN() AS `V755`, `S10` + 0.93273791 * RANDN() AS `V756`, `S4` + 0.91104336 * RANDN() AS `V757`, `S10` + 0.93273791 * RANDN() AS `V758`, `S5` + 0.90553851 * RANDN() AS `V759`, `S6` + 0.92736185 * RANDN() AS `V760`, `S8` + 0.94339811 * RANDN() AS `V761`, `S10` + 0.93273791 * RANDN() AS `V762`, `S8` + 0.94339811 * RANDN() AS `V763`, `S2` + 0.92195445 * RANDN() AS `V764`, `S8` + 0.94339811 * RANDN() AS `V765`, `S6` + 0.92736185 * RANDN() AS `V766`, `S7` + 0.92736185 * RANDN() AS `V767`, `S5` + 0.90553851 * RANDN() AS `V768`, `S5` + 0.90553851 * RANDN() AS `V769`, `S1` + 0.93808315 * RANDN() AS `V770`, `S5` + 0.90553851 * RANDN() AS `V771`, `S8` + 0.94339811 * RANDN() AS `V772`, `S9` + 0.92736185 * RANDN() AS `V773`, `S5` + 0.90553851 * RANDN() AS `V774`, `S3` + 0.92195445 * RANDN() AS `V775`, `S4` + 0.91104336 * RANDN() AS `V776`, `S7` + 0.92736185 * RANDN() AS `V777`, `S2` + 0.92195445 * RANDN() AS `V778`, `S1` + 0.93808315 * RANDN() AS `V779`, `S10` + 0.93273791 * RANDN() AS `V780`, `S2` + 0.92195445 * RANDN() AS `V781`, `S1` + 0.93808315 * RANDN() AS `V782`, `S4` + 0.91104336 * RANDN() AS `V783`, `S10` + 0.93273791 * RANDN() AS `V784`, `S8` + 0.94339811 * RANDN() AS `V785`, `S5` + 0.90553851 * RANDN() AS `V786`, `S9` + 0.92736185 * RANDN() AS `V787`, `S4` + 0.91104336 * RANDN() AS `V788`, `S6` + 0.92736185 * RANDN() AS `V789`, `S10` + 0.93273791 * RANDN() AS `V790`, `S1` + 0.93808315 * RANDN() AS `V791`, `S6` + 0.92736185 * RANDN() AS `V792`, `S9` + 0.92736185 * RANDN() AS `V793`, `S10` + 0.93273791 * RANDN() AS `V794`, `S6` + 0.92736185 * RANDN() AS `V795`, `S4` + 0.91104336 * RANDN() AS `V796`, `S5` + 0.90553851 * RANDN() AS `V797`, `S3` + 0.92195445 * RANDN() AS `V798`, `S6` + 0.92736185 * RANDN() AS `V799`, `S4` + 0.91104336 * RANDN() AS `V800`, `S1` + 0.93808315 * RANDN() AS `V801`, `S9` + 0.92736185 * RANDN() AS `V802`, `S5` + 0.90553851 * RANDN() AS `V803`, `S7` + 0.92736185 * RANDN() AS `V804`, `S5` + 0.90553851 * RANDN() AS `V805`, `S9` + 0.92736185 * RANDN() AS `V806`, `S5` + 0.90553851 * RANDN() AS `V807`, `S1` + 0.93808315 * RANDN() AS `V808`, `S9` + 0.92736185 * RANDN() AS `V809`, `S7` + 0.92736185 * RANDN() AS `V810`, `S3` + 0.92195445 * RANDN() AS `V811`, `S10` + 0.93273791 * RANDN() AS `V812`, `S1` + 0.93808315 * RANDN() AS `V813`, `S1` + 0.93808315 * RANDN() AS `V814`, `S6` + 0.92736185 * RANDN() AS `V815`, `S2` + 0.92195445 * RANDN() AS `V816`, `S10` + 0.93273791 * RANDN() AS `V817`, `S6` + 0.92736185 * RANDN() AS `V818`, `S5` + 0.90553851 * RANDN() AS `V819`, `S10` + 0.93273791 * RANDN() AS `V820`, `S6` + 0.92736185 * RANDN() AS `V821`, `S1` + 0.93808315 * RANDN() AS `V822`, `S6` + 0.92736185 * RANDN() AS `V823`, `S5` + 0.90553851 * RANDN() AS `V824`, `S3` + 0.92195445 * RANDN() AS `V825`, `S7` + 0.92736185 * RANDN() AS `V826`, `S3` + 0.92195445 * RANDN() AS `V827`, `S1` + 0.93808315 * RANDN() AS `V828`, `S9` + 0.92736185 * RANDN() AS `V829`, `S3` + 0.92195445 * RANDN() AS `V830`, `S1` + 0.93808315 * RANDN() AS `V831`, `S7` + 0.92736185 * RANDN() AS `V832`, `S2` + 0.92195445 * RANDN() AS `V833`, `S8` + 0.94339811 * RANDN() AS `V834`, `S1` + 0.93808315 * RANDN() AS `V835`, `S4` + 0.91104336 * RANDN() AS `V836`, `S3` + 0.92195445 * RANDN() AS `V837`, `S5` + 0.90553851 * RANDN() AS `V838`, `S5` + 0.90553851 * RANDN() AS `V839`, `S9` + 0.92736185 * RANDN() AS `V840`, `S9` + 0.92736185 * RANDN() AS `V841`, `S10` + 0.93273791 * RANDN() AS `V842`, `S9` + 0.92736185 * RANDN() AS `V843`, `S9` + 0.92736185 * RANDN() AS `V844`, `S1` + 0.93808315 * RANDN() AS `V845`, `S9` + 0.92736185 * RANDN() AS `V846`, `S10` + 0.93273791 * RANDN() AS `V847`, `S5` + 0.90553851 * RANDN() AS `V848`, `S10` + 0.93273791 * RANDN() AS `V849`, `S1` + 0.93808315 * RANDN() AS `V850`, `S1` + 0.93808315 * RANDN() AS `V851`, `S6` + 0.92736185 * RANDN() AS `V852`, `S10` + 0.93273791 * RANDN() AS `V853`, `S5` + 0.90553851 * RANDN() AS `V854`, `S10` + 0.93273791 * RANDN() AS `V855`, `S2` + 0.92195445 * RANDN() AS `V856`, `S9` + 0.92736185 * RANDN() AS `V857`, `S8` + 0.94339811 * RANDN() AS `V858`, `S9` + 0.92736185 * RANDN() AS `V859`, `S7` + 0.92736185 * RANDN() AS `V860`, `S5` + 0.90553851 * RANDN() AS `V861`, `S7` + 0.92736185 * RANDN() AS `V862`, `S6` + 0.92736185 * RANDN() AS `V863`, `S10` + 0.93273791 * RANDN() AS `V864`, `S4` + 0.91104336 * RANDN() AS `V865`, `S9` + 0.92736185 * RANDN() AS `V866`, `S4` + 0.91104336 * RANDN() AS `V867`, `S1` + 0.93808315 * RANDN() AS `V868`, `S9` + 0.92736185 * RANDN() AS `V869`, `S9` + 0.92736185 * RANDN() AS `V870`, `S10` + 0.93273791 * RANDN() AS `V871`, `S5` + 0.90553851 * RANDN() AS `V872`, `S3` + 0.92195445 * RANDN() AS `V873`, `S1` + 0.93808315 * RANDN() AS `V874`, `S8` + 0.94339811 * RANDN() AS `V875`, `S1` + 0.93808315 * RANDN() AS `V876`, `S6` + 0.92736185 * RANDN() AS `V877`, `S4` + 0.91104336 * RANDN() AS `V878`, `S9` + 0.92736185 * RANDN() AS `V879`, `S7` + 0.92736185 * RANDN() AS `V880`, `S4` + 0.91104336 * RANDN() AS `V881`, `S3` + 0.92195445 * RANDN() AS `V882`, `S4` + 0.91104336 * RANDN() AS `V883`, `S1` + 0.93808315 * RANDN() AS `V884`, `S8` + 0.94339811 * RANDN() AS `V885`, `S2` + 0.92195445 * RANDN() AS `V886`, `S4` + 0.91104336 * RANDN() AS `V887`, `S7` + 0.92736185 * RANDN() AS `V888`, `S2` + 0.92195445 * RANDN() AS `V889`, `S2` + 0.92195445 * RANDN() AS `V890`, `S4` + 0.91104336 * RANDN() AS `V891`, `S2` + 0.92195445 * RANDN() AS `V892`, `S4` + 0.91104336 * RANDN() AS `V893`, `S10` + 0.93273791 * RANDN() AS `V894`, `S7` + 0.92736185 * RANDN() AS `V895`, `S10` + 0.93273791 * RANDN() AS `V896`, `S6` + 0.92736185 * RANDN() AS `V897`, `S9` + 0.92736185 * RANDN() AS `V898`, `S5` + 0.90553851 * RANDN() AS `V899`, `S1` + 0.93808315 * RANDN() AS `V900`, `S3` + 0.92195445 * RANDN() AS `V901`, `S4` + 0.91104336 * RANDN() AS `V902`, `S7` + 0.92736185 * RANDN() AS `V903`, `S2` + 0.92195445 * RANDN() AS `V904`, `S7` + 0.92736185 * RANDN() AS `V905`, `S6` + 0.92736185 * RANDN() AS `V906`, `S1` + 0.93808315 * RANDN() AS `V907`, `S6` + 0.92736185 * RANDN() AS `V908`, `S6` + 0.92736185 * RANDN() AS `V909`, `S6` + 0.92736185 * RANDN() AS `V910`, `S3` + 0.92195445 * RANDN() AS `V911`, `S6` + 0.92736185 * RANDN() AS `V912`, `S3` + 0.92195445 * RANDN() AS `V913`, `S5` + 0.90553851 * RANDN() AS `V914`, `S1` + 0.93808315 * RANDN() AS `V915`, `S8` + 0.94339811 * RANDN() AS `V916`, `S4` + 0.91104336 * RANDN() AS `V917`, `S5` + 0.90553851 * RANDN() AS `V918`, `S6` + 0.92736185 * RANDN() AS `V919`, `S4` + 0.91104336 * RANDN() AS `V920`, `S7` + 0.92736185 * RANDN() AS `V921`, `S5` + 0.90553851 * RANDN() AS `V922`, `S5` + 0.90553851 * RANDN() AS `V923`, `S1` + 0.93808315 * RANDN() AS `V924`, `S8` + 0.94339811 * RANDN() AS `V925`, `S7` + 0.92736185 * RANDN() AS `V926`, `S2` + 0.92195445 * RANDN() AS `V927`, `S1` + 0.93808315 * RANDN() AS `V928`, `S8` + 0.94339811 * RANDN() AS `V929`, `S6` + 0.92736185 * RANDN() AS `V930`, `S1` + 0.93808315 * RANDN() AS `V931`, `S10` + 0.93273791 * RANDN() AS `V932`, `S4` + 0.91104336 * RANDN() AS `V933`, `S8` + 0.94339811 * RANDN() AS `V934`, `S2` + 0.92195445 * RANDN() AS `V935`, `S2` + 0.92195445 * RANDN() AS `V936`, `S4` + 0.91104336 * RANDN() AS `V937`, `S10` + 0.93273791 * RANDN() AS `V938`, `S6` + 0.92736185 * RANDN() AS `V939`, `S3` + 0.92195445 * RANDN() AS `V940`, `S1` + 0.93808315 * RANDN() AS `V941`, `S5` + 0.90553851 * RANDN() AS `V942`, `S6` + 0.92736185 * RANDN() AS `V943`, `S9` + 0.92736185 * RANDN() AS `V944`, `S3` + 0.92195445 * RANDN() AS `V945`, `S7` + 0.92736185 * RANDN() AS `V946`, `S2` + 0.92195445 * RANDN() AS `V947`, `S10` + 0.93273791 * RANDN() AS `V948`, `S3` + 0.92195445 * RANDN() AS `V949`, `S8` + 0.94339811 * RANDN() AS `V950`, `S3` + 0.92195445 * RANDN() AS `V951`, `S9` + 0.92736185 * RANDN() AS `V952`, `S9` + 0.92736185 * RANDN() AS `V953`, `S9` + 0.92736185 * RANDN() AS `V954`, `S6` + 0.92736185 * RANDN() AS `V955`, `S6` + 0.92736185 * RANDN() AS `V956`, `S6` + 0.92736185 * RANDN() AS `V957`, `S7` + 0.92736185 * RANDN() AS `V958`, `S2` + 0.92195445 * RANDN() AS `V959`, `S7` + 0.92736185 * RANDN() AS `V960`, `S3` + 0.92195445 * RANDN() AS `V961`, `S3` + 0.92195445 * RANDN() AS `V962`, `S3` + 0.92195445 * RANDN() AS `V963`, `S9` + 0.92736185 * RANDN() AS `V964`, `S10` + 0.93273791 * RANDN() AS `V965`, `S1` + 0.93808315 * RANDN() AS `V966`, `S3` + 0.92195445 * RANDN() AS `V967`, `S6` + 0.92736185 * RANDN() AS `V968`, `S5` + 0.90553851 * RANDN() AS `V969`, `S8` + 0.94339811 * RANDN() AS `V970`, `S2` + 0.92195445 * RANDN() AS `V971`, `S10` + 0.93273791 * RANDN() AS `V972`, `S7` + 0.92736185 * RANDN() AS `V973`, `S9` + 0.92736185 * RANDN() AS `V974`, `S2` + 0.92195445 * RANDN() AS `V975`, `S3` + 0.92195445 * RANDN() AS `V976`, `S5` + 0.90553851 * RANDN() AS `V977`, `S7` + 0.92736185 * RANDN() AS `V978`, `S9` + 0.92736185 * RANDN() AS `V979`, `S3` + 0.92195445 * RANDN() AS `V980`, `S3` + 0.92195445 * RANDN() AS `V981`, `S4` + 0.91104336 * RANDN() AS `V982`, `S9` + 0.92736185 * RANDN() AS `V983`, `S2` + 0.92195445 * RANDN() AS `V984`, `S2` + 0.92195445 * RANDN() AS `V985`, `S8` + 0.94339811 * RANDN() AS `V986`, `S3` + 0.92195445 * RANDN() AS `V987`, `S3` + 0.92195445 * RANDN() AS `V988`, `S6` + 0.92736185 * RANDN() AS `V989`, `S3` + 0.92195445 * RANDN() AS `V990`, `S9` + 0.92736185 * RANDN() AS `V991`, `S8` + 0.94339811 * RANDN() AS `V992`, `S10` + 0.93273791 * RANDN() AS `V993`, `S7` + 0.92736185 * RANDN() AS `V994`, `S3` + 0.92195445 * RANDN() AS `V995`, `S8` + 0.94339811 * RANDN() AS `V996`, `S9` + 0.92736185 * RANDN() AS `V997`, `S4` + 0.91104336 * RANDN() AS `V998`, `S6` + 0.92736185 * RANDN() AS `V999`, `S10` + 0.93273791 * RANDN() AS `V1000`
FROM (SELECT `S1` AS `S1`, `S2` AS `S2`, `S3` AS `S3`, `S4` AS `S4`, `S5` AS `S5`, `S6` AS `S6`, `S7` AS `S7`, `S8` AS `S8`, `S9` AS `S9`, `S10` AS `S10`
FROM (SELECT `id`, 0.346410161513775 * RANDN() AS `S1`, 0.387298334620742 * RANDN() AS `S2`, 0.387298334620742 * RANDN() AS `S3`, 0.412310562561766 * RANDN() AS `S4`, 0.424264068711929 * RANDN() AS `S5`, 0.374165738677394 * RANDN() AS `S6`, 0.374165738677394 * RANDN() AS `S7`, 0.33166247903554 * RANDN() AS `S8`, 0.374165738677394 * RANDN() AS `S9`, 0.360555127546399 * RANDN() AS `S10`
FROM `analyis_tbl`) `oknotynkmw`) `fojpxxqbnz`) `npxikqwuue`
17/12/19 12:03:03 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:50912 in memory (size: 134.6 KB, free: 2004.2 MB)
17/12/19 12:03:03 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:50912 in memory (size: 134.6 KB, free: 2004.3 MB)
17/12/19 12:03:03 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:50912 in memory (size: 135.7 KB, free: 2004.5 MB)
17/12/19 12:03:03 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:50912 in memory (size: 135.7 KB, free: 2004.6 MB)
17/12/19 12:03:05 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 12:03:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:03:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz67`
WHERE (0 = 1)
17/12/19 12:03:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:03:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 12:03:06 INFO CodeGenerator: Code generated in 41.776716 ms
17/12/19 12:03:06 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 12:03:06 INFO DAGScheduler: Got job 4 (take at <unknown>:0) with 1 output partitions
17/12/19 12:03:06 INFO DAGScheduler: Final stage: ResultStage 4 (take at <unknown>:0)
17/12/19 12:03:06 INFO DAGScheduler: Parents of final stage: List()
17/12/19 12:03:06 INFO DAGScheduler: Missing parents: List()
17/12/19 12:03:06 INFO DAGScheduler: Submitting ResultStage 4 (WorkerRDD[20] at RDD at rdd.scala:18), which has no missing parents
17/12/19 12:03:06 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 519.2 KB, free 2004.1 MB)
17/12/19 12:03:06 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 190.0 KB, free 2003.9 MB)
17/12/19 12:03:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:50912 (size: 190.0 KB, free: 2004.4 MB)
17/12/19 12:03:06 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/19 12:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (WorkerRDD[20] at RDD at rdd.scala:18)
17/12/19 12:03:06 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/12/19 12:03:06 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 6012 bytes)
17/12/19 12:03:06 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/12/19 12:03:06 INFO CodeGenerator: Code generated in 440.391446 ms
17/12/19 12:03:06 INFO CodeGenerator: Code generated in 125.396224 ms
17/12/19 12:05:58 INFO MemoryStore: Block rdd_20_0 stored as values in memory (estimated size 133.7 MB, free 1870.2 MB)
17/12/19 12:05:58 INFO BlockManagerInfo: Added rdd_20_0 in memory on 127.0.0.1:50912 (size: 133.7 MB, free: 1870.7 MB)
17/12/19 12:05:58 WARN Executor: 1 block locks were not released by TID = 4:
[rdd_20_0]
17/12/19 12:05:58 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 143069 bytes result sent to driver
17/12/19 12:05:58 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 172074 ms on localhost (executor driver) (1/1)
17/12/19 12:05:58 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/12/19 12:05:58 INFO DAGScheduler: ResultStage 4 (take at <unknown>:0) finished in 172.074 s
17/12/19 12:05:58 INFO DAGScheduler: Job 4 finished: take at <unknown>:0, took 172.118024 s
17/12/19 12:05:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:05:59 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ae8cf5f99
17/12/19 12:05:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:05:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ae8cf5f99` AS `zzz68`
WHERE (0 = 1)
17/12/19 12:05:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:05:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ae8cf5f99`
17/12/19 12:05:59 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 12:05:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:05:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz69`
WHERE (0 = 1)
17/12/19 12:06:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:06:02 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.0013) AS `V1`, (`V2` < 0.0035) AS `V2`, (`V3` < 0.0035) AS `V3`, (`V4` < 0.009) AS `V4`, (`V5` < 0.075) AS `V5`, (`V6` < 0.0375) AS `V6`, (`V7` < 0.3) AS `V7`, (`V8` < 0.0045) AS `V8`, (`V9` < 0.1) AS `V9`, (`V10` < 0.075) AS `V10`, (`V11` < 0.3) AS `V11`, (`V12` < 0.054) AS `V12`, (`V13` < 4e-04) AS `V13`, (`V14` < 0.0138) AS `V14`, (`V15` < 0.026) AS `V15`, (`V16` < 0.0055) AS `V16`, (`V17` < 0.0138) AS `V17`, (`V18` < 0.054) AS `V18`, (`V19` < 0.0375) AS `V19`, (`V20` < 0.009) AS `V20`, (`V21` < 0.075) AS `V21`, (`V22` < 0.0045) AS `V22`, (`V23` < 0.0018) AS `V23`, (`V24` < 0.026) AS `V24`, (`V25` < 0.0018) AS `V25`, (`V26` < 0.0185) AS `V26`, (`V27` < 0.0018) AS `V27`, (`V28` < 0.0018) AS `V28`, (`V29` < 0.0013) AS `V29`, (`V30` < 0.009) AS `V30`, (`V31` < 0.0375) AS `V31`, (`V32` < 0.0028) AS `V32`, (`V33` < 0.0375) AS `V33`, (`V34` < 0.3) AS `V34`, (`V35` < 0.0138) AS `V35`, (`V36` < 0.0055) AS `V36`, (`V37` < 0.0055) AS `V37`, (`V38` < 0.0375) AS `V38`, (`V39` < 0.0138) AS `V39`, (`V40` < 0.009) AS `V40`, (`V41` < 0.0138) AS `V41`, (`V42` < 0.0018) AS `V42`, (`V43` < 0.0375) AS `V43`, (`V44` < 0.0035) AS `V44`, (`V45` < 0.0028) AS `V45`, (`V46` < 0.0045) AS `V46`, (`V47` < 0.0185) AS `V47`, (`V48` < 0.009) AS `V48`, (`V49` < 0.0138) AS `V49`, (`V50` < 0.0028) AS `V50`, (`V51` < 0.026) AS `V51`, (`V52` < 0.0035) AS `V52`, (`V53` < 0.0055) AS `V53`, (`V54` < 0.054) AS `V54`, (`V55` < 0.0138) AS `V55`, (`V56` < 0.026) AS `V56`, (`V57` < 0.0035) AS `V57`, (`V58` < 0.0375) AS `V58`, (`V59` < 0.3) AS `V59`, (`V60` < 0.0035) AS `V60`, (`V61` < 1e-04) AS `V61`, (`V62` < 0.0055) AS `V62`, (`V63` < 0.0185) AS `V63`, (`V64` < 0.0028) AS `V64`, (`V65` < 0.0045) AS `V65`, (`V66` < 0.0018) AS `V66`, (`V67` < 0.1) AS `V67`, (`V68` < 4e-04) AS `V68`, (`V69` < 8e-04) AS `V69`, (`V70` < 0.15) AS `V70`, (`V71` < 0.075) AS `V71`, (`V72` < 0.0028) AS `V72`, (`V73` < 8e-04) AS `V73`, (`V74` < 0.009) AS `V74`, (`V75` < 0.026) AS `V75`, (`V76` < 0.0375) AS `V76`, (`V77` < 0.054) AS `V77`, (`V78` < 0.009) AS `V78`, (`V79` < 8e-04) AS `V79`, (`V80` < 0.0028) AS `V80`, (`V81` < 0.0018) AS `V81`, (`V82` < 0.075) AS `V82`, (`V83` < 0.15) AS `V83`, (`V84` < 0.0055) AS `V84`, (`V85` < 0.0185) AS `V85`, (`V86` < 8e-04) AS `V86`, (`V87` < 0.0018) AS `V87`, (`V88` < 0.075) AS `V88`, (`V89` < 0.0035) AS `V89`, (`V90` < 0.0185) AS `V90`, (`V91` < 0.0045) AS `V91`, (`V92` < 0.054) AS `V92`, (`V93` < 0.1) AS `V93`, (`V94` < 0.0138) AS `V94`, (`V95` < 0.0185) AS `V95`, (`V96` < 0.0138) AS `V96`, (`V97` < 0.054) AS `V97`, (`V98` < 0.0138) AS `V98`, (`V99` < 0.1) AS `V99`, (`V100` < 0.0138) AS `V100`, (`V101` < 0.0023) AS `V101`, (`V102` < 0.0185) AS `V102`, (`V103` < 0.3) AS `V103`, (`V104` < 0.0375) AS `V104`, (`V105` < 1e-04) AS `V105`, (`V106` < 0.0055) AS `V106`, (`V107` < 0.0055) AS `V107`, (`V108` < 0.026) AS `V108`, (`V109` < 0.009) AS `V109`, (`V110` < 0.0375) AS `V110`, (`V111` < 0.0138) AS `V111`, (`V112` < 0.026) AS `V112`, (`V113` < 0.0028) AS `V113`, (`V114` < 0.0018) AS `V114`, (`V115` < 0.075) AS `V115`, (`V116` < 0.0375) AS `V116`, (`V117` < 0.075) AS `V117`, (`V118` < 0.0185) AS `V118`, (`V119` < 0.1) AS `V119`, (`V120` < 4e-04) AS `V120`, (`V121` < 0.0023) AS `V121`, (`V122` < 0.0023) AS `V122`, (`V123` < 0.0375) AS `V123`, (`V124` < 0.009) AS `V124`, (`V125` < 0.0028) AS `V125`, (`V126` < 0.0035) AS `V126`, (`V127` < 0.0035) AS `V127`, (`V128` < 0.054) AS `V128`, (`V129` < 0.0018) AS `V129`, (`V130` < 0.054) AS `V130`, (`V131` < 0.1) AS `V131`, (`V132` < 0.0185) AS `V132`, (`V133` < 0.0185) AS `V133`, (`V134` < 0.0023) AS `V134`, (`V135` < 0.0045) AS `V135`, (`V136` < 0.0023) AS `V136`, (`V137` < 0.0028) AS `V137`, (`V138` < 0.0023) AS `V138`, (`V139` < 0.054) AS `V139`, (`V140` < 0.0055) AS `V140`, (`V141` < 0.0185) AS `V141`, (`V142` < 0.0375) AS `V142`, (`V143` < 0.15) AS `V143`, (`V144` < 0.0375) AS `V144`, (`V145` < 0.0185) AS `V145`, (`V146` < 0.1) AS `V146`, (`V147` < 0.0035) AS `V147`, (`V148` < 0.0185) AS `V148`, (`V149` < 0.0035) AS `V149`, (`V150` < 0.0375) AS `V150`, (`V151` < 0.0028) AS `V151`, (`V152` < 0.009) AS `V152`, (`V153` < 0.0055) AS `V153`, (`V154` < 0.0375) AS `V154`, (`V155` < 0.0028) AS `V155`, (`V156` < 0.0185) AS `V156`, (`V157` < 0.15) AS `V157`, (`V158` < 0.054) AS `V158`, (`V159` < 0.0055) AS `V159`, (`V160` < 0.0023) AS `V160`, (`V161` < 0.0375) AS `V161`, (`V162` < 0.0013) AS `V162`, (`V163` < 3e-04) AS `V163`, (`V164` < 0.0375) AS `V164`, (`V165` < 0.0055) AS `V165`, (`V166` < 0.3) AS `V166`, (`V167` < 0.009) AS `V167`, (`V168` < 0.0055) AS `V168`, (`V169` < 0.0185) AS `V169`, (`V170` < 0.0185) AS `V170`, (`V171` < 0.1) AS `V171`, (`V172` < 0.0055) AS `V172`, (`V173` < 0.0138) AS `V173`, (`V174` < 0.0185) AS `V174`, (`V175` < 0.0055) AS `V175`, (`V176` < 0.026) AS `V176`, (`V177` < 0.0375) AS `V177`, (`V178` < 0.0138) AS `V178`, (`V179` < 0.0055) AS `V179`, (`V180` < 0.0185) AS `V180`, (`V181` < 0.026) AS `V181`, (`V182` < 0.0018) AS `V182`, (`V183` < 0.0045) AS `V183`, (`V184` < 0.0045) AS `V184`, (`V185` < 0.009) AS `V185`, (`V186` < 4e-04) AS `V186`, (`V187` < 0.0138) AS `V187`, (`V188` < 0.0138) AS `V188`, (`V189` < 0.026) AS `V189`, (`V190` < 0.0045) AS `V190`, (`V191` < 0.026) AS `V191`, (`V192` < 0.0028) AS `V192`, (`V193` < 0.0375) AS `V193`, (`V194` < 0.026) AS `V194`, (`V195` < 0.0045) AS `V195`, (`V196` < 0.0045) AS `V196`, (`V197` < 0.0035) AS `V197`, (`V198` < 0.0055) AS `V198`, (`V199` < 0.0035) AS `V199`, (`V200` < 0.0028) AS `V200`, (`V201` < 0.0035) AS `V201`, (`V202` < 0.026) AS `V202`, (`V203` < 0.0138) AS `V203`, (`V204` < 0.0045) AS `V204`, (`V205` < 8e-04) AS `V205`, (`V206` < 0.0028) AS `V206`, (`V207` < 0.0185) AS `V207`, (`V208` < 0.1) AS `V208`, (`V209` < 0.0028) AS `V209`, (`V210` < 0.0013) AS `V210`, (`V211` < 0.0185) AS `V211`, (`V212` < 0.0018) AS `V212`, (`V213` < 0.054) AS `V213`, (`V214` < 0.0045) AS `V214`, (`V215` < 0.075) AS `V215`, (`V216` < 0.009) AS `V216`, (`V217` < 0.3) AS `V217`, (`V218` < 0.0055) AS `V218`, (`V219` < 0.0035) AS `V219`, (`V220` < 0.075) AS `V220`, (`V221` < 0.15) AS `V221`, (`V222` < 0.0055) AS `V222`, (`V223` < 0.0185) AS `V223`, (`V224` < 0.1) AS `V224`, (`V225` < 0.0375) AS `V225`, (`V226` < 0.0018) AS `V226`, (`V227` < 0.0375) AS `V227`, (`V228` < 0.1) AS `V228`, (`V229` < 4e-04) AS `V229`, (`V230` < 0.0055) AS `V230`, (`V231` < 0.054) AS `V231`, (`V232` < 0.0045) AS `V232`, (`V233` < 0.0138) AS `V233`, (`V234` < 0.0375) AS `V234`, (`V235` < 0.0375) AS `V235`, (`V236` < 0.0035) AS `V236`, (`V237` < 0.0138) AS `V237`, (`V238` < 0.0035) AS `V238`, (`V239` < 0.0045) AS `V239`, (`V240` < 0.0375) AS `V240`, (`V241` < 0.0045) AS `V241`, (`V242` < 0.075) AS `V242`, (`V243` < 0.0055) AS `V243`, (`V244` < 0.0138) AS `V244`, (`V245` < 0.009) AS `V245`, (`V246` < 0.15) AS `V246`, (`V247` < 0.009) AS `V247`, (`V248` < 0.0013) AS `V248`, (`V249` < 0.0045) AS `V249`, (`V250` < 0.0185) AS `V250`, (`V251` < 0.0375) AS `V251`, (`V252` < 0.0035) AS `V252`, (`V253` < 0.026) AS `V253`, (`V254` < 0.026) AS `V254`, (`V255` < 0.0055) AS `V255`, (`V256` < 0.0138) AS `V256`, (`V257` < 0.026) AS `V257`, (`V258` < 0.009) AS `V258`, (`V259` < 0.0028) AS `V259`, (`V260` < 3e-04) AS `V260`, (`V261` < 0.0138) AS `V261`, (`V262` < 0.15) AS `V262`, (`V263` < 0.0035) AS `V263`, (`V264` < 0.0045) AS `V264`, (`V265` < 0.1) AS `V265`, (`V266` < 0.0035) AS `V266`, (`V267` < 0.0023) AS `V267`, (`V268` < 0.0035) AS `V268`, (`V269` < 0.0185) AS `V269`, (`V270` < 0.15) AS `V270`, (`V271` < 0.0028) AS `V271`, (`V272` < 0.026) AS `V272`, (`V273` < 0.0045) AS `V273`, (`V274` < 0.0035) AS `V274`, (`V275` < 0.0138) AS `V275`, (`V276` < 0.0055) AS `V276`, (`V277` < 0.0185) AS `V277`, (`V278` < 0.075) AS `V278`, (`V279` < 0.026) AS `V279`, (`V280` < 0.3) AS `V280`, (`V281` < 0.0028) AS `V281`, (`V282` < 0.0185) AS `V282`, (`V283` < 0.0028) AS `V283`, (`V284` < 0.0055) AS `V284`, (`V285` < 0.0035) AS `V285`, (`V286` < 0.0045) AS `V286`, (`V287` < 0.0018) AS `V287`, (`V288` < 0.0023) AS `V288`, (`V289` < 0.0045) AS `V289`, (`V290` < 0.0055) AS `V290`, (`V291` < 0.0045) AS `V291`, (`V292` < 0.075) AS `V292`, (`V293` < 0.0035) AS `V293`, (`V294` < 0.0028) AS `V294`, (`V295` < 0.0375) AS `V295`, (`V296` < 0.0023) AS `V296`, (`V297` < 0.0375) AS `V297`, (`V298` < 0.3) AS `V298`, (`V299` < 0.0045) AS `V299`, (`V300` < 0.0045) AS `V300`, (`V301` < 0.0055) AS `V301`, (`V302` < 0.0055) AS `V302`, (`V303` < 0.0045) AS `V303`, (`V304` < 0.009) AS `V304`, (`V305` < 0.0185) AS `V305`, (`V306` < 0.0045) AS `V306`, (`V307` < 0.1) AS `V307`, (`V308` < 0.0185) AS `V308`, (`V309` < 0.0055) AS `V309`, (`V310` < 0.0055) AS `V310`, (`V311` < 0.0023) AS `V311`, (`V312` < 0.0045) AS `V312`, (`V313` < 0.0138) AS `V313`, (`V314` < 0.0055) AS `V314`, (`V315` < 0.0028) AS `V315`, (`V316` < 0.0055) AS `V316`, (`V317` < 0.054) AS `V317`, (`V318` < 0.0375) AS `V318`, (`V319` < 0.0375) AS `V319`, (`V320` < 0.0375) AS `V320`, (`V321` < 0.054) AS `V321`, (`V322` < 0.0023) AS `V322`, (`V323` < 0.0185) AS `V323`, (`V324` < 0.0045) AS `V324`, (`V325` < 0.0138) AS `V325`, (`V326` < 0.0045) AS `V326`, (`V327` < 0.054) AS `V327`, (`V328` < 4e-04) AS `V328`, (`V329` < 0.075) AS `V329`, (`V330` < 0.1) AS `V330`, (`V331` < 0.026) AS `V331`, (`V332` < 0.026) AS `V332`, (`V333` < 0.0045) AS `V333`, (`V334` < 0.0035) AS `V334`, (`V335` < 0.0055) AS `V335`, (`V336` < 0.0185) AS `V336`, (`V337` < 0.009) AS `V337`, (`V338` < 0.0055) AS `V338`, (`V339` < 0.0375) AS `V339`, (`V340` < 0.009) AS `V340`, (`V341` < 0.0023) AS `V341`, (`V342` < 0.0035) AS `V342`, (`V343` < 0.0023) AS `V343`, (`V344` < 0.026) AS `V344`, (`V345` < 0.0023) AS `V345`, (`V346` < 0.0375) AS `V346`, (`V347` < 0.026) AS `V347`, (`V348` < 0.075) AS `V348`, (`V349` < 0.0045) AS `V349`, (`V350` < 0.009) AS `V350`, (`V351` < 0.0055) AS `V351`, (`V352` < 0.009) AS `V352`, (`V353` < 0.0138) AS `V353`, (`V354` < 0.0375) AS `V354`, (`V355` < 0.0185) AS `V355`, (`V356` < 0.0138) AS `V356`, (`V357` < 0.0185) AS `V357`, (`V358` < 0.0023) AS `V358`, (`V359` < 0.0023) AS `V359`, (`V360` < 0.026) AS `V360`, (`V361` < 0.0013) AS `V361`, (`V362` < 0.026) AS `V362`, (`V363` < 0.1) AS `V363`, (`V364` < 0.026) AS `V364`, (`V365` < 0.0055) AS `V365`, (`V366` < 0.1) AS `V366`, (`V367` < 0.0138) AS `V367`, (`V368` < 0.0375) AS `V368`, (`V369` < 0.026) AS `V369`, (`V370` < 0.0055) AS `V370`, (`V371` < 0.054) AS `V371`, (`V372` < 0.026) AS `V372`, (`V373` < 0.0028) AS `V373`, (`V374` < 0.0055) AS `V374`, (`V375` < 0.0045) AS `V375`, (`V376` < 0.3) AS `V376`, (`V377` < 0.0045) AS `V377`, (`V378` < 0.1) AS `V378`, (`V379` < 0.0185) AS `V379`, (`V380` < 0.0028) AS `V380`, (`V381` < 0.15) AS `V381`, (`V382` < 8e-04) AS `V382`, (`V383` < 0.0028) AS `V383`, (`V384` < 0.0018) AS `V384`, (`V385` < 0.0013) AS `V385`, (`V386` < 0.026) AS `V386`, (`V387` < 3e-04) AS `V387`, (`V388` < 0.0185) AS `V388`, (`V389` < 0.0028) AS `V389`, (`V390` < 0.0375) AS `V390`, (`V391` < 0.0028) AS `V391`, (`V392` < 0.0028) AS `V392`, (`V393` < 4e-04) AS `V393`, (`V394` < 0.009) AS `V394`, (`V395` < 0.009) AS `V395`, (`V396` < 0.026) AS `V396`, (`V397` < 0.1) AS `V397`, (`V398` < 0.0138) AS `V398`, (`V399` < 0.075) AS `V399`, (`V400` < 0.15) AS `V400`, (`V401` < 0.0045) AS `V401`, (`V402` < 0.075) AS `V402`, (`V403` < 0.0028) AS `V403`, (`V404` < 0.009) AS `V404`, (`V405` < 0.009) AS `V405`, (`V406` < 0.0023) AS `V406`, (`V407` < 0.0185) AS `V407`, (`V408` < 0.0028) AS `V408`, (`V409` < 0.0018) AS `V409`, (`V410` < 0.054) AS `V410`, (`V411` < 0.1) AS `V411`, (`V412` < 0.0138) AS `V412`, (`V413` < 0.075) AS `V413`, (`V414` < 0.0045) AS `V414`, (`V415` < 0.15) AS `V415`, (`V416` < 0.0375) AS `V416`, (`V417` < 0.0185) AS `V417`, (`V418` < 0.054) AS `V418`, (`V419` < 0.0045) AS `V419`, (`V420` < 0.0185) AS `V420`, (`V421` < 0.0023) AS `V421`, (`V422` < 0.0055) AS `V422`, (`V423` < 0.0045) AS `V423`, (`V424` < 0.0375) AS `V424`, (`V425` < 0.0375) AS `V425`, (`V426` < 0.0028) AS `V426`, (`V427` < 0.0013) AS `V427`, (`V428` < 0.0035) AS `V428`, (`V429` < 0.0185) AS `V429`, (`V430` < 0.075) AS `V430`, (`V431` < 0.0185) AS `V431`, (`V432` < 0.0013) AS `V432`, (`V433` < 0.0035) AS `V433`, (`V434` < 0.15) AS `V434`, (`V435` < 0.0035) AS `V435`, (`V436` < 0.15) AS `V436`, (`V437` < 0.075) AS `V437`, (`V438` < 0.0028) AS `V438`, (`V439` < 0.009) AS `V439`, (`V440` < 0.054) AS `V440`, (`V441` < 0.1) AS `V441`, (`V442` < 3e-04) AS `V442`, (`V443` < 0.0375) AS `V443`, (`V444` < 0.0013) AS `V444`, (`V445` < 0.0055) AS `V445`, (`V446` < 0.0375) AS `V446`, (`V447` < 0.0185) AS `V447`, (`V448` < 0.0023) AS `V448`, (`V449` < 0.026) AS `V449`, (`V450` < 0.0138) AS `V450`, (`V451` < 0.0045) AS `V451`, (`V452` < 0.1) AS `V452`, (`V453` < 0.0138) AS `V453`, (`V454` < 0.026) AS `V454`, (`V455` < 0.0138) AS `V455`, (`V456` < 0.0138) AS `V456`, (`V457` < 0.0045) AS `V457`, (`V458` < 0.0045) AS `V458`, (`V459` < 0.009) AS `V459`, (`V460` < 1e-04) AS `V460`, (`V461` < 0.0028) AS `V461`, (`V462` < 0.026) AS `V462`, (`V463` < 0.0138) AS `V463`, (`V464` < 0.0138) AS `V464`, (`V465` < 0.0045) AS `V465`, (`V466` < 0.0018) AS `V466`, (`V467` < 0.054) AS `V467`, (`V468` < 8e-04) AS `V468`, (`V469` < 0.0138) AS `V469`, (`V470` < 0.0028) AS `V470`, (`V471` < 0.0185) AS `V471`, (`V472` < 0.0045) AS `V472`, (`V473` < 0.0035) AS `V473`, (`V474` < 0.0185) AS `V474`, (`V475` < 0.0055) AS `V475`, (`V476` < 0.0013) AS `V476`, (`V477` < 0.075) AS `V477`, (`V478` < 0.009) AS `V478`, (`V479` < 0.009) AS `V479`, (`V480` < 8e-04) AS `V480`, (`V481` < 0.0138) AS `V481`, (`V482` < 0.15) AS `V482`, (`V483` < 0.026) AS `V483`, (`V484` < 0.0013) AS `V484`, (`V485` < 0.0045) AS `V485`, (`V486` < 0.0138) AS `V486`, (`V487` < 0.009) AS `V487`, (`V488` < 1e-04) AS `V488`, (`V489` < 0.054) AS `V489`, (`V490` < 0.0018) AS `V490`, (`V491` < 0.054) AS `V491`, (`V492` < 0.0185) AS `V492`, (`V493` < 0.0375) AS `V493`, (`V494` < 0.0138) AS `V494`, (`V495` < 0.0028) AS `V495`, (`V496` < 0.026) AS `V496`, (`V497` < 0.3) AS `V497`, (`V498` < 0.0045) AS `V498`, (`V499` < 4e-04) AS `V499`, (`V500` < 0.026) AS `V500`, (`V501` < 0.0023) AS `V501`, (`V502` < 0.0138) AS `V502`, (`V503` < 0.0035) AS `V503`, (`V504` < 0.009) AS `V504`, (`V505` < 0.0055) AS `V505`, (`V506` < 0.0045) AS `V506`, (`V507` < 3e-04) AS `V507`, (`V508` < 0.0035) AS `V508`, (`V509` < 0.0185) AS `V509`, (`V510` < 0.0045) AS `V510`, (`V511` < 0.0023) AS `V511`, (`V512` < 0.0028) AS `V512`, (`V513` < 0.0018) AS `V513`, (`V514` < 0.0138) AS `V514`, (`V515` < 0.0035) AS `V515`, (`V516` < 0.0138) AS `V516`, (`V517` < 0.0138) AS `V517`, (`V518` < 0.0055) AS `V518`, (`V519` < 0.0185) AS `V519`, (`V520` < 0.009) AS `V520`, (`V521` < 0.0375) AS `V521`, (`V522` < 0.0045) AS `V522`, (`V523` < 0.0028) AS `V523`, (`V524` < 0.054) AS `V524`, (`V525` < 0.075) AS `V525`, (`V526` < 0.075) AS `V526`, (`V527` < 0.0018) AS `V527`, (`V528` < 0.054) AS `V528`, (`V529` < 0.0035) AS `V529`, (`V530` < 0.026) AS `V530`, (`V531` < 0.0375) AS `V531`, (`V532` < 0.0138) AS `V532`, (`V533` < 0.026) AS `V533`, (`V534` < 0.0028) AS `V534`, (`V535` < 0.0028) AS `V535`, (`V536` < 0.0018) AS `V536`, (`V537` < 0.0138) AS `V537`, (`V538` < 0.009) AS `V538`, (`V539` < 0.0035) AS `V539`, (`V540` < 0.1) AS `V540`, (`V541` < 0.0138) AS `V541`, (`V542` < 0.026) AS `V542`, (`V543` < 0.0023) AS `V543`, (`V544` < 0.0018) AS `V544`, (`V545` < 0.026) AS `V545`, (`V546` < 0.026) AS `V546`, (`V547` < 0.026) AS `V547`, (`V548` < 0.009) AS `V548`, (`V549` < 4e-04) AS `V549`, (`V550` < 0.075) AS `V550`, (`V551` < 0.0018) AS `V551`, (`V552` < 0.0045) AS `V552`, (`V553` < 0.0138) AS `V553`, (`V554` < 0.009) AS `V554`, (`V555` < 0.0138) AS `V555`, (`V556` < 0.0023) AS `V556`, (`V557` < 0.0055) AS `V557`, (`V558` < 0.0035) AS `V558`, (`V559` < 0.075) AS `V559`, (`V560` < 0.0055) AS `V560`, (`V561` < 0.0055) AS `V561`, (`V562` < 0.0045) AS `V562`, (`V563` < 0.0045) AS `V563`, (`V564` < 0.0185) AS `V564`, (`V565` < 0.054) AS `V565`, (`V566` < 0.0028) AS `V566`, (`V567` < 0.0138) AS `V567`, (`V568` < 0.0035) AS `V568`, (`V569` < 0.3) AS `V569`, (`V570` < 0.009) AS `V570`, (`V571` < 0.0185) AS `V571`, (`V572` < 0.0138) AS `V572`, (`V573` < 0.0028) AS `V573`, (`V574` < 0.0185) AS `V574`, (`V575` < 0.009) AS `V575`, (`V576` < 0.0035) AS `V576`, (`V577` < 0.026) AS `V577`, (`V578` < 0.0375) AS `V578`, (`V579` < 0.009) AS `V579`, (`V580` < 0.009) AS `V580`, (`V581` < 0.0185) AS `V581`, (`V582` < 0.0045) AS `V582`, (`V583` < 0.0138) AS `V583`, (`V584` < 0.009) AS `V584`, (`V585` < 3e-04) AS `V585`, (`V586` < 0.0055) AS `V586`, (`V587` < 0.0375) AS `V587`, (`V588` < 0.0028) AS `V588`, (`V589` < 0.1) AS `V589`, (`V590` < 0.009) AS `V590`, (`V591` < 0.075) AS `V591`, (`V592` < 3e-04) AS `V592`, (`V593` < 0.0023) AS `V593`, (`V594` < 0.0045) AS `V594`, (`V595` < 0.0055) AS `V595`, (`V596` < 0.0045) AS `V596`, (`V597` < 0.009) AS `V597`, (`V598` < 0.0375) AS `V598`, (`V599` < 0.0055) AS `V599`, (`V600` < 8e-04) AS `V600`, (`V601` < 0.0138) AS `V601`, (`V602` < 0.075) AS `V602`, (`V603` < 0.0035) AS `V603`, (`V604` < 0.0138) AS `V604`, (`V605` < 0.075) AS `V605`, (`V606` < 0.0185) AS `V606`, (`V607` < 0.0185) AS `V607`, (`V608` < 0.0138) AS `V608`, (`V609` < 0.0055) AS `V609`, (`V610` < 0.0055) AS `V610`, (`V611` < 8e-04) AS `V611`, (`V612` < 0.0375) AS `V612`, (`V613` < 0.0375) AS `V613`, (`V614` < 0.0138) AS `V614`, (`V615` < 0.0045) AS `V615`, (`V616` < 0.0028) AS `V616`, (`V617` < 0.0055) AS `V617`, (`V618` < 0.0013) AS `V618`, (`V619` < 0.0035) AS `V619`, (`V620` < 0.0375) AS `V620`, (`V621` < 0.0185) AS `V621`, (`V622` < 0.0185) AS `V622`, (`V623` < 0.0185) AS `V623`, (`V624` < 0.009) AS `V624`, (`V625` < 0.15) AS `V625`, (`V626` < 0.054) AS `V626`, (`V627` < 0.0185) AS `V627`, (`V628` < 0.0138) AS `V628`, (`V629` < 0.0375) AS `V629`, (`V630` < 0.0028) AS `V630`, (`V631` < 0.009) AS `V631`, (`V632` < 0.0375) AS `V632`, (`V633` < 0.0138) AS `V633`, (`V634` < 0.0138) AS `V634`, (`V635` < 0.009) AS `V635`, (`V636` < 0.0138) AS `V636`, (`V637` < 0.0185) AS `V637`, (`V638` < 0.026) AS `V638`, (`V639` < 3e-04) AS `V639`, (`V640` < 0.0185) AS `V640`, (`V641` < 0.026) AS `V641`, (`V642` < 0.0028) AS `V642`, (`V643` < 0.009) AS `V643`, (`V644` < 0.009) AS `V644`, (`V645` < 0.009) AS `V645`, (`V646` < 0.075) AS `V646`, (`V647` < 0.0185) AS `V647`, (`V648` < 0.0185) AS `V648`, (`V649` < 0.0138) AS `V649`, (`V650` < 0.0185) AS `V650`, (`V651` < 0.009) AS `V651`, (`V652` < 0.026) AS `V652`, (`V653` < 0.0035) AS `V653`, (`V654` < 0.15) AS `V654`, (`V655` < 0.0028) AS `V655`, (`V656` < 0.0375) AS `V656`, (`V657` < 0.0028) AS `V657`, (`V658` < 0.0185) AS `V658`, (`V659` < 0.0055) AS `V659`, (`V660` < 0.3) AS `V660`, (`V661` < 0.0035) AS `V661`, (`V662` < 0.009) AS `V662`, (`V663` < 0.0185) AS `V663`, (`V664` < 0.1) AS `V664`, (`V665` < 0.0185) AS `V665`, (`V666` < 0.026) AS `V666`, (`V667` < 0.009) AS `V667`, (`V668` < 0.0375) AS `V668`, (`V669` < 0.0375) AS `V669`, (`V670` < 0.009) AS `V670`, (`V671` < 0.0055) AS `V671`, (`V672` < 0.0035) AS `V672`, (`V673` < 0.0185) AS `V673`, (`V674` < 0.0375) AS `V674`, (`V675` < 0.0028) AS `V675`, (`V676` < 0.0055) AS `V676`, (`V677` < 0.0138) AS `V677`, (`V678` < 0.0018) AS `V678`, (`V679` < 0.15) AS `V679`, (`V680` < 0.0375) AS `V680`, (`V681` < 0.0185) AS `V681`, (`V682` < 0.0018) AS `V682`, (`V683` < 0.0028) AS `V683`, (`V684` < 0.054) AS `V684`, (`V685` < 0.009) AS `V685`, (`V686` < 0.054) AS `V686`, (`V687` < 0.0185) AS `V687`, (`V688` < 0.0023) AS `V688`, (`V689` < 0.0185) AS `V689`, (`V690` < 0.054) AS `V690`, (`V691` < 0.0028) AS `V691`, (`V692` < 0.0028) AS `V692`, (`V693` < 0.0138) AS `V693`, (`V694` < 0.0375) AS `V694`, (`V695` < 0.0035) AS `V695`, (`V696` < 0.009) AS `V696`, (`V697` < 0.0028) AS `V697`, (`V698` < 0.0013) AS `V698`, (`V699` < 0.0013) AS `V699`, (`V700` < 0.026) AS `V700`, (`V701` < 0.009) AS `V701`, (`V702` < 0.0045) AS `V702`, (`V703` < 0.0375) AS `V703`, (`V704` < 0.0138) AS `V704`, (`V705` < 0.0138) AS `V705`, (`V706` < 0.026) AS `V706`, (`V707` < 0.0035) AS `V707`, (`V708` < 0.0028) AS `V708`, (`V709` < 0.075) AS `V709`, (`V710` < 0.0185) AS `V710`, (`V711` < 0.0375) AS `V711`, (`V712` < 0.009) AS `V712`, (`V713` < 0.0028) AS `V713`, (`V714` < 0.026) AS `V714`, (`V715` < 0.0138) AS `V715`, (`V716` < 0.0028) AS `V716`, (`V717` < 0.0035) AS `V717`, (`V718` < 0.075) AS `V718`, (`V719` < 0.009) AS `V719`, (`V720` < 0.0035) AS `V720`, (`V721` < 0.0185) AS `V721`, (`V722` < 0.0055) AS `V722`, (`V723` < 0.0023) AS `V723`, (`V724` < 0.0138) AS `V724`, (`V725` < 0.0023) AS `V725`, (`V726` < 0.0138) AS `V726`, (`V727` < 0.054) AS `V727`, (`V728` < 0.0185) AS `V728`, (`V729` < 0.0375) AS `V729`, (`V730` < 0.026) AS `V730`, (`V731` < 0.026) AS `V731`, (`V732` < 0.3) AS `V732`, (`V733` < 0.0138) AS `V733`, (`V734` < 0.0045) AS `V734`, (`V735` < 0.0018) AS `V735`, (`V736` < 0.0045) AS `V736`, (`V737` < 0.0035) AS `V737`, (`V738` < 0.0138) AS `V738`, (`V739` < 0.0138) AS `V739`, (`V740` < 0.3) AS `V740`, (`V741` < 0.0185) AS `V741`, (`V742` < 0.0185) AS `V742`, (`V743` < 0.0185) AS `V743`, (`V744` < 0.0185) AS `V744`, (`V745` < 0.009) AS `V745`, (`V746` < 0.0035) AS `V746`, (`V747` < 0.0138) AS `V747`, (`V748` < 0.026) AS `V748`, (`V749` < 0.0055) AS `V749`, (`V750` < 0.0055) AS `V750`, (`V751` < 0.0045) AS `V751`, (`V752` < 0.0035) AS `V752`, (`V753` < 0.1) AS `V753`, (`V754` < 0.0185) AS `V754`, (`V755` < 0.0185) AS `V755`, (`V756` < 0.0023) AS `V756`, (`V757` < 0.009) AS `V757`, (`V758` < 0.054) AS `V758`, (`V759` < 0.009) AS `V759`, (`V760` < 0.0045) AS `V760`, (`V761` < 0.0028) AS `V761`, (`V762` < 0.0375) AS `V762`, (`V763` < 0.0055) AS `V763`, (`V764` < 0.075) AS `V764`, (`V765` < 0.0045) AS `V765`, (`V766` < 0.0018) AS `V766`, (`V767` < 0.0375) AS `V767`, (`V768` < 0.054) AS `V768`, (`V769` < 0.0185) AS `V769`, (`V770` < 0.026) AS `V770`, (`V771` < 0.0375) AS `V771`, (`V772` < 4e-04) AS `V772`, (`V773` < 0.009) AS `V773`, (`V774` < 0.0138) AS `V774`, (`V775` < 0.0023) AS `V775`, (`V776` < 0.0375) AS `V776`, (`V777` < 0.0185) AS `V777`, (`V778` < 0.0028) AS `V778`, (`V779` < 0.0028) AS `V779`, (`V780` < 0.0018) AS `V780`, (`V781` < 0.15) AS `V781`, (`V782` < 0.15) AS `V782`, (`V783` < 0.1) AS `V783`, (`V784` < 0.026) AS `V784`, (`V785` < 0.0028) AS `V785`, (`V786` < 0.0138) AS `V786`, (`V787` < 0.026) AS `V787`, (`V788` < 0.0023) AS `V788`, (`V789` < 0.0138) AS `V789`, (`V790` < 0.0138) AS `V790`, (`V791` < 0.0028) AS `V791`, (`V792` < 0.009) AS `V792`, (`V793` < 0.026) AS `V793`, (`V794` < 0.0375) AS `V794`, (`V795` < 0.0375) AS `V795`, (`V796` < 0.075) AS `V796`, (`V797` < 0.0185) AS `V797`, (`V798` < 0.054) AS `V798`, (`V799` < 4e-04) AS `V799`, (`V800` < 0.0055) AS `V800`, (`V801` < 0.026) AS `V801`, (`V802` < 0.075) AS `V802`, (`V803` < 0.009) AS `V803`, (`V804` < 0.075) AS `V804`, (`V805` < 0.0045) AS `V805`, (`V806` < 0.0055) AS `V806`, (`V807` < 4e-04) AS `V807`, (`V808` < 0.0185) AS `V808`, (`V809` < 0.0055) AS `V809`, (`V810` < 0.0023) AS `V810`, (`V811` < 0.009) AS `V811`, (`V812` < 0.075) AS `V812`, (`V813` < 0.0055) AS `V813`, (`V814` < 0.0023) AS `V814`, (`V815` < 0.0035) AS `V815`, (`V816` < 0.0185) AS `V816`, (`V817` < 0.026) AS `V817`, (`V818` < 0.009) AS `V818`, (`V819` < 0.0138) AS `V819`, (`V820` < 0.0023) AS `V820`, (`V821` < 0.0023) AS `V821`, (`V822` < 0.009) AS `V822`, (`V823` < 0.1) AS `V823`, (`V824` < 0.0185) AS `V824`, (`V825` < 0.0055) AS `V825`, (`V826` < 0.0375) AS `V826`, (`V827` < 0.0045) AS `V827`, (`V828` < 0.0035) AS `V828`, (`V829` < 0.026) AS `V829`, (`V830` < 0.0045) AS `V830`, (`V831` < 0.054) AS `V831`, (`V832` < 0.0045) AS `V832`, (`V833` < 0.0185) AS `V833`, (`V834` < 0.0375) AS `V834`, (`V835` < 0.0185) AS `V835`, (`V836` < 0.0138) AS `V836`, (`V837` < 0.026) AS `V837`, (`V838` < 0.15) AS `V838`, (`V839` < 0.075) AS `V839`, (`V840` < 3e-04) AS `V840`, (`V841` < 0.0138) AS `V841`, (`V842` < 0.1) AS `V842`, (`V843` < 0.026) AS `V843`, (`V844` < 0.0023) AS `V844`, (`V845` < 0.009) AS `V845`, (`V846` < 0.009) AS `V846`, (`V847` < 0.026) AS `V847`, (`V848` < 0.0028) AS `V848`, (`V849` < 0.3) AS `V849`, (`V850` < 0.075) AS `V850`, (`V851` < 0.0028) AS `V851`, (`V852` < 0.0018) AS `V852`, (`V853` < 0.0045) AS `V853`, (`V854` < 0.15) AS `V854`, (`V855` < 0.3) AS `V855`, (`V856` < 0.15) AS `V856`, (`V857` < 0.0035) AS `V857`, (`V858` < 0.009) AS `V858`, (`V859` < 0.0028) AS `V859`, (`V860` < 0.009) AS `V860`, (`V861` < 0.0138) AS `V861`, (`V862` < 0.1) AS `V862`, (`V863` < 0.0138) AS `V863`, (`V864` < 0.0055) AS `V864`, (`V865` < 0.0028) AS `V865`, (`V866` < 0.075) AS `V866`, (`V867` < 0.0023) AS `V867`, (`V868` < 0.0028) AS `V868`, (`V869` < 0.009) AS `V869`, (`V870` < 0.0055) AS `V870`, (`V871` < 0.0375) AS `V871`, (`V872` < 0.0055) AS `V872`, (`V873` < 0.009) AS `V873`, (`V874` < 0.009) AS `V874`, (`V875` < 0.0185) AS `V875`, (`V876` < 0.0185) AS `V876`, (`V877` < 8e-04) AS `V877`, (`V878` < 0.0035) AS `V878`, (`V879` < 0.0013) AS `V879`, (`V880` < 0.075) AS `V880`, (`V881` < 0.0375) AS `V881`, (`V882` < 0.0138) AS `V882`, (`V883` < 4e-04) AS `V883`, (`V884` < 0.0138) AS `V884`, (`V885` < 0.054) AS `V885`, (`V886` < 0.0138) AS `V886`, (`V887` < 0.0045) AS `V887`, (`V888` < 0.0023) AS `V888`, (`V889` < 0.0138) AS `V889`, (`V890` < 0.054) AS `V890`, (`V891` < 0.054) AS `V891`, (`V892` < 0.0185) AS `V892`, (`V893` < 0.075) AS `V893`, (`V894` < 0.0055) AS `V894`, (`V895` < 0.0018) AS `V895`, (`V896` < 0.009) AS `V896`, (`V897` < 0.0055) AS `V897`, (`V898` < 0.026) AS `V898`, (`V899` < 0.0138) AS `V899`, (`V900` < 0.0023) AS `V900`, (`V901` < 0.0138) AS `V901`, (`V902` < 0.0138) AS `V902`, (`V903` < 0.026) AS `V903`, (`V904` < 0.0018) AS `V904`, (`V905` < 0.0055) AS `V905`, (`V906` < 0.0055) AS `V906`, (`V907` < 0.0185) AS `V907`, (`V908` < 0.0055) AS `V908`, (`V909` < 1e-04) AS `V909`, (`V910` < 0.054) AS `V910`, (`V911` < 0.0023) AS `V911`, (`V912` < 0.009) AS `V912`, (`V913` < 0.026) AS `V913`, (`V914` < 0.009) AS `V914`, (`V915` < 0.0185) AS `V915`, (`V916` < 0.026) AS `V916`, (`V917` < 0.1) AS `V917`, (`V918` < 0.0028) AS `V918`, (`V919` < 0.0028) AS `V919`, (`V920` < 0.0045) AS `V920`, (`V921` < 0.054) AS `V921`, (`V922` < 0.0138) AS `V922`, (`V923` < 0.0055) AS `V923`, (`V924` < 0.0138) AS `V924`, (`V925` < 0.009) AS `V925`, (`V926` < 0.0185) AS `V926`, (`V927` < 0.0013) AS `V927`, (`V928` < 0.009) AS `V928`, (`V929` < 0.0045) AS `V929`, (`V930` < 0.0045) AS `V930`, (`V931` < 0.026) AS `V931`, (`V932` < 0.0028) AS `V932`, (`V933` < 0.0138) AS `V933`, (`V934` < 0.054) AS `V934`, (`V935` < 0.0028) AS `V935`, (`V936` < 0.0138) AS `V936`, (`V937` < 0.1) AS `V937`, (`V938` < 0.0138) AS `V938`, (`V939` < 0.0055) AS `V939`, (`V940` < 0.054) AS `V940`, (`V941` < 0.0023) AS `V941`, (`V942` < 0.0018) AS `V942`, (`V943` < 0.0055) AS `V943`, (`V944` < 0.0375) AS `V944`, (`V945` < 0.0185) AS `V945`, (`V946` < 0.0055) AS `V946`, (`V947` < 0.0375) AS `V947`, (`V948` < 0.15) AS `V948`, (`V949` < 0.009) AS `V949`, (`V950` < 0.0045) AS `V950`, (`V951` < 0.3) AS `V951`, (`V952` < 0.054) AS `V952`, (`V953` < 0.0045) AS `V953`, (`V954` < 0.0375) AS `V954`, (`V955` < 0.0035) AS `V955`, (`V956` < 0.0045) AS `V956`, (`V957` < 0.0035) AS `V957`, (`V958` < 0.026) AS `V958`, (`V959` < 0.0375) AS `V959`, (`V960` < 0.0028) AS `V960`, (`V961` < 0.054) AS `V961`, (`V962` < 0.0023) AS `V962`, (`V963` < 0.026) AS `V963`, (`V964` < 0.0375) AS `V964`, (`V965` < 0.0035) AS `V965`, (`V966` < 0.0375) AS `V966`, (`V967` < 0.0045) AS `V967`, (`V968` < 0.0185) AS `V968`, (`V969` < 0.0055) AS `V969`, (`V970` < 0.075) AS `V970`, (`V971` < 0.026) AS `V971`, (`V972` < 0.15) AS `V972`, (`V973` < 0.054) AS `V973`, (`V974` < 0.15) AS `V974`, (`V975` < 0.026) AS `V975`, (`V976` < 0.0138) AS `V976`, (`V977` < 0.0375) AS `V977`, (`V978` < 0.009) AS `V978`, (`V979` < 0.075) AS `V979`, (`V980` < 0.0138) AS `V980`, (`V981` < 0.0013) AS `V981`, (`V982` < 0.1) AS `V982`, (`V983` < 0.009) AS `V983`, (`V984` < 0.009) AS `V984`, (`V985` < 0.0185) AS `V985`, (`V986` < 0.0185) AS `V986`, (`V987` < 0.0045) AS `V987`, (`V988` < 0.0185) AS `V988`, (`V989` < 0.0138) AS `V989`, (`V990` < 0.0375) AS `V990`, (`V991` < 0.0018) AS `V991`, (`V992` < 0.0138) AS `V992`, (`V993` < 0.0035) AS `V993`, (`V994` < 0.0375) AS `V994`, (`V995` < 0.0028) AS `V995`, (`V996` < 0.3) AS `V996`, (`V997` < 0.0045) AS `V997`, (`V998` < 0.009) AS `V998`, (`V999` < 0.0028) AS `V999`, (`V1000` < 0.0138) AS `V1000`
FROM `analyis_tbl`
17/12/19 12:06:02 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 12:06:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:06:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz70`
WHERE (0 = 1)
17/12/19 12:06:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:06:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 12:06:03 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/12/19 12:06:03 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 12:06:03 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 2 output partitions
17/12/19 12:06:03 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:196)
17/12/19 12:06:03 INFO DAGScheduler: Parents of final stage: List()
17/12/19 12:06:03 INFO DAGScheduler: Missing parents: List()
17/12/19 12:06:03 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at collect at utils.scala:196), which has no missing parents
17/12/19 12:06:03 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1014.4 KB, free 1869.2 MB)
17/12/19 12:06:03 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 276.8 KB, free 1869.0 MB)
17/12/19 12:06:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:50912 (size: 276.8 KB, free: 1870.5 MB)
17/12/19 12:06:03 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/19 12:06:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at collect at utils.scala:196)
17/12/19 12:06:03 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
17/12/19 12:06:03 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6044 bytes)
17/12/19 12:06:03 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 6044 bytes)
17/12/19 12:06:03 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/19 12:06:03 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/12/19 12:06:03 INFO BlockManager: Found block rdd_20_0 locally
17/12/19 12:06:03 INFO CodeGenerator: Code generated in 296.883029 ms
17/12/19 12:06:04 INFO CodeGenerator: Code generated in 319.978161 ms
17/12/19 12:06:08 WARN CodeGenerator: Error calculating stats of compiled class.
java.io.EOFException
	at java.io.DataInputStream.readFully(Unknown Source)
	at java.io.DataInputStream.readFully(Unknown Source)
	at org.codehaus.janino.util.ClassFile.loadAttribute(ClassFile.java:1509)
	at org.codehaus.janino.util.ClassFile.loadAttributes(ClassFile.java:644)
	at org.codehaus.janino.util.ClassFile.loadFields(ClassFile.java:623)
	at org.codehaus.janino.util.ClassFile.<init>(ClassFile.java:280)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anonfun$recordCompilationStats$1.apply(CodeGenerator.scala:967)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anonfun$recordCompilationStats$1.apply(CodeGenerator.scala:964)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.recordCompilationStats(CodeGenerator.scala:964)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(CodeGenerator.scala:936)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:998)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:995)
	at org.spark_project.guava.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)
	at org.spark_project.guava.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)
	at org.spark_project.guava.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)
	at org.spark_project.guava.cache.LocalCache$Segment.get(LocalCache.java:2257)
	at org.spark_project.guava.cache.LocalCache.get(LocalCache.java:4000)
	at org.spark_project.guava.cache.LocalCache.getOrLoad(LocalCache.java:4004)
	at org.spark_project.guava.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4874)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.compile(CodeGenerator.scala:890)
	at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:405)
	at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:359)
	at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:32)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:874)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.extractProjection$lzycompute(ExpressionEncoder.scala:266)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.extractProjection(ExpressionEncoder.scala:266)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:290)
	at org.apache.spark.sql.SparkSession$$anonfun$3.apply(SparkSession.scala:547)
	at org.apache.spark.sql.SparkSession$$anonfun$3.apply(SparkSession.scala:547)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:232)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/12/19 12:06:08 INFO CodeGenerator: Code generated in 3436.299221 ms
17/12/19 12:06:17 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 960392 bytes result sent to driver
17/12/19 12:06:17 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 13662 ms on localhost (executor driver) (1/2)
17/12/19 12:09:05 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:50912 in memory (size: 190.0 KB, free: 1870.6 MB)
17/12/19 12:09:05 INFO MemoryStore: Block rdd_20_1 stored as values in memory (estimated size 133.7 MB, free 1736.0 MB)
17/12/19 12:09:05 INFO BlockManagerInfo: Added rdd_20_1 in memory on 127.0.0.1:50912 (size: 133.7 MB, free: 1737.0 MB)
17/12/19 12:09:12 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 963099 bytes result sent to driver
17/12/19 12:09:12 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 189193 ms on localhost (executor driver) (2/2)
17/12/19 12:09:12 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/19 12:09:12 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:196) finished in 189.193 s
17/12/19 12:09:12 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 189.223353 s
17/12/19 12:09:12 INFO CodeGenerator: Code generated in 100.10055 ms
17/12/19 12:09:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:09:21 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ae81f3e66ad
17/12/19 12:09:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:09:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ae81f3e66ad` AS `zzz71`
WHERE (0 = 1)
17/12/19 12:09:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:09:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ae81f3e66ad`
17/12/19 12:09:21 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 12:09:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:09:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz72`
WHERE (0 = 1)
17/12/19 12:09:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:09:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 12:09:21 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 12:09:21 INFO DAGScheduler: Got job 6 (take at <unknown>:0) with 1 output partitions
17/12/19 12:09:21 INFO DAGScheduler: Final stage: ResultStage 6 (take at <unknown>:0)
17/12/19 12:09:21 INFO DAGScheduler: Parents of final stage: List()
17/12/19 12:09:21 INFO DAGScheduler: Missing parents: List()
17/12/19 12:09:21 INFO DAGScheduler: Submitting ResultStage 6 (WorkerRDD[37] at RDD at rdd.scala:18), which has no missing parents
17/12/19 12:09:21 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 114.2 KB, free 1735.9 MB)
17/12/19 12:09:21 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 42.6 KB, free 1735.8 MB)
17/12/19 12:09:21 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:50912 (size: 42.6 KB, free: 1736.9 MB)
17/12/19 12:09:21 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/12/19 12:09:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (WorkerRDD[37] at RDD at rdd.scala:18)
17/12/19 12:09:21 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/19 12:09:21 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 6012 bytes)
17/12/19 12:09:21 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
17/12/19 12:09:23 INFO MemoryStore: Block rdd_37_0 stored as values in memory (estimated size 80.0 B, free 1735.8 MB)
17/12/19 12:09:23 INFO BlockManagerInfo: Added rdd_37_0 in memory on 127.0.0.1:50912 (size: 80.0 B, free: 1736.9 MB)
17/12/19 12:09:23 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1997 bytes result sent to driver
17/12/19 12:09:23 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 2619 ms on localhost (executor driver) (1/1)
17/12/19 12:09:23 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/19 12:09:23 INFO DAGScheduler: ResultStage 6 (take at <unknown>:0) finished in 2.619 s
17/12/19 12:09:23 INFO DAGScheduler: Job 6 finished: take at <unknown>:0, took 2.638482 s
17/12/19 12:09:23 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 12:09:23 INFO DAGScheduler: Got job 7 (take at <unknown>:0) with 1 output partitions
17/12/19 12:09:23 INFO DAGScheduler: Final stage: ResultStage 7 (take at <unknown>:0)
17/12/19 12:09:23 INFO DAGScheduler: Parents of final stage: List()
17/12/19 12:09:23 INFO DAGScheduler: Missing parents: List()
17/12/19 12:09:23 INFO DAGScheduler: Submitting ResultStage 7 (WorkerRDD[37] at RDD at rdd.scala:18), which has no missing parents
17/12/19 12:09:23 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 114.2 KB, free 1735.7 MB)
17/12/19 12:09:23 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 42.6 KB, free 1735.7 MB)
17/12/19 12:09:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:50912 (size: 42.6 KB, free: 1736.9 MB)
17/12/19 12:09:23 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/12/19 12:09:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (WorkerRDD[37] at RDD at rdd.scala:18)
17/12/19 12:09:23 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/12/19 12:09:23 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8, localhost, executor driver, partition 1, PROCESS_LOCAL, 6012 bytes)
17/12/19 12:09:23 INFO Executor: Running task 0.0 in stage 7.0 (TID 8)
17/12/19 12:09:26 INFO MemoryStore: Block rdd_37_1 stored as values in memory (estimated size 80.0 B, free 1735.7 MB)
17/12/19 12:09:26 INFO BlockManagerInfo: Added rdd_37_1 in memory on 127.0.0.1:50912 (size: 80.0 B, free: 1736.9 MB)
17/12/19 12:09:26 INFO Executor: Finished task 0.0 in stage 7.0 (TID 8). 1910 bytes result sent to driver
17/12/19 12:09:26 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 2520 ms on localhost (executor driver) (1/1)
17/12/19 12:09:26 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/12/19 12:09:26 INFO DAGScheduler: ResultStage 7 (take at <unknown>:0) finished in 2.520 s
17/12/19 12:09:26 INFO DAGScheduler: Job 7 finished: take at <unknown>:0, took 2.528428 s
17/12/19 12:09:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:09:26 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ae8b9f22fc
17/12/19 12:09:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:09:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ae8b9f22fc` AS `zzz73`
WHERE (0 = 1)
17/12/19 12:09:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:09:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ae8b9f22fc`
LIMIT 10
17/12/19 12:09:26 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 12:09:26 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/12/19 12:09:26 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:196)
17/12/19 12:09:26 INFO DAGScheduler: Parents of final stage: List()
17/12/19 12:09:26 INFO DAGScheduler: Missing parents: List()
17/12/19 12:09:26 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[41] at collect at utils.scala:196), which has no missing parents
17/12/19 12:09:26 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 116.1 KB, free 1735.5 MB)
17/12/19 12:09:26 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 43.8 KB, free 1735.5 MB)
17/12/19 12:09:26 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:50912 (size: 43.8 KB, free: 1736.8 MB)
17/12/19 12:09:26 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/12/19 12:09:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[41] at collect at utils.scala:196)
17/12/19 12:09:26 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/19 12:09:26 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5959 bytes)
17/12/19 12:09:26 INFO Executor: Running task 0.0 in stage 8.0 (TID 9)
17/12/19 12:09:26 INFO BlockManager: Found block rdd_37_0 locally
17/12/19 12:09:26 INFO Executor: Finished task 0.0 in stage 8.0 (TID 9). 1070 bytes result sent to driver
17/12/19 12:09:26 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:196) finished in 0.015 s
17/12/19 12:09:26 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.012888 s
17/12/19 12:09:26 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 9) in 15 ms on localhost (executor driver) (1/1)
17/12/19 12:09:26 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 12:09:26 INFO DAGScheduler: Got job 9 (collect at utils.scala:196) with 1 output partitions
17/12/19 12:09:26 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/12/19 12:09:26 INFO DAGScheduler: Parents of final stage: List()
17/12/19 12:09:26 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/19 12:09:26 INFO DAGScheduler: Missing parents: List()
17/12/19 12:09:26 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[41] at collect at utils.scala:196), which has no missing parents
17/12/19 12:09:26 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 116.1 KB, free 1735.4 MB)
17/12/19 12:09:26 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 43.8 KB, free 1735.3 MB)
17/12/19 12:09:26 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:50912 (size: 43.8 KB, free: 1736.8 MB)
17/12/19 12:09:26 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/12/19 12:09:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[41] at collect at utils.scala:196)
17/12/19 12:09:26 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/12/19 12:09:26 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 5959 bytes)
17/12/19 12:09:26 INFO Executor: Running task 0.0 in stage 9.0 (TID 10)
17/12/19 12:09:26 INFO BlockManager: Found block rdd_37_1 locally
17/12/19 12:09:26 INFO Executor: Finished task 0.0 in stage 9.0 (TID 10). 1228 bytes result sent to driver
17/12/19 12:09:26 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.016 s
17/12/19 12:09:26 INFO DAGScheduler: Job 9 finished: collect at utils.scala:196, took 0.012339 s
17/12/19 12:09:26 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 10) in 16 ms on localhost (executor driver) (1/1)
17/12/19 12:09:26 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/12/19 12:09:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:09:26 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`, `V11` AS `V11`, `V12` AS `V12`, `V13` AS `V13`, `V14` AS `V14`, `V15` AS `V15`, `V16` AS `V16`, `V17` AS `V17`, `V18` AS `V18`, `V19` AS `V19`, `V20` AS `V20`, `V21` AS `V21`, `V22` AS `V22`, `V23` AS `V23`, `V24` AS `V24`, `V25` AS `V25`, `V26` AS `V26`, `V27` AS `V27`, `V28` AS `V28`, `V29` AS `V29`, `V30` AS `V30`, `V31` AS `V31`, `V32` AS `V32`, `V33` AS `V33`, `V34` AS `V34`, `V35` AS `V35`, `V36` AS `V36`, `V37` AS `V37`, `V38` AS `V38`, `V39` AS `V39`, `V40` AS `V40`, `V41` AS `V41`, `V42` AS `V42`, `V43` AS `V43`, `V44` AS `V44`, `V45` AS `V45`, `V46` AS `V46`, `V47` AS `V47`, `V48` AS `V48`, `V49` AS `V49`, `V50` AS `V50`, `V51` AS `V51`, `V52` AS `V52`, `V53` AS `V53`, `V54` AS `V54`, `V55` AS `V55`, `V56` AS `V56`, `V57` AS `V57`, `V58` AS `V58`, `V59` AS `V59`, `V60` AS `V60`, `V61` AS `V61`, `V62` AS `V62`, `V63` AS `V63`, `V64` AS `V64`, `V65` AS `V65`, `V66` AS `V66`, `V67` AS `V67`, `V68` AS `V68`, `V69` AS `V69`, `V70` AS `V70`, `V71` AS `V71`, `V72` AS `V72`, `V73` AS `V73`, `V74` AS `V74`, `V75` AS `V75`, `V76` AS `V76`, `V77` AS `V77`, `V78` AS `V78`, `V79` AS `V79`, `V80` AS `V80`, `V81` AS `V81`, `V82` AS `V82`, `V83` AS `V83`, `V84` AS `V84`, `V85` AS `V85`, `V86` AS `V86`, `V87` AS `V87`, `V88` AS `V88`, `V89` AS `V89`, `V90` AS `V90`, `V91` AS `V91`, `V92` AS `V92`, `V93` AS `V93`, `V94` AS `V94`, `V95` AS `V95`, `V96` AS `V96`, `V97` AS `V97`, `V98` AS `V98`, `V99` AS `V99`, `V100` AS `V100`
FROM (SELECT `S1`, `S1` + 0.92195445 * RANDN() AS `V1`, `S1` + 0.92195445 * RANDN() AS `V2`, `S1` + 0.92195445 * RANDN() AS `V3`, `S1` + 0.92195445 * RANDN() AS `V4`, `S1` + 0.92195445 * RANDN() AS `V5`, `S1` + 0.92195445 * RANDN() AS `V6`, `S1` + 0.92195445 * RANDN() AS `V7`, `S1` + 0.92195445 * RANDN() AS `V8`, `S1` + 0.92195445 * RANDN() AS `V9`, `S1` + 0.92195445 * RANDN() AS `V10`, `S1` + 0.92195445 * RANDN() AS `V11`, `S1` + 0.92195445 * RANDN() AS `V12`, `S1` + 0.92195445 * RANDN() AS `V13`, `S1` + 0.92195445 * RANDN() AS `V14`, `S1` + 0.92195445 * RANDN() AS `V15`, `S1` + 0.92195445 * RANDN() AS `V16`, `S1` + 0.92195445 * RANDN() AS `V17`, `S1` + 0.92195445 * RANDN() AS `V18`, `S1` + 0.92195445 * RANDN() AS `V19`, `S1` + 0.92195445 * RANDN() AS `V20`, `S1` + 0.92195445 * RANDN() AS `V21`, `S1` + 0.92195445 * RANDN() AS `V22`, `S1` + 0.92195445 * RANDN() AS `V23`, `S1` + 0.92195445 * RANDN() AS `V24`, `S1` + 0.92195445 * RANDN() AS `V25`, `S1` + 0.92195445 * RANDN() AS `V26`, `S1` + 0.92195445 * RANDN() AS `V27`, `S1` + 0.92195445 * RANDN() AS `V28`, `S1` + 0.92195445 * RANDN() AS `V29`, `S1` + 0.92195445 * RANDN() AS `V30`, `S1` + 0.92195445 * RANDN() AS `V31`, `S1` + 0.92195445 * RANDN() AS `V32`, `S1` + 0.92195445 * RANDN() AS `V33`, `S1` + 0.92195445 * RANDN() AS `V34`, `S1` + 0.92195445 * RANDN() AS `V35`, `S1` + 0.92195445 * RANDN() AS `V36`, `S1` + 0.92195445 * RANDN() AS `V37`, `S1` + 0.92195445 * RANDN() AS `V38`, `S1` + 0.92195445 * RANDN() AS `V39`, `S1` + 0.92195445 * RANDN() AS `V40`, `S1` + 0.92195445 * RANDN() AS `V41`, `S1` + 0.92195445 * RANDN() AS `V42`, `S1` + 0.92195445 * RANDN() AS `V43`, `S1` + 0.92195445 * RANDN() AS `V44`, `S1` + 0.92195445 * RANDN() AS `V45`, `S1` + 0.92195445 * RANDN() AS `V46`, `S1` + 0.92195445 * RANDN() AS `V47`, `S1` + 0.92195445 * RANDN() AS `V48`, `S1` + 0.92195445 * RANDN() AS `V49`, `S1` + 0.92195445 * RANDN() AS `V50`, `S1` + 0.92195445 * RANDN() AS `V51`, `S1` + 0.92195445 * RANDN() AS `V52`, `S1` + 0.92195445 * RANDN() AS `V53`, `S1` + 0.92195445 * RANDN() AS `V54`, `S1` + 0.92195445 * RANDN() AS `V55`, `S1` + 0.92195445 * RANDN() AS `V56`, `S1` + 0.92195445 * RANDN() AS `V57`, `S1` + 0.92195445 * RANDN() AS `V58`, `S1` + 0.92195445 * RANDN() AS `V59`, `S1` + 0.92195445 * RANDN() AS `V60`, `S1` + 0.92195445 * RANDN() AS `V61`, `S1` + 0.92195445 * RANDN() AS `V62`, `S1` + 0.92195445 * RANDN() AS `V63`, `S1` + 0.92195445 * RANDN() AS `V64`, `S1` + 0.92195445 * RANDN() AS `V65`, `S1` + 0.92195445 * RANDN() AS `V66`, `S1` + 0.92195445 * RANDN() AS `V67`, `S1` + 0.92195445 * RANDN() AS `V68`, `S1` + 0.92195445 * RANDN() AS `V69`, `S1` + 0.92195445 * RANDN() AS `V70`, `S1` + 0.92195445 * RANDN() AS `V71`, `S1` + 0.92195445 * RANDN() AS `V72`, `S1` + 0.92195445 * RANDN() AS `V73`, `S1` + 0.92195445 * RANDN() AS `V74`, `S1` + 0.92195445 * RANDN() AS `V75`, `S1` + 0.92195445 * RANDN() AS `V76`, `S1` + 0.92195445 * RANDN() AS `V77`, `S1` + 0.92195445 * RANDN() AS `V78`, `S1` + 0.92195445 * RANDN() AS `V79`, `S1` + 0.92195445 * RANDN() AS `V80`, `S1` + 0.92195445 * RANDN() AS `V81`, `S1` + 0.92195445 * RANDN() AS `V82`, `S1` + 0.92195445 * RANDN() AS `V83`, `S1` + 0.92195445 * RANDN() AS `V84`, `S1` + 0.92195445 * RANDN() AS `V85`, `S1` + 0.92195445 * RANDN() AS `V86`, `S1` + 0.92195445 * RANDN() AS `V87`, `S1` + 0.92195445 * RANDN() AS `V88`, `S1` + 0.92195445 * RANDN() AS `V89`, `S1` + 0.92195445 * RANDN() AS `V90`, `S1` + 0.92195445 * RANDN() AS `V91`, `S1` + 0.92195445 * RANDN() AS `V92`, `S1` + 0.92195445 * RANDN() AS `V93`, `S1` + 0.92195445 * RANDN() AS `V94`, `S1` + 0.92195445 * RANDN() AS `V95`, `S1` + 0.92195445 * RANDN() AS `V96`, `S1` + 0.92195445 * RANDN() AS `V97`, `S1` + 0.92195445 * RANDN() AS `V98`, `S1` + 0.92195445 * RANDN() AS `V99`, `S1` + 0.92195445 * RANDN() AS `V100`
FROM (SELECT `S1` AS `S1`
FROM (SELECT `id`, 0.387298334620742 * RANDN() AS `S1`
FROM `analyis_tbl`) `fylqwwwulw`) `kkldssfolp`) `fwvdwbujhi`
17/12/19 12:09:26 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 12:09:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:09:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz74`
WHERE (0 = 1)
17/12/19 12:09:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:09:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 12:09:26 INFO CodeGenerator: Code generated in 34.302119 ms
17/12/19 12:09:26 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 12:09:26 INFO DAGScheduler: Got job 10 (take at <unknown>:0) with 1 output partitions
17/12/19 12:09:26 INFO DAGScheduler: Final stage: ResultStage 10 (take at <unknown>:0)
17/12/19 12:09:26 INFO DAGScheduler: Parents of final stage: List()
17/12/19 12:09:26 INFO DAGScheduler: Missing parents: List()
17/12/19 12:09:26 INFO DAGScheduler: Submitting ResultStage 10 (WorkerRDD[47] at RDD at rdd.scala:18), which has no missing parents
17/12/19 12:09:26 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 190.8 KB, free 1735.2 MB)
17/12/19 12:09:26 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 58.7 KB, free 1735.1 MB)
17/12/19 12:09:26 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:50912 (size: 58.7 KB, free: 1736.7 MB)
17/12/19 12:09:26 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/12/19 12:09:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (WorkerRDD[47] at RDD at rdd.scala:18)
17/12/19 12:09:26 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/12/19 12:09:26 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6012 bytes)
17/12/19 12:09:26 INFO Executor: Running task 0.0 in stage 10.0 (TID 11)
17/12/19 12:09:27 INFO CodeGenerator: Code generated in 19.724464 ms
17/12/19 12:12:29 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:50912 in memory (size: 43.8 KB, free: 1736.8 MB)
17/12/19 12:12:29 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:50912 in memory (size: 43.8 KB, free: 1736.8 MB)
17/12/19 12:12:29 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:50912 in memory (size: 42.6 KB, free: 1736.9 MB)
17/12/19 12:12:29 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:50912 in memory (size: 42.6 KB, free: 1736.9 MB)
17/12/19 12:12:30 INFO MemoryStore: Block rdd_47_0 stored as values in memory (estimated size 135.2 MB, free 1600.5 MB)
17/12/19 12:12:30 INFO BlockManagerInfo: Added rdd_47_0 in memory on 127.0.0.1:50912 (size: 135.2 MB, free: 1601.7 MB)
17/12/19 12:12:30 WARN Executor: 1 block locks were not released by TID = 11:
[rdd_47_0]
17/12/19 12:12:30 INFO Executor: Finished task 0.0 in stage 10.0 (TID 11). 16277 bytes result sent to driver
17/12/19 12:12:30 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 11) in 183685 ms on localhost (executor driver) (1/1)
17/12/19 12:12:30 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/19 12:12:30 INFO DAGScheduler: ResultStage 10 (take at <unknown>:0) finished in 183.685 s
17/12/19 12:12:30 INFO DAGScheduler: Job 10 finished: take at <unknown>:0, took 183.702039 s
17/12/19 12:12:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:12:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ae82dd74192
17/12/19 12:12:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:12:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ae82dd74192` AS `zzz75`
WHERE (0 = 1)
17/12/19 12:12:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:12:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ae82dd74192`
17/12/19 12:12:30 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 12:12:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:12:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz76`
WHERE (0 = 1)
17/12/19 12:12:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:12:31 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.01) AS `V1`, (`V2` < 0.01) AS `V2`, (`V3` < 0.01) AS `V3`, (`V4` < 0.01) AS `V4`, (`V5` < 0.01) AS `V5`, (`V6` < 0.01) AS `V6`, (`V7` < 0.01) AS `V7`, (`V8` < 0.01) AS `V8`, (`V9` < 0.01) AS `V9`, (`V10` < 0.01) AS `V10`, (`V11` < 0.01) AS `V11`, (`V12` < 0.01) AS `V12`, (`V13` < 0.01) AS `V13`, (`V14` < 0.01) AS `V14`, (`V15` < 0.01) AS `V15`, (`V16` < 0.01) AS `V16`, (`V17` < 0.01) AS `V17`, (`V18` < 0.01) AS `V18`, (`V19` < 0.01) AS `V19`, (`V20` < 0.01) AS `V20`, (`V21` < 0.01) AS `V21`, (`V22` < 0.01) AS `V22`, (`V23` < 0.01) AS `V23`, (`V24` < 0.01) AS `V24`, (`V25` < 0.01) AS `V25`, (`V26` < 0.01) AS `V26`, (`V27` < 0.01) AS `V27`, (`V28` < 0.01) AS `V28`, (`V29` < 0.01) AS `V29`, (`V30` < 0.01) AS `V30`, (`V31` < 0.01) AS `V31`, (`V32` < 0.01) AS `V32`, (`V33` < 0.01) AS `V33`, (`V34` < 0.01) AS `V34`, (`V35` < 0.01) AS `V35`, (`V36` < 0.01) AS `V36`, (`V37` < 0.01) AS `V37`, (`V38` < 0.01) AS `V38`, (`V39` < 0.01) AS `V39`, (`V40` < 0.01) AS `V40`, (`V41` < 0.01) AS `V41`, (`V42` < 0.01) AS `V42`, (`V43` < 0.01) AS `V43`, (`V44` < 0.01) AS `V44`, (`V45` < 0.01) AS `V45`, (`V46` < 0.01) AS `V46`, (`V47` < 0.01) AS `V47`, (`V48` < 0.01) AS `V48`, (`V49` < 0.01) AS `V49`, (`V50` < 0.01) AS `V50`, (`V51` < 0.01) AS `V51`, (`V52` < 0.01) AS `V52`, (`V53` < 0.01) AS `V53`, (`V54` < 0.01) AS `V54`, (`V55` < 0.01) AS `V55`, (`V56` < 0.01) AS `V56`, (`V57` < 0.01) AS `V57`, (`V58` < 0.01) AS `V58`, (`V59` < 0.01) AS `V59`, (`V60` < 0.01) AS `V60`, (`V61` < 0.01) AS `V61`, (`V62` < 0.01) AS `V62`, (`V63` < 0.01) AS `V63`, (`V64` < 0.01) AS `V64`, (`V65` < 0.01) AS `V65`, (`V66` < 0.01) AS `V66`, (`V67` < 0.01) AS `V67`, (`V68` < 0.01) AS `V68`, (`V69` < 0.01) AS `V69`, (`V70` < 0.01) AS `V70`, (`V71` < 0.01) AS `V71`, (`V72` < 0.01) AS `V72`, (`V73` < 0.01) AS `V73`, (`V74` < 0.01) AS `V74`, (`V75` < 0.01) AS `V75`, (`V76` < 0.01) AS `V76`, (`V77` < 0.01) AS `V77`, (`V78` < 0.01) AS `V78`, (`V79` < 0.01) AS `V79`, (`V80` < 0.01) AS `V80`, (`V81` < 0.01) AS `V81`, (`V82` < 0.01) AS `V82`, (`V83` < 0.01) AS `V83`, (`V84` < 0.01) AS `V84`, (`V85` < 0.01) AS `V85`, (`V86` < 0.01) AS `V86`, (`V87` < 0.01) AS `V87`, (`V88` < 0.01) AS `V88`, (`V89` < 0.01) AS `V89`, (`V90` < 0.01) AS `V90`, (`V91` < 0.01) AS `V91`, (`V92` < 0.01) AS `V92`, (`V93` < 0.01) AS `V93`, (`V94` < 0.01) AS `V94`, (`V95` < 0.01) AS `V95`, (`V96` < 0.01) AS `V96`, (`V97` < 0.01) AS `V97`, (`V98` < 0.01) AS `V98`, (`V99` < 0.01) AS `V99`, (`V100` < 0.01) AS `V100`
FROM `analyis_tbl`
17/12/19 12:12:31 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 12:12:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:12:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz77`
WHERE (0 = 1)
17/12/19 12:12:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:12:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 12:12:31 INFO CodeGenerator: Code generated in 34.174874 ms
17/12/19 12:12:31 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 12:12:31 INFO DAGScheduler: Got job 11 (collect at utils.scala:196) with 2 output partitions
17/12/19 12:12:31 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:196)
17/12/19 12:12:31 INFO DAGScheduler: Parents of final stage: List()
17/12/19 12:12:31 INFO DAGScheduler: Missing parents: List()
17/12/19 12:12:31 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[54] at collect at utils.scala:196), which has no missing parents
17/12/19 12:12:31 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 283.7 KB, free 1600.2 MB)
17/12/19 12:12:31 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 76.3 KB, free 1600.1 MB)
17/12/19 12:12:31 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:50912 (size: 76.3 KB, free: 1601.6 MB)
17/12/19 12:12:31 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/12/19 12:12:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[54] at collect at utils.scala:196)
17/12/19 12:12:31 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks
17/12/19 12:12:31 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6045 bytes)
17/12/19 12:12:31 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 6045 bytes)
17/12/19 12:12:31 INFO Executor: Running task 0.0 in stage 11.0 (TID 12)
17/12/19 12:12:31 INFO BlockManager: Found block rdd_47_0 locally
17/12/19 12:12:33 INFO Executor: Running task 1.0 in stage 11.0 (TID 13)
17/12/19 12:12:33 INFO CodeGenerator: Code generated in 1976.943759 ms
17/12/19 12:12:33 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:50912 in memory (size: 58.7 KB, free: 1601.7 MB)
17/12/19 12:12:33 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:50912 in memory (size: 276.8 KB, free: 1601.9 MB)
17/12/19 12:12:33 INFO CodeGenerator: Code generated in 104.733093 ms
17/12/19 12:12:34 INFO Executor: Finished task 0.0 in stage 11.0 (TID 12). 637098 bytes result sent to driver
17/12/19 12:12:34 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 12) in 3435 ms on localhost (executor driver) (1/2)
17/12/19 12:15:29 INFO MemoryStore: Block rdd_47_1 stored as values in memory (estimated size 135.2 MB, free 1466.4 MB)
17/12/19 12:15:29 INFO BlockManagerInfo: Added rdd_47_1 in memory on 127.0.0.1:50912 (size: 135.2 MB, free: 1466.7 MB)
17/12/19 12:15:30 INFO Executor: Finished task 1.0 in stage 11.0 (TID 13). 639690 bytes result sent to driver
17/12/19 12:15:30 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 13) in 178856 ms on localhost (executor driver) (2/2)
17/12/19 12:15:30 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/12/19 12:15:30 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:196) finished in 178.856 s
17/12/19 12:15:30 INFO DAGScheduler: Job 11 finished: collect at utils.scala:196, took 178.873481 s
17/12/19 12:15:30 INFO CodeGenerator: Code generated in 14.291825 ms
17/12/19 12:15:33 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:50912 in memory (size: 76.3 KB, free: 1466.8 MB)
17/12/19 12:15:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:15:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 12:15:34 INFO CodeGenerator: Code generated in 5.508154 ms
17/12/19 12:15:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:15:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 12:15:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:15:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 12:15:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:15:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 12:15:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:15:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 12:15:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:15:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 12:15:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:15:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 12:15:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:15:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 12:15:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 12:15:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 12:15:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 12:15:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 12:16:13 INFO SparkContext: Invoking stop() from shutdown hook
17/12/19 12:16:13 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/19 12:16:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/19 12:16:13 INFO MemoryStore: MemoryStore cleared
17/12/19 12:16:13 INFO BlockManager: BlockManager stopped
17/12/19 12:16:13 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/19 12:16:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/19 12:16:13 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-c119635a-4731-404d-ab4c-1100d3917dd8\userFiles-3ea19ebe-3841-4208-90af-234e6621c0a0
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-c119635a-4731-404d-ab4c-1100d3917dd8\userFiles-3ea19ebe-3841-4208-90af-234e6621c0a0
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 12:16:13 INFO SparkContext: Successfully stopped SparkContext
17/12/19 12:16:13 INFO ShutdownHookManager: Shutdown hook called
17/12/19 12:16:13 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-c119635a-4731-404d-ab4c-1100d3917dd8\userFiles-3ea19ebe-3841-4208-90af-234e6621c0a0
17/12/19 12:16:13 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-c119635a-4731-404d-ab4c-1100d3917dd8\userFiles-3ea19ebe-3841-4208-90af-234e6621c0a0
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-c119635a-4731-404d-ab4c-1100d3917dd8\userFiles-3ea19ebe-3841-4208-90af-234e6621c0a0
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 12:16:13 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-c119635a-4731-404d-ab4c-1100d3917dd8
17/12/19 12:16:13 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-c119635a-4731-404d-ab4c-1100d3917dd8
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-c119635a-4731-404d-ab4c-1100d3917dd8
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 13:48:49 INFO SparkContext: Running Spark version 2.1.0
17/12/19 13:48:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/19 13:48:50 INFO SecurityManager: Changing view acls to: conan
17/12/19 13:48:50 INFO SecurityManager: Changing modify acls to: conan
17/12/19 13:48:50 INFO SecurityManager: Changing view acls groups to: 
17/12/19 13:48:50 INFO SecurityManager: Changing modify acls groups to: 
17/12/19 13:48:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(conan); groups with view permissions: Set(); users  with modify permissions: Set(conan); groups with modify permissions: Set()
17/12/19 13:48:50 INFO Utils: Successfully started service 'sparkDriver' on port 53597.
17/12/19 13:48:50 INFO SparkEnv: Registering MapOutputTracker
17/12/19 13:48:50 INFO SparkEnv: Registering BlockManagerMaster
17/12/19 13:48:50 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/19 13:48:50 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/19 13:48:50 INFO DiskBlockManager: Created local directory at C:\Users\conan\AppData\Local\Temp\blockmgr-241bbaa5-5526-40f7-879f-2410cecc2aaf
17/12/19 13:48:50 INFO MemoryStore: MemoryStore started with capacity 2004.6 MB
17/12/19 13:48:50 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/19 13:48:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/19 13:48:50 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/19 13:48:50 INFO SparkContext: Added JAR file:/C:/Users/conan/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:53597/jars/sparklyr-2.1-2.11.jar with timestamp 1513691330510
17/12/19 13:48:50 INFO Executor: Starting executor ID driver on host localhost
17/12/19 13:48:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53618.
17/12/19 13:48:50 INFO NettyBlockTransferService: Server created on 127.0.0.1:53618
17/12/19 13:48:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/19 13:48:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53618, None)
17/12/19 13:48:50 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53618 with 2004.6 MB RAM, BlockManagerId(driver, 127.0.0.1, 53618, None)
17/12/19 13:48:50 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53618, None)
17/12/19 13:48:50 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53618, None)
17/12/19 13:48:51 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/19 13:48:51 INFO SharedState: Warehouse path is 'C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/19 13:48:51 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/19 13:48:51 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/19 13:48:51 INFO ObjectStore: ObjectStore, initialize called
17/12/19 13:48:52 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/19 13:48:52 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/19 13:48:53 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/19 13:48:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 13:48:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 13:48:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 13:48:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 13:48:54 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/19 13:48:54 INFO ObjectStore: Initialized ObjectStore
17/12/19 13:48:54 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/19 13:48:55 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/19 13:48:55 INFO HiveMetaStore: Added admin role in metastore
17/12/19 13:48:55 INFO HiveMetaStore: Added public role in metastore
17/12/19 13:48:55 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/19 13:48:55 INFO HiveMetaStore: 0: get_all_databases
17/12/19 13:48:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/19 13:48:55 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/19 13:48:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/19 13:48:55 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 13:48:55 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/Temp/1386e001-0d8e-46eb-9050-f26bb2040894_resources
17/12/19 13:48:55 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/1386e001-0d8e-46eb-9050-f26bb2040894
17/12/19 13:48:55 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/1386e001-0d8e-46eb-9050-f26bb2040894
17/12/19 13:48:55 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/1386e001-0d8e-46eb-9050-f26bb2040894/_tmp_space.db
17/12/19 13:48:55 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/19 13:48:55 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:48:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:48:55 INFO HiveMetaStore: 0: get_database: global_temp
17/12/19 13:48:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/19 13:48:55 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/19 13:48:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:48:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:48:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:48:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:48:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:48:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:48:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 13:49:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:24 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:49:24 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:49:24 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:49:24 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:49:24 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:49:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:49:24 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 13:49:24 INFO CodeGenerator: Code generated in 274.055981 ms
17/12/19 13:49:24 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 13:49:24 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/19 13:49:24 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/19 13:49:24 INFO DAGScheduler: Parents of final stage: List()
17/12/19 13:49:24 INFO DAGScheduler: Missing parents: List()
17/12/19 13:49:24 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/12/19 13:49:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 2004.6 MB)
17/12/19 13:49:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2004.6 MB)
17/12/19 13:49:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.6 MB)
17/12/19 13:49:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/12/19 13:49:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/19 13:49:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/19 13:49:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/19 13:49:25 INFO Executor: Fetching spark://127.0.0.1:53597/jars/sparklyr-2.1-2.11.jar with timestamp 1513691330510
17/12/19 13:49:25 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53597 after 14 ms (0 ms spent in bootstraps)
17/12/19 13:49:25 INFO Utils: Fetching spark://127.0.0.1:53597/jars/sparklyr-2.1-2.11.jar to C:\Users\conan\AppData\Local\Temp\spark-10ef9647-9bcc-4679-ae47-6101db6305d8\userFiles-8b8769fc-4426-4101-9e7c-7bccce33dbc4\fetchFileTemp2986487199239813597.tmp
17/12/19 13:49:25 INFO Executor: Adding file:/C:/Users/conan/AppData/Local/Temp/spark-10ef9647-9bcc-4679-ae47-6101db6305d8/userFiles-8b8769fc-4426-4101-9e7c-7bccce33dbc4/sparklyr-2.1-2.11.jar to class loader
17/12/19 13:49:25 INFO CodeGenerator: Code generated in 14.078492 ms
17/12/19 13:49:25 INFO CodeGenerator: Code generated in 12.534563 ms
17/12/19 13:49:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/12/19 13:49:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 327 ms on localhost (executor driver) (1/1)
17/12/19 13:49:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/19 13:49:25 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.337 s
17/12/19 13:49:25 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.514984 s
17/12/19 13:49:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:25 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 13:49:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:25 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 13:49:25 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 13:49:25 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 13:49:25 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 13:49:25 INFO FileSourceStrategy: Output Data Schema: struct<V1: double, V2: double, V3: double, V4: double, V5: double ... 8 more fields>
17/12/19 13:49:25 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 13:49:25 INFO CodeGenerator: Code generated in 8.35927 ms
17/12/19 13:49:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.7 KB, free 2004.3 MB)
17/12/19 13:49:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2004.3 MB)
17/12/19 13:49:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.6 MB)
17/12/19 13:49:26 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/19 13:49:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 13:49:26 INFO CodeGenerator: Code generated in 32.240525 ms
17/12/19 13:49:26 INFO CodeGenerator: Code generated in 11.933831 ms
17/12/19 13:49:26 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 13:49:26 INFO DAGScheduler: Registering RDD 10 (sql at <unknown>:0)
17/12/19 13:49:26 INFO DAGScheduler: Registering RDD 15 (sql at <unknown>:0)
17/12/19 13:49:26 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/19 13:49:26 INFO DAGScheduler: Final stage: ResultStage 3 (sql at <unknown>:0)
17/12/19 13:49:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/12/19 13:49:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/12/19 13:49:26 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0), which has no missing parents
17/12/19 13:49:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.1 KB, free 2004.3 MB)
17/12/19 13:49:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.5 KB, free 2004.3 MB)
17/12/19 13:49:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53618 (size: 7.5 KB, free: 2004.6 MB)
17/12/19 13:49:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0)
17/12/19 13:49:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/19 13:49:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/19 13:49:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/19 13:49:26 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_2f1ce94327325fb82aac6edc1922a73263cb295211622ebc3ee48fe7810ae4c1.csv, range: 0-1912, partition values: [empty row]
17/12/19 13:49:26 INFO CodeGenerator: Code generated in 10.833182 ms
17/12/19 13:49:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1896 bytes result sent to driver
17/12/19 13:49:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 402 ms on localhost (executor driver) (1/1)
17/12/19 13:49:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/19 13:49:26 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.418 s
17/12/19 13:49:26 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:49:26 INFO DAGScheduler: running: Set()
17/12/19 13:49:26 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/12/19 13:49:26 INFO DAGScheduler: failed: Set()
17/12/19 13:49:26 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/19 13:49:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.3 KB, free 2004.2 MB)
17/12/19 13:49:27 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2004.2 MB)
17/12/19 13:49:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53618 (size: 6.9 KB, free: 2004.6 MB)
17/12/19 13:49:27 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/19 13:49:27 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
17/12/19 13:49:27 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5942 bytes)
17/12/19 13:49:27 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5942 bytes)
17/12/19 13:49:27 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/19 13:49:27 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
17/12/19 13:49:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 13:49:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 13:49:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:49:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:49:27 INFO MemoryStore: Block rdd_12_1 stored as values in memory (estimated size 1512.0 B, free 2004.2 MB)
17/12/19 13:49:27 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 1512.0 B, free 2004.2 MB)
17/12/19 13:49:27 INFO BlockManagerInfo: Added rdd_12_1 in memory on 127.0.0.1:53618 (size: 1512.0 B, free: 2004.6 MB)
17/12/19 13:49:27 INFO BlockManagerInfo: Added rdd_12_0 in memory on 127.0.0.1:53618 (size: 1512.0 B, free: 2004.6 MB)
17/12/19 13:49:27 INFO CodeGenerator: Code generated in 7.693972 ms
17/12/19 13:49:27 INFO CodeGenerator: Code generated in 23.745326 ms
17/12/19 13:49:27 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 3151 bytes result sent to driver
17/12/19 13:49:27 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 3241 bytes result sent to driver
17/12/19 13:49:27 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 275 ms on localhost (executor driver) (1/2)
17/12/19 13:49:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 275 ms on localhost (executor driver) (2/2)
17/12/19 13:49:27 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/19 13:49:27 INFO DAGScheduler: ShuffleMapStage 2 (sql at <unknown>:0) finished in 0.275 s
17/12/19 13:49:27 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:49:27 INFO DAGScheduler: running: Set()
17/12/19 13:49:27 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/12/19 13:49:27 INFO DAGScheduler: failed: Set()
17/12/19 13:49:27 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
17/12/19 13:49:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 2004.2 MB)
17/12/19 13:49:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.2 MB)
17/12/19 13:49:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.6 MB)
17/12/19 13:49:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0)
17/12/19 13:49:27 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/19 13:49:27 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/19 13:49:27 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
17/12/19 13:49:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 13:49:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:49:27 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 1865 bytes result sent to driver
17/12/19 13:49:27 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 15 ms on localhost (executor driver) (1/1)
17/12/19 13:49:27 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/19 13:49:27 INFO DAGScheduler: ResultStage 3 (sql at <unknown>:0) finished in 0.015 s
17/12/19 13:49:27 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.863067 s
17/12/19 13:49:27 INFO CodeGenerator: Code generated in 6.214608 ms
17/12/19 13:49:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:27 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 13:49:27 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:49:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/19 13:49:27 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:196)
17/12/19 13:49:27 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:49:27 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:196)
17/12/19 13:49:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/12/19 13:49:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/12/19 13:49:27 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
17/12/19 13:49:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 15.3 KB, free 2004.2 MB)
17/12/19 13:49:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.9 KB, free 2004.2 MB)
17/12/19 13:49:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:53618 (size: 6.9 KB, free: 2004.5 MB)
17/12/19 13:49:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196)
17/12/19 13:49:27 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
17/12/19 13:49:27 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5934 bytes)
17/12/19 13:49:27 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 5934 bytes)
17/12/19 13:49:27 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/19 13:49:27 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/12/19 13:49:27 INFO BlockManager: Found block rdd_12_0 locally
17/12/19 13:49:27 INFO BlockManager: Found block rdd_12_1 locally
17/12/19 13:49:27 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1950 bytes result sent to driver
17/12/19 13:49:27 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 2127 bytes result sent to driver
17/12/19 13:49:27 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 32 ms on localhost (executor driver) (1/2)
17/12/19 13:49:27 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 32 ms on localhost (executor driver) (2/2)
17/12/19 13:49:27 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/19 13:49:27 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:196) finished in 0.032 s
17/12/19 13:49:27 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:49:27 INFO DAGScheduler: running: Set()
17/12/19 13:49:27 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/12/19 13:49:27 INFO DAGScheduler: failed: Set()
17/12/19 13:49:27 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196), which has no missing parents
17/12/19 13:49:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 2004.2 MB)
17/12/19 13:49:27 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.2 MB)
17/12/19 13:49:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.5 MB)
17/12/19 13:49:27 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196)
17/12/19 13:49:27 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/19 13:49:27 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/19 13:49:27 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
17/12/19 13:49:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 13:49:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:49:27 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1707 bytes result sent to driver
17/12/19 13:49:27 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:49:27 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.071109 s
17/12/19 13:49:27 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:49:27 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/19 13:49:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz1`
WHERE (0 = 1)
17/12/19 13:49:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 13:49:27 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.5 MB)
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 50
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 51
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 57
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 58
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 59
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 60
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 61
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 62
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 63
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 64
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 65
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 66
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 67
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 68
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 69
17/12/19 13:49:27 INFO ContextCleaner: Cleaned shuffle 1
17/12/19 13:49:27 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53618 in memory (size: 7.5 KB, free: 2004.6 MB)
17/12/19 13:49:27 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53618 in memory (size: 6.9 KB, free: 2004.6 MB)
17/12/19 13:49:27 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.6 MB)
17/12/19 13:49:27 INFO ContextCleaner: Cleaned accumulator 238
17/12/19 13:49:27 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:53618 in memory (size: 6.9 KB, free: 2004.6 MB)
17/12/19 13:49:28 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 13:49:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/19 13:49:28 INFO DAGScheduler: Got job 3 (take at <unknown>:0) with 1 output partitions
17/12/19 13:49:28 INFO DAGScheduler: Final stage: ResultStage 8 (take at <unknown>:0)
17/12/19 13:49:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/12/19 13:49:28 INFO DAGScheduler: Missing parents: List()
17/12/19 13:49:28 INFO DAGScheduler: Submitting ResultStage 8 (WorkerRDD[29] at RDD at rdd.scala:18), which has no missing parents
17/12/19 13:49:28 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 128.7 KB, free 2004.1 MB)
17/12/19 13:49:28 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 49.6 KB, free 2004.1 MB)
17/12/19 13:49:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:53618 (size: 49.6 KB, free: 2004.5 MB)
17/12/19 13:49:28 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (WorkerRDD[29] at RDD at rdd.scala:18)
17/12/19 13:49:28 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/19 13:49:28 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5913 bytes)
17/12/19 13:49:28 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/12/19 13:49:28 INFO BlockManager: Found block rdd_12_0 locally
17/12/19 13:49:28 INFO CodeGenerator: Code generated in 49.381578 ms
17/12/19 13:49:28 INFO CodeGenerator: Code generated in 12.663318 ms
17/12/19 13:49:29 INFO MemoryStore: Block rdd_29_0 stored as values in memory (estimated size 80.0 B, free 2004.1 MB)
17/12/19 13:49:29 INFO BlockManagerInfo: Added rdd_29_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.5 MB)
17/12/19 13:49:29 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2410 bytes result sent to driver
17/12/19 13:49:29 INFO DAGScheduler: ResultStage 8 (take at <unknown>:0) finished in 0.853 s
17/12/19 13:49:29 INFO DAGScheduler: Job 3 finished: take at <unknown>:0, took 0.859988 s
17/12/19 13:49:29 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 853 ms on localhost (executor driver) (1/1)
17/12/19 13:49:29 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/19 13:49:29 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 13:49:29 INFO DAGScheduler: Got job 4 (take at <unknown>:0) with 1 output partitions
17/12/19 13:49:29 INFO DAGScheduler: Final stage: ResultStage 10 (take at <unknown>:0)
17/12/19 13:49:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
17/12/19 13:49:29 INFO DAGScheduler: Missing parents: List()
17/12/19 13:49:29 INFO DAGScheduler: Submitting ResultStage 10 (WorkerRDD[29] at RDD at rdd.scala:18), which has no missing parents
17/12/19 13:49:29 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 128.7 KB, free 2004.0 MB)
17/12/19 13:49:29 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 49.6 KB, free 2003.9 MB)
17/12/19 13:49:29 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:53618 (size: 49.6 KB, free: 2004.5 MB)
17/12/19 13:49:29 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (WorkerRDD[29] at RDD at rdd.scala:18)
17/12/19 13:49:29 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/12/19 13:49:29 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 5913 bytes)
17/12/19 13:49:29 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
17/12/19 13:49:29 INFO BlockManager: Found block rdd_12_1 locally
17/12/19 13:49:30 INFO MemoryStore: Block rdd_29_1 stored as values in memory (estimated size 80.0 B, free 2003.9 MB)
17/12/19 13:49:30 INFO BlockManagerInfo: Added rdd_29_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.5 MB)
17/12/19 13:49:30 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 2233 bytes result sent to driver
17/12/19 13:49:30 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 710 ms on localhost (executor driver) (1/1)
17/12/19 13:49:30 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/19 13:49:30 INFO DAGScheduler: ResultStage 10 (take at <unknown>:0) finished in 0.710 s
17/12/19 13:49:30 INFO DAGScheduler: Job 4 finished: take at <unknown>:0, took 0.714110 s
17/12/19 13:49:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:30 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.5 MB)
17/12/19 13:49:30 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:53618 in memory (size: 49.6 KB, free: 2004.5 MB)
17/12/19 13:49:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e8766e27e2
17/12/19 13:49:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:30 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:53618 in memory (size: 49.6 KB, free: 2004.6 MB)
17/12/19 13:49:30 INFO ContextCleaner: Cleaned accumulator 1
17/12/19 13:49:30 INFO ContextCleaner: Cleaned accumulator 0
17/12/19 13:49:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8766e27e2` AS `zzz2`
WHERE (0 = 1)
17/12/19 13:49:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8766e27e2`
LIMIT 10
17/12/19 13:49:30 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:49:30 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:49:30 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:196)
17/12/19 13:49:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/12/19 13:49:30 INFO DAGScheduler: Missing parents: List()
17/12/19 13:49:30 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[33] at collect at utils.scala:196), which has no missing parents
17/12/19 13:49:30 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 131.7 KB, free 2004.2 MB)
17/12/19 13:49:30 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 51.4 KB, free 2004.1 MB)
17/12/19 13:49:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:53618 (size: 51.4 KB, free: 2004.5 MB)
17/12/19 13:49:30 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[33] at collect at utils.scala:196)
17/12/19 13:49:30 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/12/19 13:49:30 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5860 bytes)
17/12/19 13:49:30 INFO Executor: Running task 0.0 in stage 12.0 (TID 10)
17/12/19 13:49:30 INFO BlockManager: Found block rdd_29_0 locally
17/12/19 13:49:30 INFO CodeGenerator: Code generated in 8.682479 ms
17/12/19 13:49:30 INFO CodeGenerator: Code generated in 15.861054 ms
17/12/19 13:49:30 INFO Executor: Finished task 0.0 in stage 12.0 (TID 10). 1391 bytes result sent to driver
17/12/19 13:49:30 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:196) finished in 0.069 s
17/12/19 13:49:30 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.065411 s
17/12/19 13:49:30 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 10) in 69 ms on localhost (executor driver) (1/1)
17/12/19 13:49:30 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/12/19 13:49:30 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:49:30 INFO DAGScheduler: Got job 6 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:49:30 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/12/19 13:49:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/12/19 13:49:30 INFO DAGScheduler: Missing parents: List()
17/12/19 13:49:30 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[33] at collect at utils.scala:196), which has no missing parents
17/12/19 13:49:30 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 131.7 KB, free 2004.0 MB)
17/12/19 13:49:30 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 51.4 KB, free 2003.9 MB)
17/12/19 13:49:30 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:53618 (size: 51.4 KB, free: 2004.5 MB)
17/12/19 13:49:30 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[33] at collect at utils.scala:196)
17/12/19 13:49:30 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/12/19 13:49:30 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11, localhost, executor driver, partition 1, PROCESS_LOCAL, 5860 bytes)
17/12/19 13:49:30 INFO Executor: Running task 0.0 in stage 14.0 (TID 11)
17/12/19 13:49:30 INFO BlockManager: Found block rdd_29_1 locally
17/12/19 13:49:30 INFO Executor: Finished task 0.0 in stage 14.0 (TID 11). 1233 bytes result sent to driver
17/12/19 13:49:30 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.016 s
17/12/19 13:49:30 INFO DAGScheduler: Job 6 finished: collect at utils.scala:196, took 0.016880 s
17/12/19 13:49:30 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:49:30 INFO CodeGenerator: Code generated in 6.631458 ms
17/12/19 13:49:30 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/12/19 13:49:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 13:49:30 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:49:30 INFO DAGScheduler: Got job 7 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:49:30 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:196)
17/12/19 13:49:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
17/12/19 13:49:30 INFO DAGScheduler: Missing parents: List()
17/12/19 13:49:30 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[35] at collect at utils.scala:196), which has no missing parents
17/12/19 13:49:30 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 11.7 KB, free 2003.9 MB)
17/12/19 13:49:30 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.3 KB, free 2003.9 MB)
17/12/19 13:49:30 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:53618 (size: 5.3 KB, free: 2004.5 MB)
17/12/19 13:49:30 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[35] at collect at utils.scala:196)
17/12/19 13:49:30 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/12/19 13:49:30 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 5860 bytes)
17/12/19 13:49:30 INFO Executor: Running task 0.0 in stage 16.0 (TID 12)
17/12/19 13:49:30 INFO BlockManager: Found block rdd_12_0 locally
17/12/19 13:49:30 INFO Executor: Finished task 0.0 in stage 16.0 (TID 12). 1459 bytes result sent to driver
17/12/19 13:49:30 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 12) in 15 ms on localhost (executor driver) (1/1)
17/12/19 13:49:30 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/12/19 13:49:30 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:196) finished in 0.015 s
17/12/19 13:49:30 INFO DAGScheduler: Job 7 finished: collect at utils.scala:196, took 0.019561 s
17/12/19 13:49:30 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:49:30 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:49:30 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:196)
17/12/19 13:49:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
17/12/19 13:49:30 INFO DAGScheduler: Missing parents: List()
17/12/19 13:49:30 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[35] at collect at utils.scala:196), which has no missing parents
17/12/19 13:49:30 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 11.7 KB, free 2003.9 MB)
17/12/19 13:49:30 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.3 KB, free 2003.9 MB)
17/12/19 13:49:30 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:53618 (size: 5.3 KB, free: 2004.5 MB)
17/12/19 13:49:30 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[35] at collect at utils.scala:196)
17/12/19 13:49:30 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/12/19 13:49:30 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 5860 bytes)
17/12/19 13:49:30 INFO Executor: Running task 0.0 in stage 18.0 (TID 13)
17/12/19 13:49:30 INFO BlockManager: Found block rdd_12_1 locally
17/12/19 13:49:30 INFO Executor: Finished task 0.0 in stage 18.0 (TID 13). 1459 bytes result sent to driver
17/12/19 13:49:30 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 13) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:49:30 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/12/19 13:49:30 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:49:30 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.016680 s
17/12/19 13:49:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:30 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:49:30 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:49:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:49:30 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:49:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:49:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:49:30 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 13:49:30 INFO CodeGenerator: Code generated in 7.808379 ms
17/12/19 13:49:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:49:55 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:49:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:49:55 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:49:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:49:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:49:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 13:49:55 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 13:49:55 INFO DAGScheduler: Got job 9 (collect at utils.scala:58) with 1 output partitions
17/12/19 13:49:55 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:58)
17/12/19 13:49:55 INFO DAGScheduler: Parents of final stage: List()
17/12/19 13:49:55 INFO DAGScheduler: Missing parents: List()
17/12/19 13:49:55 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[42] at map at utils.scala:55), which has no missing parents
17/12/19 13:49:55 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.7 KB, free 2003.9 MB)
17/12/19 13:49:55 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2003.9 MB)
17/12/19 13:49:55 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.5 MB)
17/12/19 13:49:55 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[42] at map at utils.scala:55)
17/12/19 13:49:55 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/12/19 13:49:55 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 6432 bytes)
17/12/19 13:49:55 INFO Executor: Running task 0.0 in stage 19.0 (TID 14)
17/12/19 13:49:55 INFO Executor: Finished task 0.0 in stage 19.0 (TID 14). 938 bytes result sent to driver
17/12/19 13:49:55 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:58) finished in 0.015 s
17/12/19 13:49:55 INFO DAGScheduler: Job 9 finished: collect at utils.scala:58, took 0.021226 s
17/12/19 13:49:55 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 14) in 15 ms on localhost (executor driver) (1/1)
17/12/19 13:49:55 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/12/19 13:49:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:55 INFO MapPartitionsRDD: Removing RDD 12 from persistence list
17/12/19 13:49:55 INFO BlockManager: Removing RDD 12
17/12/19 13:49:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:56 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 13:49:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:56 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 13:49:56 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 13:49:56 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 13:49:56 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 13:49:56 INFO FileSourceStrategy: Output Data Schema: struct<V1: double, V2: double, V3: double, V4: double ... 2 more fields>
17/12/19 13:49:56 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 13:49:56 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 293.7 KB, free 2003.6 MB)
17/12/19 13:49:56 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2003.6 MB)
17/12/19 13:49:56 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.4 MB)
17/12/19 13:49:56 INFO SparkContext: Created broadcast 14 from sql at <unknown>:0
17/12/19 13:49:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 13:49:56 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 13:49:56 INFO DAGScheduler: Registering RDD 46 (sql at <unknown>:0)
17/12/19 13:49:56 INFO DAGScheduler: Registering RDD 51 (sql at <unknown>:0)
17/12/19 13:49:56 INFO DAGScheduler: Got job 10 (sql at <unknown>:0) with 1 output partitions
17/12/19 13:49:56 INFO DAGScheduler: Final stage: ResultStage 22 (sql at <unknown>:0)
17/12/19 13:49:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
17/12/19 13:49:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
17/12/19 13:49:56 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[46] at sql at <unknown>:0), which has no missing parents
17/12/19 13:49:56 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 12.2 KB, free 2003.6 MB)
17/12/19 13:49:56 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2003.6 MB)
17/12/19 13:49:56 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.4 MB)
17/12/19 13:49:56 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[46] at sql at <unknown>:0)
17/12/19 13:49:56 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
17/12/19 13:49:56 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/19 13:49:56 INFO Executor: Running task 0.0 in stage 20.0 (TID 15)
17/12/19 13:49:56 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_9c5b584c444f1b0d84c0ee8cb4291700e07355f1e61dc2fccf380c4648516612.csv, range: 0-781, partition values: [empty row]
17/12/19 13:49:56 INFO CodeGenerator: Code generated in 9.063459 ms
17/12/19 13:49:56 INFO Executor: Finished task 0.0 in stage 20.0 (TID 15). 1719 bytes result sent to driver
17/12/19 13:49:56 INFO DAGScheduler: ShuffleMapStage 20 (sql at <unknown>:0) finished in 0.043 s
17/12/19 13:49:56 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:49:56 INFO DAGScheduler: running: Set()
17/12/19 13:49:56 INFO DAGScheduler: waiting: Set(ShuffleMapStage 21, ResultStage 22)
17/12/19 13:49:56 INFO DAGScheduler: failed: Set()
17/12/19 13:49:56 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 15) in 43 ms on localhost (executor driver) (1/1)
17/12/19 13:49:56 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/12/19 13:49:56 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[51] at sql at <unknown>:0), which has no missing parents
17/12/19 13:49:56 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 12.3 KB, free 2003.5 MB)
17/12/19 13:49:56 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2003.5 MB)
17/12/19 13:49:56 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.4 MB)
17/12/19 13:49:56 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[51] at sql at <unknown>:0)
17/12/19 13:49:56 INFO TaskSchedulerImpl: Adding task set 21.0 with 2 tasks
17/12/19 13:49:56 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 16, localhost, executor driver, partition 0, ANY, 5942 bytes)
17/12/19 13:49:56 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 17, localhost, executor driver, partition 1, ANY, 5942 bytes)
17/12/19 13:49:56 INFO Executor: Running task 0.0 in stage 21.0 (TID 16)
17/12/19 13:49:56 INFO Executor: Running task 1.0 in stage 21.0 (TID 17)
17/12/19 13:49:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 13:49:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:49:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 13:49:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:49:56 INFO MemoryStore: Block rdd_48_1 stored as values in memory (estimated size 696.0 B, free 2003.5 MB)
17/12/19 13:49:56 INFO MemoryStore: Block rdd_48_0 stored as values in memory (estimated size 696.0 B, free 2003.5 MB)
17/12/19 13:49:56 INFO BlockManagerInfo: Added rdd_48_1 in memory on 127.0.0.1:53618 (size: 696.0 B, free: 2004.4 MB)
17/12/19 13:49:56 INFO BlockManagerInfo: Added rdd_48_0 in memory on 127.0.0.1:53618 (size: 696.0 B, free: 2004.4 MB)
17/12/19 13:49:56 INFO Executor: Finished task 1.0 in stage 21.0 (TID 17). 2985 bytes result sent to driver
17/12/19 13:49:56 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 17) in 15 ms on localhost (executor driver) (1/2)
17/12/19 13:49:56 INFO Executor: Finished task 0.0 in stage 21.0 (TID 16). 3064 bytes result sent to driver
17/12/19 13:49:56 INFO DAGScheduler: ShuffleMapStage 21 (sql at <unknown>:0) finished in 0.031 s
17/12/19 13:49:56 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:49:56 INFO DAGScheduler: running: Set()
17/12/19 13:49:56 INFO DAGScheduler: waiting: Set(ResultStage 22)
17/12/19 13:49:56 INFO DAGScheduler: failed: Set()
17/12/19 13:49:56 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[54] at sql at <unknown>:0), which has no missing parents
17/12/19 13:49:56 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 16) in 15 ms on localhost (executor driver) (2/2)
17/12/19 13:49:56 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 2003.5 MB)
17/12/19 13:49:56 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.5 MB)
17/12/19 13:49:56 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/12/19 13:49:56 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.4 MB)
17/12/19 13:49:56 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[54] at sql at <unknown>:0)
17/12/19 13:49:56 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/12/19 13:49:56 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 18, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/19 13:49:56 INFO Executor: Running task 0.0 in stage 22.0 (TID 18)
17/12/19 13:49:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 13:49:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:49:56 INFO Executor: Finished task 0.0 in stage 22.0 (TID 18). 1707 bytes result sent to driver
17/12/19 13:49:56 INFO DAGScheduler: ResultStage 22 (sql at <unknown>:0) finished in 0.000 s
17/12/19 13:49:56 INFO DAGScheduler: Job 10 finished: sql at <unknown>:0, took 0.090615 s
17/12/19 13:49:56 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 18) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:49:56 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/12/19 13:49:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:56 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 13:49:56 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:49:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 145 bytes
17/12/19 13:49:56 INFO DAGScheduler: Registering RDD 58 (collect at utils.scala:196)
17/12/19 13:49:56 INFO DAGScheduler: Got job 11 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:49:56 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:196)
17/12/19 13:49:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
17/12/19 13:49:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 24)
17/12/19 13:49:56 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[58] at collect at utils.scala:196), which has no missing parents
17/12/19 13:49:56 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 12.3 KB, free 2003.5 MB)
17/12/19 13:49:56 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2003.5 MB)
17/12/19 13:49:56 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.4 MB)
17/12/19 13:49:56 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[58] at collect at utils.scala:196)
17/12/19 13:49:56 INFO TaskSchedulerImpl: Adding task set 24.0 with 2 tasks
17/12/19 13:49:56 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5935 bytes)
17/12/19 13:49:56 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 20, localhost, executor driver, partition 1, PROCESS_LOCAL, 5935 bytes)
17/12/19 13:49:56 INFO Executor: Running task 0.0 in stage 24.0 (TID 19)
17/12/19 13:49:56 INFO Executor: Running task 1.0 in stage 24.0 (TID 20)
17/12/19 13:49:56 INFO BlockManager: Found block rdd_48_0 locally
17/12/19 13:49:56 INFO BlockManager: Found block rdd_48_1 locally
17/12/19 13:49:56 INFO Executor: Finished task 0.0 in stage 24.0 (TID 19). 1871 bytes result sent to driver
17/12/19 13:49:56 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 19) in 16 ms on localhost (executor driver) (1/2)
17/12/19 13:49:56 INFO Executor: Finished task 1.0 in stage 24.0 (TID 20). 1871 bytes result sent to driver
17/12/19 13:49:56 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 20) in 16 ms on localhost (executor driver) (2/2)
17/12/19 13:49:56 INFO DAGScheduler: ShuffleMapStage 24 (collect at utils.scala:196) finished in 0.016 s
17/12/19 13:49:56 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:49:56 INFO DAGScheduler: running: Set()
17/12/19 13:49:56 INFO DAGScheduler: waiting: Set(ResultStage 25)
17/12/19 13:49:56 INFO DAGScheduler: failed: Set()
17/12/19 13:49:56 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[61] at collect at utils.scala:196), which has no missing parents
17/12/19 13:49:56 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
17/12/19 13:49:56 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.0 KB, free 2003.5 MB)
17/12/19 13:49:56 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.5 MB)
17/12/19 13:49:56 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.4 MB)
17/12/19 13:49:56 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[61] at collect at utils.scala:196)
17/12/19 13:49:56 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
17/12/19 13:49:56 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 21, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 13:49:56 INFO Executor: Running task 0.0 in stage 25.0 (TID 21)
17/12/19 13:49:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 13:49:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:49:56 INFO Executor: Finished task 0.0 in stage 25.0 (TID 21). 1707 bytes result sent to driver
17/12/19 13:49:56 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 21) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:49:56 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:49:56 INFO DAGScheduler: Job 11 finished: collect at utils.scala:196, took 0.043830 s
17/12/19 13:49:56 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
17/12/19 13:49:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz3`
WHERE (0 = 1)
17/12/19 13:49:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 13:49:56 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 13:49:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 145 bytes
17/12/19 13:49:56 INFO DAGScheduler: Got job 12 (take at <unknown>:0) with 1 output partitions
17/12/19 13:49:56 INFO DAGScheduler: Final stage: ResultStage 27 (take at <unknown>:0)
17/12/19 13:49:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
17/12/19 13:49:56 INFO DAGScheduler: Missing parents: List()
17/12/19 13:49:56 INFO DAGScheduler: Submitting ResultStage 27 (WorkerRDD[65] at RDD at rdd.scala:18), which has no missing parents
17/12/19 13:49:56 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 123.4 KB, free 2003.4 MB)
17/12/19 13:49:56 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 48.4 KB, free 2003.3 MB)
17/12/19 13:49:56 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:53618 (size: 48.4 KB, free: 2004.4 MB)
17/12/19 13:49:56 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (WorkerRDD[65] at RDD at rdd.scala:18)
17/12/19 13:49:56 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
17/12/19 13:49:56 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 13:49:56 INFO Executor: Running task 0.0 in stage 27.0 (TID 22)
17/12/19 13:49:56 INFO BlockManager: Found block rdd_48_0 locally
17/12/19 13:49:56 INFO CodeGenerator: Code generated in 17.687036 ms
17/12/19 13:49:56 INFO CodeGenerator: Code generated in 7.720025 ms
17/12/19 13:49:57 INFO MemoryStore: Block rdd_65_0 stored as values in memory (estimated size 80.0 B, free 2003.3 MB)
17/12/19 13:49:57 INFO BlockManagerInfo: Added rdd_65_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.4 MB)
17/12/19 13:49:57 INFO Executor: Finished task 0.0 in stage 27.0 (TID 22). 2410 bytes result sent to driver
17/12/19 13:49:57 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 22) in 695 ms on localhost (executor driver) (1/1)
17/12/19 13:49:57 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
17/12/19 13:49:57 INFO DAGScheduler: ResultStage 27 (take at <unknown>:0) finished in 0.696 s
17/12/19 13:49:57 INFO DAGScheduler: Job 12 finished: take at <unknown>:0, took 0.712979 s
17/12/19 13:49:57 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 13:49:57 INFO DAGScheduler: Got job 13 (take at <unknown>:0) with 1 output partitions
17/12/19 13:49:57 INFO DAGScheduler: Final stage: ResultStage 29 (take at <unknown>:0)
17/12/19 13:49:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
17/12/19 13:49:57 INFO DAGScheduler: Missing parents: List()
17/12/19 13:49:57 INFO DAGScheduler: Submitting ResultStage 29 (WorkerRDD[65] at RDD at rdd.scala:18), which has no missing parents
17/12/19 13:49:57 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 123.4 KB, free 2003.2 MB)
17/12/19 13:49:57 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 48.4 KB, free 2003.2 MB)
17/12/19 13:49:57 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:53618 (size: 48.4 KB, free: 2004.3 MB)
17/12/19 13:49:57 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (WorkerRDD[65] at RDD at rdd.scala:18)
17/12/19 13:49:57 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
17/12/19 13:49:57 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 23, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 13:49:57 INFO Executor: Running task 0.0 in stage 29.0 (TID 23)
17/12/19 13:49:57 INFO BlockManager: Found block rdd_48_1 locally
17/12/19 13:49:57 INFO MemoryStore: Block rdd_65_1 stored as values in memory (estimated size 80.0 B, free 2003.2 MB)
17/12/19 13:49:57 INFO BlockManagerInfo: Added rdd_65_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.3 MB)
17/12/19 13:49:57 INFO Executor: Finished task 0.0 in stage 29.0 (TID 23). 2154 bytes result sent to driver
17/12/19 13:49:57 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 23) in 679 ms on localhost (executor driver) (1/1)
17/12/19 13:49:57 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
17/12/19 13:49:57 INFO DAGScheduler: ResultStage 29 (take at <unknown>:0) finished in 0.679 s
17/12/19 13:49:57 INFO DAGScheduler: Job 13 finished: take at <unknown>:0, took 0.687470 s
17/12/19 13:49:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:57 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e8765c3180
17/12/19 13:49:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8765c3180` AS `zzz4`
WHERE (0 = 1)
17/12/19 13:49:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8765c3180`
LIMIT 10
17/12/19 13:49:58 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:49:58 INFO DAGScheduler: Got job 14 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:49:58 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:196)
17/12/19 13:49:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
17/12/19 13:49:58 INFO DAGScheduler: Missing parents: List()
17/12/19 13:49:58 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[69] at collect at utils.scala:196), which has no missing parents
17/12/19 13:49:58 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 126.5 KB, free 2003.0 MB)
17/12/19 13:49:58 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 50.2 KB, free 2003.0 MB)
17/12/19 13:49:58 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:53618 (size: 50.2 KB, free: 2004.3 MB)
17/12/19 13:49:58 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[69] at collect at utils.scala:196)
17/12/19 13:49:58 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
17/12/19 13:49:58 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 5860 bytes)
17/12/19 13:49:58 INFO Executor: Running task 0.0 in stage 31.0 (TID 24)
17/12/19 13:49:58 INFO BlockManager: Found block rdd_65_0 locally
17/12/19 13:49:58 INFO Executor: Finished task 0.0 in stage 31.0 (TID 24). 1233 bytes result sent to driver
17/12/19 13:49:58 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 24) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:49:58 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
17/12/19 13:49:58 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:49:58 INFO DAGScheduler: Job 14 finished: collect at utils.scala:196, took 0.012710 s
17/12/19 13:49:58 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:49:58 INFO DAGScheduler: Got job 15 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:49:58 INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:196)
17/12/19 13:49:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
17/12/19 13:49:58 INFO DAGScheduler: Missing parents: List()
17/12/19 13:49:58 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[69] at collect at utils.scala:196), which has no missing parents
17/12/19 13:49:58 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 126.5 KB, free 2002.9 MB)
17/12/19 13:49:58 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 50.2 KB, free 2002.8 MB)
17/12/19 13:49:58 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:53618 (size: 50.2 KB, free: 2004.2 MB)
17/12/19 13:49:58 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[69] at collect at utils.scala:196)
17/12/19 13:49:58 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
17/12/19 13:49:58 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 25, localhost, executor driver, partition 1, PROCESS_LOCAL, 5860 bytes)
17/12/19 13:49:58 INFO Executor: Running task 0.0 in stage 33.0 (TID 25)
17/12/19 13:49:58 INFO BlockManager: Found block rdd_65_1 locally
17/12/19 13:49:58 INFO Executor: Finished task 0.0 in stage 33.0 (TID 25). 1233 bytes result sent to driver
17/12/19 13:49:58 INFO DAGScheduler: ResultStage 33 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:49:58 INFO DAGScheduler: Job 15 finished: collect at utils.scala:196, took 0.013166 s
17/12/19 13:49:58 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 25) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:49:58 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
17/12/19 13:49:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:58 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 13:49:58 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:49:58 INFO DAGScheduler: Got job 16 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:49:58 INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:196)
17/12/19 13:49:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
17/12/19 13:49:58 INFO DAGScheduler: Missing parents: List()
17/12/19 13:49:58 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[71] at collect at utils.scala:196), which has no missing parents
17/12/19 13:49:58 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 8.8 KB, free 2002.8 MB)
17/12/19 13:49:58 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2002.8 MB)
17/12/19 13:49:58 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:53618 (size: 4.5 KB, free: 2004.2 MB)
17/12/19 13:49:58 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[71] at collect at utils.scala:196)
17/12/19 13:49:58 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
17/12/19 13:49:58 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 5860 bytes)
17/12/19 13:49:58 INFO Executor: Running task 0.0 in stage 35.0 (TID 26)
17/12/19 13:49:58 INFO BlockManager: Found block rdd_48_0 locally
17/12/19 13:49:58 INFO Executor: Finished task 0.0 in stage 35.0 (TID 26). 1309 bytes result sent to driver
17/12/19 13:49:58 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 26) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:49:58 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
17/12/19 13:49:58 INFO DAGScheduler: ResultStage 35 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:49:58 INFO DAGScheduler: Job 16 finished: collect at utils.scala:196, took 0.009222 s
17/12/19 13:49:58 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:49:58 INFO DAGScheduler: Got job 17 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:49:58 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:196)
17/12/19 13:49:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
17/12/19 13:49:58 INFO DAGScheduler: Missing parents: List()
17/12/19 13:49:58 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[71] at collect at utils.scala:196), which has no missing parents
17/12/19 13:49:58 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 8.8 KB, free 2002.8 MB)
17/12/19 13:49:58 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2002.8 MB)
17/12/19 13:49:58 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:53618 (size: 4.5 KB, free: 2004.2 MB)
17/12/19 13:49:58 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
17/12/19 13:49:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[71] at collect at utils.scala:196)
17/12/19 13:49:58 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
17/12/19 13:49:58 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 27, localhost, executor driver, partition 1, PROCESS_LOCAL, 5860 bytes)
17/12/19 13:49:58 INFO Executor: Running task 0.0 in stage 37.0 (TID 27)
17/12/19 13:49:58 INFO BlockManager: Found block rdd_48_1 locally
17/12/19 13:49:58 INFO Executor: Finished task 0.0 in stage 37.0 (TID 27). 1475 bytes result sent to driver
17/12/19 13:49:58 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:196) finished in 0.005 s
17/12/19 13:49:58 INFO DAGScheduler: Job 17 finished: collect at utils.scala:196, took 0.009251 s
17/12/19 13:49:58 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 27) in 4 ms on localhost (executor driver) (1/1)
17/12/19 13:49:58 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
17/12/19 13:49:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:49:58 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:49:58 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:49:58 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:49:58 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:49:58 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:49:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:49:58 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 13:52:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:52:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:52:36 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:52:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:52:36 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:52:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:52:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:52:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 13:52:36 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 13:52:36 INFO DAGScheduler: Got job 18 (collect at utils.scala:58) with 1 output partitions
17/12/19 13:52:36 INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:58)
17/12/19 13:52:36 INFO DAGScheduler: Parents of final stage: List()
17/12/19 13:52:36 INFO DAGScheduler: Missing parents: List()
17/12/19 13:52:36 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[78] at map at utils.scala:55), which has no missing parents
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 8.7 KB, free 2002.8 MB)
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2002.8 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.2 MB)
17/12/19 13:52:36 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
17/12/19 13:52:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[78] at map at utils.scala:55)
17/12/19 13:52:36 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
17/12/19 13:52:36 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 6505 bytes)
17/12/19 13:52:36 INFO Executor: Running task 0.0 in stage 38.0 (TID 28)
17/12/19 13:52:36 INFO Executor: Finished task 0.0 in stage 38.0 (TID 28). 966 bytes result sent to driver
17/12/19 13:52:36 INFO DAGScheduler: ResultStage 38 (collect at utils.scala:58) finished in 0.000 s
17/12/19 13:52:36 INFO DAGScheduler: Job 18 finished: collect at utils.scala:58, took 0.013545 s
17/12/19 13:52:36 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 28) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:52:36 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
17/12/19 13:52:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:52:36 INFO MapPartitionsRDD: Removing RDD 48 from persistence list
17/12/19 13:52:36 INFO BlockManager: Removing RDD 48
17/12/19 13:52:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 900
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:53618 in memory (size: 4.5 KB, free: 2004.2 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:53618 in memory (size: 4.5 KB, free: 2004.2 MB)
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 1324
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 1325
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.2 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:53618 in memory (size: 51.4 KB, free: 2004.3 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:53618 in memory (size: 51.4 KB, free: 2004.3 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:53618 in memory (size: 5.3 KB, free: 2004.3 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:53618 in memory (size: 5.3 KB, free: 2004.3 MB)
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 662
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 663
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.3 MB)
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 712
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 713
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 719
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 720
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 721
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 722
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 723
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 724
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 725
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 726
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 727
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 728
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 729
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 730
17/12/19 13:52:36 INFO ContextCleaner: Cleaned accumulator 731
17/12/19 13:52:36 INFO ContextCleaner: Cleaned shuffle 4
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.3 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.3 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.4 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.4 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.4 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:53618 in memory (size: 48.4 KB, free: 2004.4 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:53618 in memory (size: 48.4 KB, free: 2004.5 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:53618 in memory (size: 50.2 KB, free: 2004.5 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:53618 in memory (size: 50.2 KB, free: 2004.6 MB)
17/12/19 13:52:36 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 13:52:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:52:36 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 13:52:36 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 13:52:36 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 13:52:36 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 13:52:36 INFO FileSourceStrategy: Output Data Schema: struct<V1: double, V2: double, V3: double, V4: double ... 2 more fields>
17/12/19 13:52:36 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 293.7 KB, free 2003.7 MB)
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2003.7 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.5 MB)
17/12/19 13:52:36 INFO SparkContext: Created broadcast 27 from sql at <unknown>:0
17/12/19 13:52:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 13:52:36 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 13:52:36 INFO DAGScheduler: Registering RDD 82 (sql at <unknown>:0)
17/12/19 13:52:36 INFO DAGScheduler: Registering RDD 87 (sql at <unknown>:0)
17/12/19 13:52:36 INFO DAGScheduler: Got job 19 (sql at <unknown>:0) with 1 output partitions
17/12/19 13:52:36 INFO DAGScheduler: Final stage: ResultStage 41 (sql at <unknown>:0)
17/12/19 13:52:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
17/12/19 13:52:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 40)
17/12/19 13:52:36 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[82] at sql at <unknown>:0), which has no missing parents
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 12.2 KB, free 2003.7 MB)
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2003.6 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.5 MB)
17/12/19 13:52:36 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
17/12/19 13:52:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[82] at sql at <unknown>:0)
17/12/19 13:52:36 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
17/12/19 13:52:36 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/19 13:52:36 INFO Executor: Running task 0.0 in stage 39.0 (TID 29)
17/12/19 13:52:36 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_116ac4a04da2c6e5f2d25075e4b4d327f2ea406ea9bc41deafbc97105162fd24.csv, range: 0-771, partition values: [empty row]
17/12/19 13:52:36 INFO Executor: Finished task 0.0 in stage 39.0 (TID 29). 1632 bytes result sent to driver
17/12/19 13:52:36 INFO DAGScheduler: ShuffleMapStage 39 (sql at <unknown>:0) finished in 0.033 s
17/12/19 13:52:36 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:52:36 INFO DAGScheduler: running: Set()
17/12/19 13:52:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 40, ResultStage 41)
17/12/19 13:52:36 INFO DAGScheduler: failed: Set()
17/12/19 13:52:36 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 29) in 33 ms on localhost (executor driver) (1/1)
17/12/19 13:52:36 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
17/12/19 13:52:36 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[87] at sql at <unknown>:0), which has no missing parents
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 12.3 KB, free 2003.6 MB)
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2003.6 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.5 MB)
17/12/19 13:52:36 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
17/12/19 13:52:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[87] at sql at <unknown>:0)
17/12/19 13:52:36 INFO TaskSchedulerImpl: Adding task set 40.0 with 2 tasks
17/12/19 13:52:36 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 30, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/19 13:52:36 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 31, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/19 13:52:36 INFO Executor: Running task 0.0 in stage 40.0 (TID 30)
17/12/19 13:52:36 INFO Executor: Running task 1.0 in stage 40.0 (TID 31)
17/12/19 13:52:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 13:52:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:52:36 INFO MemoryStore: Block rdd_84_0 stored as values in memory (estimated size 696.0 B, free 2003.6 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Added rdd_84_0 in memory on 127.0.0.1:53618 (size: 696.0 B, free: 2004.5 MB)
17/12/19 13:52:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 13:52:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:52:36 INFO MemoryStore: Block rdd_84_1 stored as values in memory (estimated size 696.0 B, free 2003.6 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Added rdd_84_1 in memory on 127.0.0.1:53618 (size: 696.0 B, free: 2004.5 MB)
17/12/19 13:52:36 INFO Executor: Finished task 0.0 in stage 40.0 (TID 30). 3064 bytes result sent to driver
17/12/19 13:52:36 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 30) in 16 ms on localhost (executor driver) (1/2)
17/12/19 13:52:36 INFO Executor: Finished task 1.0 in stage 40.0 (TID 31). 2993 bytes result sent to driver
17/12/19 13:52:36 INFO DAGScheduler: ShuffleMapStage 40 (sql at <unknown>:0) finished in 0.031 s
17/12/19 13:52:36 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 31) in 31 ms on localhost (executor driver) (2/2)
17/12/19 13:52:36 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:52:36 INFO DAGScheduler: running: Set()
17/12/19 13:52:36 INFO DAGScheduler: waiting: Set(ResultStage 41)
17/12/19 13:52:36 INFO DAGScheduler: failed: Set()
17/12/19 13:52:36 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
17/12/19 13:52:36 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[90] at sql at <unknown>:0), which has no missing parents
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 7.0 KB, free 2003.6 MB)
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.6 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.5 MB)
17/12/19 13:52:36 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:996
17/12/19 13:52:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[90] at sql at <unknown>:0)
17/12/19 13:52:36 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
17/12/19 13:52:36 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 32, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/19 13:52:36 INFO Executor: Running task 0.0 in stage 41.0 (TID 32)
17/12/19 13:52:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 13:52:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:52:36 INFO Executor: Finished task 0.0 in stage 41.0 (TID 32). 1707 bytes result sent to driver
17/12/19 13:52:36 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 32) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:52:36 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
17/12/19 13:52:36 INFO DAGScheduler: ResultStage 41 (sql at <unknown>:0) finished in 0.000 s
17/12/19 13:52:36 INFO DAGScheduler: Job 19 finished: sql at <unknown>:0, took 0.075272 s
17/12/19 13:52:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:52:36 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 13:52:36 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:52:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 145 bytes
17/12/19 13:52:36 INFO DAGScheduler: Registering RDD 94 (collect at utils.scala:196)
17/12/19 13:52:36 INFO DAGScheduler: Got job 20 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:52:36 INFO DAGScheduler: Final stage: ResultStage 44 (collect at utils.scala:196)
17/12/19 13:52:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
17/12/19 13:52:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
17/12/19 13:52:36 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[94] at collect at utils.scala:196), which has no missing parents
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 12.3 KB, free 2003.6 MB)
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2003.6 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.5 MB)
17/12/19 13:52:36 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
17/12/19 13:52:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[94] at collect at utils.scala:196)
17/12/19 13:52:36 INFO TaskSchedulerImpl: Adding task set 43.0 with 2 tasks
17/12/19 13:52:36 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/19 13:52:36 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 34, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/19 13:52:36 INFO Executor: Running task 0.0 in stage 43.0 (TID 33)
17/12/19 13:52:36 INFO BlockManager: Found block rdd_84_0 locally
17/12/19 13:52:36 INFO Executor: Running task 1.0 in stage 43.0 (TID 34)
17/12/19 13:52:36 INFO BlockManager: Found block rdd_84_1 locally
17/12/19 13:52:36 INFO Executor: Finished task 1.0 in stage 43.0 (TID 34). 1871 bytes result sent to driver
17/12/19 13:52:36 INFO Executor: Finished task 0.0 in stage 43.0 (TID 33). 1871 bytes result sent to driver
17/12/19 13:52:36 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 34) in 16 ms on localhost (executor driver) (1/2)
17/12/19 13:52:36 INFO DAGScheduler: ShuffleMapStage 43 (collect at utils.scala:196) finished in 0.016 s
17/12/19 13:52:36 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:52:36 INFO DAGScheduler: running: Set()
17/12/19 13:52:36 INFO DAGScheduler: waiting: Set(ResultStage 44)
17/12/19 13:52:36 INFO DAGScheduler: failed: Set()
17/12/19 13:52:36 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[97] at collect at utils.scala:196), which has no missing parents
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 7.0 KB, free 2003.6 MB)
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.6 MB)
17/12/19 13:52:36 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 33) in 16 ms on localhost (executor driver) (2/2)
17/12/19 13:52:36 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
17/12/19 13:52:36 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.5 MB)
17/12/19 13:52:36 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:996
17/12/19 13:52:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[97] at collect at utils.scala:196)
17/12/19 13:52:36 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
17/12/19 13:52:36 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 35, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/19 13:52:36 INFO Executor: Running task 0.0 in stage 44.0 (TID 35)
17/12/19 13:52:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 13:52:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:52:36 INFO Executor: Finished task 0.0 in stage 44.0 (TID 35). 1786 bytes result sent to driver
17/12/19 13:52:36 INFO DAGScheduler: ResultStage 44 (collect at utils.scala:196) finished in 0.018 s
17/12/19 13:52:36 INFO DAGScheduler: Job 20 finished: collect at utils.scala:196, took 0.034620 s
17/12/19 13:52:36 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 35) in 18 ms on localhost (executor driver) (1/1)
17/12/19 13:52:36 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
17/12/19 13:52:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:52:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz5`
WHERE (0 = 1)
17/12/19 13:52:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:52:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 13:52:36 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 13:52:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 145 bytes
17/12/19 13:52:36 INFO DAGScheduler: Got job 21 (take at <unknown>:0) with 1 output partitions
17/12/19 13:52:36 INFO DAGScheduler: Final stage: ResultStage 46 (take at <unknown>:0)
17/12/19 13:52:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
17/12/19 13:52:36 INFO DAGScheduler: Missing parents: List()
17/12/19 13:52:36 INFO DAGScheduler: Submitting ResultStage 46 (WorkerRDD[101] at RDD at rdd.scala:18), which has no missing parents
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 120.8 KB, free 2003.5 MB)
17/12/19 13:52:36 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 48.2 KB, free 2003.4 MB)
17/12/19 13:52:36 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:53618 (size: 48.2 KB, free: 2004.5 MB)
17/12/19 13:52:36 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
17/12/19 13:52:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (WorkerRDD[101] at RDD at rdd.scala:18)
17/12/19 13:52:36 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
17/12/19 13:52:36 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 13:52:36 INFO Executor: Running task 0.0 in stage 46.0 (TID 36)
17/12/19 13:52:36 INFO BlockManager: Found block rdd_84_0 locally
17/12/19 13:52:37 INFO MemoryStore: Block rdd_101_0 stored as values in memory (estimated size 80.0 B, free 2003.4 MB)
17/12/19 13:52:37 INFO BlockManagerInfo: Added rdd_101_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.5 MB)
17/12/19 13:52:37 INFO Executor: Finished task 0.0 in stage 46.0 (TID 36). 2154 bytes result sent to driver
17/12/19 13:52:37 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 36) in 697 ms on localhost (executor driver) (1/1)
17/12/19 13:52:37 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
17/12/19 13:52:37 INFO DAGScheduler: ResultStage 46 (take at <unknown>:0) finished in 0.697 s
17/12/19 13:52:37 INFO DAGScheduler: Job 21 finished: take at <unknown>:0, took 0.702284 s
17/12/19 13:52:37 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 13:52:37 INFO DAGScheduler: Got job 22 (take at <unknown>:0) with 1 output partitions
17/12/19 13:52:37 INFO DAGScheduler: Final stage: ResultStage 48 (take at <unknown>:0)
17/12/19 13:52:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
17/12/19 13:52:37 INFO DAGScheduler: Missing parents: List()
17/12/19 13:52:37 INFO DAGScheduler: Submitting ResultStage 48 (WorkerRDD[101] at RDD at rdd.scala:18), which has no missing parents
17/12/19 13:52:37 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 120.8 KB, free 2003.3 MB)
17/12/19 13:52:37 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 48.2 KB, free 2003.3 MB)
17/12/19 13:52:37 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:53618 (size: 48.2 KB, free: 2004.4 MB)
17/12/19 13:52:37 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:996
17/12/19 13:52:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (WorkerRDD[101] at RDD at rdd.scala:18)
17/12/19 13:52:37 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
17/12/19 13:52:37 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 37, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 13:52:37 INFO Executor: Running task 0.0 in stage 48.0 (TID 37)
17/12/19 13:52:37 INFO BlockManager: Found block rdd_84_1 locally
17/12/19 13:52:38 INFO MemoryStore: Block rdd_101_1 stored as values in memory (estimated size 80.0 B, free 2003.3 MB)
17/12/19 13:52:38 INFO BlockManagerInfo: Added rdd_101_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.4 MB)
17/12/19 13:52:38 INFO Executor: Finished task 0.0 in stage 48.0 (TID 37). 2154 bytes result sent to driver
17/12/19 13:52:38 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 37) in 633 ms on localhost (executor driver) (1/1)
17/12/19 13:52:38 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
17/12/19 13:52:38 INFO DAGScheduler: ResultStage 48 (take at <unknown>:0) finished in 0.633 s
17/12/19 13:52:38 INFO DAGScheduler: Job 22 finished: take at <unknown>:0, took 0.643990 s
17/12/19 13:52:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:52:38 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e8330e4702
17/12/19 13:52:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:52:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8330e4702` AS `zzz6`
WHERE (0 = 1)
17/12/19 13:52:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:52:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8330e4702`
LIMIT 10
17/12/19 13:52:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:52:38 INFO DAGScheduler: Got job 23 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:52:38 INFO DAGScheduler: Final stage: ResultStage 50 (collect at utils.scala:196)
17/12/19 13:52:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
17/12/19 13:52:38 INFO DAGScheduler: Missing parents: List()
17/12/19 13:52:38 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[105] at collect at utils.scala:196), which has no missing parents
17/12/19 13:52:38 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 123.8 KB, free 2003.1 MB)
17/12/19 13:52:38 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 49.9 KB, free 2003.1 MB)
17/12/19 13:52:38 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:53618 (size: 49.9 KB, free: 2004.4 MB)
17/12/19 13:52:38 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
17/12/19 13:52:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[105] at collect at utils.scala:196)
17/12/19 13:52:38 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
17/12/19 13:52:38 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:52:38 INFO Executor: Running task 0.0 in stage 50.0 (TID 38)
17/12/19 13:52:38 INFO BlockManager: Found block rdd_101_0 locally
17/12/19 13:52:38 INFO Executor: Finished task 0.0 in stage 50.0 (TID 38). 1399 bytes result sent to driver
17/12/19 13:52:38 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 38) in 4 ms on localhost (executor driver) (1/1)
17/12/19 13:52:38 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
17/12/19 13:52:38 INFO DAGScheduler: ResultStage 50 (collect at utils.scala:196) finished in 0.004 s
17/12/19 13:52:38 INFO DAGScheduler: Job 23 finished: collect at utils.scala:196, took 0.014803 s
17/12/19 13:52:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:52:38 INFO DAGScheduler: Got job 24 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:52:38 INFO DAGScheduler: Final stage: ResultStage 52 (collect at utils.scala:196)
17/12/19 13:52:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51)
17/12/19 13:52:38 INFO DAGScheduler: Missing parents: List()
17/12/19 13:52:38 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[105] at collect at utils.scala:196), which has no missing parents
17/12/19 13:52:38 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 123.8 KB, free 2003.0 MB)
17/12/19 13:52:38 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 49.9 KB, free 2002.9 MB)
17/12/19 13:52:38 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:53618 (size: 49.9 KB, free: 2004.3 MB)
17/12/19 13:52:38 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
17/12/19 13:52:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[105] at collect at utils.scala:196)
17/12/19 13:52:38 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
17/12/19 13:52:38 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 39, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:52:38 INFO Executor: Running task 0.0 in stage 52.0 (TID 39)
17/12/19 13:52:38 INFO BlockManager: Found block rdd_101_1 locally
17/12/19 13:52:38 INFO Executor: Finished task 0.0 in stage 52.0 (TID 39). 1391 bytes result sent to driver
17/12/19 13:52:38 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 39) in 16 ms on localhost (executor driver) (1/1)
17/12/19 13:52:38 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
17/12/19 13:52:38 INFO DAGScheduler: ResultStage 52 (collect at utils.scala:196) finished in 0.016 s
17/12/19 13:52:38 INFO DAGScheduler: Job 24 finished: collect at utils.scala:196, took 0.010742 s
17/12/19 13:52:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:52:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 13:52:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:52:38 INFO DAGScheduler: Got job 25 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:52:38 INFO DAGScheduler: Final stage: ResultStage 54 (collect at utils.scala:196)
17/12/19 13:52:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
17/12/19 13:52:38 INFO DAGScheduler: Missing parents: List()
17/12/19 13:52:38 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[107] at collect at utils.scala:196), which has no missing parents
17/12/19 13:52:38 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 8.8 KB, free 2002.9 MB)
17/12/19 13:52:38 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2002.9 MB)
17/12/19 13:52:38 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:53618 (size: 4.5 KB, free: 2004.3 MB)
17/12/19 13:52:38 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:996
17/12/19 13:52:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[107] at collect at utils.scala:196)
17/12/19 13:52:38 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
17/12/19 13:52:38 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:52:38 INFO Executor: Running task 0.0 in stage 54.0 (TID 40)
17/12/19 13:52:38 INFO BlockManager: Found block rdd_84_0 locally
17/12/19 13:52:38 INFO Executor: Finished task 0.0 in stage 54.0 (TID 40). 1486 bytes result sent to driver
17/12/19 13:52:38 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 40) in 16 ms on localhost (executor driver) (1/1)
17/12/19 13:52:38 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
17/12/19 13:52:38 INFO DAGScheduler: ResultStage 54 (collect at utils.scala:196) finished in 0.016 s
17/12/19 13:52:38 INFO DAGScheduler: Job 25 finished: collect at utils.scala:196, took 0.010075 s
17/12/19 13:52:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:52:38 INFO DAGScheduler: Got job 26 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:52:38 INFO DAGScheduler: Final stage: ResultStage 56 (collect at utils.scala:196)
17/12/19 13:52:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)
17/12/19 13:52:38 INFO DAGScheduler: Missing parents: List()
17/12/19 13:52:38 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[107] at collect at utils.scala:196), which has no missing parents
17/12/19 13:52:38 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 8.8 KB, free 2002.9 MB)
17/12/19 13:52:38 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2002.9 MB)
17/12/19 13:52:38 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:53618 (size: 4.5 KB, free: 2004.3 MB)
17/12/19 13:52:38 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
17/12/19 13:52:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[107] at collect at utils.scala:196)
17/12/19 13:52:38 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
17/12/19 13:52:38 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 41, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:52:38 INFO Executor: Running task 0.0 in stage 56.0 (TID 41)
17/12/19 13:52:38 INFO BlockManager: Found block rdd_84_1 locally
17/12/19 13:52:38 INFO Executor: Finished task 0.0 in stage 56.0 (TID 41). 1572 bytes result sent to driver
17/12/19 13:52:38 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 41) in 5 ms on localhost (executor driver) (1/1)
17/12/19 13:52:38 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
17/12/19 13:52:38 INFO DAGScheduler: ResultStage 56 (collect at utils.scala:196) finished in 0.006 s
17/12/19 13:52:38 INFO DAGScheduler: Job 26 finished: collect at utils.scala:196, took 0.010600 s
17/12/19 13:52:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:52:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:52:38 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:52:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:52:38 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:52:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:52:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:52:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 13:54:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:54:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:54:55 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:54:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:54:55 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:54:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:54:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:54:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 13:54:55 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 13:54:55 INFO DAGScheduler: Got job 27 (collect at utils.scala:58) with 1 output partitions
17/12/19 13:54:55 INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:58)
17/12/19 13:54:55 INFO DAGScheduler: Parents of final stage: List()
17/12/19 13:54:55 INFO DAGScheduler: Missing parents: List()
17/12/19 13:54:55 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[114] at map at utils.scala:55), which has no missing parents
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 8.7 KB, free 2002.9 MB)
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2002.9 MB)
17/12/19 13:54:55 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.3 MB)
17/12/19 13:54:55 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:996
17/12/19 13:54:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[114] at map at utils.scala:55)
17/12/19 13:54:55 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
17/12/19 13:54:55 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 6577 bytes)
17/12/19 13:54:55 INFO Executor: Running task 0.0 in stage 57.0 (TID 42)
17/12/19 13:54:55 INFO Executor: Finished task 0.0 in stage 57.0 (TID 42). 1081 bytes result sent to driver
17/12/19 13:54:55 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 42) in 2 ms on localhost (executor driver) (1/1)
17/12/19 13:54:55 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
17/12/19 13:54:55 INFO DAGScheduler: ResultStage 57 (collect at utils.scala:58) finished in 0.002 s
17/12/19 13:54:55 INFO DAGScheduler: Job 27 finished: collect at utils.scala:58, took 0.008710 s
17/12/19 13:54:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:54:55 INFO MapPartitionsRDD: Removing RDD 84 from persistence list
17/12/19 13:54:55 INFO BlockManager: Removing RDD 84
17/12/19 13:54:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:54:55 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 13:54:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:54:55 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 13:54:55 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 13:54:55 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 13:54:55 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 13:54:55 INFO FileSourceStrategy: Output Data Schema: struct<V1: double, V2: double, V3: double, V4: double ... 2 more fields>
17/12/19 13:54:55 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 293.7 KB, free 2002.6 MB)
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2002.6 MB)
17/12/19 13:54:55 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.3 MB)
17/12/19 13:54:55 INFO SparkContext: Created broadcast 40 from sql at <unknown>:0
17/12/19 13:54:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 13:54:55 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 13:54:55 INFO DAGScheduler: Registering RDD 118 (sql at <unknown>:0)
17/12/19 13:54:55 INFO DAGScheduler: Registering RDD 123 (sql at <unknown>:0)
17/12/19 13:54:55 INFO DAGScheduler: Got job 28 (sql at <unknown>:0) with 1 output partitions
17/12/19 13:54:55 INFO DAGScheduler: Final stage: ResultStage 60 (sql at <unknown>:0)
17/12/19 13:54:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
17/12/19 13:54:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 59)
17/12/19 13:54:55 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[118] at sql at <unknown>:0), which has no missing parents
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 12.2 KB, free 2002.6 MB)
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2002.6 MB)
17/12/19 13:54:55 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.3 MB)
17/12/19 13:54:55 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:996
17/12/19 13:54:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[118] at sql at <unknown>:0)
17/12/19 13:54:55 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
17/12/19 13:54:55 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/19 13:54:55 INFO Executor: Running task 0.0 in stage 58.0 (TID 43)
17/12/19 13:54:55 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_5f70652405f9e0cff455ec247215028d4037835c2b005fee519dce06926e4934.csv, range: 0-623, partition values: [empty row]
17/12/19 13:54:55 INFO Executor: Finished task 0.0 in stage 58.0 (TID 43). 1553 bytes result sent to driver
17/12/19 13:54:55 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 43) in 43 ms on localhost (executor driver) (1/1)
17/12/19 13:54:55 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
17/12/19 13:54:55 INFO DAGScheduler: ShuffleMapStage 58 (sql at <unknown>:0) finished in 0.043 s
17/12/19 13:54:55 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:54:55 INFO DAGScheduler: running: Set()
17/12/19 13:54:55 INFO DAGScheduler: waiting: Set(ResultStage 60, ShuffleMapStage 59)
17/12/19 13:54:55 INFO DAGScheduler: failed: Set()
17/12/19 13:54:55 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[123] at sql at <unknown>:0), which has no missing parents
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 12.3 KB, free 2002.5 MB)
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2002.5 MB)
17/12/19 13:54:55 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.3 MB)
17/12/19 13:54:55 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:996
17/12/19 13:54:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[123] at sql at <unknown>:0)
17/12/19 13:54:55 INFO TaskSchedulerImpl: Adding task set 59.0 with 2 tasks
17/12/19 13:54:55 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 44, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/19 13:54:55 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 45, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/19 13:54:55 INFO Executor: Running task 0.0 in stage 59.0 (TID 44)
17/12/19 13:54:55 INFO Executor: Running task 1.0 in stage 59.0 (TID 45)
17/12/19 13:54:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 13:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:54:55 INFO MemoryStore: Block rdd_120_0 stored as values in memory (estimated size 664.0 B, free 2002.5 MB)
17/12/19 13:54:55 INFO BlockManagerInfo: Added rdd_120_0 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.3 MB)
17/12/19 13:54:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 13:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:54:55 INFO MemoryStore: Block rdd_120_1 stored as values in memory (estimated size 664.0 B, free 2002.5 MB)
17/12/19 13:54:55 INFO BlockManagerInfo: Added rdd_120_1 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.3 MB)
17/12/19 13:54:55 INFO Executor: Finished task 0.0 in stage 59.0 (TID 44). 3151 bytes result sent to driver
17/12/19 13:54:55 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 44) in 20 ms on localhost (executor driver) (1/2)
17/12/19 13:54:55 INFO Executor: Finished task 1.0 in stage 59.0 (TID 45). 3151 bytes result sent to driver
17/12/19 13:54:55 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 45) in 19 ms on localhost (executor driver) (2/2)
17/12/19 13:54:55 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
17/12/19 13:54:55 INFO DAGScheduler: ShuffleMapStage 59 (sql at <unknown>:0) finished in 0.020 s
17/12/19 13:54:55 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:54:55 INFO DAGScheduler: running: Set()
17/12/19 13:54:55 INFO DAGScheduler: waiting: Set(ResultStage 60)
17/12/19 13:54:55 INFO DAGScheduler: failed: Set()
17/12/19 13:54:55 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[126] at sql at <unknown>:0), which has no missing parents
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.0 KB, free 2002.5 MB)
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.5 MB)
17/12/19 13:54:55 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 13:54:55 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
17/12/19 13:54:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[126] at sql at <unknown>:0)
17/12/19 13:54:55 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
17/12/19 13:54:55 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 46, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/19 13:54:55 INFO Executor: Running task 0.0 in stage 60.0 (TID 46)
17/12/19 13:54:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 13:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:54:55 INFO Executor: Finished task 0.0 in stage 60.0 (TID 46). 1865 bytes result sent to driver
17/12/19 13:54:55 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 46) in 16 ms on localhost (executor driver) (1/1)
17/12/19 13:54:55 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
17/12/19 13:54:55 INFO DAGScheduler: ResultStage 60 (sql at <unknown>:0) finished in 0.016 s
17/12/19 13:54:55 INFO DAGScheduler: Job 28 finished: sql at <unknown>:0, took 0.075537 s
17/12/19 13:54:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:54:55 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 13:54:55 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:54:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 145 bytes
17/12/19 13:54:55 INFO DAGScheduler: Registering RDD 130 (collect at utils.scala:196)
17/12/19 13:54:55 INFO DAGScheduler: Got job 29 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:54:55 INFO DAGScheduler: Final stage: ResultStage 63 (collect at utils.scala:196)
17/12/19 13:54:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
17/12/19 13:54:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
17/12/19 13:54:55 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[130] at collect at utils.scala:196), which has no missing parents
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 12.3 KB, free 2002.5 MB)
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2002.5 MB)
17/12/19 13:54:55 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.3 MB)
17/12/19 13:54:55 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:996
17/12/19 13:54:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[130] at collect at utils.scala:196)
17/12/19 13:54:55 INFO TaskSchedulerImpl: Adding task set 62.0 with 2 tasks
17/12/19 13:54:55 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/19 13:54:55 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 48, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/19 13:54:55 INFO Executor: Running task 0.0 in stage 62.0 (TID 47)
17/12/19 13:54:55 INFO Executor: Running task 1.0 in stage 62.0 (TID 48)
17/12/19 13:54:55 INFO BlockManager: Found block rdd_120_1 locally
17/12/19 13:54:55 INFO BlockManager: Found block rdd_120_0 locally
17/12/19 13:54:55 INFO Executor: Finished task 1.0 in stage 62.0 (TID 48). 1792 bytes result sent to driver
17/12/19 13:54:55 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 48) in 16 ms on localhost (executor driver) (1/2)
17/12/19 13:54:55 INFO Executor: Finished task 0.0 in stage 62.0 (TID 47). 1792 bytes result sent to driver
17/12/19 13:54:55 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 47) in 16 ms on localhost (executor driver) (2/2)
17/12/19 13:54:55 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
17/12/19 13:54:55 INFO DAGScheduler: ShuffleMapStage 62 (collect at utils.scala:196) finished in 0.016 s
17/12/19 13:54:55 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:54:55 INFO DAGScheduler: running: Set()
17/12/19 13:54:55 INFO DAGScheduler: waiting: Set(ResultStage 63)
17/12/19 13:54:55 INFO DAGScheduler: failed: Set()
17/12/19 13:54:55 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[133] at collect at utils.scala:196), which has no missing parents
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 7.0 KB, free 2002.5 MB)
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.5 MB)
17/12/19 13:54:55 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.2 MB)
17/12/19 13:54:55 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:996
17/12/19 13:54:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[133] at collect at utils.scala:196)
17/12/19 13:54:55 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
17/12/19 13:54:55 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 49, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/19 13:54:55 INFO Executor: Running task 0.0 in stage 63.0 (TID 49)
17/12/19 13:54:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 13:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:54:55 INFO Executor: Finished task 0.0 in stage 63.0 (TID 49). 1707 bytes result sent to driver
17/12/19 13:54:55 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 49) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:54:55 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
17/12/19 13:54:55 INFO DAGScheduler: ResultStage 63 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:54:55 INFO DAGScheduler: Job 29 finished: collect at utils.scala:196, took 0.030132 s
17/12/19 13:54:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:54:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz7`
WHERE (0 = 1)
17/12/19 13:54:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:54:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 13:54:55 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 13:54:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 145 bytes
17/12/19 13:54:55 INFO DAGScheduler: Got job 30 (take at <unknown>:0) with 1 output partitions
17/12/19 13:54:55 INFO DAGScheduler: Final stage: ResultStage 65 (take at <unknown>:0)
17/12/19 13:54:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
17/12/19 13:54:55 INFO DAGScheduler: Missing parents: List()
17/12/19 13:54:55 INFO DAGScheduler: Submitting ResultStage 65 (WorkerRDD[137] at RDD at rdd.scala:18), which has no missing parents
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 120.7 KB, free 2002.4 MB)
17/12/19 13:54:55 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 48.1 KB, free 2002.3 MB)
17/12/19 13:54:55 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:53618 (size: 48.1 KB, free: 2004.2 MB)
17/12/19 13:54:55 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:996
17/12/19 13:54:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (WorkerRDD[137] at RDD at rdd.scala:18)
17/12/19 13:54:55 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
17/12/19 13:54:55 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 13:54:55 INFO Executor: Running task 0.0 in stage 65.0 (TID 50)
17/12/19 13:54:55 INFO BlockManager: Found block rdd_120_0 locally
17/12/19 13:54:56 INFO MemoryStore: Block rdd_137_0 stored as values in memory (estimated size 80.0 B, free 2002.3 MB)
17/12/19 13:54:56 INFO BlockManagerInfo: Added rdd_137_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.2 MB)
17/12/19 13:54:56 INFO Executor: Finished task 0.0 in stage 65.0 (TID 50). 2241 bytes result sent to driver
17/12/19 13:54:56 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 50) in 672 ms on localhost (executor driver) (1/1)
17/12/19 13:54:56 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
17/12/19 13:54:56 INFO DAGScheduler: ResultStage 65 (take at <unknown>:0) finished in 0.672 s
17/12/19 13:54:56 INFO DAGScheduler: Job 30 finished: take at <unknown>:0, took 0.682562 s
17/12/19 13:54:56 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 13:54:56 INFO DAGScheduler: Got job 31 (take at <unknown>:0) with 1 output partitions
17/12/19 13:54:56 INFO DAGScheduler: Final stage: ResultStage 67 (take at <unknown>:0)
17/12/19 13:54:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
17/12/19 13:54:56 INFO DAGScheduler: Missing parents: List()
17/12/19 13:54:56 INFO DAGScheduler: Submitting ResultStage 67 (WorkerRDD[137] at RDD at rdd.scala:18), which has no missing parents
17/12/19 13:54:56 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 120.7 KB, free 2002.2 MB)
17/12/19 13:54:56 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 48.1 KB, free 2002.2 MB)
17/12/19 13:54:56 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:53618 (size: 48.1 KB, free: 2004.2 MB)
17/12/19 13:54:56 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:996
17/12/19 13:54:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (WorkerRDD[137] at RDD at rdd.scala:18)
17/12/19 13:54:56 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
17/12/19 13:54:56 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 51, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 13:54:56 INFO Executor: Running task 0.0 in stage 67.0 (TID 51)
17/12/19 13:54:56 INFO BlockManager: Found block rdd_120_1 locally
17/12/19 13:54:56 INFO MemoryStore: Block rdd_137_1 stored as values in memory (estimated size 80.0 B, free 2002.2 MB)
17/12/19 13:54:56 INFO BlockManagerInfo: Added rdd_137_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.2 MB)
17/12/19 13:54:56 INFO Executor: Finished task 0.0 in stage 67.0 (TID 51). 2154 bytes result sent to driver
17/12/19 13:54:56 INFO DAGScheduler: ResultStage 67 (take at <unknown>:0) finished in 0.643 s
17/12/19 13:54:56 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 51) in 643 ms on localhost (executor driver) (1/1)
17/12/19 13:54:56 INFO DAGScheduler: Job 31 finished: take at <unknown>:0, took 0.642159 s
17/12/19 13:54:56 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
17/12/19 13:54:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:54:56 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e815c161de
17/12/19 13:54:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:54:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e815c161de` AS `zzz8`
WHERE (0 = 1)
17/12/19 13:54:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:54:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e815c161de`
LIMIT 10
17/12/19 13:54:56 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:54:56 INFO DAGScheduler: Got job 32 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:54:56 INFO DAGScheduler: Final stage: ResultStage 69 (collect at utils.scala:196)
17/12/19 13:54:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
17/12/19 13:54:56 INFO DAGScheduler: Missing parents: List()
17/12/19 13:54:56 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[141] at collect at utils.scala:196), which has no missing parents
17/12/19 13:54:56 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 123.8 KB, free 2002.0 MB)
17/12/19 13:54:56 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 49.9 KB, free 2002.0 MB)
17/12/19 13:54:56 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:53618 (size: 49.9 KB, free: 2004.1 MB)
17/12/19 13:54:56 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:996
17/12/19 13:54:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[141] at collect at utils.scala:196)
17/12/19 13:54:56 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
17/12/19 13:54:56 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:54:56 INFO Executor: Running task 0.0 in stage 69.0 (TID 52)
17/12/19 13:54:56 INFO BlockManager: Found block rdd_137_0 locally
17/12/19 13:54:56 INFO Executor: Finished task 0.0 in stage 69.0 (TID 52). 1410 bytes result sent to driver
17/12/19 13:54:56 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 52) in 16 ms on localhost (executor driver) (1/1)
17/12/19 13:54:56 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
17/12/19 13:54:56 INFO DAGScheduler: ResultStage 69 (collect at utils.scala:196) finished in 0.016 s
17/12/19 13:54:56 INFO DAGScheduler: Job 32 finished: collect at utils.scala:196, took 0.009512 s
17/12/19 13:54:56 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:54:56 INFO DAGScheduler: Got job 33 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:54:56 INFO DAGScheduler: Final stage: ResultStage 71 (collect at utils.scala:196)
17/12/19 13:54:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
17/12/19 13:54:56 INFO DAGScheduler: Missing parents: List()
17/12/19 13:54:56 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[141] at collect at utils.scala:196), which has no missing parents
17/12/19 13:54:56 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 123.8 KB, free 2001.9 MB)
17/12/19 13:54:56 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 49.9 KB, free 2001.8 MB)
17/12/19 13:54:56 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:53618 (size: 49.9 KB, free: 2004.1 MB)
17/12/19 13:54:56 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:996
17/12/19 13:54:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[141] at collect at utils.scala:196)
17/12/19 13:54:56 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
17/12/19 13:54:56 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 53, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:54:56 INFO Executor: Running task 0.0 in stage 71.0 (TID 53)
17/12/19 13:54:56 INFO BlockManager: Found block rdd_137_1 locally
17/12/19 13:54:56 INFO Executor: Finished task 0.0 in stage 71.0 (TID 53). 1233 bytes result sent to driver
17/12/19 13:54:56 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 53) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:54:56 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
17/12/19 13:54:56 INFO DAGScheduler: ResultStage 71 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:54:56 INFO DAGScheduler: Job 33 finished: collect at utils.scala:196, took 0.010112 s
17/12/19 13:54:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:54:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 13:54:57 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:54:57 INFO DAGScheduler: Got job 34 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:54:57 INFO DAGScheduler: Final stage: ResultStage 73 (collect at utils.scala:196)
17/12/19 13:54:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)
17/12/19 13:54:57 INFO DAGScheduler: Missing parents: List()
17/12/19 13:54:57 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[143] at collect at utils.scala:196), which has no missing parents
17/12/19 13:54:57 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 8.8 KB, free 2001.8 MB)
17/12/19 13:54:57 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2001.8 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:53618 (size: 4.5 KB, free: 2004.1 MB)
17/12/19 13:54:57 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:996
17/12/19 13:54:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[143] at collect at utils.scala:196)
17/12/19 13:54:57 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
17/12/19 13:54:57 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:54:57 INFO Executor: Running task 0.0 in stage 73.0 (TID 54)
17/12/19 13:54:57 INFO BlockManager: Found block rdd_120_0 locally
17/12/19 13:54:57 INFO Executor: Finished task 0.0 in stage 73.0 (TID 54). 1253 bytes result sent to driver
17/12/19 13:54:57 INFO DAGScheduler: ResultStage 73 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:54:57 INFO DAGScheduler: Job 34 finished: collect at utils.scala:196, took 0.018330 s
17/12/19 13:54:57 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 54) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:54:57 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
17/12/19 13:54:57 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:54:57 INFO DAGScheduler: Got job 35 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:54:57 INFO DAGScheduler: Final stage: ResultStage 75 (collect at utils.scala:196)
17/12/19 13:54:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)
17/12/19 13:54:57 INFO DAGScheduler: Missing parents: List()
17/12/19 13:54:57 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[143] at collect at utils.scala:196), which has no missing parents
17/12/19 13:54:57 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 8.8 KB, free 2001.8 MB)
17/12/19 13:54:57 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2001.8 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:53618 (size: 4.5 KB, free: 2004.0 MB)
17/12/19 13:54:57 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:996
17/12/19 13:54:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[143] at collect at utils.scala:196)
17/12/19 13:54:57 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
17/12/19 13:54:57 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 55, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:54:57 INFO Executor: Running task 0.0 in stage 75.0 (TID 55)
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1385
17/12/19 13:54:57 INFO BlockManager: Found block rdd_120_1 locally
17/12/19 13:54:57 INFO Executor: Finished task 0.0 in stage 75.0 (TID 55). 1416 bytes result sent to driver
17/12/19 13:54:57 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 55) in 30 ms on localhost (executor driver) (1/1)
17/12/19 13:54:57 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
17/12/19 13:54:57 INFO DAGScheduler: ResultStage 75 (collect at utils.scala:196) finished in 0.030 s
17/12/19 13:54:57 INFO DAGScheduler: Job 35 finished: collect at utils.scala:196, took 0.027885 s
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:53618 in memory (size: 4.5 KB, free: 2004.1 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.1 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.1 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:53618 in memory (size: 48.2 KB, free: 2004.1 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:53618 in memory (size: 48.2 KB, free: 2004.2 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:53618 in memory (size: 49.9 KB, free: 2004.2 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:53618 in memory (size: 49.9 KB, free: 2004.3 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:53618 in memory (size: 4.5 KB, free: 2004.3 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:53618 in memory (size: 4.5 KB, free: 2004.3 MB)
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1986
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1987
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.3 MB)
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2036
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2037
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2043
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2044
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2045
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2046
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2047
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2048
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2049
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2050
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2051
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2052
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2053
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2054
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2055
17/12/19 13:54:57 INFO ContextCleaner: Cleaned shuffle 10
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.3 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.3 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 2224
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.3 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:53618 in memory (size: 48.1 KB, free: 2004.3 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:53618 in memory (size: 48.1 KB, free: 2004.4 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:53618 in memory (size: 49.9 KB, free: 2004.4 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:53618 in memory (size: 49.9 KB, free: 2004.5 MB)
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1374
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1375
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1381
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1382
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1383
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1384
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1386
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1387
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1388
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1389
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1390
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1391
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1392
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1393
17/12/19 13:54:57 INFO ContextCleaner: Cleaned shuffle 7
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.5 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.5 MB)
17/12/19 13:54:57 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.5 MB)
17/12/19 13:54:57 INFO ContextCleaner: Cleaned accumulator 1562
17/12/19 13:54:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:54:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:54:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:54:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:54:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:54:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:54:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:54:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 13:56:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:56:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:56:09 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:56:09 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:56:09 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:56:09 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:56:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:56:09 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 13:56:09 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 13:56:09 INFO DAGScheduler: Got job 36 (collect at utils.scala:58) with 1 output partitions
17/12/19 13:56:09 INFO DAGScheduler: Final stage: ResultStage 76 (collect at utils.scala:58)
17/12/19 13:56:09 INFO DAGScheduler: Parents of final stage: List()
17/12/19 13:56:09 INFO DAGScheduler: Missing parents: List()
17/12/19 13:56:09 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[150] at map at utils.scala:55), which has no missing parents
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 8.7 KB, free 2003.3 MB)
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2003.3 MB)
17/12/19 13:56:09 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.5 MB)
17/12/19 13:56:09 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:996
17/12/19 13:56:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[150] at map at utils.scala:55)
17/12/19 13:56:09 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
17/12/19 13:56:09 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 6649 bytes)
17/12/19 13:56:09 INFO Executor: Running task 0.0 in stage 76.0 (TID 56)
17/12/19 13:56:09 INFO Executor: Finished task 0.0 in stage 76.0 (TID 56). 1022 bytes result sent to driver
17/12/19 13:56:09 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 56) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:56:09 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
17/12/19 13:56:09 INFO DAGScheduler: ResultStage 76 (collect at utils.scala:58) finished in 0.000 s
17/12/19 13:56:09 INFO DAGScheduler: Job 36 finished: collect at utils.scala:58, took 0.007782 s
17/12/19 13:56:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:56:09 INFO MapPartitionsRDD: Removing RDD 120 from persistence list
17/12/19 13:56:09 INFO BlockManager: Removing RDD 120
17/12/19 13:56:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:56:09 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 13:56:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:56:09 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 13:56:09 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 13:56:09 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 13:56:09 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 13:56:09 INFO FileSourceStrategy: Output Data Schema: struct<V1: double, V2: double, V3: double, V4: double ... 2 more fields>
17/12/19 13:56:09 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 293.7 KB, free 2003.0 MB)
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2003.0 MB)
17/12/19 13:56:09 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.5 MB)
17/12/19 13:56:09 INFO SparkContext: Created broadcast 53 from sql at <unknown>:0
17/12/19 13:56:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 13:56:09 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 13:56:09 INFO DAGScheduler: Registering RDD 154 (sql at <unknown>:0)
17/12/19 13:56:09 INFO DAGScheduler: Registering RDD 159 (sql at <unknown>:0)
17/12/19 13:56:09 INFO DAGScheduler: Got job 37 (sql at <unknown>:0) with 1 output partitions
17/12/19 13:56:09 INFO DAGScheduler: Final stage: ResultStage 79 (sql at <unknown>:0)
17/12/19 13:56:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
17/12/19 13:56:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78)
17/12/19 13:56:09 INFO DAGScheduler: Submitting ShuffleMapStage 77 (MapPartitionsRDD[154] at sql at <unknown>:0), which has no missing parents
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 12.2 KB, free 2003.0 MB)
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2003.0 MB)
17/12/19 13:56:09 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.5 MB)
17/12/19 13:56:09 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:996
17/12/19 13:56:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 77 (MapPartitionsRDD[154] at sql at <unknown>:0)
17/12/19 13:56:09 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
17/12/19 13:56:09 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/19 13:56:09 INFO Executor: Running task 0.0 in stage 77.0 (TID 57)
17/12/19 13:56:09 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_59e4553019580b6d3530d0d11bd5e4547ef38a0d8ca602b7d4ee80d5c7404cf5.csv, range: 0-625, partition values: [empty row]
17/12/19 13:56:09 INFO Executor: Finished task 0.0 in stage 77.0 (TID 57). 1553 bytes result sent to driver
17/12/19 13:56:09 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 57) in 15 ms on localhost (executor driver) (1/1)
17/12/19 13:56:09 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
17/12/19 13:56:09 INFO DAGScheduler: ShuffleMapStage 77 (sql at <unknown>:0) finished in 0.015 s
17/12/19 13:56:09 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:56:09 INFO DAGScheduler: running: Set()
17/12/19 13:56:09 INFO DAGScheduler: waiting: Set(ShuffleMapStage 78, ResultStage 79)
17/12/19 13:56:09 INFO DAGScheduler: failed: Set()
17/12/19 13:56:09 INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[159] at sql at <unknown>:0), which has no missing parents
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 12.3 KB, free 2003.0 MB)
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2003.0 MB)
17/12/19 13:56:09 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.5 MB)
17/12/19 13:56:09 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:996
17/12/19 13:56:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[159] at sql at <unknown>:0)
17/12/19 13:56:09 INFO TaskSchedulerImpl: Adding task set 78.0 with 2 tasks
17/12/19 13:56:09 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 58, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/19 13:56:09 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 59, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/19 13:56:09 INFO Executor: Running task 0.0 in stage 78.0 (TID 58)
17/12/19 13:56:09 INFO Executor: Running task 1.0 in stage 78.0 (TID 59)
17/12/19 13:56:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 13:56:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:56:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 13:56:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:56:09 INFO MemoryStore: Block rdd_156_1 stored as values in memory (estimated size 664.0 B, free 2003.0 MB)
17/12/19 13:56:09 INFO MemoryStore: Block rdd_156_0 stored as values in memory (estimated size 664.0 B, free 2003.0 MB)
17/12/19 13:56:09 INFO BlockManagerInfo: Added rdd_156_1 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.5 MB)
17/12/19 13:56:09 INFO BlockManagerInfo: Added rdd_156_0 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.5 MB)
17/12/19 13:56:09 INFO Executor: Finished task 1.0 in stage 78.0 (TID 59). 2985 bytes result sent to driver
17/12/19 13:56:09 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 59) in 16 ms on localhost (executor driver) (1/2)
17/12/19 13:56:09 INFO Executor: Finished task 0.0 in stage 78.0 (TID 58). 2985 bytes result sent to driver
17/12/19 13:56:09 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 58) in 16 ms on localhost (executor driver) (2/2)
17/12/19 13:56:09 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
17/12/19 13:56:09 INFO DAGScheduler: ShuffleMapStage 78 (sql at <unknown>:0) finished in 0.016 s
17/12/19 13:56:09 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:56:09 INFO DAGScheduler: running: Set()
17/12/19 13:56:09 INFO DAGScheduler: waiting: Set(ResultStage 79)
17/12/19 13:56:09 INFO DAGScheduler: failed: Set()
17/12/19 13:56:09 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[162] at sql at <unknown>:0), which has no missing parents
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 7.0 KB, free 2003.0 MB)
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.0 MB)
17/12/19 13:56:09 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.5 MB)
17/12/19 13:56:09 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:996
17/12/19 13:56:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[162] at sql at <unknown>:0)
17/12/19 13:56:09 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
17/12/19 13:56:09 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 60, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/19 13:56:09 INFO Executor: Running task 0.0 in stage 79.0 (TID 60)
17/12/19 13:56:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 13:56:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:56:09 INFO Executor: Finished task 0.0 in stage 79.0 (TID 60). 1707 bytes result sent to driver
17/12/19 13:56:09 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 60) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:56:09 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
17/12/19 13:56:09 INFO DAGScheduler: ResultStage 79 (sql at <unknown>:0) finished in 0.016 s
17/12/19 13:56:09 INFO DAGScheduler: Job 37 finished: sql at <unknown>:0, took 0.050839 s
17/12/19 13:56:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:56:09 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 13:56:09 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:56:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 145 bytes
17/12/19 13:56:09 INFO DAGScheduler: Registering RDD 166 (collect at utils.scala:196)
17/12/19 13:56:09 INFO DAGScheduler: Got job 38 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:56:09 INFO DAGScheduler: Final stage: ResultStage 82 (collect at utils.scala:196)
17/12/19 13:56:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)
17/12/19 13:56:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 81)
17/12/19 13:56:09 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[166] at collect at utils.scala:196), which has no missing parents
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 12.3 KB, free 2003.0 MB)
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2003.0 MB)
17/12/19 13:56:09 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.4 MB)
17/12/19 13:56:09 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:996
17/12/19 13:56:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[166] at collect at utils.scala:196)
17/12/19 13:56:09 INFO TaskSchedulerImpl: Adding task set 81.0 with 2 tasks
17/12/19 13:56:09 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/19 13:56:09 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 62, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/19 13:56:09 INFO Executor: Running task 0.0 in stage 81.0 (TID 61)
17/12/19 13:56:09 INFO Executor: Running task 1.0 in stage 81.0 (TID 62)
17/12/19 13:56:09 INFO BlockManager: Found block rdd_156_0 locally
17/12/19 13:56:09 INFO BlockManager: Found block rdd_156_1 locally
17/12/19 13:56:09 INFO Executor: Finished task 1.0 in stage 81.0 (TID 62). 1792 bytes result sent to driver
17/12/19 13:56:09 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 62) in 0 ms on localhost (executor driver) (1/2)
17/12/19 13:56:09 INFO Executor: Finished task 0.0 in stage 81.0 (TID 61). 1792 bytes result sent to driver
17/12/19 13:56:09 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 61) in 0 ms on localhost (executor driver) (2/2)
17/12/19 13:56:09 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
17/12/19 13:56:09 INFO DAGScheduler: ShuffleMapStage 81 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:56:09 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:56:09 INFO DAGScheduler: running: Set()
17/12/19 13:56:09 INFO DAGScheduler: waiting: Set(ResultStage 82)
17/12/19 13:56:09 INFO DAGScheduler: failed: Set()
17/12/19 13:56:09 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[169] at collect at utils.scala:196), which has no missing parents
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 7.0 KB, free 2002.9 MB)
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.9 MB)
17/12/19 13:56:09 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.4 MB)
17/12/19 13:56:09 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:996
17/12/19 13:56:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[169] at collect at utils.scala:196)
17/12/19 13:56:09 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
17/12/19 13:56:09 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 63, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/19 13:56:09 INFO Executor: Running task 0.0 in stage 82.0 (TID 63)
17/12/19 13:56:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 13:56:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:56:09 INFO Executor: Finished task 0.0 in stage 82.0 (TID 63). 1707 bytes result sent to driver
17/12/19 13:56:09 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 63) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:56:09 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
17/12/19 13:56:09 INFO DAGScheduler: ResultStage 82 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:56:09 INFO DAGScheduler: Job 38 finished: collect at utils.scala:196, took 0.022680 s
17/12/19 13:56:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:56:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz9`
WHERE (0 = 1)
17/12/19 13:56:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:56:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 13:56:09 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 13:56:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 145 bytes
17/12/19 13:56:09 INFO DAGScheduler: Got job 39 (take at <unknown>:0) with 1 output partitions
17/12/19 13:56:09 INFO DAGScheduler: Final stage: ResultStage 84 (take at <unknown>:0)
17/12/19 13:56:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)
17/12/19 13:56:09 INFO DAGScheduler: Missing parents: List()
17/12/19 13:56:09 INFO DAGScheduler: Submitting ResultStage 84 (WorkerRDD[173] at RDD at rdd.scala:18), which has no missing parents
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 123.1 KB, free 2002.8 MB)
17/12/19 13:56:09 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 48.7 KB, free 2002.8 MB)
17/12/19 13:56:09 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:53618 (size: 48.7 KB, free: 2004.4 MB)
17/12/19 13:56:09 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:996
17/12/19 13:56:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (WorkerRDD[173] at RDD at rdd.scala:18)
17/12/19 13:56:09 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
17/12/19 13:56:09 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 13:56:09 INFO Executor: Running task 0.0 in stage 84.0 (TID 64)
17/12/19 13:56:09 INFO BlockManager: Found block rdd_156_0 locally
17/12/19 13:56:10 INFO MemoryStore: Block rdd_173_0 stored as values in memory (estimated size 80.0 B, free 2002.8 MB)
17/12/19 13:56:10 INFO BlockManagerInfo: Added rdd_173_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.4 MB)
17/12/19 13:56:10 INFO Executor: Finished task 0.0 in stage 84.0 (TID 64). 2154 bytes result sent to driver
17/12/19 13:56:10 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 64) in 715 ms on localhost (executor driver) (1/1)
17/12/19 13:56:10 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
17/12/19 13:56:10 INFO DAGScheduler: ResultStage 84 (take at <unknown>:0) finished in 0.715 s
17/12/19 13:56:10 INFO DAGScheduler: Job 39 finished: take at <unknown>:0, took 0.721697 s
17/12/19 13:56:10 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 13:56:10 INFO DAGScheduler: Got job 40 (take at <unknown>:0) with 1 output partitions
17/12/19 13:56:10 INFO DAGScheduler: Final stage: ResultStage 86 (take at <unknown>:0)
17/12/19 13:56:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)
17/12/19 13:56:10 INFO DAGScheduler: Missing parents: List()
17/12/19 13:56:10 INFO DAGScheduler: Submitting ResultStage 86 (WorkerRDD[173] at RDD at rdd.scala:18), which has no missing parents
17/12/19 13:56:10 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 123.1 KB, free 2002.7 MB)
17/12/19 13:56:10 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 48.7 KB, free 2002.6 MB)
17/12/19 13:56:10 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:53618 (size: 48.7 KB, free: 2004.4 MB)
17/12/19 13:56:10 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:996
17/12/19 13:56:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (WorkerRDD[173] at RDD at rdd.scala:18)
17/12/19 13:56:10 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks
17/12/19 13:56:10 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 13:56:10 INFO Executor: Running task 0.0 in stage 86.0 (TID 65)
17/12/19 13:56:10 INFO BlockManager: Found block rdd_156_1 locally
17/12/19 13:56:11 INFO MemoryStore: Block rdd_173_1 stored as values in memory (estimated size 80.0 B, free 2002.6 MB)
17/12/19 13:56:11 INFO BlockManagerInfo: Added rdd_173_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.4 MB)
17/12/19 13:56:11 INFO Executor: Finished task 0.0 in stage 86.0 (TID 65). 2154 bytes result sent to driver
17/12/19 13:56:11 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 65) in 650 ms on localhost (executor driver) (1/1)
17/12/19 13:56:11 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
17/12/19 13:56:11 INFO DAGScheduler: ResultStage 86 (take at <unknown>:0) finished in 0.650 s
17/12/19 13:56:11 INFO DAGScheduler: Job 40 finished: take at <unknown>:0, took 0.652053 s
17/12/19 13:56:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:56:11 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e82e652d91
17/12/19 13:56:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:56:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e82e652d91` AS `zzz10`
WHERE (0 = 1)
17/12/19 13:56:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:56:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e82e652d91`
LIMIT 10
17/12/19 13:56:11 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:56:11 INFO DAGScheduler: Got job 41 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:56:11 INFO DAGScheduler: Final stage: ResultStage 88 (collect at utils.scala:196)
17/12/19 13:56:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 87)
17/12/19 13:56:11 INFO DAGScheduler: Missing parents: List()
17/12/19 13:56:11 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[177] at collect at utils.scala:196), which has no missing parents
17/12/19 13:56:11 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 126.2 KB, free 2002.5 MB)
17/12/19 13:56:11 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 50.5 KB, free 2002.4 MB)
17/12/19 13:56:11 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:53618 (size: 50.5 KB, free: 2004.3 MB)
17/12/19 13:56:11 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:996
17/12/19 13:56:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[177] at collect at utils.scala:196)
17/12/19 13:56:11 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
17/12/19 13:56:11 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:56:11 INFO Executor: Running task 0.0 in stage 88.0 (TID 66)
17/12/19 13:56:11 INFO BlockManager: Found block rdd_173_0 locally
17/12/19 13:56:11 INFO Executor: Finished task 0.0 in stage 88.0 (TID 66). 1233 bytes result sent to driver
17/12/19 13:56:11 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 66) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:56:11 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
17/12/19 13:56:11 INFO DAGScheduler: ResultStage 88 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:56:11 INFO DAGScheduler: Job 41 finished: collect at utils.scala:196, took 0.009002 s
17/12/19 13:56:11 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:56:11 INFO DAGScheduler: Got job 42 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:56:11 INFO DAGScheduler: Final stage: ResultStage 90 (collect at utils.scala:196)
17/12/19 13:56:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89)
17/12/19 13:56:11 INFO DAGScheduler: Missing parents: List()
17/12/19 13:56:11 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[177] at collect at utils.scala:196), which has no missing parents
17/12/19 13:56:11 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 126.2 KB, free 2002.3 MB)
17/12/19 13:56:11 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 50.5 KB, free 2002.3 MB)
17/12/19 13:56:11 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:53618 (size: 50.5 KB, free: 2004.3 MB)
17/12/19 13:56:11 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:996
17/12/19 13:56:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[177] at collect at utils.scala:196)
17/12/19 13:56:11 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
17/12/19 13:56:11 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 67, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:56:11 INFO Executor: Running task 0.0 in stage 90.0 (TID 67)
17/12/19 13:56:11 INFO BlockManager: Found block rdd_173_1 locally
17/12/19 13:56:11 INFO Executor: Finished task 0.0 in stage 90.0 (TID 67). 1233 bytes result sent to driver
17/12/19 13:56:11 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 67) in 15 ms on localhost (executor driver) (1/1)
17/12/19 13:56:11 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
17/12/19 13:56:11 INFO DAGScheduler: ResultStage 90 (collect at utils.scala:196) finished in 0.015 s
17/12/19 13:56:11 INFO DAGScheduler: Job 42 finished: collect at utils.scala:196, took 0.007320 s
17/12/19 13:56:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:56:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 13:56:11 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:56:11 INFO DAGScheduler: Got job 43 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:56:11 INFO DAGScheduler: Final stage: ResultStage 92 (collect at utils.scala:196)
17/12/19 13:56:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 91)
17/12/19 13:56:11 INFO DAGScheduler: Missing parents: List()
17/12/19 13:56:11 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[179] at collect at utils.scala:196), which has no missing parents
17/12/19 13:56:11 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 8.8 KB, free 2002.3 MB)
17/12/19 13:56:11 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2002.3 MB)
17/12/19 13:56:11 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:53618 (size: 4.5 KB, free: 2004.2 MB)
17/12/19 13:56:11 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:996
17/12/19 13:56:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[179] at collect at utils.scala:196)
17/12/19 13:56:11 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
17/12/19 13:56:11 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:56:11 INFO Executor: Running task 0.0 in stage 92.0 (TID 68)
17/12/19 13:56:11 INFO BlockManager: Found block rdd_156_0 locally
17/12/19 13:56:11 INFO Executor: Finished task 0.0 in stage 92.0 (TID 68). 1253 bytes result sent to driver
17/12/19 13:56:11 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 68) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:56:11 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
17/12/19 13:56:11 INFO DAGScheduler: ResultStage 92 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:56:11 INFO DAGScheduler: Job 43 finished: collect at utils.scala:196, took 0.007222 s
17/12/19 13:56:11 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:56:11 INFO DAGScheduler: Got job 44 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:56:11 INFO DAGScheduler: Final stage: ResultStage 94 (collect at utils.scala:196)
17/12/19 13:56:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 93)
17/12/19 13:56:11 INFO DAGScheduler: Missing parents: List()
17/12/19 13:56:11 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[179] at collect at utils.scala:196), which has no missing parents
17/12/19 13:56:11 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 8.8 KB, free 2002.2 MB)
17/12/19 13:56:11 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2002.2 MB)
17/12/19 13:56:11 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:53618 (size: 4.5 KB, free: 2004.2 MB)
17/12/19 13:56:11 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:996
17/12/19 13:56:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[179] at collect at utils.scala:196)
17/12/19 13:56:11 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
17/12/19 13:56:11 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 69, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:56:11 INFO Executor: Running task 0.0 in stage 94.0 (TID 69)
17/12/19 13:56:11 INFO BlockManager: Found block rdd_156_1 locally
17/12/19 13:56:11 INFO Executor: Finished task 0.0 in stage 94.0 (TID 69). 1253 bytes result sent to driver
17/12/19 13:56:11 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 69) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:56:11 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
17/12/19 13:56:11 INFO DAGScheduler: ResultStage 94 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:56:11 INFO DAGScheduler: Job 44 finished: collect at utils.scala:196, took 0.008234 s
17/12/19 13:56:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:56:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:56:11 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:56:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:56:11 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:56:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:56:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:56:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 13:57:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:57:25 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:57:25 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:57:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:57:25 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:57:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:57:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:57:25 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 13:57:25 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 13:57:25 INFO DAGScheduler: Got job 45 (collect at utils.scala:58) with 1 output partitions
17/12/19 13:57:25 INFO DAGScheduler: Final stage: ResultStage 95 (collect at utils.scala:58)
17/12/19 13:57:25 INFO DAGScheduler: Parents of final stage: List()
17/12/19 13:57:25 INFO DAGScheduler: Missing parents: List()
17/12/19 13:57:25 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[186] at map at utils.scala:55), which has no missing parents
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 8.7 KB, free 2002.2 MB)
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2002.2 MB)
17/12/19 13:57:25 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.2 MB)
17/12/19 13:57:25 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:996
17/12/19 13:57:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[186] at map at utils.scala:55)
17/12/19 13:57:25 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks
17/12/19 13:57:25 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 6721 bytes)
17/12/19 13:57:25 INFO Executor: Running task 0.0 in stage 95.0 (TID 70)
17/12/19 13:57:25 INFO Executor: Finished task 0.0 in stage 95.0 (TID 70). 1050 bytes result sent to driver
17/12/19 13:57:25 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 70) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:57:25 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
17/12/19 13:57:25 INFO DAGScheduler: ResultStage 95 (collect at utils.scala:58) finished in 0.000 s
17/12/19 13:57:25 INFO DAGScheduler: Job 45 finished: collect at utils.scala:58, took 0.007143 s
17/12/19 13:57:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:57:25 INFO MapPartitionsRDD: Removing RDD 156 from persistence list
17/12/19 13:57:25 INFO BlockManager: Removing RDD 156
17/12/19 13:57:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:57:25 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 13:57:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:57:25 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 13:57:25 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 13:57:25 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 13:57:25 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 13:57:25 INFO FileSourceStrategy: Output Data Schema: struct<V1: double, V2: double, V3: double, V4: double ... 2 more fields>
17/12/19 13:57:25 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 293.7 KB, free 2001.9 MB)
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2001.9 MB)
17/12/19 13:57:25 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.2 MB)
17/12/19 13:57:25 INFO SparkContext: Created broadcast 66 from sql at <unknown>:0
17/12/19 13:57:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 13:57:25 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 13:57:25 INFO DAGScheduler: Registering RDD 190 (sql at <unknown>:0)
17/12/19 13:57:25 INFO DAGScheduler: Registering RDD 195 (sql at <unknown>:0)
17/12/19 13:57:25 INFO DAGScheduler: Got job 46 (sql at <unknown>:0) with 1 output partitions
17/12/19 13:57:25 INFO DAGScheduler: Final stage: ResultStage 98 (sql at <unknown>:0)
17/12/19 13:57:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)
17/12/19 13:57:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 97)
17/12/19 13:57:25 INFO DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[190] at sql at <unknown>:0), which has no missing parents
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 12.2 KB, free 2001.9 MB)
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2001.9 MB)
17/12/19 13:57:25 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.2 MB)
17/12/19 13:57:25 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:996
17/12/19 13:57:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[190] at sql at <unknown>:0)
17/12/19 13:57:25 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks
17/12/19 13:57:25 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/19 13:57:25 INFO Executor: Running task 0.0 in stage 96.0 (TID 71)
17/12/19 13:57:25 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_2016a854b498e200df928811d5372357d9f6532c9a62d1bccc5c418d80f79a46.csv, range: 0-619, partition values: [empty row]
17/12/19 13:57:25 INFO Executor: Finished task 0.0 in stage 96.0 (TID 71). 1553 bytes result sent to driver
17/12/19 13:57:25 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 71) in 16 ms on localhost (executor driver) (1/1)
17/12/19 13:57:25 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
17/12/19 13:57:25 INFO DAGScheduler: ShuffleMapStage 96 (sql at <unknown>:0) finished in 0.016 s
17/12/19 13:57:25 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:57:25 INFO DAGScheduler: running: Set()
17/12/19 13:57:25 INFO DAGScheduler: waiting: Set(ShuffleMapStage 97, ResultStage 98)
17/12/19 13:57:25 INFO DAGScheduler: failed: Set()
17/12/19 13:57:25 INFO DAGScheduler: Submitting ShuffleMapStage 97 (MapPartitionsRDD[195] at sql at <unknown>:0), which has no missing parents
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 12.3 KB, free 2001.9 MB)
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2001.9 MB)
17/12/19 13:57:25 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.2 MB)
17/12/19 13:57:25 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:996
17/12/19 13:57:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 97 (MapPartitionsRDD[195] at sql at <unknown>:0)
17/12/19 13:57:25 INFO TaskSchedulerImpl: Adding task set 97.0 with 2 tasks
17/12/19 13:57:25 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 72, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/19 13:57:25 INFO TaskSetManager: Starting task 1.0 in stage 97.0 (TID 73, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/19 13:57:25 INFO Executor: Running task 0.0 in stage 97.0 (TID 72)
17/12/19 13:57:25 INFO Executor: Running task 1.0 in stage 97.0 (TID 73)
17/12/19 13:57:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 13:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:57:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 13:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:57:25 INFO MemoryStore: Block rdd_192_0 stored as values in memory (estimated size 664.0 B, free 2001.9 MB)
17/12/19 13:57:25 INFO MemoryStore: Block rdd_192_1 stored as values in memory (estimated size 664.0 B, free 2001.9 MB)
17/12/19 13:57:25 INFO BlockManagerInfo: Added rdd_192_0 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.2 MB)
17/12/19 13:57:25 INFO BlockManagerInfo: Added rdd_192_1 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.2 MB)
17/12/19 13:57:25 INFO Executor: Finished task 1.0 in stage 97.0 (TID 73). 3083 bytes result sent to driver
17/12/19 13:57:25 INFO TaskSetManager: Finished task 1.0 in stage 97.0 (TID 73) in 15 ms on localhost (executor driver) (1/2)
17/12/19 13:57:25 INFO Executor: Finished task 0.0 in stage 97.0 (TID 72). 3083 bytes result sent to driver
17/12/19 13:57:25 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 72) in 15 ms on localhost (executor driver) (2/2)
17/12/19 13:57:25 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
17/12/19 13:57:25 INFO DAGScheduler: ShuffleMapStage 97 (sql at <unknown>:0) finished in 0.015 s
17/12/19 13:57:25 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:57:25 INFO DAGScheduler: running: Set()
17/12/19 13:57:25 INFO DAGScheduler: waiting: Set(ResultStage 98)
17/12/19 13:57:25 INFO DAGScheduler: failed: Set()
17/12/19 13:57:25 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[198] at sql at <unknown>:0), which has no missing parents
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 7.0 KB, free 2001.9 MB)
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.9 MB)
17/12/19 13:57:25 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.2 MB)
17/12/19 13:57:25 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:996
17/12/19 13:57:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[198] at sql at <unknown>:0)
17/12/19 13:57:25 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks
17/12/19 13:57:25 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 74, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/19 13:57:25 INFO Executor: Running task 0.0 in stage 98.0 (TID 74)
17/12/19 13:57:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 13:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:57:25 INFO Executor: Finished task 0.0 in stage 98.0 (TID 74). 1963 bytes result sent to driver
17/12/19 13:57:25 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 74) in 18 ms on localhost (executor driver) (1/1)
17/12/19 13:57:25 INFO DAGScheduler: ResultStage 98 (sql at <unknown>:0) finished in 0.018 s
17/12/19 13:57:25 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
17/12/19 13:57:25 INFO DAGScheduler: Job 46 finished: sql at <unknown>:0, took 0.047065 s
17/12/19 13:57:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:57:25 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 13:57:25 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:57:25 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 145 bytes
17/12/19 13:57:25 INFO DAGScheduler: Registering RDD 202 (collect at utils.scala:196)
17/12/19 13:57:25 INFO DAGScheduler: Got job 47 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:57:25 INFO DAGScheduler: Final stage: ResultStage 101 (collect at utils.scala:196)
17/12/19 13:57:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 100)
17/12/19 13:57:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 100)
17/12/19 13:57:25 INFO DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[202] at collect at utils.scala:196), which has no missing parents
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 12.3 KB, free 2001.9 MB)
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2001.8 MB)
17/12/19 13:57:25 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.2 MB)
17/12/19 13:57:25 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:996
17/12/19 13:57:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[202] at collect at utils.scala:196)
17/12/19 13:57:25 INFO TaskSchedulerImpl: Adding task set 100.0 with 2 tasks
17/12/19 13:57:25 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 75, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/19 13:57:25 INFO TaskSetManager: Starting task 1.0 in stage 100.0 (TID 76, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/19 13:57:25 INFO Executor: Running task 0.0 in stage 100.0 (TID 75)
17/12/19 13:57:25 INFO Executor: Running task 1.0 in stage 100.0 (TID 76)
17/12/19 13:57:25 INFO BlockManager: Found block rdd_192_1 locally
17/12/19 13:57:25 INFO BlockManager: Found block rdd_192_0 locally
17/12/19 13:57:25 INFO Executor: Finished task 0.0 in stage 100.0 (TID 75). 1950 bytes result sent to driver
17/12/19 13:57:25 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 75) in 16 ms on localhost (executor driver) (1/2)
17/12/19 13:57:25 INFO Executor: Finished task 1.0 in stage 100.0 (TID 76). 1871 bytes result sent to driver
17/12/19 13:57:25 INFO TaskSetManager: Finished task 1.0 in stage 100.0 (TID 76) in 16 ms on localhost (executor driver) (2/2)
17/12/19 13:57:25 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
17/12/19 13:57:25 INFO DAGScheduler: ShuffleMapStage 100 (collect at utils.scala:196) finished in 0.016 s
17/12/19 13:57:25 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:57:25 INFO DAGScheduler: running: Set()
17/12/19 13:57:25 INFO DAGScheduler: waiting: Set(ResultStage 101)
17/12/19 13:57:25 INFO DAGScheduler: failed: Set()
17/12/19 13:57:25 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[205] at collect at utils.scala:196), which has no missing parents
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 7.0 KB, free 2001.8 MB)
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.8 MB)
17/12/19 13:57:25 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.2 MB)
17/12/19 13:57:25 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:996
17/12/19 13:57:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[205] at collect at utils.scala:196)
17/12/19 13:57:25 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks
17/12/19 13:57:25 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 77, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/19 13:57:25 INFO Executor: Running task 0.0 in stage 101.0 (TID 77)
17/12/19 13:57:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 13:57:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:57:25 INFO Executor: Finished task 0.0 in stage 101.0 (TID 77). 1707 bytes result sent to driver
17/12/19 13:57:25 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 77) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:57:25 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
17/12/19 13:57:25 INFO DAGScheduler: ResultStage 101 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:57:25 INFO DAGScheduler: Job 47 finished: collect at utils.scala:196, took 0.025915 s
17/12/19 13:57:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:57:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz11`
WHERE (0 = 1)
17/12/19 13:57:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:57:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 13:57:25 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 13:57:25 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 145 bytes
17/12/19 13:57:25 INFO DAGScheduler: Got job 48 (take at <unknown>:0) with 1 output partitions
17/12/19 13:57:25 INFO DAGScheduler: Final stage: ResultStage 103 (take at <unknown>:0)
17/12/19 13:57:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)
17/12/19 13:57:25 INFO DAGScheduler: Missing parents: List()
17/12/19 13:57:25 INFO DAGScheduler: Submitting ResultStage 103 (WorkerRDD[209] at RDD at rdd.scala:18), which has no missing parents
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 123.7 KB, free 2001.7 MB)
17/12/19 13:57:25 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 48.9 KB, free 2001.7 MB)
17/12/19 13:57:25 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:53618 (size: 48.9 KB, free: 2004.1 MB)
17/12/19 13:57:25 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:996
17/12/19 13:57:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (WorkerRDD[209] at RDD at rdd.scala:18)
17/12/19 13:57:25 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks
17/12/19 13:57:25 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 13:57:25 INFO Executor: Running task 0.0 in stage 103.0 (TID 78)
17/12/19 13:57:25 INFO BlockManager: Found block rdd_192_0 locally
17/12/19 13:57:26 INFO MemoryStore: Block rdd_209_0 stored as values in memory (estimated size 80.0 B, free 2001.7 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Added rdd_209_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.1 MB)
17/12/19 13:57:26 INFO Executor: Finished task 0.0 in stage 103.0 (TID 78). 2154 bytes result sent to driver
17/12/19 13:57:26 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 78) in 669 ms on localhost (executor driver) (1/1)
17/12/19 13:57:26 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
17/12/19 13:57:26 INFO DAGScheduler: ResultStage 103 (take at <unknown>:0) finished in 0.669 s
17/12/19 13:57:26 INFO DAGScheduler: Job 48 finished: take at <unknown>:0, took 0.681450 s
17/12/19 13:57:26 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 13:57:26 INFO DAGScheduler: Got job 49 (take at <unknown>:0) with 1 output partitions
17/12/19 13:57:26 INFO DAGScheduler: Final stage: ResultStage 105 (take at <unknown>:0)
17/12/19 13:57:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104)
17/12/19 13:57:26 INFO DAGScheduler: Missing parents: List()
17/12/19 13:57:26 INFO DAGScheduler: Submitting ResultStage 105 (WorkerRDD[209] at RDD at rdd.scala:18), which has no missing parents
17/12/19 13:57:26 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 123.7 KB, free 2001.5 MB)
17/12/19 13:57:26 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 48.9 KB, free 2001.5 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:53618 (size: 48.9 KB, free: 2004.1 MB)
17/12/19 13:57:26 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:996
17/12/19 13:57:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (WorkerRDD[209] at RDD at rdd.scala:18)
17/12/19 13:57:26 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks
17/12/19 13:57:26 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 79, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 13:57:26 INFO Executor: Running task 0.0 in stage 105.0 (TID 79)
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3372
17/12/19 13:57:26 INFO BlockManager: Found block rdd_192_1 locally
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:53618 in memory (size: 4.5 KB, free: 2004.1 MB)
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2648
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2649
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.1 MB)
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2698
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2699
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2705
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2706
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2707
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2708
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2709
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2710
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2711
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2712
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2713
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2714
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2715
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2716
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2717
17/12/19 13:57:26 INFO ContextCleaner: Cleaned shuffle 13
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.1 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.1 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.1 MB)
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 2886
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.1 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.1 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:53618 in memory (size: 48.7 KB, free: 2004.2 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:53618 in memory (size: 48.7 KB, free: 2004.2 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:53618 in memory (size: 50.5 KB, free: 2004.3 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:53618 in memory (size: 50.5 KB, free: 2004.3 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:53618 in memory (size: 4.5 KB, free: 2004.3 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:53618 in memory (size: 4.5 KB, free: 2004.3 MB)
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3310
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3311
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.3 MB)
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3360
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3361
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3367
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3368
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3369
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3370
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3371
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3373
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3374
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3375
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3376
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3377
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3378
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3379
17/12/19 13:57:26 INFO ContextCleaner: Cleaned shuffle 16
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.3 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.3 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.4 MB)
17/12/19 13:57:26 INFO ContextCleaner: Cleaned accumulator 3548
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.4 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.4 MB)
17/12/19 13:57:26 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:53618 in memory (size: 48.9 KB, free: 2004.4 MB)
17/12/19 13:57:27 INFO MemoryStore: Block rdd_209_1 stored as values in memory (estimated size 80.0 B, free 2002.6 MB)
17/12/19 13:57:27 INFO BlockManagerInfo: Added rdd_209_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.4 MB)
17/12/19 13:57:27 INFO Executor: Finished task 0.0 in stage 105.0 (TID 79). 2331 bytes result sent to driver
17/12/19 13:57:27 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 79) in 728 ms on localhost (executor driver) (1/1)
17/12/19 13:57:27 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
17/12/19 13:57:27 INFO DAGScheduler: ResultStage 105 (take at <unknown>:0) finished in 0.728 s
17/12/19 13:57:27 INFO DAGScheduler: Job 49 finished: take at <unknown>:0, took 0.733847 s
17/12/19 13:57:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:57:27 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e86feb6b0a
17/12/19 13:57:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:57:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e86feb6b0a` AS `zzz12`
WHERE (0 = 1)
17/12/19 13:57:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:57:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e86feb6b0a`
LIMIT 10
17/12/19 13:57:27 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:57:27 INFO DAGScheduler: Got job 50 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:57:27 INFO DAGScheduler: Final stage: ResultStage 107 (collect at utils.scala:196)
17/12/19 13:57:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 106)
17/12/19 13:57:27 INFO DAGScheduler: Missing parents: List()
17/12/19 13:57:27 INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[213] at collect at utils.scala:196), which has no missing parents
17/12/19 13:57:27 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 126.8 KB, free 2002.4 MB)
17/12/19 13:57:27 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 50.7 KB, free 2002.4 MB)
17/12/19 13:57:27 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:53618 (size: 50.7 KB, free: 2004.4 MB)
17/12/19 13:57:27 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:996
17/12/19 13:57:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[213] at collect at utils.scala:196)
17/12/19 13:57:27 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks
17/12/19 13:57:27 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:57:27 INFO Executor: Running task 0.0 in stage 107.0 (TID 80)
17/12/19 13:57:27 INFO BlockManager: Found block rdd_209_0 locally
17/12/19 13:57:27 INFO Executor: Finished task 0.0 in stage 107.0 (TID 80). 1233 bytes result sent to driver
17/12/19 13:57:27 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 80) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:57:27 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
17/12/19 13:57:27 INFO DAGScheduler: ResultStage 107 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:57:27 INFO DAGScheduler: Job 50 finished: collect at utils.scala:196, took 0.008960 s
17/12/19 13:57:27 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:57:27 INFO DAGScheduler: Got job 51 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:57:27 INFO DAGScheduler: Final stage: ResultStage 109 (collect at utils.scala:196)
17/12/19 13:57:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 108)
17/12/19 13:57:27 INFO DAGScheduler: Missing parents: List()
17/12/19 13:57:27 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[213] at collect at utils.scala:196), which has no missing parents
17/12/19 13:57:27 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 126.8 KB, free 2002.3 MB)
17/12/19 13:57:27 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 50.7 KB, free 2002.2 MB)
17/12/19 13:57:27 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:53618 (size: 50.7 KB, free: 2004.3 MB)
17/12/19 13:57:27 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:996
17/12/19 13:57:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[213] at collect at utils.scala:196)
17/12/19 13:57:27 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks
17/12/19 13:57:27 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 81, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:57:27 INFO Executor: Running task 0.0 in stage 109.0 (TID 81)
17/12/19 13:57:27 INFO BlockManager: Found block rdd_209_1 locally
17/12/19 13:57:27 INFO Executor: Finished task 0.0 in stage 109.0 (TID 81). 1233 bytes result sent to driver
17/12/19 13:57:27 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 81) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:57:27 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
17/12/19 13:57:27 INFO DAGScheduler: ResultStage 109 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:57:27 INFO DAGScheduler: Job 51 finished: collect at utils.scala:196, took 0.007570 s
17/12/19 13:57:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:57:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 13:57:27 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:57:27 INFO DAGScheduler: Got job 52 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:57:27 INFO DAGScheduler: Final stage: ResultStage 111 (collect at utils.scala:196)
17/12/19 13:57:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 110)
17/12/19 13:57:27 INFO DAGScheduler: Missing parents: List()
17/12/19 13:57:27 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[215] at collect at utils.scala:196), which has no missing parents
17/12/19 13:57:27 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 8.8 KB, free 2002.2 MB)
17/12/19 13:57:27 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2002.2 MB)
17/12/19 13:57:27 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:53618 (size: 4.5 KB, free: 2004.3 MB)
17/12/19 13:57:27 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:996
17/12/19 13:57:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[215] at collect at utils.scala:196)
17/12/19 13:57:27 INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks
17/12/19 13:57:27 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:57:27 INFO Executor: Running task 0.0 in stage 111.0 (TID 82)
17/12/19 13:57:27 INFO BlockManager: Found block rdd_192_0 locally
17/12/19 13:57:27 INFO Executor: Finished task 0.0 in stage 111.0 (TID 82). 1254 bytes result sent to driver
17/12/19 13:57:27 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 82) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:57:27 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
17/12/19 13:57:27 INFO DAGScheduler: ResultStage 111 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:57:27 INFO DAGScheduler: Job 52 finished: collect at utils.scala:196, took 0.006921 s
17/12/19 13:57:27 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:57:27 INFO DAGScheduler: Got job 53 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:57:27 INFO DAGScheduler: Final stage: ResultStage 113 (collect at utils.scala:196)
17/12/19 13:57:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 112)
17/12/19 13:57:27 INFO DAGScheduler: Missing parents: List()
17/12/19 13:57:27 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[215] at collect at utils.scala:196), which has no missing parents
17/12/19 13:57:27 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 8.8 KB, free 2002.2 MB)
17/12/19 13:57:27 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2002.2 MB)
17/12/19 13:57:27 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:53618 (size: 4.5 KB, free: 2004.3 MB)
17/12/19 13:57:27 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:996
17/12/19 13:57:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[215] at collect at utils.scala:196)
17/12/19 13:57:27 INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks
17/12/19 13:57:27 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 83, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:57:27 INFO Executor: Running task 0.0 in stage 113.0 (TID 83)
17/12/19 13:57:27 INFO BlockManager: Found block rdd_192_1 locally
17/12/19 13:57:27 INFO Executor: Finished task 0.0 in stage 113.0 (TID 83). 1252 bytes result sent to driver
17/12/19 13:57:27 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 83) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:57:27 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
17/12/19 13:57:27 INFO DAGScheduler: ResultStage 113 (collect at utils.scala:196) finished in 0.016 s
17/12/19 13:57:27 INFO DAGScheduler: Job 53 finished: collect at utils.scala:196, took 0.006236 s
17/12/19 13:57:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:57:27 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:57:27 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:57:27 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:57:27 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:57:27 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:57:27 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:57:27 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 13:58:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:58:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:58:13 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:58:13 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:58:13 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:58:13 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:58:13 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:58:13 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 13:58:13 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 13:58:13 INFO DAGScheduler: Got job 54 (collect at utils.scala:58) with 1 output partitions
17/12/19 13:58:13 INFO DAGScheduler: Final stage: ResultStage 114 (collect at utils.scala:58)
17/12/19 13:58:13 INFO DAGScheduler: Parents of final stage: List()
17/12/19 13:58:13 INFO DAGScheduler: Missing parents: List()
17/12/19 13:58:13 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[222] at map at utils.scala:55), which has no missing parents
17/12/19 13:58:13 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 8.7 KB, free 2002.2 MB)
17/12/19 13:58:13 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2002.2 MB)
17/12/19 13:58:13 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.3 MB)
17/12/19 13:58:13 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:996
17/12/19 13:58:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[222] at map at utils.scala:55)
17/12/19 13:58:13 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks
17/12/19 13:58:13 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 6793 bytes)
17/12/19 13:58:13 INFO Executor: Running task 0.0 in stage 114.0 (TID 84)
17/12/19 13:58:13 INFO Executor: Finished task 0.0 in stage 114.0 (TID 84). 1078 bytes result sent to driver
17/12/19 13:58:13 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 84) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:58:13 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
17/12/19 13:58:13 INFO DAGScheduler: ResultStage 114 (collect at utils.scala:58) finished in 0.000 s
17/12/19 13:58:13 INFO DAGScheduler: Job 54 finished: collect at utils.scala:58, took 0.007769 s
17/12/19 13:58:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:58:13 INFO MapPartitionsRDD: Removing RDD 192 from persistence list
17/12/19 13:58:13 INFO BlockManager: Removing RDD 192
17/12/19 13:58:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:58:13 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 13:58:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:58:13 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 13:58:13 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 13:58:13 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 13:58:13 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 13:58:13 INFO FileSourceStrategy: Output Data Schema: struct<V1: double, V2: double, V3: double, V4: double ... 2 more fields>
17/12/19 13:58:13 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 13:58:13 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 293.7 KB, free 2001.9 MB)
17/12/19 13:58:13 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2001.9 MB)
17/12/19 13:58:13 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.3 MB)
17/12/19 13:58:13 INFO SparkContext: Created broadcast 79 from sql at <unknown>:0
17/12/19 13:58:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 13:58:13 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 13:58:13 INFO DAGScheduler: Registering RDD 226 (sql at <unknown>:0)
17/12/19 13:58:13 INFO DAGScheduler: Registering RDD 231 (sql at <unknown>:0)
17/12/19 13:58:13 INFO DAGScheduler: Got job 55 (sql at <unknown>:0) with 1 output partitions
17/12/19 13:58:13 INFO DAGScheduler: Final stage: ResultStage 117 (sql at <unknown>:0)
17/12/19 13:58:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
17/12/19 13:58:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 116)
17/12/19 13:58:13 INFO DAGScheduler: Submitting ShuffleMapStage 115 (MapPartitionsRDD[226] at sql at <unknown>:0), which has no missing parents
17/12/19 13:58:13 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 12.2 KB, free 2001.9 MB)
17/12/19 13:58:13 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2001.9 MB)
17/12/19 13:58:13 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.3 MB)
17/12/19 13:58:13 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:996
17/12/19 13:58:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[226] at sql at <unknown>:0)
17/12/19 13:58:13 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks
17/12/19 13:58:13 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/19 13:58:13 INFO Executor: Running task 0.0 in stage 115.0 (TID 85)
17/12/19 13:58:13 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_86fd7feef7ea1853a8a5d0bd4a89f41b92a91b27b5c1b3cf5a0f84dcecb34d70.csv, range: 0-623, partition values: [empty row]
17/12/19 13:58:13 INFO Executor: Finished task 0.0 in stage 115.0 (TID 85). 1553 bytes result sent to driver
17/12/19 13:58:13 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 85) in 15 ms on localhost (executor driver) (1/1)
17/12/19 13:58:13 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
17/12/19 13:58:13 INFO DAGScheduler: ShuffleMapStage 115 (sql at <unknown>:0) finished in 0.015 s
17/12/19 13:58:13 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:58:13 INFO DAGScheduler: running: Set()
17/12/19 13:58:13 INFO DAGScheduler: waiting: Set(ResultStage 117, ShuffleMapStage 116)
17/12/19 13:58:13 INFO DAGScheduler: failed: Set()
17/12/19 13:58:13 INFO DAGScheduler: Submitting ShuffleMapStage 116 (MapPartitionsRDD[231] at sql at <unknown>:0), which has no missing parents
17/12/19 13:58:13 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 12.3 KB, free 2001.8 MB)
17/12/19 13:58:13 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2001.8 MB)
17/12/19 13:58:13 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.3 MB)
17/12/19 13:58:13 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:996
17/12/19 13:58:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 116 (MapPartitionsRDD[231] at sql at <unknown>:0)
17/12/19 13:58:13 INFO TaskSchedulerImpl: Adding task set 116.0 with 2 tasks
17/12/19 13:58:13 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 86, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/19 13:58:13 INFO TaskSetManager: Starting task 1.0 in stage 116.0 (TID 87, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/19 13:58:13 INFO Executor: Running task 1.0 in stage 116.0 (TID 87)
17/12/19 13:58:13 INFO Executor: Running task 0.0 in stage 116.0 (TID 86)
17/12/19 13:58:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 13:58:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 13:58:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:58:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:58:13 INFO MemoryStore: Block rdd_228_1 stored as values in memory (estimated size 664.0 B, free 2001.8 MB)
17/12/19 13:58:13 INFO MemoryStore: Block rdd_228_0 stored as values in memory (estimated size 664.0 B, free 2001.8 MB)
17/12/19 13:58:13 INFO BlockManagerInfo: Added rdd_228_0 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.3 MB)
17/12/19 13:58:13 INFO BlockManagerInfo: Added rdd_228_1 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.3 MB)
17/12/19 13:58:13 INFO Executor: Finished task 0.0 in stage 116.0 (TID 86). 3064 bytes result sent to driver
17/12/19 13:58:13 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 86) in 16 ms on localhost (executor driver) (1/2)
17/12/19 13:58:13 INFO Executor: Finished task 1.0 in stage 116.0 (TID 87). 3064 bytes result sent to driver
17/12/19 13:58:13 INFO TaskSetManager: Finished task 1.0 in stage 116.0 (TID 87) in 16 ms on localhost (executor driver) (2/2)
17/12/19 13:58:13 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
17/12/19 13:58:13 INFO DAGScheduler: ShuffleMapStage 116 (sql at <unknown>:0) finished in 0.016 s
17/12/19 13:58:13 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:58:13 INFO DAGScheduler: running: Set()
17/12/19 13:58:13 INFO DAGScheduler: waiting: Set(ResultStage 117)
17/12/19 13:58:13 INFO DAGScheduler: failed: Set()
17/12/19 13:58:13 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[234] at sql at <unknown>:0), which has no missing parents
17/12/19 13:58:13 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 7.0 KB, free 2001.8 MB)
17/12/19 13:58:13 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.8 MB)
17/12/19 13:58:13 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 13:58:13 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:996
17/12/19 13:58:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[234] at sql at <unknown>:0)
17/12/19 13:58:13 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks
17/12/19 13:58:13 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 88, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/19 13:58:13 INFO Executor: Running task 0.0 in stage 117.0 (TID 88)
17/12/19 13:58:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 13:58:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:58:13 INFO Executor: Finished task 0.0 in stage 117.0 (TID 88). 1707 bytes result sent to driver
17/12/19 13:58:13 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 88) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:58:13 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
17/12/19 13:58:13 INFO DAGScheduler: ResultStage 117 (sql at <unknown>:0) finished in 0.000 s
17/12/19 13:58:13 INFO DAGScheduler: Job 55 finished: sql at <unknown>:0, took 0.049268 s
17/12/19 13:58:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:58:13 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 13:58:13 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:58:13 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 145 bytes
17/12/19 13:58:13 INFO DAGScheduler: Registering RDD 238 (collect at utils.scala:196)
17/12/19 13:58:13 INFO DAGScheduler: Got job 56 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:58:13 INFO DAGScheduler: Final stage: ResultStage 120 (collect at utils.scala:196)
17/12/19 13:58:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 119)
17/12/19 13:58:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 119)
17/12/19 13:58:13 INFO DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[238] at collect at utils.scala:196), which has no missing parents
17/12/19 13:58:13 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 12.3 KB, free 2001.8 MB)
17/12/19 13:58:13 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2001.8 MB)
17/12/19 13:58:14 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.3 MB)
17/12/19 13:58:14 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:996
17/12/19 13:58:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[238] at collect at utils.scala:196)
17/12/19 13:58:14 INFO TaskSchedulerImpl: Adding task set 119.0 with 2 tasks
17/12/19 13:58:14 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/19 13:58:14 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 90, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/19 13:58:14 INFO Executor: Running task 1.0 in stage 119.0 (TID 90)
17/12/19 13:58:14 INFO Executor: Running task 0.0 in stage 119.0 (TID 89)
17/12/19 13:58:14 INFO BlockManager: Found block rdd_228_1 locally
17/12/19 13:58:14 INFO BlockManager: Found block rdd_228_0 locally
17/12/19 13:58:14 INFO Executor: Finished task 1.0 in stage 119.0 (TID 90). 1958 bytes result sent to driver
17/12/19 13:58:14 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 90) in 3 ms on localhost (executor driver) (1/2)
17/12/19 13:58:14 INFO Executor: Finished task 0.0 in stage 119.0 (TID 89). 1879 bytes result sent to driver
17/12/19 13:58:14 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 89) in 4 ms on localhost (executor driver) (2/2)
17/12/19 13:58:14 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
17/12/19 13:58:14 INFO DAGScheduler: ShuffleMapStage 119 (collect at utils.scala:196) finished in 0.004 s
17/12/19 13:58:14 INFO DAGScheduler: looking for newly runnable stages
17/12/19 13:58:14 INFO DAGScheduler: running: Set()
17/12/19 13:58:14 INFO DAGScheduler: waiting: Set(ResultStage 120)
17/12/19 13:58:14 INFO DAGScheduler: failed: Set()
17/12/19 13:58:14 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[241] at collect at utils.scala:196), which has no missing parents
17/12/19 13:58:14 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 7.0 KB, free 2001.8 MB)
17/12/19 13:58:14 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.8 MB)
17/12/19 13:58:14 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.2 MB)
17/12/19 13:58:14 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:996
17/12/19 13:58:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[241] at collect at utils.scala:196)
17/12/19 13:58:14 INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks
17/12/19 13:58:14 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 91, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/19 13:58:14 INFO Executor: Running task 0.0 in stage 120.0 (TID 91)
17/12/19 13:58:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 13:58:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 13:58:14 INFO Executor: Finished task 0.0 in stage 120.0 (TID 91). 1707 bytes result sent to driver
17/12/19 13:58:14 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 91) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:58:14 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
17/12/19 13:58:14 INFO DAGScheduler: ResultStage 120 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:58:14 INFO DAGScheduler: Job 56 finished: collect at utils.scala:196, took 0.023490 s
17/12/19 13:58:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:58:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz13`
WHERE (0 = 1)
17/12/19 13:58:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:58:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 13:58:14 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 13:58:14 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 145 bytes
17/12/19 13:58:14 INFO DAGScheduler: Got job 57 (take at <unknown>:0) with 1 output partitions
17/12/19 13:58:14 INFO DAGScheduler: Final stage: ResultStage 122 (take at <unknown>:0)
17/12/19 13:58:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 121)
17/12/19 13:58:14 INFO DAGScheduler: Missing parents: List()
17/12/19 13:58:14 INFO DAGScheduler: Submitting ResultStage 122 (WorkerRDD[245] at RDD at rdd.scala:18), which has no missing parents
17/12/19 13:58:14 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 122.9 KB, free 2001.7 MB)
17/12/19 13:58:14 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 48.8 KB, free 2001.6 MB)
17/12/19 13:58:14 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:53618 (size: 48.8 KB, free: 2004.2 MB)
17/12/19 13:58:14 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:996
17/12/19 13:58:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (WorkerRDD[245] at RDD at rdd.scala:18)
17/12/19 13:58:14 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks
17/12/19 13:58:14 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 13:58:14 INFO Executor: Running task 0.0 in stage 122.0 (TID 92)
17/12/19 13:58:14 INFO BlockManager: Found block rdd_228_0 locally
17/12/19 13:58:14 INFO MemoryStore: Block rdd_245_0 stored as values in memory (estimated size 80.0 B, free 2001.6 MB)
17/12/19 13:58:14 INFO BlockManagerInfo: Added rdd_245_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.2 MB)
17/12/19 13:58:14 INFO Executor: Finished task 0.0 in stage 122.0 (TID 92). 2154 bytes result sent to driver
17/12/19 13:58:14 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 92) in 702 ms on localhost (executor driver) (1/1)
17/12/19 13:58:14 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
17/12/19 13:58:14 INFO DAGScheduler: ResultStage 122 (take at <unknown>:0) finished in 0.702 s
17/12/19 13:58:14 INFO DAGScheduler: Job 57 finished: take at <unknown>:0, took 0.707523 s
17/12/19 13:58:14 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 13:58:14 INFO DAGScheduler: Got job 58 (take at <unknown>:0) with 1 output partitions
17/12/19 13:58:14 INFO DAGScheduler: Final stage: ResultStage 124 (take at <unknown>:0)
17/12/19 13:58:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 123)
17/12/19 13:58:14 INFO DAGScheduler: Missing parents: List()
17/12/19 13:58:14 INFO DAGScheduler: Submitting ResultStage 124 (WorkerRDD[245] at RDD at rdd.scala:18), which has no missing parents
17/12/19 13:58:14 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 122.9 KB, free 2001.5 MB)
17/12/19 13:58:14 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 48.8 KB, free 2001.5 MB)
17/12/19 13:58:14 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:53618 (size: 48.8 KB, free: 2004.2 MB)
17/12/19 13:58:14 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:996
17/12/19 13:58:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 124 (WorkerRDD[245] at RDD at rdd.scala:18)
17/12/19 13:58:14 INFO TaskSchedulerImpl: Adding task set 124.0 with 1 tasks
17/12/19 13:58:14 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 93, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 13:58:14 INFO Executor: Running task 0.0 in stage 124.0 (TID 93)
17/12/19 13:58:14 INFO BlockManager: Found block rdd_228_1 locally
17/12/19 13:58:15 INFO MemoryStore: Block rdd_245_1 stored as values in memory (estimated size 80.0 B, free 2001.5 MB)
17/12/19 13:58:15 INFO BlockManagerInfo: Added rdd_245_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.2 MB)
17/12/19 13:58:15 INFO Executor: Finished task 0.0 in stage 124.0 (TID 93). 2154 bytes result sent to driver
17/12/19 13:58:15 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 93) in 606 ms on localhost (executor driver) (1/1)
17/12/19 13:58:15 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
17/12/19 13:58:15 INFO DAGScheduler: ResultStage 124 (take at <unknown>:0) finished in 0.606 s
17/12/19 13:58:15 INFO DAGScheduler: Job 58 finished: take at <unknown>:0, took 0.607469 s
17/12/19 13:58:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:58:15 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e83d184b
17/12/19 13:58:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:58:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e83d184b` AS `zzz14`
WHERE (0 = 1)
17/12/19 13:58:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:58:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e83d184b`
LIMIT 10
17/12/19 13:58:15 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:58:15 INFO DAGScheduler: Got job 59 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:58:15 INFO DAGScheduler: Final stage: ResultStage 126 (collect at utils.scala:196)
17/12/19 13:58:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 125)
17/12/19 13:58:15 INFO DAGScheduler: Missing parents: List()
17/12/19 13:58:15 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[249] at collect at utils.scala:196), which has no missing parents
17/12/19 13:58:15 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 125.9 KB, free 2001.3 MB)
17/12/19 13:58:15 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 50.5 KB, free 2001.3 MB)
17/12/19 13:58:15 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:53618 (size: 50.5 KB, free: 2004.1 MB)
17/12/19 13:58:15 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:996
17/12/19 13:58:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[249] at collect at utils.scala:196)
17/12/19 13:58:15 INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks
17/12/19 13:58:15 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:58:15 INFO Executor: Running task 0.0 in stage 126.0 (TID 94)
17/12/19 13:58:15 INFO BlockManager: Found block rdd_245_0 locally
17/12/19 13:58:15 INFO Executor: Finished task 0.0 in stage 126.0 (TID 94). 1233 bytes result sent to driver
17/12/19 13:58:15 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 94) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:58:15 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
17/12/19 13:58:15 INFO DAGScheduler: ResultStage 126 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:58:15 INFO DAGScheduler: Job 59 finished: collect at utils.scala:196, took 0.009437 s
17/12/19 13:58:15 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:58:15 INFO DAGScheduler: Got job 60 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:58:15 INFO DAGScheduler: Final stage: ResultStage 128 (collect at utils.scala:196)
17/12/19 13:58:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 127)
17/12/19 13:58:15 INFO DAGScheduler: Missing parents: List()
17/12/19 13:58:15 INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[249] at collect at utils.scala:196), which has no missing parents
17/12/19 13:58:15 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 125.9 KB, free 2001.2 MB)
17/12/19 13:58:15 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 50.5 KB, free 2001.1 MB)
17/12/19 13:58:15 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:53618 (size: 50.5 KB, free: 2004.1 MB)
17/12/19 13:58:15 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:996
17/12/19 13:58:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 128 (MapPartitionsRDD[249] at collect at utils.scala:196)
17/12/19 13:58:15 INFO TaskSchedulerImpl: Adding task set 128.0 with 1 tasks
17/12/19 13:58:15 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 95, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:58:15 INFO Executor: Running task 0.0 in stage 128.0 (TID 95)
17/12/19 13:58:15 INFO BlockManager: Found block rdd_245_1 locally
17/12/19 13:58:15 INFO Executor: Finished task 0.0 in stage 128.0 (TID 95). 1233 bytes result sent to driver
17/12/19 13:58:15 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 95) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:58:15 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
17/12/19 13:58:15 INFO DAGScheduler: ResultStage 128 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:58:15 INFO DAGScheduler: Job 60 finished: collect at utils.scala:196, took 0.008703 s
17/12/19 13:58:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:58:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 13:58:15 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:58:15 INFO DAGScheduler: Got job 61 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:58:15 INFO DAGScheduler: Final stage: ResultStage 130 (collect at utils.scala:196)
17/12/19 13:58:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 129)
17/12/19 13:58:15 INFO DAGScheduler: Missing parents: List()
17/12/19 13:58:15 INFO DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[251] at collect at utils.scala:196), which has no missing parents
17/12/19 13:58:15 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 8.8 KB, free 2001.1 MB)
17/12/19 13:58:15 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2001.1 MB)
17/12/19 13:58:15 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:53618 (size: 4.5 KB, free: 2004.0 MB)
17/12/19 13:58:15 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:996
17/12/19 13:58:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[251] at collect at utils.scala:196)
17/12/19 13:58:15 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks
17/12/19 13:58:15 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:58:15 INFO Executor: Running task 0.0 in stage 130.0 (TID 96)
17/12/19 13:58:15 INFO BlockManager: Found block rdd_228_0 locally
17/12/19 13:58:15 INFO Executor: Finished task 0.0 in stage 130.0 (TID 96). 1251 bytes result sent to driver
17/12/19 13:58:15 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 96) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:58:15 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
17/12/19 13:58:15 INFO DAGScheduler: ResultStage 130 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:58:15 INFO DAGScheduler: Job 61 finished: collect at utils.scala:196, took 0.007136 s
17/12/19 13:58:15 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 13:58:15 INFO DAGScheduler: Got job 62 (collect at utils.scala:196) with 1 output partitions
17/12/19 13:58:15 INFO DAGScheduler: Final stage: ResultStage 132 (collect at utils.scala:196)
17/12/19 13:58:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 131)
17/12/19 13:58:15 INFO DAGScheduler: Missing parents: List()
17/12/19 13:58:15 INFO DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[251] at collect at utils.scala:196), which has no missing parents
17/12/19 13:58:15 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 8.8 KB, free 2001.1 MB)
17/12/19 13:58:15 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2001.1 MB)
17/12/19 13:58:15 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:53618 (size: 4.5 KB, free: 2004.0 MB)
17/12/19 13:58:15 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:996
17/12/19 13:58:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[251] at collect at utils.scala:196)
17/12/19 13:58:15 INFO TaskSchedulerImpl: Adding task set 132.0 with 1 tasks
17/12/19 13:58:15 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 97, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 13:58:15 INFO Executor: Running task 0.0 in stage 132.0 (TID 97)
17/12/19 13:58:15 INFO BlockManager: Found block rdd_228_1 locally
17/12/19 13:58:15 INFO Executor: Finished task 0.0 in stage 132.0 (TID 97). 1251 bytes result sent to driver
17/12/19 13:58:15 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 97) in 0 ms on localhost (executor driver) (1/1)
17/12/19 13:58:15 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
17/12/19 13:58:15 INFO DAGScheduler: ResultStage 132 (collect at utils.scala:196) finished in 0.000 s
17/12/19 13:58:15 INFO DAGScheduler: Job 62 finished: collect at utils.scala:196, took 0.007398 s
17/12/19 13:58:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 13:58:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 13:58:15 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:58:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:58:15 INFO HiveMetaStore: 0: get_database: default
17/12/19 13:58:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 13:58:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 13:58:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 14:06:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:06:59 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 14:06:59 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:06:59 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:06:59 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:06:59 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:06:59 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 14:06:59 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 14:06:59 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 14:06:59 INFO DAGScheduler: Got job 63 (collect at utils.scala:58) with 1 output partitions
17/12/19 14:06:59 INFO DAGScheduler: Final stage: ResultStage 133 (collect at utils.scala:58)
17/12/19 14:06:59 INFO DAGScheduler: Parents of final stage: List()
17/12/19 14:06:59 INFO DAGScheduler: Missing parents: List()
17/12/19 14:06:59 INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[258] at map at utils.scala:55), which has no missing parents
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 8.7 KB, free 2001.1 MB)
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2001.1 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.0 MB)
17/12/19 14:06:59 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:996
17/12/19 14:06:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[258] at map at utils.scala:55)
17/12/19 14:06:59 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks
17/12/19 14:06:59 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 6863 bytes)
17/12/19 14:06:59 INFO Executor: Running task 0.0 in stage 133.0 (TID 98)
17/12/19 14:06:59 INFO Executor: Finished task 0.0 in stage 133.0 (TID 98). 1194 bytes result sent to driver
17/12/19 14:06:59 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 98) in 4 ms on localhost (executor driver) (1/1)
17/12/19 14:06:59 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
17/12/19 14:06:59 INFO DAGScheduler: ResultStage 133 (collect at utils.scala:58) finished in 0.004 s
17/12/19 14:06:59 INFO DAGScheduler: Job 63 finished: collect at utils.scala:58, took 0.007882 s
17/12/19 14:06:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:06:59 INFO MapPartitionsRDD: Removing RDD 228 from persistence list
17/12/19 14:06:59 INFO BlockManager: Removing RDD 228
17/12/19 14:06:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:06:59 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 14:06:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:06:59 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 14:06:59 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 14:06:59 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 14:06:59 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 14:06:59 INFO FileSourceStrategy: Output Data Schema: struct<V1: double, V2: double, V3: double, V4: double ... 2 more fields>
17/12/19 14:06:59 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 293.7 KB, free 2000.8 MB)
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2000.8 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.0 MB)
17/12/19 14:06:59 INFO SparkContext: Created broadcast 92 from sql at <unknown>:0
17/12/19 14:06:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 14:06:59 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 14:06:59 INFO DAGScheduler: Registering RDD 262 (sql at <unknown>:0)
17/12/19 14:06:59 INFO DAGScheduler: Registering RDD 267 (sql at <unknown>:0)
17/12/19 14:06:59 INFO DAGScheduler: Got job 64 (sql at <unknown>:0) with 1 output partitions
17/12/19 14:06:59 INFO DAGScheduler: Final stage: ResultStage 136 (sql at <unknown>:0)
17/12/19 14:06:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 135)
17/12/19 14:06:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 135)
17/12/19 14:06:59 INFO DAGScheduler: Submitting ShuffleMapStage 134 (MapPartitionsRDD[262] at sql at <unknown>:0), which has no missing parents
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 12.2 KB, free 2000.8 MB)
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2000.7 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.0 MB)
17/12/19 14:06:59 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:996
17/12/19 14:06:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 134 (MapPartitionsRDD[262] at sql at <unknown>:0)
17/12/19 14:06:59 INFO TaskSchedulerImpl: Adding task set 134.0 with 1 tasks
17/12/19 14:06:59 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 99, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/19 14:06:59 INFO Executor: Running task 0.0 in stage 134.0 (TID 99)
17/12/19 14:06:59 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_008533ebffe74ad9fab351b9c0daaf7d58471021bf541e6b2a6a80eabdb4babc.csv, range: 0-621, partition values: [empty row]
17/12/19 14:06:59 INFO Executor: Finished task 0.0 in stage 134.0 (TID 99). 1553 bytes result sent to driver
17/12/19 14:06:59 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 99) in 16 ms on localhost (executor driver) (1/1)
17/12/19 14:06:59 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
17/12/19 14:06:59 INFO DAGScheduler: ShuffleMapStage 134 (sql at <unknown>:0) finished in 0.016 s
17/12/19 14:06:59 INFO DAGScheduler: looking for newly runnable stages
17/12/19 14:06:59 INFO DAGScheduler: running: Set()
17/12/19 14:06:59 INFO DAGScheduler: waiting: Set(ShuffleMapStage 135, ResultStage 136)
17/12/19 14:06:59 INFO DAGScheduler: failed: Set()
17/12/19 14:06:59 INFO DAGScheduler: Submitting ShuffleMapStage 135 (MapPartitionsRDD[267] at sql at <unknown>:0), which has no missing parents
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 12.3 KB, free 2000.7 MB)
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2000.7 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.0 MB)
17/12/19 14:06:59 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:996
17/12/19 14:06:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 135 (MapPartitionsRDD[267] at sql at <unknown>:0)
17/12/19 14:06:59 INFO TaskSchedulerImpl: Adding task set 135.0 with 2 tasks
17/12/19 14:06:59 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 100, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/19 14:06:59 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 101, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/19 14:06:59 INFO Executor: Running task 0.0 in stage 135.0 (TID 100)
17/12/19 14:06:59 INFO Executor: Running task 1.0 in stage 135.0 (TID 101)
17/12/19 14:06:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 14:06:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:06:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 14:06:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:06:59 INFO MemoryStore: Block rdd_264_0 stored as values in memory (estimated size 664.0 B, free 2000.7 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Added rdd_264_0 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.0 MB)
17/12/19 14:06:59 INFO MemoryStore: Block rdd_264_1 stored as values in memory (estimated size 664.0 B, free 2000.7 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Added rdd_264_1 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.0 MB)
17/12/19 14:06:59 INFO Executor: Finished task 0.0 in stage 135.0 (TID 100). 3064 bytes result sent to driver
17/12/19 14:06:59 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 100) in 20 ms on localhost (executor driver) (1/2)
17/12/19 14:06:59 INFO Executor: Finished task 1.0 in stage 135.0 (TID 101). 2985 bytes result sent to driver
17/12/19 14:06:59 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 101) in 48 ms on localhost (executor driver) (2/2)
17/12/19 14:06:59 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
17/12/19 14:06:59 INFO DAGScheduler: ShuffleMapStage 135 (sql at <unknown>:0) finished in 0.048 s
17/12/19 14:06:59 INFO DAGScheduler: looking for newly runnable stages
17/12/19 14:06:59 INFO DAGScheduler: running: Set()
17/12/19 14:06:59 INFO DAGScheduler: waiting: Set(ResultStage 136)
17/12/19 14:06:59 INFO DAGScheduler: failed: Set()
17/12/19 14:06:59 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[270] at sql at <unknown>:0), which has no missing parents
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 7.0 KB, free 2000.7 MB)
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2000.7 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.0 MB)
17/12/19 14:06:59 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:996
17/12/19 14:06:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[270] at sql at <unknown>:0)
17/12/19 14:06:59 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks
17/12/19 14:06:59 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 102, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/19 14:06:59 INFO Executor: Running task 0.0 in stage 136.0 (TID 102)
17/12/19 14:06:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 14:06:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:06:59 INFO Executor: Finished task 0.0 in stage 136.0 (TID 102). 1873 bytes result sent to driver
17/12/19 14:06:59 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 102) in 6 ms on localhost (executor driver) (1/1)
17/12/19 14:06:59 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
17/12/19 14:06:59 INFO DAGScheduler: ResultStage 136 (sql at <unknown>:0) finished in 0.006 s
17/12/19 14:06:59 INFO DAGScheduler: Job 64 finished: sql at <unknown>:0, took 0.076503 s
17/12/19 14:06:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:06:59 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.0 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:53618 in memory (size: 48.9 KB, free: 2004.1 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:53618 in memory (size: 50.7 KB, free: 2004.1 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:53618 in memory (size: 50.7 KB, free: 2004.2 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:53618 in memory (size: 4.5 KB, free: 2004.2 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:53618 in memory (size: 4.5 KB, free: 2004.2 MB)
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 3972
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 3973
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.2 MB)
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4022
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4023
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4029
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4030
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4031
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4032
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4033
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4034
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4035
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4036
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4037
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4038
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4039
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4040
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4041
17/12/19 14:06:59 INFO ContextCleaner: Cleaned shuffle 19
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.2 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.2 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4210
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:53618 in memory (size: 48.8 KB, free: 2004.2 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:53618 in memory (size: 48.8 KB, free: 2004.3 MB)
17/12/19 14:06:59 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 14:06:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 21 is 145 bytes
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:53618 in memory (size: 50.5 KB, free: 2004.3 MB)
17/12/19 14:06:59 INFO DAGScheduler: Registering RDD 274 (collect at utils.scala:196)
17/12/19 14:06:59 INFO DAGScheduler: Got job 65 (collect at utils.scala:196) with 1 output partitions
17/12/19 14:06:59 INFO DAGScheduler: Final stage: ResultStage 139 (collect at utils.scala:196)
17/12/19 14:06:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 138)
17/12/19 14:06:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 138)
17/12/19 14:06:59 INFO DAGScheduler: Submitting ShuffleMapStage 138 (MapPartitionsRDD[274] at collect at utils.scala:196), which has no missing parents
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:53618 in memory (size: 50.5 KB, free: 2004.4 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:53618 in memory (size: 4.5 KB, free: 2004.4 MB)
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 12.3 KB, free 2002.0 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:53618 in memory (size: 4.5 KB, free: 2004.4 MB)
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4634
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4635
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2002.0 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.4 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.4 MB)
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4684
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4685
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4691
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4692
17/12/19 14:06:59 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:996
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4693
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4694
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4695
17/12/19 14:06:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 138 (MapPartitionsRDD[274] at collect at utils.scala:196)
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4696
17/12/19 14:06:59 INFO TaskSchedulerImpl: Adding task set 138.0 with 2 tasks
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4697
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4698
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4699
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4700
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4701
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4702
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4703
17/12/19 14:06:59 INFO ContextCleaner: Cleaned shuffle 22
17/12/19 14:06:59 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.4 MB)
17/12/19 14:06:59 INFO TaskSetManager: Starting task 1.0 in stage 138.0 (TID 104, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/19 14:06:59 INFO Executor: Running task 0.0 in stage 138.0 (TID 103)
17/12/19 14:06:59 INFO Executor: Running task 1.0 in stage 138.0 (TID 104)
17/12/19 14:06:59 INFO BlockManager: Found block rdd_264_1 locally
17/12/19 14:06:59 INFO BlockManager: Found block rdd_264_0 locally
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.4 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.4 MB)
17/12/19 14:06:59 INFO ContextCleaner: Cleaned accumulator 4872
17/12/19 14:06:59 INFO Executor: Finished task 0.0 in stage 138.0 (TID 103). 1792 bytes result sent to driver
17/12/19 14:06:59 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 103) in 15 ms on localhost (executor driver) (1/2)
17/12/19 14:06:59 INFO Executor: Finished task 1.0 in stage 138.0 (TID 104). 1792 bytes result sent to driver
17/12/19 14:06:59 INFO TaskSetManager: Finished task 1.0 in stage 138.0 (TID 104) in 0 ms on localhost (executor driver) (2/2)
17/12/19 14:06:59 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
17/12/19 14:06:59 INFO DAGScheduler: ShuffleMapStage 138 (collect at utils.scala:196) finished in 0.015 s
17/12/19 14:06:59 INFO DAGScheduler: looking for newly runnable stages
17/12/19 14:06:59 INFO DAGScheduler: running: Set()
17/12/19 14:06:59 INFO DAGScheduler: waiting: Set(ResultStage 139)
17/12/19 14:06:59 INFO DAGScheduler: failed: Set()
17/12/19 14:06:59 INFO DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[277] at collect at utils.scala:196), which has no missing parents
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 7.0 KB, free 2002.1 MB)
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.1 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.4 MB)
17/12/19 14:06:59 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:996
17/12/19 14:06:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[277] at collect at utils.scala:196)
17/12/19 14:06:59 INFO TaskSchedulerImpl: Adding task set 139.0 with 1 tasks
17/12/19 14:06:59 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 105, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/19 14:06:59 INFO Executor: Running task 0.0 in stage 139.0 (TID 105)
17/12/19 14:06:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 14:06:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:06:59 INFO Executor: Finished task 0.0 in stage 139.0 (TID 105). 1707 bytes result sent to driver
17/12/19 14:06:59 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 105) in 0 ms on localhost (executor driver) (1/1)
17/12/19 14:06:59 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
17/12/19 14:06:59 INFO DAGScheduler: ResultStage 139 (collect at utils.scala:196) finished in 0.000 s
17/12/19 14:06:59 INFO DAGScheduler: Job 65 finished: collect at utils.scala:196, took 0.030913 s
17/12/19 14:06:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:06:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz15`
WHERE (0 = 1)
17/12/19 14:06:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:06:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 14:06:59 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 14:06:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 21 is 145 bytes
17/12/19 14:06:59 INFO DAGScheduler: Got job 66 (take at <unknown>:0) with 1 output partitions
17/12/19 14:06:59 INFO DAGScheduler: Final stage: ResultStage 141 (take at <unknown>:0)
17/12/19 14:06:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 140)
17/12/19 14:06:59 INFO DAGScheduler: Missing parents: List()
17/12/19 14:06:59 INFO DAGScheduler: Submitting ResultStage 141 (WorkerRDD[281] at RDD at rdd.scala:18), which has no missing parents
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 115.2 KB, free 2002.0 MB)
17/12/19 14:06:59 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 46.7 KB, free 2001.9 MB)
17/12/19 14:06:59 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:53618 (size: 46.7 KB, free: 2004.4 MB)
17/12/19 14:06:59 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:996
17/12/19 14:06:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 141 (WorkerRDD[281] at RDD at rdd.scala:18)
17/12/19 14:06:59 INFO TaskSchedulerImpl: Adding task set 141.0 with 1 tasks
17/12/19 14:06:59 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 14:06:59 INFO Executor: Running task 0.0 in stage 141.0 (TID 106)
17/12/19 14:06:59 INFO BlockManager: Found block rdd_264_0 locally
17/12/19 14:07:00 INFO MemoryStore: Block rdd_281_0 stored as values in memory (estimated size 80.0 B, free 2001.9 MB)
17/12/19 14:07:00 INFO BlockManagerInfo: Added rdd_281_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.4 MB)
17/12/19 14:07:00 INFO Executor: Finished task 0.0 in stage 141.0 (TID 106). 2154 bytes result sent to driver
17/12/19 14:07:00 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 106) in 616 ms on localhost (executor driver) (1/1)
17/12/19 14:07:00 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool 
17/12/19 14:07:00 INFO DAGScheduler: ResultStage 141 (take at <unknown>:0) finished in 0.616 s
17/12/19 14:07:00 INFO DAGScheduler: Job 66 finished: take at <unknown>:0, took 0.623195 s
17/12/19 14:07:00 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 14:07:00 INFO DAGScheduler: Got job 67 (take at <unknown>:0) with 1 output partitions
17/12/19 14:07:00 INFO DAGScheduler: Final stage: ResultStage 143 (take at <unknown>:0)
17/12/19 14:07:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 142)
17/12/19 14:07:00 INFO DAGScheduler: Missing parents: List()
17/12/19 14:07:00 INFO DAGScheduler: Submitting ResultStage 143 (WorkerRDD[281] at RDD at rdd.scala:18), which has no missing parents
17/12/19 14:07:00 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 115.2 KB, free 2001.8 MB)
17/12/19 14:07:00 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 46.7 KB, free 2001.8 MB)
17/12/19 14:07:00 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:53618 (size: 46.7 KB, free: 2004.3 MB)
17/12/19 14:07:00 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:996
17/12/19 14:07:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 143 (WorkerRDD[281] at RDD at rdd.scala:18)
17/12/19 14:07:00 INFO TaskSchedulerImpl: Adding task set 143.0 with 1 tasks
17/12/19 14:07:00 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 107, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 14:07:00 INFO Executor: Running task 0.0 in stage 143.0 (TID 107)
17/12/19 14:07:00 INFO BlockManager: Found block rdd_264_1 locally
17/12/19 14:07:01 INFO MemoryStore: Block rdd_281_1 stored as values in memory (estimated size 80.0 B, free 2001.8 MB)
17/12/19 14:07:01 INFO BlockManagerInfo: Added rdd_281_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.3 MB)
17/12/19 14:07:01 INFO Executor: Finished task 0.0 in stage 143.0 (TID 107). 2154 bytes result sent to driver
17/12/19 14:07:01 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 107) in 594 ms on localhost (executor driver) (1/1)
17/12/19 14:07:01 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
17/12/19 14:07:01 INFO DAGScheduler: ResultStage 143 (take at <unknown>:0) finished in 0.594 s
17/12/19 14:07:01 INFO DAGScheduler: Job 67 finished: take at <unknown>:0, took 0.610981 s
17/12/19 14:07:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:07:01 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e8174d5638
17/12/19 14:07:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:07:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8174d5638` AS `zzz16`
WHERE (0 = 1)
17/12/19 14:07:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:07:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8174d5638`
LIMIT 10
17/12/19 14:07:01 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 14:07:01 INFO DAGScheduler: Got job 68 (collect at utils.scala:196) with 1 output partitions
17/12/19 14:07:01 INFO DAGScheduler: Final stage: ResultStage 145 (collect at utils.scala:196)
17/12/19 14:07:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 144)
17/12/19 14:07:01 INFO DAGScheduler: Missing parents: List()
17/12/19 14:07:01 INFO DAGScheduler: Submitting ResultStage 145 (MapPartitionsRDD[285] at collect at utils.scala:196), which has no missing parents
17/12/19 14:07:01 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 118.2 KB, free 2001.7 MB)
17/12/19 14:07:01 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 48.5 KB, free 2001.6 MB)
17/12/19 14:07:01 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:53618 (size: 48.5 KB, free: 2004.3 MB)
17/12/19 14:07:01 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:996
17/12/19 14:07:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 145 (MapPartitionsRDD[285] at collect at utils.scala:196)
17/12/19 14:07:01 INFO TaskSchedulerImpl: Adding task set 145.0 with 1 tasks
17/12/19 14:07:01 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 108, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 14:07:01 INFO Executor: Running task 0.0 in stage 145.0 (TID 108)
17/12/19 14:07:01 INFO BlockManager: Found block rdd_281_0 locally
17/12/19 14:07:01 INFO Executor: Finished task 0.0 in stage 145.0 (TID 108). 1233 bytes result sent to driver
17/12/19 14:07:01 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 108) in 0 ms on localhost (executor driver) (1/1)
17/12/19 14:07:01 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool 
17/12/19 14:07:01 INFO DAGScheduler: ResultStage 145 (collect at utils.scala:196) finished in 0.000 s
17/12/19 14:07:01 INFO DAGScheduler: Job 68 finished: collect at utils.scala:196, took 0.009457 s
17/12/19 14:07:01 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 14:07:01 INFO DAGScheduler: Got job 69 (collect at utils.scala:196) with 1 output partitions
17/12/19 14:07:01 INFO DAGScheduler: Final stage: ResultStage 147 (collect at utils.scala:196)
17/12/19 14:07:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 146)
17/12/19 14:07:01 INFO DAGScheduler: Missing parents: List()
17/12/19 14:07:01 INFO DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[285] at collect at utils.scala:196), which has no missing parents
17/12/19 14:07:01 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 118.2 KB, free 2001.5 MB)
17/12/19 14:07:01 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 48.5 KB, free 2001.4 MB)
17/12/19 14:07:01 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:53618 (size: 48.5 KB, free: 2004.2 MB)
17/12/19 14:07:01 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:996
17/12/19 14:07:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[285] at collect at utils.scala:196)
17/12/19 14:07:01 INFO TaskSchedulerImpl: Adding task set 147.0 with 1 tasks
17/12/19 14:07:01 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 109, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 14:07:01 INFO Executor: Running task 0.0 in stage 147.0 (TID 109)
17/12/19 14:07:01 INFO BlockManager: Found block rdd_281_1 locally
17/12/19 14:07:01 INFO Executor: Finished task 0.0 in stage 147.0 (TID 109). 1233 bytes result sent to driver
17/12/19 14:07:01 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 109) in 0 ms on localhost (executor driver) (1/1)
17/12/19 14:07:01 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
17/12/19 14:07:01 INFO DAGScheduler: ResultStage 147 (collect at utils.scala:196) finished in 0.000 s
17/12/19 14:07:01 INFO DAGScheduler: Job 69 finished: collect at utils.scala:196, took 0.009444 s
17/12/19 14:07:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:07:01 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `eeimhpifwo`
17/12/19 14:07:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:07:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 14:07:01 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:07:01 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:07:01 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:07:01 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:07:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 14:07:01 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 14:11:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:11:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 14:11:39 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:11:39 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:11:39 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:11:39 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:11:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 14:11:39 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 14:11:39 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 14:11:39 INFO DAGScheduler: Got job 70 (collect at utils.scala:58) with 1 output partitions
17/12/19 14:11:39 INFO DAGScheduler: Final stage: ResultStage 148 (collect at utils.scala:58)
17/12/19 14:11:39 INFO DAGScheduler: Parents of final stage: List()
17/12/19 14:11:39 INFO DAGScheduler: Missing parents: List()
17/12/19 14:11:39 INFO DAGScheduler: Submitting ResultStage 148 (MapPartitionsRDD[292] at map at utils.scala:55), which has no missing parents
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 8.7 KB, free 2001.4 MB)
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2001.4 MB)
17/12/19 14:11:39 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.2 MB)
17/12/19 14:11:39 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:996
17/12/19 14:11:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[292] at map at utils.scala:55)
17/12/19 14:11:39 INFO TaskSchedulerImpl: Adding task set 148.0 with 1 tasks
17/12/19 14:11:39 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 6935 bytes)
17/12/19 14:11:39 INFO Executor: Running task 0.0 in stage 148.0 (TID 110)
17/12/19 14:11:39 INFO Executor: Finished task 0.0 in stage 148.0 (TID 110). 1135 bytes result sent to driver
17/12/19 14:11:39 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 110) in 0 ms on localhost (executor driver) (1/1)
17/12/19 14:11:39 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
17/12/19 14:11:39 INFO DAGScheduler: ResultStage 148 (collect at utils.scala:58) finished in 0.000 s
17/12/19 14:11:39 INFO DAGScheduler: Job 70 finished: collect at utils.scala:58, took 0.007101 s
17/12/19 14:11:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:11:39 INFO MapPartitionsRDD: Removing RDD 264 from persistence list
17/12/19 14:11:39 INFO BlockManager: Removing RDD 264
17/12/19 14:11:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:11:39 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 14:11:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:11:39 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 14:11:39 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 14:11:39 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 14:11:39 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 14:11:39 INFO FileSourceStrategy: Output Data Schema: struct<V1: double, V2: double, V3: double, V4: double ... 2 more fields>
17/12/19 14:11:39 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 293.7 KB, free 2001.1 MB)
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2001.1 MB)
17/12/19 14:11:39 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.2 MB)
17/12/19 14:11:39 INFO SparkContext: Created broadcast 103 from sql at <unknown>:0
17/12/19 14:11:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 14:11:39 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 14:11:39 INFO DAGScheduler: Registering RDD 296 (sql at <unknown>:0)
17/12/19 14:11:39 INFO DAGScheduler: Registering RDD 301 (sql at <unknown>:0)
17/12/19 14:11:39 INFO DAGScheduler: Got job 71 (sql at <unknown>:0) with 1 output partitions
17/12/19 14:11:39 INFO DAGScheduler: Final stage: ResultStage 151 (sql at <unknown>:0)
17/12/19 14:11:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 150)
17/12/19 14:11:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 150)
17/12/19 14:11:39 INFO DAGScheduler: Submitting ShuffleMapStage 149 (MapPartitionsRDD[296] at sql at <unknown>:0), which has no missing parents
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 12.2 KB, free 2001.1 MB)
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2001.1 MB)
17/12/19 14:11:39 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.2 MB)
17/12/19 14:11:39 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:996
17/12/19 14:11:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 149 (MapPartitionsRDD[296] at sql at <unknown>:0)
17/12/19 14:11:39 INFO TaskSchedulerImpl: Adding task set 149.0 with 1 tasks
17/12/19 14:11:39 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 111, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/19 14:11:39 INFO Executor: Running task 0.0 in stage 149.0 (TID 111)
17/12/19 14:11:39 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_304bf7bcdfe12891d499eae08f83c716f140a5d5062fa41926a166e4fb5f62ef.csv, range: 0-621, partition values: [empty row]
17/12/19 14:11:39 INFO Executor: Finished task 0.0 in stage 149.0 (TID 111). 1553 bytes result sent to driver
17/12/19 14:11:39 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 111) in 15 ms on localhost (executor driver) (1/1)
17/12/19 14:11:39 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
17/12/19 14:11:39 INFO DAGScheduler: ShuffleMapStage 149 (sql at <unknown>:0) finished in 0.015 s
17/12/19 14:11:39 INFO DAGScheduler: looking for newly runnable stages
17/12/19 14:11:39 INFO DAGScheduler: running: Set()
17/12/19 14:11:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 150, ResultStage 151)
17/12/19 14:11:39 INFO DAGScheduler: failed: Set()
17/12/19 14:11:39 INFO DAGScheduler: Submitting ShuffleMapStage 150 (MapPartitionsRDD[301] at sql at <unknown>:0), which has no missing parents
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 12.3 KB, free 2001.1 MB)
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2001.1 MB)
17/12/19 14:11:39 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.2 MB)
17/12/19 14:11:39 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:996
17/12/19 14:11:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 150 (MapPartitionsRDD[301] at sql at <unknown>:0)
17/12/19 14:11:39 INFO TaskSchedulerImpl: Adding task set 150.0 with 2 tasks
17/12/19 14:11:39 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 112, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/19 14:11:39 INFO TaskSetManager: Starting task 1.0 in stage 150.0 (TID 113, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/19 14:11:39 INFO Executor: Running task 0.0 in stage 150.0 (TID 112)
17/12/19 14:11:39 INFO Executor: Running task 1.0 in stage 150.0 (TID 113)
17/12/19 14:11:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 14:11:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:11:39 INFO MemoryStore: Block rdd_298_0 stored as values in memory (estimated size 664.0 B, free 2001.1 MB)
17/12/19 14:11:39 INFO BlockManagerInfo: Added rdd_298_0 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.2 MB)
17/12/19 14:11:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 14:11:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:11:39 INFO MemoryStore: Block rdd_298_1 stored as values in memory (estimated size 664.0 B, free 2001.1 MB)
17/12/19 14:11:39 INFO BlockManagerInfo: Added rdd_298_1 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.2 MB)
17/12/19 14:11:39 INFO Executor: Finished task 0.0 in stage 150.0 (TID 112). 3241 bytes result sent to driver
17/12/19 14:11:39 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 112) in 32 ms on localhost (executor driver) (1/2)
17/12/19 14:11:39 INFO Executor: Finished task 1.0 in stage 150.0 (TID 113). 3162 bytes result sent to driver
17/12/19 14:11:39 INFO TaskSetManager: Finished task 1.0 in stage 150.0 (TID 113) in 32 ms on localhost (executor driver) (2/2)
17/12/19 14:11:39 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool 
17/12/19 14:11:39 INFO DAGScheduler: ShuffleMapStage 150 (sql at <unknown>:0) finished in 0.032 s
17/12/19 14:11:39 INFO DAGScheduler: looking for newly runnable stages
17/12/19 14:11:39 INFO DAGScheduler: running: Set()
17/12/19 14:11:39 INFO DAGScheduler: waiting: Set(ResultStage 151)
17/12/19 14:11:39 INFO DAGScheduler: failed: Set()
17/12/19 14:11:39 INFO DAGScheduler: Submitting ResultStage 151 (MapPartitionsRDD[304] at sql at <unknown>:0), which has no missing parents
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 7.0 KB, free 2001.1 MB)
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.1 MB)
17/12/19 14:11:39 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.2 MB)
17/12/19 14:11:39 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:996
17/12/19 14:11:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 151 (MapPartitionsRDD[304] at sql at <unknown>:0)
17/12/19 14:11:39 INFO TaskSchedulerImpl: Adding task set 151.0 with 1 tasks
17/12/19 14:11:39 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 114, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/19 14:11:39 INFO Executor: Running task 0.0 in stage 151.0 (TID 114)
17/12/19 14:11:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 14:11:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:11:39 INFO Executor: Finished task 0.0 in stage 151.0 (TID 114). 1707 bytes result sent to driver
17/12/19 14:11:39 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 114) in 0 ms on localhost (executor driver) (1/1)
17/12/19 14:11:39 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool 
17/12/19 14:11:39 INFO DAGScheduler: ResultStage 151 (sql at <unknown>:0) finished in 0.000 s
17/12/19 14:11:39 INFO DAGScheduler: Job 71 finished: sql at <unknown>:0, took 0.059379 s
17/12/19 14:11:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:11:39 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 14:11:39 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 14:11:39 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 145 bytes
17/12/19 14:11:39 INFO DAGScheduler: Registering RDD 308 (collect at utils.scala:196)
17/12/19 14:11:39 INFO DAGScheduler: Got job 72 (collect at utils.scala:196) with 1 output partitions
17/12/19 14:11:39 INFO DAGScheduler: Final stage: ResultStage 154 (collect at utils.scala:196)
17/12/19 14:11:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 153)
17/12/19 14:11:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 153)
17/12/19 14:11:39 INFO DAGScheduler: Submitting ShuffleMapStage 153 (MapPartitionsRDD[308] at collect at utils.scala:196), which has no missing parents
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 12.3 KB, free 2001.1 MB)
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2001.1 MB)
17/12/19 14:11:39 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.2 MB)
17/12/19 14:11:39 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:996
17/12/19 14:11:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 153 (MapPartitionsRDD[308] at collect at utils.scala:196)
17/12/19 14:11:39 INFO TaskSchedulerImpl: Adding task set 153.0 with 2 tasks
17/12/19 14:11:39 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 115, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/19 14:11:39 INFO TaskSetManager: Starting task 1.0 in stage 153.0 (TID 116, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/19 14:11:39 INFO Executor: Running task 1.0 in stage 153.0 (TID 116)
17/12/19 14:11:39 INFO Executor: Running task 0.0 in stage 153.0 (TID 115)
17/12/19 14:11:39 INFO BlockManager: Found block rdd_298_0 locally
17/12/19 14:11:39 INFO BlockManager: Found block rdd_298_1 locally
17/12/19 14:11:39 INFO Executor: Finished task 0.0 in stage 153.0 (TID 115). 2037 bytes result sent to driver
17/12/19 14:11:39 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 115) in 11 ms on localhost (executor driver) (1/2)
17/12/19 14:11:39 INFO Executor: Finished task 1.0 in stage 153.0 (TID 116). 2037 bytes result sent to driver
17/12/19 14:11:39 INFO TaskSetManager: Finished task 1.0 in stage 153.0 (TID 116) in 10 ms on localhost (executor driver) (2/2)
17/12/19 14:11:39 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool 
17/12/19 14:11:39 INFO DAGScheduler: ShuffleMapStage 153 (collect at utils.scala:196) finished in 0.011 s
17/12/19 14:11:39 INFO DAGScheduler: looking for newly runnable stages
17/12/19 14:11:39 INFO DAGScheduler: running: Set()
17/12/19 14:11:39 INFO DAGScheduler: waiting: Set(ResultStage 154)
17/12/19 14:11:39 INFO DAGScheduler: failed: Set()
17/12/19 14:11:39 INFO DAGScheduler: Submitting ResultStage 154 (MapPartitionsRDD[311] at collect at utils.scala:196), which has no missing parents
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 7.0 KB, free 2001.0 MB)
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.0 MB)
17/12/19 14:11:39 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.2 MB)
17/12/19 14:11:39 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:996
17/12/19 14:11:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 154 (MapPartitionsRDD[311] at collect at utils.scala:196)
17/12/19 14:11:39 INFO TaskSchedulerImpl: Adding task set 154.0 with 1 tasks
17/12/19 14:11:39 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 117, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/19 14:11:39 INFO Executor: Running task 0.0 in stage 154.0 (TID 117)
17/12/19 14:11:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 14:11:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:11:39 INFO Executor: Finished task 0.0 in stage 154.0 (TID 117). 1707 bytes result sent to driver
17/12/19 14:11:39 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 117) in 0 ms on localhost (executor driver) (1/1)
17/12/19 14:11:39 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
17/12/19 14:11:39 INFO DAGScheduler: ResultStage 154 (collect at utils.scala:196) finished in 0.000 s
17/12/19 14:11:39 INFO DAGScheduler: Job 72 finished: collect at utils.scala:196, took 0.023762 s
17/12/19 14:11:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:11:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz17`
WHERE (0 = 1)
17/12/19 14:11:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:11:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 14:11:39 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 14:11:39 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 145 bytes
17/12/19 14:11:39 INFO DAGScheduler: Got job 73 (take at <unknown>:0) with 1 output partitions
17/12/19 14:11:39 INFO DAGScheduler: Final stage: ResultStage 156 (take at <unknown>:0)
17/12/19 14:11:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 155)
17/12/19 14:11:39 INFO DAGScheduler: Missing parents: List()
17/12/19 14:11:39 INFO DAGScheduler: Submitting ResultStage 156 (WorkerRDD[315] at RDD at rdd.scala:18), which has no missing parents
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 115.5 KB, free 2000.9 MB)
17/12/19 14:11:39 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 46.8 KB, free 2000.9 MB)
17/12/19 14:11:39 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:53618 (size: 46.8 KB, free: 2004.1 MB)
17/12/19 14:11:39 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:996
17/12/19 14:11:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 156 (WorkerRDD[315] at RDD at rdd.scala:18)
17/12/19 14:11:39 INFO TaskSchedulerImpl: Adding task set 156.0 with 1 tasks
17/12/19 14:11:39 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 118, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 14:11:39 INFO Executor: Running task 0.0 in stage 156.0 (TID 118)
17/12/19 14:11:39 INFO BlockManager: Found block rdd_298_0 locally
17/12/19 14:11:40 INFO MemoryStore: Block rdd_315_0 stored as values in memory (estimated size 80.0 B, free 2000.9 MB)
17/12/19 14:11:40 INFO BlockManagerInfo: Added rdd_315_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.1 MB)
17/12/19 14:11:40 INFO Executor: Finished task 0.0 in stage 156.0 (TID 118). 2154 bytes result sent to driver
17/12/19 14:11:40 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 118) in 601 ms on localhost (executor driver) (1/1)
17/12/19 14:11:40 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool 
17/12/19 14:11:40 INFO DAGScheduler: ResultStage 156 (take at <unknown>:0) finished in 0.601 s
17/12/19 14:11:40 INFO DAGScheduler: Job 73 finished: take at <unknown>:0, took 0.599383 s
17/12/19 14:11:40 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 14:11:40 INFO DAGScheduler: Got job 74 (take at <unknown>:0) with 1 output partitions
17/12/19 14:11:40 INFO DAGScheduler: Final stage: ResultStage 158 (take at <unknown>:0)
17/12/19 14:11:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 157)
17/12/19 14:11:40 INFO DAGScheduler: Missing parents: List()
17/12/19 14:11:40 INFO DAGScheduler: Submitting ResultStage 158 (WorkerRDD[315] at RDD at rdd.scala:18), which has no missing parents
17/12/19 14:11:40 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 115.5 KB, free 2000.8 MB)
17/12/19 14:11:40 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 46.8 KB, free 2000.7 MB)
17/12/19 14:11:40 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:53618 (size: 46.8 KB, free: 2004.1 MB)
17/12/19 14:11:40 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:996
17/12/19 14:11:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 158 (WorkerRDD[315] at RDD at rdd.scala:18)
17/12/19 14:11:40 INFO TaskSchedulerImpl: Adding task set 158.0 with 1 tasks
17/12/19 14:11:40 INFO TaskSetManager: Starting task 0.0 in stage 158.0 (TID 119, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 14:11:40 INFO Executor: Running task 0.0 in stage 158.0 (TID 119)
17/12/19 14:11:40 INFO BlockManager: Found block rdd_298_1 locally
17/12/19 14:11:40 INFO MemoryStore: Block rdd_315_1 stored as values in memory (estimated size 80.0 B, free 2000.7 MB)
17/12/19 14:11:40 INFO BlockManagerInfo: Added rdd_315_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.1 MB)
17/12/19 14:11:40 INFO Executor: Finished task 0.0 in stage 158.0 (TID 119). 2241 bytes result sent to driver
17/12/19 14:11:40 INFO TaskSetManager: Finished task 0.0 in stage 158.0 (TID 119) in 671 ms on localhost (executor driver) (1/1)
17/12/19 14:11:40 INFO TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool 
17/12/19 14:11:40 INFO DAGScheduler: ResultStage 158 (take at <unknown>:0) finished in 0.671 s
17/12/19 14:11:40 INFO DAGScheduler: Job 74 finished: take at <unknown>:0, took 0.686172 s
17/12/19 14:11:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:11:40 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e850da11f7
17/12/19 14:11:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:11:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e850da11f7` AS `zzz18`
WHERE (0 = 1)
17/12/19 14:11:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:11:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e850da11f7`
LIMIT 10
17/12/19 14:11:40 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 14:11:40 INFO DAGScheduler: Got job 75 (collect at utils.scala:196) with 1 output partitions
17/12/19 14:11:40 INFO DAGScheduler: Final stage: ResultStage 160 (collect at utils.scala:196)
17/12/19 14:11:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 159)
17/12/19 14:11:40 INFO DAGScheduler: Missing parents: List()
17/12/19 14:11:40 INFO DAGScheduler: Submitting ResultStage 160 (MapPartitionsRDD[319] at collect at utils.scala:196), which has no missing parents
17/12/19 14:11:40 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 118.6 KB, free 2000.6 MB)
17/12/19 14:11:40 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 48.5 KB, free 2000.6 MB)
17/12/19 14:11:40 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:53618 (size: 48.5 KB, free: 2004.0 MB)
17/12/19 14:11:40 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:996
17/12/19 14:11:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 160 (MapPartitionsRDD[319] at collect at utils.scala:196)
17/12/19 14:11:40 INFO TaskSchedulerImpl: Adding task set 160.0 with 1 tasks
17/12/19 14:11:40 INFO TaskSetManager: Starting task 0.0 in stage 160.0 (TID 120, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 14:11:40 INFO Executor: Running task 0.0 in stage 160.0 (TID 120)
17/12/19 14:11:40 INFO BlockManager: Found block rdd_315_0 locally
17/12/19 14:11:40 INFO Executor: Finished task 0.0 in stage 160.0 (TID 120). 1233 bytes result sent to driver
17/12/19 14:11:40 INFO TaskSetManager: Finished task 0.0 in stage 160.0 (TID 120) in 0 ms on localhost (executor driver) (1/1)
17/12/19 14:11:40 INFO TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool 
17/12/19 14:11:40 INFO DAGScheduler: ResultStage 160 (collect at utils.scala:196) finished in 0.015 s
17/12/19 14:11:40 INFO DAGScheduler: Job 75 finished: collect at utils.scala:196, took 0.009106 s
17/12/19 14:11:40 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 14:11:40 INFO DAGScheduler: Got job 76 (collect at utils.scala:196) with 1 output partitions
17/12/19 14:11:40 INFO DAGScheduler: Final stage: ResultStage 162 (collect at utils.scala:196)
17/12/19 14:11:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 161)
17/12/19 14:11:40 INFO DAGScheduler: Missing parents: List()
17/12/19 14:11:40 INFO DAGScheduler: Submitting ResultStage 162 (MapPartitionsRDD[319] at collect at utils.scala:196), which has no missing parents
17/12/19 14:11:40 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 118.6 KB, free 2000.4 MB)
17/12/19 14:11:40 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 48.5 KB, free 2000.4 MB)
17/12/19 14:11:40 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:53618 (size: 48.5 KB, free: 2004.0 MB)
17/12/19 14:11:40 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:996
17/12/19 14:11:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 162 (MapPartitionsRDD[319] at collect at utils.scala:196)
17/12/19 14:11:40 INFO TaskSchedulerImpl: Adding task set 162.0 with 1 tasks
17/12/19 14:11:40 INFO TaskSetManager: Starting task 0.0 in stage 162.0 (TID 121, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 14:11:40 INFO Executor: Running task 0.0 in stage 162.0 (TID 121)
17/12/19 14:11:40 INFO BlockManager: Found block rdd_315_1 locally
17/12/19 14:11:40 INFO Executor: Finished task 0.0 in stage 162.0 (TID 121). 1233 bytes result sent to driver
17/12/19 14:11:40 INFO TaskSetManager: Finished task 0.0 in stage 162.0 (TID 121) in 0 ms on localhost (executor driver) (1/1)
17/12/19 14:11:40 INFO TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool 
17/12/19 14:11:40 INFO DAGScheduler: ResultStage 162 (collect at utils.scala:196) finished in 0.000 s
17/12/19 14:11:40 INFO DAGScheduler: Job 76 finished: collect at utils.scala:196, took 0.008340 s
17/12/19 14:11:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:11:41 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `bwxxmjbbvc`
17/12/19 14:11:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:11:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 14:11:41 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:11:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:11:41 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:11:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:11:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 14:11:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 14:13:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:13:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 14:13:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:13:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:13:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:13:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:13:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 14:13:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 14:13:03 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 14:13:03 INFO DAGScheduler: Got job 77 (collect at utils.scala:58) with 1 output partitions
17/12/19 14:13:03 INFO DAGScheduler: Final stage: ResultStage 163 (collect at utils.scala:58)
17/12/19 14:13:03 INFO DAGScheduler: Parents of final stage: List()
17/12/19 14:13:03 INFO DAGScheduler: Missing parents: List()
17/12/19 14:13:03 INFO DAGScheduler: Submitting ResultStage 163 (MapPartitionsRDD[326] at map at utils.scala:55), which has no missing parents
17/12/19 14:13:03 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 8.7 KB, free 2000.4 MB)
17/12/19 14:13:03 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2000.4 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.0 MB)
17/12/19 14:13:03 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:996
17/12/19 14:13:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 163 (MapPartitionsRDD[326] at map at utils.scala:55)
17/12/19 14:13:03 INFO TaskSchedulerImpl: Adding task set 163.0 with 1 tasks
17/12/19 14:13:03 INFO TaskSetManager: Starting task 0.0 in stage 163.0 (TID 122, localhost, executor driver, partition 0, PROCESS_LOCAL, 7007 bytes)
17/12/19 14:13:03 INFO Executor: Running task 0.0 in stage 163.0 (TID 122)
17/12/19 14:13:03 INFO Executor: Finished task 0.0 in stage 163.0 (TID 122). 1340 bytes result sent to driver
17/12/19 14:13:03 INFO TaskSetManager: Finished task 0.0 in stage 163.0 (TID 122) in 16 ms on localhost (executor driver) (1/1)
17/12/19 14:13:03 INFO TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool 
17/12/19 14:13:03 INFO DAGScheduler: ResultStage 163 (collect at utils.scala:58) finished in 0.016 s
17/12/19 14:13:03 INFO DAGScheduler: Job 77 finished: collect at utils.scala:58, took 0.007053 s
17/12/19 14:13:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:13:03 INFO MapPartitionsRDD: Removing RDD 298 from persistence list
17/12/19 14:13:03 INFO BlockManager: Removing RDD 298
17/12/19 14:13:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:13:03 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 14:13:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:13:03 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 14:13:03 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 14:13:03 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 14:13:03 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 14:13:03 INFO FileSourceStrategy: Output Data Schema: struct<V1: double, V2: double, V3: double, V4: double ... 2 more fields>
17/12/19 14:13:03 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 14:13:03 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 293.7 KB, free 2000.1 MB)
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5259
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5815
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.0 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.0 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:53618 in memory (size: 46.7 KB, free: 2004.0 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:53618 in memory (size: 46.7 KB, free: 2004.1 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:53618 in memory (size: 48.5 KB, free: 2004.1 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:53618 in memory (size: 48.5 KB, free: 2004.2 MB)
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5199
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5200
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.2 MB)
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5249
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5250
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5256
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5257
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5258
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5260
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5261
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5262
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5263
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5264
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5265
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5266
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5267
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5268
17/12/19 14:13:03 INFO ContextCleaner: Cleaned shuffle 25
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.2 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.2 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/19 14:13:03 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2000.8 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.2 MB)
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5437
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.2 MB)
17/12/19 14:13:03 INFO SparkContext: Created broadcast 114 from sql at <unknown>:0
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/19 14:13:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:53618 in memory (size: 46.8 KB, free: 2004.2 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:53618 in memory (size: 46.8 KB, free: 2004.3 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:53618 in memory (size: 48.5 KB, free: 2004.3 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:53618 in memory (size: 48.5 KB, free: 2004.4 MB)
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5764
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5765
17/12/19 14:13:03 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.4 MB)
17/12/19 14:13:03 INFO ContextCleaner: Cleaned accumulator 5814
17/12/19 14:13:03 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 14:13:03 INFO DAGScheduler: Registering RDD 330 (sql at <unknown>:0)
17/12/19 14:13:03 INFO DAGScheduler: Registering RDD 335 (sql at <unknown>:0)
17/12/19 14:13:03 INFO DAGScheduler: Got job 78 (sql at <unknown>:0) with 1 output partitions
17/12/19 14:13:03 INFO DAGScheduler: Final stage: ResultStage 166 (sql at <unknown>:0)
17/12/19 14:13:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 165)
17/12/19 14:13:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 165)
17/12/19 14:13:03 INFO DAGScheduler: Submitting ShuffleMapStage 164 (MapPartitionsRDD[330] at sql at <unknown>:0), which has no missing parents
17/12/19 14:13:03 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 12.2 KB, free 2001.5 MB)
17/12/19 14:13:03 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2001.5 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.4 MB)
17/12/19 14:13:03 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:996
17/12/19 14:13:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 164 (MapPartitionsRDD[330] at sql at <unknown>:0)
17/12/19 14:13:03 INFO TaskSchedulerImpl: Adding task set 164.0 with 1 tasks
17/12/19 14:13:03 INFO TaskSetManager: Starting task 0.0 in stage 164.0 (TID 123, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/19 14:13:03 INFO Executor: Running task 0.0 in stage 164.0 (TID 123)
17/12/19 14:13:03 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_c858d408b102f9be3ff3521f6602c01a64818c99acf02434941afc38a9df3368.csv, range: 0-631, partition values: [empty row]
17/12/19 14:13:03 INFO Executor: Finished task 0.0 in stage 164.0 (TID 123). 1553 bytes result sent to driver
17/12/19 14:13:03 INFO TaskSetManager: Finished task 0.0 in stage 164.0 (TID 123) in 31 ms on localhost (executor driver) (1/1)
17/12/19 14:13:03 INFO TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool 
17/12/19 14:13:03 INFO DAGScheduler: ShuffleMapStage 164 (sql at <unknown>:0) finished in 0.031 s
17/12/19 14:13:03 INFO DAGScheduler: looking for newly runnable stages
17/12/19 14:13:03 INFO DAGScheduler: running: Set()
17/12/19 14:13:03 INFO DAGScheduler: waiting: Set(ShuffleMapStage 165, ResultStage 166)
17/12/19 14:13:03 INFO DAGScheduler: failed: Set()
17/12/19 14:13:03 INFO DAGScheduler: Submitting ShuffleMapStage 165 (MapPartitionsRDD[335] at sql at <unknown>:0), which has no missing parents
17/12/19 14:13:03 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 12.3 KB, free 2001.5 MB)
17/12/19 14:13:03 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2001.5 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.4 MB)
17/12/19 14:13:03 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:996
17/12/19 14:13:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 165 (MapPartitionsRDD[335] at sql at <unknown>:0)
17/12/19 14:13:03 INFO TaskSchedulerImpl: Adding task set 165.0 with 2 tasks
17/12/19 14:13:03 INFO TaskSetManager: Starting task 0.0 in stage 165.0 (TID 124, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/19 14:13:03 INFO TaskSetManager: Starting task 1.0 in stage 165.0 (TID 125, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/19 14:13:03 INFO Executor: Running task 0.0 in stage 165.0 (TID 124)
17/12/19 14:13:03 INFO Executor: Running task 1.0 in stage 165.0 (TID 125)
17/12/19 14:13:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 14:13:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:13:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 14:13:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:13:03 INFO MemoryStore: Block rdd_332_0 stored as values in memory (estimated size 664.0 B, free 2001.5 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Added rdd_332_0 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.4 MB)
17/12/19 14:13:03 INFO MemoryStore: Block rdd_332_1 stored as values in memory (estimated size 664.0 B, free 2001.5 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Added rdd_332_1 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.4 MB)
17/12/19 14:13:03 INFO Executor: Finished task 1.0 in stage 165.0 (TID 125). 2906 bytes result sent to driver
17/12/19 14:13:03 INFO TaskSetManager: Finished task 1.0 in stage 165.0 (TID 125) in 0 ms on localhost (executor driver) (1/2)
17/12/19 14:13:03 INFO Executor: Finished task 0.0 in stage 165.0 (TID 124). 2906 bytes result sent to driver
17/12/19 14:13:03 INFO TaskSetManager: Finished task 0.0 in stage 165.0 (TID 124) in 0 ms on localhost (executor driver) (2/2)
17/12/19 14:13:03 INFO TaskSchedulerImpl: Removed TaskSet 165.0, whose tasks have all completed, from pool 
17/12/19 14:13:03 INFO DAGScheduler: ShuffleMapStage 165 (sql at <unknown>:0) finished in 0.000 s
17/12/19 14:13:03 INFO DAGScheduler: looking for newly runnable stages
17/12/19 14:13:03 INFO DAGScheduler: running: Set()
17/12/19 14:13:03 INFO DAGScheduler: waiting: Set(ResultStage 166)
17/12/19 14:13:03 INFO DAGScheduler: failed: Set()
17/12/19 14:13:03 INFO DAGScheduler: Submitting ResultStage 166 (MapPartitionsRDD[338] at sql at <unknown>:0), which has no missing parents
17/12/19 14:13:03 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 7.0 KB, free 2001.5 MB)
17/12/19 14:13:03 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.4 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 14:13:03 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:996
17/12/19 14:13:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 166 (MapPartitionsRDD[338] at sql at <unknown>:0)
17/12/19 14:13:03 INFO TaskSchedulerImpl: Adding task set 166.0 with 1 tasks
17/12/19 14:13:03 INFO TaskSetManager: Starting task 0.0 in stage 166.0 (TID 126, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/19 14:13:03 INFO Executor: Running task 0.0 in stage 166.0 (TID 126)
17/12/19 14:13:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 14:13:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:13:03 INFO Executor: Finished task 0.0 in stage 166.0 (TID 126). 1786 bytes result sent to driver
17/12/19 14:13:03 INFO TaskSetManager: Finished task 0.0 in stage 166.0 (TID 126) in 2 ms on localhost (executor driver) (1/1)
17/12/19 14:13:03 INFO TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool 
17/12/19 14:13:03 INFO DAGScheduler: ResultStage 166 (sql at <unknown>:0) finished in 0.002 s
17/12/19 14:13:03 INFO DAGScheduler: Job 78 finished: sql at <unknown>:0, took 0.066026 s
17/12/19 14:13:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:13:03 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 14:13:03 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 14:13:03 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 27 is 145 bytes
17/12/19 14:13:03 INFO DAGScheduler: Registering RDD 342 (collect at utils.scala:196)
17/12/19 14:13:03 INFO DAGScheduler: Got job 79 (collect at utils.scala:196) with 1 output partitions
17/12/19 14:13:03 INFO DAGScheduler: Final stage: ResultStage 169 (collect at utils.scala:196)
17/12/19 14:13:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 168)
17/12/19 14:13:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 168)
17/12/19 14:13:03 INFO DAGScheduler: Submitting ShuffleMapStage 168 (MapPartitionsRDD[342] at collect at utils.scala:196), which has no missing parents
17/12/19 14:13:03 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 12.3 KB, free 2001.4 MB)
17/12/19 14:13:03 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2001.4 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.3 MB)
17/12/19 14:13:03 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:996
17/12/19 14:13:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 168 (MapPartitionsRDD[342] at collect at utils.scala:196)
17/12/19 14:13:03 INFO TaskSchedulerImpl: Adding task set 168.0 with 2 tasks
17/12/19 14:13:03 INFO TaskSetManager: Starting task 0.0 in stage 168.0 (TID 127, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/19 14:13:03 INFO TaskSetManager: Starting task 1.0 in stage 168.0 (TID 128, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/19 14:13:03 INFO Executor: Running task 1.0 in stage 168.0 (TID 128)
17/12/19 14:13:03 INFO Executor: Running task 0.0 in stage 168.0 (TID 127)
17/12/19 14:13:03 INFO BlockManager: Found block rdd_332_1 locally
17/12/19 14:13:03 INFO BlockManager: Found block rdd_332_0 locally
17/12/19 14:13:03 INFO Executor: Finished task 1.0 in stage 168.0 (TID 128). 1792 bytes result sent to driver
17/12/19 14:13:03 INFO TaskSetManager: Finished task 1.0 in stage 168.0 (TID 128) in 0 ms on localhost (executor driver) (1/2)
17/12/19 14:13:03 INFO Executor: Finished task 0.0 in stage 168.0 (TID 127). 1792 bytes result sent to driver
17/12/19 14:13:03 INFO TaskSetManager: Finished task 0.0 in stage 168.0 (TID 127) in 0 ms on localhost (executor driver) (2/2)
17/12/19 14:13:03 INFO TaskSchedulerImpl: Removed TaskSet 168.0, whose tasks have all completed, from pool 
17/12/19 14:13:03 INFO DAGScheduler: ShuffleMapStage 168 (collect at utils.scala:196) finished in 0.000 s
17/12/19 14:13:03 INFO DAGScheduler: looking for newly runnable stages
17/12/19 14:13:03 INFO DAGScheduler: running: Set()
17/12/19 14:13:03 INFO DAGScheduler: waiting: Set(ResultStage 169)
17/12/19 14:13:03 INFO DAGScheduler: failed: Set()
17/12/19 14:13:03 INFO DAGScheduler: Submitting ResultStage 169 (MapPartitionsRDD[345] at collect at utils.scala:196), which has no missing parents
17/12/19 14:13:03 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 7.0 KB, free 2001.4 MB)
17/12/19 14:13:03 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.4 MB)
17/12/19 14:13:03 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 14:13:03 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:996
17/12/19 14:13:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 169 (MapPartitionsRDD[345] at collect at utils.scala:196)
17/12/19 14:13:03 INFO TaskSchedulerImpl: Adding task set 169.0 with 1 tasks
17/12/19 14:13:03 INFO TaskSetManager: Starting task 0.0 in stage 169.0 (TID 129, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/19 14:13:03 INFO Executor: Running task 0.0 in stage 169.0 (TID 129)
17/12/19 14:13:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 14:13:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
17/12/19 14:13:03 INFO Executor: Finished task 0.0 in stage 169.0 (TID 129). 1865 bytes result sent to driver
17/12/19 14:13:03 INFO TaskSetManager: Finished task 0.0 in stage 169.0 (TID 129) in 16 ms on localhost (executor driver) (1/1)
17/12/19 14:13:03 INFO DAGScheduler: ResultStage 169 (collect at utils.scala:196) finished in 0.016 s
17/12/19 14:13:03 INFO TaskSchedulerImpl: Removed TaskSet 169.0, whose tasks have all completed, from pool 
17/12/19 14:13:03 INFO DAGScheduler: Job 79 finished: collect at utils.scala:196, took 0.020721 s
17/12/19 14:13:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:13:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz19`
WHERE (0 = 1)
17/12/19 14:13:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:13:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 14:13:04 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 14:13:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 27 is 145 bytes
17/12/19 14:13:04 INFO DAGScheduler: Got job 80 (take at <unknown>:0) with 1 output partitions
17/12/19 14:13:04 INFO DAGScheduler: Final stage: ResultStage 171 (take at <unknown>:0)
17/12/19 14:13:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 170)
17/12/19 14:13:04 INFO DAGScheduler: Missing parents: List()
17/12/19 14:13:04 INFO DAGScheduler: Submitting ResultStage 171 (WorkerRDD[349] at RDD at rdd.scala:18), which has no missing parents
17/12/19 14:13:04 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 115.5 KB, free 2001.3 MB)
17/12/19 14:13:04 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 46.8 KB, free 2001.3 MB)
17/12/19 14:13:04 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:53618 (size: 46.8 KB, free: 2004.3 MB)
17/12/19 14:13:04 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:996
17/12/19 14:13:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 171 (WorkerRDD[349] at RDD at rdd.scala:18)
17/12/19 14:13:04 INFO TaskSchedulerImpl: Adding task set 171.0 with 1 tasks
17/12/19 14:13:04 INFO TaskSetManager: Starting task 0.0 in stage 171.0 (TID 130, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 14:13:04 INFO Executor: Running task 0.0 in stage 171.0 (TID 130)
17/12/19 14:13:04 INFO BlockManager: Found block rdd_332_0 locally
17/12/19 14:13:04 INFO MemoryStore: Block rdd_349_0 stored as values in memory (estimated size 80.0 B, free 2001.3 MB)
17/12/19 14:13:04 INFO BlockManagerInfo: Added rdd_349_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.3 MB)
17/12/19 14:13:04 INFO Executor: Finished task 0.0 in stage 171.0 (TID 130). 2241 bytes result sent to driver
17/12/19 14:13:04 INFO TaskSetManager: Finished task 0.0 in stage 171.0 (TID 130) in 649 ms on localhost (executor driver) (1/1)
17/12/19 14:13:04 INFO TaskSchedulerImpl: Removed TaskSet 171.0, whose tasks have all completed, from pool 
17/12/19 14:13:04 INFO DAGScheduler: ResultStage 171 (take at <unknown>:0) finished in 0.650 s
17/12/19 14:13:04 INFO DAGScheduler: Job 80 finished: take at <unknown>:0, took 0.662186 s
17/12/19 14:13:04 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 14:13:04 INFO DAGScheduler: Got job 81 (take at <unknown>:0) with 1 output partitions
17/12/19 14:13:04 INFO DAGScheduler: Final stage: ResultStage 173 (take at <unknown>:0)
17/12/19 14:13:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 172)
17/12/19 14:13:04 INFO DAGScheduler: Missing parents: List()
17/12/19 14:13:04 INFO DAGScheduler: Submitting ResultStage 173 (WorkerRDD[349] at RDD at rdd.scala:18), which has no missing parents
17/12/19 14:13:04 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 115.5 KB, free 2001.1 MB)
17/12/19 14:13:04 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 46.8 KB, free 2001.1 MB)
17/12/19 14:13:04 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:53618 (size: 46.8 KB, free: 2004.2 MB)
17/12/19 14:13:04 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:996
17/12/19 14:13:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 173 (WorkerRDD[349] at RDD at rdd.scala:18)
17/12/19 14:13:04 INFO TaskSchedulerImpl: Adding task set 173.0 with 1 tasks
17/12/19 14:13:04 INFO TaskSetManager: Starting task 0.0 in stage 173.0 (TID 131, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 14:13:04 INFO Executor: Running task 0.0 in stage 173.0 (TID 131)
17/12/19 14:13:04 INFO BlockManager: Found block rdd_332_1 locally
17/12/19 14:13:05 INFO MemoryStore: Block rdd_349_1 stored as values in memory (estimated size 80.0 B, free 2001.1 MB)
17/12/19 14:13:05 INFO BlockManagerInfo: Added rdd_349_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.2 MB)
17/12/19 14:13:05 INFO Executor: Finished task 0.0 in stage 173.0 (TID 131). 2154 bytes result sent to driver
17/12/19 14:13:05 INFO TaskSetManager: Finished task 0.0 in stage 173.0 (TID 131) in 634 ms on localhost (executor driver) (1/1)
17/12/19 14:13:05 INFO TaskSchedulerImpl: Removed TaskSet 173.0, whose tasks have all completed, from pool 
17/12/19 14:13:05 INFO DAGScheduler: ResultStage 173 (take at <unknown>:0) finished in 0.634 s
17/12/19 14:13:05 INFO DAGScheduler: Job 81 finished: take at <unknown>:0, took 0.640504 s
17/12/19 14:13:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:13:05 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e826547b19
17/12/19 14:13:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:13:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e826547b19` AS `zzz20`
WHERE (0 = 1)
17/12/19 14:13:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:13:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e826547b19`
LIMIT 10
17/12/19 14:13:05 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 14:13:05 INFO DAGScheduler: Got job 82 (collect at utils.scala:196) with 1 output partitions
17/12/19 14:13:05 INFO DAGScheduler: Final stage: ResultStage 175 (collect at utils.scala:196)
17/12/19 14:13:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 174)
17/12/19 14:13:05 INFO DAGScheduler: Missing parents: List()
17/12/19 14:13:05 INFO DAGScheduler: Submitting ResultStage 175 (MapPartitionsRDD[353] at collect at utils.scala:196), which has no missing parents
17/12/19 14:13:05 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 118.6 KB, free 2001.0 MB)
17/12/19 14:13:05 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 48.6 KB, free 2000.9 MB)
17/12/19 14:13:05 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:53618 (size: 48.6 KB, free: 2004.2 MB)
17/12/19 14:13:05 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:996
17/12/19 14:13:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 175 (MapPartitionsRDD[353] at collect at utils.scala:196)
17/12/19 14:13:05 INFO TaskSchedulerImpl: Adding task set 175.0 with 1 tasks
17/12/19 14:13:05 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 132, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 14:13:05 INFO Executor: Running task 0.0 in stage 175.0 (TID 132)
17/12/19 14:13:05 INFO BlockManager: Found block rdd_349_0 locally
17/12/19 14:13:05 INFO Executor: Finished task 0.0 in stage 175.0 (TID 132). 1233 bytes result sent to driver
17/12/19 14:13:05 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 132) in 0 ms on localhost (executor driver) (1/1)
17/12/19 14:13:05 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool 
17/12/19 14:13:05 INFO DAGScheduler: ResultStage 175 (collect at utils.scala:196) finished in 0.000 s
17/12/19 14:13:05 INFO DAGScheduler: Job 82 finished: collect at utils.scala:196, took 0.009553 s
17/12/19 14:13:05 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 14:13:05 INFO DAGScheduler: Got job 83 (collect at utils.scala:196) with 1 output partitions
17/12/19 14:13:05 INFO DAGScheduler: Final stage: ResultStage 177 (collect at utils.scala:196)
17/12/19 14:13:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 176)
17/12/19 14:13:05 INFO DAGScheduler: Missing parents: List()
17/12/19 14:13:05 INFO DAGScheduler: Submitting ResultStage 177 (MapPartitionsRDD[353] at collect at utils.scala:196), which has no missing parents
17/12/19 14:13:05 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 118.6 KB, free 2000.8 MB)
17/12/19 14:13:05 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 48.6 KB, free 2000.8 MB)
17/12/19 14:13:05 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:53618 (size: 48.6 KB, free: 2004.2 MB)
17/12/19 14:13:05 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:996
17/12/19 14:13:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 177 (MapPartitionsRDD[353] at collect at utils.scala:196)
17/12/19 14:13:05 INFO TaskSchedulerImpl: Adding task set 177.0 with 1 tasks
17/12/19 14:13:05 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 133, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 14:13:05 INFO Executor: Running task 0.0 in stage 177.0 (TID 133)
17/12/19 14:13:05 INFO BlockManager: Found block rdd_349_1 locally
17/12/19 14:13:05 INFO Executor: Finished task 0.0 in stage 177.0 (TID 133). 1233 bytes result sent to driver
17/12/19 14:13:05 INFO TaskSetManager: Finished task 0.0 in stage 177.0 (TID 133) in 0 ms on localhost (executor driver) (1/1)
17/12/19 14:13:05 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool 
17/12/19 14:13:05 INFO DAGScheduler: ResultStage 177 (collect at utils.scala:196) finished in 0.016 s
17/12/19 14:13:05 INFO DAGScheduler: Job 83 finished: collect at utils.scala:196, took 0.009774 s
17/12/19 14:13:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:13:05 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `ujnmhchkyv`
17/12/19 14:13:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:13:05 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 14:13:05 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:13:05 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:13:05 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:13:05 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:13:05 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 14:13:05 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 14:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:15:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 14:15:36 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:15:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:15:36 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:15:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:15:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 14:15:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 14:15:36 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 14:15:36 INFO DAGScheduler: Got job 84 (collect at utils.scala:58) with 1 output partitions
17/12/19 14:15:36 INFO DAGScheduler: Final stage: ResultStage 178 (collect at utils.scala:58)
17/12/19 14:15:36 INFO DAGScheduler: Parents of final stage: List()
17/12/19 14:15:36 INFO DAGScheduler: Missing parents: List()
17/12/19 14:15:36 INFO DAGScheduler: Submitting ResultStage 178 (MapPartitionsRDD[360] at map at utils.scala:55), which has no missing parents
17/12/19 14:15:36 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 8.7 KB, free 2000.8 MB)
17/12/19 14:15:36 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2000.8 MB)
17/12/19 14:15:36 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.1 MB)
17/12/19 14:15:36 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:996
17/12/19 14:15:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 178 (MapPartitionsRDD[360] at map at utils.scala:55)
17/12/19 14:15:36 INFO TaskSchedulerImpl: Adding task set 178.0 with 1 tasks
17/12/19 14:15:36 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 134, localhost, executor driver, partition 0, PROCESS_LOCAL, 7079 bytes)
17/12/19 14:15:36 INFO Executor: Running task 0.0 in stage 178.0 (TID 134)
17/12/19 14:15:36 INFO Executor: Finished task 0.0 in stage 178.0 (TID 134). 1349 bytes result sent to driver
17/12/19 14:15:36 INFO TaskSetManager: Finished task 0.0 in stage 178.0 (TID 134) in 16 ms on localhost (executor driver) (1/1)
17/12/19 14:15:36 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool 
17/12/19 14:15:36 INFO DAGScheduler: ResultStage 178 (collect at utils.scala:58) finished in 0.016 s
17/12/19 14:15:36 INFO DAGScheduler: Job 84 finished: collect at utils.scala:58, took 0.008264 s
17/12/19 14:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:15:36 INFO MapPartitionsRDD: Removing RDD 332 from persistence list
17/12/19 14:15:36 INFO BlockManager: Removing RDD 332
17/12/19 14:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:15:36 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 14:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:15:36 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 14:15:36 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 14:15:36 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 14:15:36 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 14:15:36 INFO FileSourceStrategy: Output Data Schema: struct<V1: double, V2: double, V3: double, V4: double ... 2 more fields>
17/12/19 14:15:36 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 14:15:36 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 293.7 KB, free 2000.5 MB)
17/12/19 14:15:36 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2000.5 MB)
17/12/19 14:15:36 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.1 MB)
17/12/19 14:15:36 INFO SparkContext: Created broadcast 125 from sql at <unknown>:0
17/12/19 14:15:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 14:15:36 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 14:15:36 INFO DAGScheduler: Registering RDD 364 (sql at <unknown>:0)
17/12/19 14:15:36 INFO DAGScheduler: Registering RDD 369 (sql at <unknown>:0)
17/12/19 14:15:36 INFO DAGScheduler: Got job 85 (sql at <unknown>:0) with 1 output partitions
17/12/19 14:15:36 INFO DAGScheduler: Final stage: ResultStage 181 (sql at <unknown>:0)
17/12/19 14:15:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 180)
17/12/19 14:15:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 180)
17/12/19 14:15:36 INFO DAGScheduler: Submitting ShuffleMapStage 179 (MapPartitionsRDD[364] at sql at <unknown>:0), which has no missing parents
17/12/19 14:15:36 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 12.2 KB, free 2000.4 MB)
17/12/19 14:15:36 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2000.4 MB)
17/12/19 14:15:36 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.1 MB)
17/12/19 14:15:36 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:996
17/12/19 14:15:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 179 (MapPartitionsRDD[364] at sql at <unknown>:0)
17/12/19 14:15:36 INFO TaskSchedulerImpl: Adding task set 179.0 with 1 tasks
17/12/19 14:15:36 INFO TaskSetManager: Starting task 0.0 in stage 179.0 (TID 135, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/19 14:15:36 INFO Executor: Running task 0.0 in stage 179.0 (TID 135)
17/12/19 14:15:36 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_73ab1fa81668f5904f854d82b594b390e7bfc7a0871ad185495bc1eb1ade5a39.csv, range: 0-627, partition values: [empty row]
17/12/19 14:15:36 INFO Executor: Finished task 0.0 in stage 179.0 (TID 135). 1632 bytes result sent to driver
17/12/19 14:15:36 INFO TaskSetManager: Finished task 0.0 in stage 179.0 (TID 135) in 31 ms on localhost (executor driver) (1/1)
17/12/19 14:15:36 INFO TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool 
17/12/19 14:15:36 INFO DAGScheduler: ShuffleMapStage 179 (sql at <unknown>:0) finished in 0.031 s
17/12/19 14:15:36 INFO DAGScheduler: looking for newly runnable stages
17/12/19 14:15:36 INFO DAGScheduler: running: Set()
17/12/19 14:15:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 180, ResultStage 181)
17/12/19 14:15:36 INFO DAGScheduler: failed: Set()
17/12/19 14:15:36 INFO DAGScheduler: Submitting ShuffleMapStage 180 (MapPartitionsRDD[369] at sql at <unknown>:0), which has no missing parents
17/12/19 14:15:36 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 12.3 KB, free 2000.4 MB)
17/12/19 14:15:36 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2000.4 MB)
17/12/19 14:15:36 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.1 MB)
17/12/19 14:15:36 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:996
17/12/19 14:15:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 180 (MapPartitionsRDD[369] at sql at <unknown>:0)
17/12/19 14:15:36 INFO TaskSchedulerImpl: Adding task set 180.0 with 2 tasks
17/12/19 14:15:36 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 136, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/19 14:15:36 INFO TaskSetManager: Starting task 1.0 in stage 180.0 (TID 137, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/19 14:15:36 INFO Executor: Running task 0.0 in stage 180.0 (TID 136)
17/12/19 14:15:36 INFO Executor: Running task 1.0 in stage 180.0 (TID 137)
17/12/19 14:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 14:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 14:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:15:36 INFO MemoryStore: Block rdd_366_1 stored as values in memory (estimated size 664.0 B, free 2000.4 MB)
17/12/19 14:15:36 INFO MemoryStore: Block rdd_366_0 stored as values in memory (estimated size 664.0 B, free 2000.4 MB)
17/12/19 14:15:36 INFO BlockManagerInfo: Added rdd_366_1 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.1 MB)
17/12/19 14:15:36 INFO BlockManagerInfo: Added rdd_366_0 in memory on 127.0.0.1:53618 (size: 664.0 B, free: 2004.1 MB)
17/12/19 14:15:36 INFO Executor: Finished task 0.0 in stage 180.0 (TID 136). 2906 bytes result sent to driver
17/12/19 14:15:36 INFO TaskSetManager: Finished task 0.0 in stage 180.0 (TID 136) in 0 ms on localhost (executor driver) (1/2)
17/12/19 14:15:37 INFO Executor: Finished task 1.0 in stage 180.0 (TID 137). 3064 bytes result sent to driver
17/12/19 14:15:37 INFO TaskSetManager: Finished task 1.0 in stage 180.0 (TID 137) in 15 ms on localhost (executor driver) (2/2)
17/12/19 14:15:37 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool 
17/12/19 14:15:37 INFO DAGScheduler: ShuffleMapStage 180 (sql at <unknown>:0) finished in 0.015 s
17/12/19 14:15:37 INFO DAGScheduler: looking for newly runnable stages
17/12/19 14:15:37 INFO DAGScheduler: running: Set()
17/12/19 14:15:37 INFO DAGScheduler: waiting: Set(ResultStage 181)
17/12/19 14:15:37 INFO DAGScheduler: failed: Set()
17/12/19 14:15:37 INFO DAGScheduler: Submitting ResultStage 181 (MapPartitionsRDD[372] at sql at <unknown>:0), which has no missing parents
17/12/19 14:15:37 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 7.0 KB, free 2000.4 MB)
17/12/19 14:15:37 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2000.4 MB)
17/12/19 14:15:37 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.1 MB)
17/12/19 14:15:37 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:996
17/12/19 14:15:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 181 (MapPartitionsRDD[372] at sql at <unknown>:0)
17/12/19 14:15:37 INFO TaskSchedulerImpl: Adding task set 181.0 with 1 tasks
17/12/19 14:15:37 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 138, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/19 14:15:37 INFO Executor: Running task 0.0 in stage 181.0 (TID 138)
17/12/19 14:15:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 14:15:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:15:37 INFO Executor: Finished task 0.0 in stage 181.0 (TID 138). 1707 bytes result sent to driver
17/12/19 14:15:37 INFO TaskSetManager: Finished task 0.0 in stage 181.0 (TID 138) in 0 ms on localhost (executor driver) (1/1)
17/12/19 14:15:37 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool 
17/12/19 14:15:37 INFO DAGScheduler: ResultStage 181 (sql at <unknown>:0) finished in 0.000 s
17/12/19 14:15:37 INFO DAGScheduler: Job 85 finished: sql at <unknown>:0, took 0.045724 s
17/12/19 14:15:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:15:37 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 14:15:37 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 14:15:37 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 30 is 145 bytes
17/12/19 14:15:37 INFO DAGScheduler: Registering RDD 376 (collect at utils.scala:196)
17/12/19 14:15:37 INFO DAGScheduler: Got job 86 (collect at utils.scala:196) with 1 output partitions
17/12/19 14:15:37 INFO DAGScheduler: Final stage: ResultStage 184 (collect at utils.scala:196)
17/12/19 14:15:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 183)
17/12/19 14:15:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 183)
17/12/19 14:15:37 INFO DAGScheduler: Submitting ShuffleMapStage 183 (MapPartitionsRDD[376] at collect at utils.scala:196), which has no missing parents
17/12/19 14:15:37 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 12.3 KB, free 2000.4 MB)
17/12/19 14:15:37 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2000.4 MB)
17/12/19 14:15:37 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:53618 (size: 6.1 KB, free: 2004.1 MB)
17/12/19 14:15:37 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:996
17/12/19 14:15:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 183 (MapPartitionsRDD[376] at collect at utils.scala:196)
17/12/19 14:15:37 INFO TaskSchedulerImpl: Adding task set 183.0 with 2 tasks
17/12/19 14:15:37 INFO TaskSetManager: Starting task 0.0 in stage 183.0 (TID 139, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/19 14:15:37 INFO TaskSetManager: Starting task 1.0 in stage 183.0 (TID 140, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/19 14:15:37 INFO Executor: Running task 0.0 in stage 183.0 (TID 139)
17/12/19 14:15:37 INFO Executor: Running task 1.0 in stage 183.0 (TID 140)
17/12/19 14:15:37 INFO BlockManager: Found block rdd_366_0 locally
17/12/19 14:15:37 INFO BlockManager: Found block rdd_366_1 locally
17/12/19 14:15:37 INFO Executor: Finished task 0.0 in stage 183.0 (TID 139). 1871 bytes result sent to driver
17/12/19 14:15:37 INFO TaskSetManager: Finished task 0.0 in stage 183.0 (TID 139) in 15 ms on localhost (executor driver) (1/2)
17/12/19 14:15:37 INFO Executor: Finished task 1.0 in stage 183.0 (TID 140). 1950 bytes result sent to driver
17/12/19 14:15:37 INFO TaskSetManager: Finished task 1.0 in stage 183.0 (TID 140) in 15 ms on localhost (executor driver) (2/2)
17/12/19 14:15:37 INFO TaskSchedulerImpl: Removed TaskSet 183.0, whose tasks have all completed, from pool 
17/12/19 14:15:37 INFO DAGScheduler: ShuffleMapStage 183 (collect at utils.scala:196) finished in 0.015 s
17/12/19 14:15:37 INFO DAGScheduler: looking for newly runnable stages
17/12/19 14:15:37 INFO DAGScheduler: running: Set()
17/12/19 14:15:37 INFO DAGScheduler: waiting: Set(ResultStage 184)
17/12/19 14:15:37 INFO DAGScheduler: failed: Set()
17/12/19 14:15:37 INFO DAGScheduler: Submitting ResultStage 184 (MapPartitionsRDD[379] at collect at utils.scala:196), which has no missing parents
17/12/19 14:15:37 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 7.0 KB, free 2000.4 MB)
17/12/19 14:15:37 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2000.4 MB)
17/12/19 14:15:37 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.1 MB)
17/12/19 14:15:37 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:996
17/12/19 14:15:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 184 (MapPartitionsRDD[379] at collect at utils.scala:196)
17/12/19 14:15:37 INFO TaskSchedulerImpl: Adding task set 184.0 with 1 tasks
17/12/19 14:15:37 INFO TaskSetManager: Starting task 0.0 in stage 184.0 (TID 141, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/19 14:15:37 INFO Executor: Running task 0.0 in stage 184.0 (TID 141)
17/12/19 14:15:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 14:15:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 14:15:37 INFO Executor: Finished task 0.0 in stage 184.0 (TID 141). 1707 bytes result sent to driver
17/12/19 14:15:37 INFO TaskSetManager: Finished task 0.0 in stage 184.0 (TID 141) in 0 ms on localhost (executor driver) (1/1)
17/12/19 14:15:37 INFO TaskSchedulerImpl: Removed TaskSet 184.0, whose tasks have all completed, from pool 
17/12/19 14:15:37 INFO DAGScheduler: ResultStage 184 (collect at utils.scala:196) finished in 0.000 s
17/12/19 14:15:37 INFO DAGScheduler: Job 86 finished: collect at utils.scala:196, took 0.026174 s
17/12/19 14:15:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:15:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz21`
WHERE (0 = 1)
17/12/19 14:15:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:15:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 14:15:37 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 14:15:37 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 30 is 145 bytes
17/12/19 14:15:37 INFO DAGScheduler: Got job 87 (take at <unknown>:0) with 1 output partitions
17/12/19 14:15:37 INFO DAGScheduler: Final stage: ResultStage 186 (take at <unknown>:0)
17/12/19 14:15:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 185)
17/12/19 14:15:37 INFO DAGScheduler: Missing parents: List()
17/12/19 14:15:37 INFO DAGScheduler: Submitting ResultStage 186 (WorkerRDD[383] at RDD at rdd.scala:18), which has no missing parents
17/12/19 14:15:37 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 116.5 KB, free 2000.3 MB)
17/12/19 14:15:37 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 47.1 KB, free 2000.2 MB)
17/12/19 14:15:37 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:53618 (size: 47.1 KB, free: 2004.1 MB)
17/12/19 14:15:37 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:996
17/12/19 14:15:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 186 (WorkerRDD[383] at RDD at rdd.scala:18)
17/12/19 14:15:37 INFO TaskSchedulerImpl: Adding task set 186.0 with 1 tasks
17/12/19 14:15:37 INFO TaskSetManager: Starting task 0.0 in stage 186.0 (TID 142, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 14:15:37 INFO Executor: Running task 0.0 in stage 186.0 (TID 142)
17/12/19 14:15:37 INFO BlockManager: Found block rdd_366_0 locally
17/12/19 14:15:37 INFO MemoryStore: Block rdd_383_0 stored as values in memory (estimated size 80.0 B, free 2000.2 MB)
17/12/19 14:15:37 INFO BlockManagerInfo: Added rdd_383_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.1 MB)
17/12/19 14:15:37 INFO Executor: Finished task 0.0 in stage 186.0 (TID 142). 2241 bytes result sent to driver
17/12/19 14:15:37 INFO TaskSetManager: Finished task 0.0 in stage 186.0 (TID 142) in 649 ms on localhost (executor driver) (1/1)
17/12/19 14:15:37 INFO TaskSchedulerImpl: Removed TaskSet 186.0, whose tasks have all completed, from pool 
17/12/19 14:15:37 INFO DAGScheduler: ResultStage 186 (take at <unknown>:0) finished in 0.649 s
17/12/19 14:15:37 INFO DAGScheduler: Job 87 finished: take at <unknown>:0, took 0.661552 s
17/12/19 14:15:37 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 14:15:37 INFO DAGScheduler: Got job 88 (take at <unknown>:0) with 1 output partitions
17/12/19 14:15:37 INFO DAGScheduler: Final stage: ResultStage 188 (take at <unknown>:0)
17/12/19 14:15:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 187)
17/12/19 14:15:37 INFO DAGScheduler: Missing parents: List()
17/12/19 14:15:37 INFO DAGScheduler: Submitting ResultStage 188 (WorkerRDD[383] at RDD at rdd.scala:18), which has no missing parents
17/12/19 14:15:37 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 116.5 KB, free 2000.1 MB)
17/12/19 14:15:37 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 47.1 KB, free 2000.1 MB)
17/12/19 14:15:37 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:53618 (size: 47.1 KB, free: 2004.0 MB)
17/12/19 14:15:37 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:996
17/12/19 14:15:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 188 (WorkerRDD[383] at RDD at rdd.scala:18)
17/12/19 14:15:37 INFO TaskSchedulerImpl: Adding task set 188.0 with 1 tasks
17/12/19 14:15:37 INFO TaskSetManager: Starting task 0.0 in stage 188.0 (TID 143, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 14:15:37 INFO Executor: Running task 0.0 in stage 188.0 (TID 143)
17/12/19 14:15:37 INFO BlockManager: Found block rdd_366_1 locally
17/12/19 14:15:38 INFO MemoryStore: Block rdd_383_1 stored as values in memory (estimated size 80.0 B, free 2000.1 MB)
17/12/19 14:15:38 INFO BlockManagerInfo: Added rdd_383_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.0 MB)
17/12/19 14:15:38 INFO Executor: Finished task 0.0 in stage 188.0 (TID 143). 2154 bytes result sent to driver
17/12/19 14:15:38 INFO TaskSetManager: Finished task 0.0 in stage 188.0 (TID 143) in 645 ms on localhost (executor driver) (1/1)
17/12/19 14:15:38 INFO TaskSchedulerImpl: Removed TaskSet 188.0, whose tasks have all completed, from pool 
17/12/19 14:15:38 INFO DAGScheduler: ResultStage 188 (take at <unknown>:0) finished in 0.645 s
17/12/19 14:15:38 INFO DAGScheduler: Job 88 finished: take at <unknown>:0, took 0.658823 s
17/12/19 14:15:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:15:38 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e83fbe4aac
17/12/19 14:15:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:15:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e83fbe4aac` AS `zzz22`
WHERE (0 = 1)
17/12/19 14:15:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:15:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e83fbe4aac`
LIMIT 10
17/12/19 14:15:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 14:15:38 INFO DAGScheduler: Got job 89 (collect at utils.scala:196) with 1 output partitions
17/12/19 14:15:38 INFO DAGScheduler: Final stage: ResultStage 190 (collect at utils.scala:196)
17/12/19 14:15:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 189)
17/12/19 14:15:38 INFO DAGScheduler: Missing parents: List()
17/12/19 14:15:38 INFO DAGScheduler: Submitting ResultStage 190 (MapPartitionsRDD[387] at collect at utils.scala:196), which has no missing parents
17/12/19 14:15:38 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 119.5 KB, free 1999.9 MB)
17/12/19 14:15:38 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 48.9 KB, free 1999.9 MB)
17/12/19 14:15:38 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:53618 (size: 48.9 KB, free: 2004.0 MB)
17/12/19 14:15:38 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:996
17/12/19 14:15:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 190 (MapPartitionsRDD[387] at collect at utils.scala:196)
17/12/19 14:15:38 INFO TaskSchedulerImpl: Adding task set 190.0 with 1 tasks
17/12/19 14:15:38 INFO TaskSetManager: Starting task 0.0 in stage 190.0 (TID 144, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 14:15:38 INFO Executor: Running task 0.0 in stage 190.0 (TID 144)
17/12/19 14:15:38 INFO BlockManager: Found block rdd_383_0 locally
17/12/19 14:15:38 INFO Executor: Finished task 0.0 in stage 190.0 (TID 144). 1233 bytes result sent to driver
17/12/19 14:15:38 INFO TaskSetManager: Finished task 0.0 in stage 190.0 (TID 144) in 0 ms on localhost (executor driver) (1/1)
17/12/19 14:15:38 INFO TaskSchedulerImpl: Removed TaskSet 190.0, whose tasks have all completed, from pool 
17/12/19 14:15:38 INFO DAGScheduler: ResultStage 190 (collect at utils.scala:196) finished in 0.000 s
17/12/19 14:15:38 INFO DAGScheduler: Job 89 finished: collect at utils.scala:196, took 0.009154 s
17/12/19 14:15:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 14:15:38 INFO DAGScheduler: Got job 90 (collect at utils.scala:196) with 1 output partitions
17/12/19 14:15:38 INFO DAGScheduler: Final stage: ResultStage 192 (collect at utils.scala:196)
17/12/19 14:15:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 191)
17/12/19 14:15:38 INFO DAGScheduler: Missing parents: List()
17/12/19 14:15:38 INFO DAGScheduler: Submitting ResultStage 192 (MapPartitionsRDD[387] at collect at utils.scala:196), which has no missing parents
17/12/19 14:15:38 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 119.5 KB, free 1999.8 MB)
17/12/19 14:15:38 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 48.9 KB, free 1999.7 MB)
17/12/19 14:15:38 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:53618 (size: 48.9 KB, free: 2003.9 MB)
17/12/19 14:15:38 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:996
17/12/19 14:15:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 192 (MapPartitionsRDD[387] at collect at utils.scala:196)
17/12/19 14:15:38 INFO TaskSchedulerImpl: Adding task set 192.0 with 1 tasks
17/12/19 14:15:38 INFO TaskSetManager: Starting task 0.0 in stage 192.0 (TID 145, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 14:15:38 INFO Executor: Running task 0.0 in stage 192.0 (TID 145)
17/12/19 14:15:38 INFO BlockManager: Found block rdd_383_1 locally
17/12/19 14:15:38 INFO Executor: Finished task 0.0 in stage 192.0 (TID 145). 1233 bytes result sent to driver
17/12/19 14:15:38 INFO TaskSetManager: Finished task 0.0 in stage 192.0 (TID 145) in 0 ms on localhost (executor driver) (1/1)
17/12/19 14:15:38 INFO TaskSchedulerImpl: Removed TaskSet 192.0, whose tasks have all completed, from pool 
17/12/19 14:15:38 INFO DAGScheduler: ResultStage 192 (collect at utils.scala:196) finished in 0.000 s
17/12/19 14:15:38 INFO DAGScheduler: Job 90 finished: collect at utils.scala:196, took 0.007371 s
17/12/19 14:15:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:15:38 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `adwdekbfji`
LIMIT 10
17/12/19 14:15:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 14:15:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 14:15:38 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:15:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:15:38 INFO HiveMetaStore: 0: get_database: default
17/12/19 14:15:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 14:15:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 14:15:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 127.0.0.1:53618 in memory (size: 48.9 KB, free: 2004.0 MB)
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 127.0.0.1:53618 in memory (size: 48.9 KB, free: 2004.0 MB)
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 5821
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 5822
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 5823
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 5824
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 5825
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 5826
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 5827
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 5828
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 5829
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 5830
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 5831
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 5832
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 5833
17/12/19 14:18:51 INFO ContextCleaner: Cleaned shuffle 28
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.0 MB)
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.0 MB)
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.0 MB)
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6002
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.0 MB)
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.0 MB)
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:53618 in memory (size: 46.8 KB, free: 2004.1 MB)
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:53618 in memory (size: 46.8 KB, free: 2004.1 MB)
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:53618 in memory (size: 48.6 KB, free: 2004.2 MB)
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:53618 in memory (size: 48.6 KB, free: 2004.2 MB)
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6329
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6330
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.2 MB)
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6379
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6380
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6386
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6387
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6388
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6389
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6390
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6391
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6392
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6393
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6394
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6395
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6396
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6397
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6398
17/12/19 14:18:51 INFO ContextCleaner: Cleaned shuffle 31
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.2 MB)
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.2 MB)
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/19 14:18:51 INFO ContextCleaner: Cleaned accumulator 6567
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:53618 in memory (size: 6.1 KB, free: 2004.2 MB)
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 127.0.0.1:53618 in memory (size: 47.1 KB, free: 2004.3 MB)
17/12/19 14:18:51 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 127.0.0.1:53618 in memory (size: 47.1 KB, free: 2004.3 MB)
17/12/19 15:04:42 WARN NettyRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@3d046bc1,BlockManagerId(driver, 127.0.0.1, 53618, None))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 14 more
17/12/19 15:04:55 WARN NettyRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@3d046bc1,BlockManagerId(driver, 127.0.0.1, 53618, None))] in 2 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 14 more
17/12/19 15:05:02 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
17/12/19 15:05:02 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
17/12/19 15:15:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:47 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:15:47 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:15:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:15:47 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:15:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:15:47 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:15:47 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:15:47 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 15:15:47 INFO DAGScheduler: Got job 91 (collect at utils.scala:58) with 1 output partitions
17/12/19 15:15:47 INFO DAGScheduler: Final stage: ResultStage 193 (collect at utils.scala:58)
17/12/19 15:15:47 INFO DAGScheduler: Parents of final stage: List()
17/12/19 15:15:47 INFO DAGScheduler: Missing parents: List()
17/12/19 15:15:47 INFO DAGScheduler: Submitting ResultStage 193 (MapPartitionsRDD[394] at map at utils.scala:55), which has no missing parents
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 8.7 KB, free 2001.2 MB)
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2001.2 MB)
17/12/19 15:15:47 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.3 MB)
17/12/19 15:15:47 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 193 (MapPartitionsRDD[394] at map at utils.scala:55)
17/12/19 15:15:47 INFO TaskSchedulerImpl: Adding task set 193.0 with 1 tasks
17/12/19 15:15:47 INFO TaskSetManager: Starting task 0.0 in stage 193.0 (TID 146, localhost, executor driver, partition 0, PROCESS_LOCAL, 7151 bytes)
17/12/19 15:15:47 INFO Executor: Running task 0.0 in stage 193.0 (TID 146)
17/12/19 15:15:47 INFO Executor: Finished task 0.0 in stage 193.0 (TID 146). 1219 bytes result sent to driver
17/12/19 15:15:47 INFO TaskSetManager: Finished task 0.0 in stage 193.0 (TID 146) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:15:47 INFO TaskSchedulerImpl: Removed TaskSet 193.0, whose tasks have all completed, from pool 
17/12/19 15:15:47 INFO DAGScheduler: ResultStage 193 (collect at utils.scala:58) finished in 0.000 s
17/12/19 15:15:47 INFO DAGScheduler: Job 91 finished: collect at utils.scala:58, took 0.010877 s
17/12/19 15:15:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:47 INFO MapPartitionsRDD: Removing RDD 366 from persistence list
17/12/19 15:15:47 INFO BlockManager: Removing RDD 366
17/12/19 15:15:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:47 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:15:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:47 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 15:15:47 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 15:15:47 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 15:15:47 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 15:15:47 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 15:15:47 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 293.7 KB, free 2000.9 MB)
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2000.9 MB)
17/12/19 15:15:47 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.3 MB)
17/12/19 15:15:47 INFO SparkContext: Created broadcast 136 from sql at <unknown>:0
17/12/19 15:15:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 15:15:47 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 15:15:47 INFO DAGScheduler: Registering RDD 398 (sql at <unknown>:0)
17/12/19 15:15:47 INFO DAGScheduler: Registering RDD 403 (sql at <unknown>:0)
17/12/19 15:15:47 INFO DAGScheduler: Got job 92 (sql at <unknown>:0) with 1 output partitions
17/12/19 15:15:47 INFO DAGScheduler: Final stage: ResultStage 196 (sql at <unknown>:0)
17/12/19 15:15:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 195)
17/12/19 15:15:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 195)
17/12/19 15:15:47 INFO DAGScheduler: Submitting ShuffleMapStage 194 (MapPartitionsRDD[398] at sql at <unknown>:0), which has no missing parents
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 12.1 KB, free 2000.9 MB)
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2000.8 MB)
17/12/19 15:15:47 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.3 MB)
17/12/19 15:15:47 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 194 (MapPartitionsRDD[398] at sql at <unknown>:0)
17/12/19 15:15:47 INFO TaskSchedulerImpl: Adding task set 194.0 with 1 tasks
17/12/19 15:15:47 INFO TaskSetManager: Starting task 0.0 in stage 194.0 (TID 147, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/19 15:15:47 INFO Executor: Running task 0.0 in stage 194.0 (TID 147)
17/12/19 15:15:47 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_4e126730517688e370c5c3337e6250db568290b574c30aedca9958ce750d1d1f.csv, range: 0-462, partition values: [empty row]
17/12/19 15:15:47 INFO CodeGenerator: Code generated in 9.778598 ms
17/12/19 15:15:47 INFO Executor: Finished task 0.0 in stage 194.0 (TID 147). 1632 bytes result sent to driver
17/12/19 15:15:47 INFO TaskSetManager: Finished task 0.0 in stage 194.0 (TID 147) in 32 ms on localhost (executor driver) (1/1)
17/12/19 15:15:47 INFO TaskSchedulerImpl: Removed TaskSet 194.0, whose tasks have all completed, from pool 
17/12/19 15:15:47 INFO DAGScheduler: ShuffleMapStage 194 (sql at <unknown>:0) finished in 0.032 s
17/12/19 15:15:47 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:15:47 INFO DAGScheduler: running: Set()
17/12/19 15:15:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 195, ResultStage 196)
17/12/19 15:15:47 INFO DAGScheduler: failed: Set()
17/12/19 15:15:47 INFO DAGScheduler: Submitting ShuffleMapStage 195 (MapPartitionsRDD[403] at sql at <unknown>:0), which has no missing parents
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 11.9 KB, free 2000.8 MB)
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2000.8 MB)
17/12/19 15:15:47 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.3 MB)
17/12/19 15:15:47 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 195 (MapPartitionsRDD[403] at sql at <unknown>:0)
17/12/19 15:15:47 INFO TaskSchedulerImpl: Adding task set 195.0 with 2 tasks
17/12/19 15:15:47 INFO TaskSetManager: Starting task 0.0 in stage 195.0 (TID 148, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/19 15:15:47 INFO TaskSetManager: Starting task 1.0 in stage 195.0 (TID 149, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/19 15:15:47 INFO Executor: Running task 0.0 in stage 195.0 (TID 148)
17/12/19 15:15:47 INFO Executor: Running task 1.0 in stage 195.0 (TID 149)
17/12/19 15:15:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:15:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:15:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:15:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:15:47 INFO MemoryStore: Block rdd_400_0 stored as values in memory (estimated size 544.0 B, free 2000.8 MB)
17/12/19 15:15:47 INFO BlockManagerInfo: Added rdd_400_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.3 MB)
17/12/19 15:15:47 INFO MemoryStore: Block rdd_400_1 stored as values in memory (estimated size 544.0 B, free 2000.8 MB)
17/12/19 15:15:47 INFO BlockManagerInfo: Added rdd_400_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.3 MB)
17/12/19 15:15:47 INFO Executor: Finished task 1.0 in stage 195.0 (TID 149). 3064 bytes result sent to driver
17/12/19 15:15:47 INFO TaskSetManager: Finished task 1.0 in stage 195.0 (TID 149) in 15 ms on localhost (executor driver) (1/2)
17/12/19 15:15:47 INFO Executor: Finished task 0.0 in stage 195.0 (TID 148). 3064 bytes result sent to driver
17/12/19 15:15:47 INFO TaskSetManager: Finished task 0.0 in stage 195.0 (TID 148) in 15 ms on localhost (executor driver) (2/2)
17/12/19 15:15:47 INFO TaskSchedulerImpl: Removed TaskSet 195.0, whose tasks have all completed, from pool 
17/12/19 15:15:47 INFO DAGScheduler: ShuffleMapStage 195 (sql at <unknown>:0) finished in 0.015 s
17/12/19 15:15:47 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:15:47 INFO DAGScheduler: running: Set()
17/12/19 15:15:47 INFO DAGScheduler: waiting: Set(ResultStage 196)
17/12/19 15:15:47 INFO DAGScheduler: failed: Set()
17/12/19 15:15:47 INFO DAGScheduler: Submitting ResultStage 196 (MapPartitionsRDD[406] at sql at <unknown>:0), which has no missing parents
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 7.0 KB, free 2000.8 MB)
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2000.8 MB)
17/12/19 15:15:47 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 15:15:47 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 196 (MapPartitionsRDD[406] at sql at <unknown>:0)
17/12/19 15:15:47 INFO TaskSchedulerImpl: Adding task set 196.0 with 1 tasks
17/12/19 15:15:47 INFO TaskSetManager: Starting task 0.0 in stage 196.0 (TID 150, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/19 15:15:47 INFO Executor: Running task 0.0 in stage 196.0 (TID 150)
17/12/19 15:15:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:15:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:15:47 INFO Executor: Finished task 0.0 in stage 196.0 (TID 150). 1707 bytes result sent to driver
17/12/19 15:15:47 INFO TaskSetManager: Finished task 0.0 in stage 196.0 (TID 150) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:15:47 INFO TaskSchedulerImpl: Removed TaskSet 196.0, whose tasks have all completed, from pool 
17/12/19 15:15:47 INFO DAGScheduler: ResultStage 196 (sql at <unknown>:0) finished in 0.000 s
17/12/19 15:15:47 INFO DAGScheduler: Job 92 finished: sql at <unknown>:0, took 0.059232 s
17/12/19 15:15:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:47 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 15:15:47 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:15:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 145 bytes
17/12/19 15:15:47 INFO DAGScheduler: Registering RDD 410 (collect at utils.scala:196)
17/12/19 15:15:47 INFO DAGScheduler: Got job 93 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:15:47 INFO DAGScheduler: Final stage: ResultStage 199 (collect at utils.scala:196)
17/12/19 15:15:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 198)
17/12/19 15:15:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 198)
17/12/19 15:15:47 INFO DAGScheduler: Submitting ShuffleMapStage 198 (MapPartitionsRDD[410] at collect at utils.scala:196), which has no missing parents
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 11.9 KB, free 2000.8 MB)
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2000.8 MB)
17/12/19 15:15:47 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.3 MB)
17/12/19 15:15:47 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 198 (MapPartitionsRDD[410] at collect at utils.scala:196)
17/12/19 15:15:47 INFO TaskSchedulerImpl: Adding task set 198.0 with 2 tasks
17/12/19 15:15:47 INFO TaskSetManager: Starting task 0.0 in stage 198.0 (TID 151, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/19 15:15:47 INFO TaskSetManager: Starting task 1.0 in stage 198.0 (TID 152, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/19 15:15:47 INFO Executor: Running task 1.0 in stage 198.0 (TID 152)
17/12/19 15:15:47 INFO Executor: Running task 0.0 in stage 198.0 (TID 151)
17/12/19 15:15:47 INFO BlockManager: Found block rdd_400_0 locally
17/12/19 15:15:47 INFO BlockManager: Found block rdd_400_1 locally
17/12/19 15:15:47 INFO Executor: Finished task 0.0 in stage 198.0 (TID 151). 1792 bytes result sent to driver
17/12/19 15:15:47 INFO TaskSetManager: Finished task 0.0 in stage 198.0 (TID 151) in 0 ms on localhost (executor driver) (1/2)
17/12/19 15:15:47 INFO Executor: Finished task 1.0 in stage 198.0 (TID 152). 1950 bytes result sent to driver
17/12/19 15:15:47 INFO TaskSetManager: Finished task 1.0 in stage 198.0 (TID 152) in 141 ms on localhost (executor driver) (2/2)
17/12/19 15:15:47 INFO TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool 
17/12/19 15:15:47 INFO DAGScheduler: ShuffleMapStage 198 (collect at utils.scala:196) finished in 0.141 s
17/12/19 15:15:47 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:15:47 INFO DAGScheduler: running: Set()
17/12/19 15:15:47 INFO DAGScheduler: waiting: Set(ResultStage 199)
17/12/19 15:15:47 INFO DAGScheduler: failed: Set()
17/12/19 15:15:47 INFO DAGScheduler: Submitting ResultStage 199 (MapPartitionsRDD[413] at collect at utils.scala:196), which has no missing parents
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 7.0 KB, free 2000.8 MB)
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2000.8 MB)
17/12/19 15:15:47 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 15:15:47 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 199 (MapPartitionsRDD[413] at collect at utils.scala:196)
17/12/19 15:15:47 INFO TaskSchedulerImpl: Adding task set 199.0 with 1 tasks
17/12/19 15:15:47 INFO TaskSetManager: Starting task 0.0 in stage 199.0 (TID 153, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/19 15:15:47 INFO Executor: Running task 0.0 in stage 199.0 (TID 153)
17/12/19 15:15:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:15:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:15:47 INFO Executor: Finished task 0.0 in stage 199.0 (TID 153). 1707 bytes result sent to driver
17/12/19 15:15:47 INFO TaskSetManager: Finished task 0.0 in stage 199.0 (TID 153) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:15:47 INFO TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool 
17/12/19 15:15:47 INFO DAGScheduler: ResultStage 199 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:15:47 INFO DAGScheduler: Job 93 finished: collect at utils.scala:196, took 0.168659 s
17/12/19 15:15:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz23`
WHERE (0 = 1)
17/12/19 15:15:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:15:47 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:15:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 145 bytes
17/12/19 15:15:47 INFO DAGScheduler: Got job 94 (take at <unknown>:0) with 1 output partitions
17/12/19 15:15:47 INFO DAGScheduler: Final stage: ResultStage 201 (take at <unknown>:0)
17/12/19 15:15:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 200)
17/12/19 15:15:47 INFO DAGScheduler: Missing parents: List()
17/12/19 15:15:47 INFO DAGScheduler: Submitting ResultStage 201 (WorkerRDD[417] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 109.2 KB, free 2000.7 MB)
17/12/19 15:15:47 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 44.5 KB, free 2000.6 MB)
17/12/19 15:15:47 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:53618 (size: 44.5 KB, free: 2004.2 MB)
17/12/19 15:15:47 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 201 (WorkerRDD[417] at RDD at rdd.scala:18)
17/12/19 15:15:47 INFO TaskSchedulerImpl: Adding task set 201.0 with 1 tasks
17/12/19 15:15:47 INFO TaskSetManager: Starting task 0.0 in stage 201.0 (TID 154, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 15:15:47 INFO Executor: Running task 0.0 in stage 201.0 (TID 154)
17/12/19 15:15:47 INFO BlockManager: Found block rdd_400_0 locally
17/12/19 15:15:47 INFO CodeGenerator: Code generated in 15.716439 ms
17/12/19 15:15:47 INFO CodeGenerator: Code generated in 8.051919 ms
17/12/19 15:15:48 INFO MemoryStore: Block rdd_417_0 stored as values in memory (estimated size 80.0 B, free 2000.6 MB)
17/12/19 15:15:48 INFO BlockManagerInfo: Added rdd_417_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.2 MB)
17/12/19 15:15:48 INFO Executor: Finished task 0.0 in stage 201.0 (TID 154). 2320 bytes result sent to driver
17/12/19 15:15:48 INFO TaskSetManager: Finished task 0.0 in stage 201.0 (TID 154) in 819 ms on localhost (executor driver) (1/1)
17/12/19 15:15:48 INFO TaskSchedulerImpl: Removed TaskSet 201.0, whose tasks have all completed, from pool 
17/12/19 15:15:48 INFO DAGScheduler: ResultStage 201 (take at <unknown>:0) finished in 0.819 s
17/12/19 15:15:48 INFO DAGScheduler: Job 94 finished: take at <unknown>:0, took 0.826783 s
17/12/19 15:15:48 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:15:48 INFO DAGScheduler: Got job 95 (take at <unknown>:0) with 1 output partitions
17/12/19 15:15:48 INFO DAGScheduler: Final stage: ResultStage 203 (take at <unknown>:0)
17/12/19 15:15:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 202)
17/12/19 15:15:48 INFO DAGScheduler: Missing parents: List()
17/12/19 15:15:48 INFO DAGScheduler: Submitting ResultStage 203 (WorkerRDD[417] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:15:48 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 109.2 KB, free 2000.5 MB)
17/12/19 15:15:48 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 44.5 KB, free 2000.5 MB)
17/12/19 15:15:48 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:53618 (size: 44.5 KB, free: 2004.2 MB)
17/12/19 15:15:48 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 203 (WorkerRDD[417] at RDD at rdd.scala:18)
17/12/19 15:15:48 INFO TaskSchedulerImpl: Adding task set 203.0 with 1 tasks
17/12/19 15:15:48 INFO TaskSetManager: Starting task 0.0 in stage 203.0 (TID 155, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 15:15:48 INFO Executor: Running task 0.0 in stage 203.0 (TID 155)
17/12/19 15:15:48 INFO BlockManager: Found block rdd_400_1 locally
17/12/19 15:15:49 INFO MemoryStore: Block rdd_417_1 stored as values in memory (estimated size 80.0 B, free 2000.5 MB)
17/12/19 15:15:49 INFO BlockManagerInfo: Added rdd_417_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.2 MB)
17/12/19 15:15:49 INFO Executor: Finished task 0.0 in stage 203.0 (TID 155). 2154 bytes result sent to driver
17/12/19 15:15:49 INFO TaskSetManager: Finished task 0.0 in stage 203.0 (TID 155) in 753 ms on localhost (executor driver) (1/1)
17/12/19 15:15:49 INFO TaskSchedulerImpl: Removed TaskSet 203.0, whose tasks have all completed, from pool 
17/12/19 15:15:49 INFO DAGScheduler: ResultStage 203 (take at <unknown>:0) finished in 0.753 s
17/12/19 15:15:49 INFO DAGScheduler: Job 95 finished: take at <unknown>:0, took 0.749938 s
17/12/19 15:15:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:49 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e82ff1158e
17/12/19 15:15:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e82ff1158e` AS `zzz24`
WHERE (0 = 1)
17/12/19 15:15:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e82ff1158e`
LIMIT 10
17/12/19 15:15:49 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:15:49 INFO DAGScheduler: Got job 96 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:15:49 INFO DAGScheduler: Final stage: ResultStage 205 (collect at utils.scala:196)
17/12/19 15:15:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 204)
17/12/19 15:15:49 INFO DAGScheduler: Missing parents: List()
17/12/19 15:15:49 INFO DAGScheduler: Submitting ResultStage 205 (MapPartitionsRDD[421] at collect at utils.scala:196), which has no missing parents
17/12/19 15:15:49 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 112.3 KB, free 2000.4 MB)
17/12/19 15:15:49 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 46.3 KB, free 2000.3 MB)
17/12/19 15:15:49 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:53618 (size: 46.3 KB, free: 2004.2 MB)
17/12/19 15:15:49 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 205 (MapPartitionsRDD[421] at collect at utils.scala:196)
17/12/19 15:15:49 INFO TaskSchedulerImpl: Adding task set 205.0 with 1 tasks
17/12/19 15:15:49 INFO TaskSetManager: Starting task 0.0 in stage 205.0 (TID 156, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:15:49 INFO Executor: Running task 0.0 in stage 205.0 (TID 156)
17/12/19 15:15:49 INFO BlockManager: Found block rdd_417_0 locally
17/12/19 15:15:49 INFO Executor: Finished task 0.0 in stage 205.0 (TID 156). 1233 bytes result sent to driver
17/12/19 15:15:49 INFO TaskSetManager: Finished task 0.0 in stage 205.0 (TID 156) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:15:49 INFO TaskSchedulerImpl: Removed TaskSet 205.0, whose tasks have all completed, from pool 
17/12/19 15:15:49 INFO DAGScheduler: ResultStage 205 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:15:49 INFO DAGScheduler: Job 96 finished: collect at utils.scala:196, took 0.008072 s
17/12/19 15:15:49 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:15:49 INFO DAGScheduler: Got job 97 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:15:49 INFO DAGScheduler: Final stage: ResultStage 207 (collect at utils.scala:196)
17/12/19 15:15:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 206)
17/12/19 15:15:49 INFO DAGScheduler: Missing parents: List()
17/12/19 15:15:49 INFO DAGScheduler: Submitting ResultStage 207 (MapPartitionsRDD[421] at collect at utils.scala:196), which has no missing parents
17/12/19 15:15:49 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 112.3 KB, free 2000.2 MB)
17/12/19 15:15:49 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 46.3 KB, free 2000.2 MB)
17/12/19 15:15:49 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:53618 (size: 46.3 KB, free: 2004.1 MB)
17/12/19 15:15:49 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 207 (MapPartitionsRDD[421] at collect at utils.scala:196)
17/12/19 15:15:49 INFO TaskSchedulerImpl: Adding task set 207.0 with 1 tasks
17/12/19 15:15:49 INFO TaskSetManager: Starting task 0.0 in stage 207.0 (TID 157, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:15:49 INFO Executor: Running task 0.0 in stage 207.0 (TID 157)
17/12/19 15:15:49 INFO BlockManager: Found block rdd_417_1 locally
17/12/19 15:15:49 INFO Executor: Finished task 0.0 in stage 207.0 (TID 157). 1399 bytes result sent to driver
17/12/19 15:15:49 INFO TaskSetManager: Finished task 0.0 in stage 207.0 (TID 157) in 19 ms on localhost (executor driver) (1/1)
17/12/19 15:15:49 INFO TaskSchedulerImpl: Removed TaskSet 207.0, whose tasks have all completed, from pool 
17/12/19 15:15:49 INFO DAGScheduler: ResultStage 207 (collect at utils.scala:196) finished in 0.019 s
17/12/19 15:15:49 INFO DAGScheduler: Job 97 finished: collect at utils.scala:196, took 0.007970 s
17/12/19 15:15:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:49 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `asskswrdpd`
LIMIT 10
17/12/19 15:15:49 INFO CodeGenerator: Code generated in 10.960049 ms
17/12/19 15:15:49 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:15:49 INFO DAGScheduler: Got job 98 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:15:49 INFO DAGScheduler: Final stage: ResultStage 209 (collect at utils.scala:196)
17/12/19 15:15:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 208)
17/12/19 15:15:49 INFO DAGScheduler: Missing parents: List()
17/12/19 15:15:49 INFO DAGScheduler: Submitting ResultStage 209 (MapPartitionsRDD[424] at collect at utils.scala:196), which has no missing parents
17/12/19 15:15:49 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 13.3 KB, free 2000.2 MB)
17/12/19 15:15:49 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 6.2 KB, free 2000.2 MB)
17/12/19 15:15:49 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:53618 (size: 6.2 KB, free: 2004.1 MB)
17/12/19 15:15:49 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 209 (MapPartitionsRDD[424] at collect at utils.scala:196)
17/12/19 15:15:49 INFO TaskSchedulerImpl: Adding task set 209.0 with 1 tasks
17/12/19 15:15:49 INFO TaskSetManager: Starting task 0.0 in stage 209.0 (TID 158, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:15:49 INFO Executor: Running task 0.0 in stage 209.0 (TID 158)
17/12/19 15:15:49 INFO BlockManager: Found block rdd_400_0 locally
17/12/19 15:15:49 INFO Executor: Finished task 0.0 in stage 209.0 (TID 158). 1573 bytes result sent to driver
17/12/19 15:15:49 INFO TaskSetManager: Finished task 0.0 in stage 209.0 (TID 158) in 16 ms on localhost (executor driver) (1/1)
17/12/19 15:15:49 INFO TaskSchedulerImpl: Removed TaskSet 209.0, whose tasks have all completed, from pool 
17/12/19 15:15:49 INFO DAGScheduler: ResultStage 209 (collect at utils.scala:196) finished in 0.016 s
17/12/19 15:15:49 INFO DAGScheduler: Job 98 finished: collect at utils.scala:196, took 0.010454 s
17/12/19 15:15:49 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:15:49 INFO DAGScheduler: Got job 99 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:15:49 INFO DAGScheduler: Final stage: ResultStage 211 (collect at utils.scala:196)
17/12/19 15:15:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 210)
17/12/19 15:15:49 INFO DAGScheduler: Missing parents: List()
17/12/19 15:15:49 INFO DAGScheduler: Submitting ResultStage 211 (MapPartitionsRDD[424] at collect at utils.scala:196), which has no missing parents
17/12/19 15:15:49 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 13.3 KB, free 2000.1 MB)
17/12/19 15:15:49 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 6.2 KB, free 2000.1 MB)
17/12/19 15:15:49 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:53618 (size: 6.2 KB, free: 2004.1 MB)
17/12/19 15:15:49 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 211 (MapPartitionsRDD[424] at collect at utils.scala:196)
17/12/19 15:15:49 INFO TaskSchedulerImpl: Adding task set 211.0 with 1 tasks
17/12/19 15:15:49 INFO TaskSetManager: Starting task 0.0 in stage 211.0 (TID 159, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:15:49 INFO Executor: Running task 0.0 in stage 211.0 (TID 159)
17/12/19 15:15:49 INFO BlockManager: Found block rdd_400_1 locally
17/12/19 15:15:49 INFO Executor: Finished task 0.0 in stage 211.0 (TID 159). 1555 bytes result sent to driver
17/12/19 15:15:49 INFO DAGScheduler: ResultStage 211 (collect at utils.scala:196) finished in 0.015 s
17/12/19 15:15:49 INFO DAGScheduler: Job 99 finished: collect at utils.scala:196, took 0.010227 s
17/12/19 15:15:49 INFO TaskSetManager: Finished task 0.0 in stage 211.0 (TID 159) in 15 ms on localhost (executor driver) (1/1)
17/12/19 15:15:49 INFO TaskSchedulerImpl: Removed TaskSet 211.0, whose tasks have all completed, from pool 
17/12/19 15:15:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:49 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `xqrbojfmnj`
17/12/19 15:15:49 INFO CodeGenerator: Code generated in 10.428415 ms
17/12/19 15:15:49 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:15:49 INFO DAGScheduler: Got job 100 (take at <unknown>:0) with 1 output partitions
17/12/19 15:15:49 INFO DAGScheduler: Final stage: ResultStage 213 (take at <unknown>:0)
17/12/19 15:15:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 212)
17/12/19 15:15:49 INFO DAGScheduler: Missing parents: List()
17/12/19 15:15:49 INFO DAGScheduler: Submitting ResultStage 213 (WorkerRDD[429] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:15:49 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 128.6 KB, free 2000.0 MB)
17/12/19 15:15:49 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 48.5 KB, free 2000.0 MB)
17/12/19 15:15:49 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:53618 (size: 48.5 KB, free: 2004.0 MB)
17/12/19 15:15:49 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 213 (WorkerRDD[429] at RDD at rdd.scala:18)
17/12/19 15:15:49 INFO TaskSchedulerImpl: Adding task set 213.0 with 1 tasks
17/12/19 15:15:49 INFO TaskSetManager: Starting task 0.0 in stage 213.0 (TID 160, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 15:15:49 INFO Executor: Running task 0.0 in stage 213.0 (TID 160)
17/12/19 15:15:49 INFO BlockManager: Found block rdd_400_0 locally
17/12/19 15:15:50 INFO MemoryStore: Block rdd_429_0 stored as values in memory (estimated size 608.0 B, free 2000.0 MB)
17/12/19 15:15:50 INFO BlockManagerInfo: Added rdd_429_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2004.0 MB)
17/12/19 15:15:50 INFO Executor: Finished task 0.0 in stage 213.0 (TID 160). 2509 bytes result sent to driver
17/12/19 15:15:50 INFO TaskSetManager: Finished task 0.0 in stage 213.0 (TID 160) in 1118 ms on localhost (executor driver) (1/1)
17/12/19 15:15:50 INFO TaskSchedulerImpl: Removed TaskSet 213.0, whose tasks have all completed, from pool 
17/12/19 15:15:50 INFO DAGScheduler: ResultStage 213 (take at <unknown>:0) finished in 1.118 s
17/12/19 15:15:50 INFO DAGScheduler: Job 100 finished: take at <unknown>:0, took 1.122540 s
17/12/19 15:15:50 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:15:50 INFO DAGScheduler: Got job 101 (take at <unknown>:0) with 1 output partitions
17/12/19 15:15:50 INFO DAGScheduler: Final stage: ResultStage 215 (take at <unknown>:0)
17/12/19 15:15:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 214)
17/12/19 15:15:50 INFO DAGScheduler: Missing parents: List()
17/12/19 15:15:50 INFO DAGScheduler: Submitting ResultStage 215 (WorkerRDD[429] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:15:50 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 128.6 KB, free 1999.8 MB)
17/12/19 15:15:50 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 48.5 KB, free 1999.8 MB)
17/12/19 15:15:50 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:53618 (size: 48.5 KB, free: 2004.0 MB)
17/12/19 15:15:50 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 215 (WorkerRDD[429] at RDD at rdd.scala:18)
17/12/19 15:15:50 INFO TaskSchedulerImpl: Adding task set 215.0 with 1 tasks
17/12/19 15:15:50 INFO TaskSetManager: Starting task 0.0 in stage 215.0 (TID 161, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 15:15:50 INFO Executor: Running task 0.0 in stage 215.0 (TID 161)
17/12/19 15:15:50 INFO BlockManager: Found block rdd_400_1 locally
17/12/19 15:15:51 INFO MemoryStore: Block rdd_429_1 stored as values in memory (estimated size 608.0 B, free 1999.8 MB)
17/12/19 15:15:51 INFO BlockManagerInfo: Added rdd_429_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2004.0 MB)
17/12/19 15:15:51 INFO Executor: Finished task 0.0 in stage 215.0 (TID 161). 2588 bytes result sent to driver
17/12/19 15:15:51 INFO TaskSetManager: Finished task 0.0 in stage 215.0 (TID 161) in 898 ms on localhost (executor driver) (1/1)
17/12/19 15:15:51 INFO TaskSchedulerImpl: Removed TaskSet 215.0, whose tasks have all completed, from pool 
17/12/19 15:15:51 INFO DAGScheduler: ResultStage 215 (take at <unknown>:0) finished in 0.898 s
17/12/19 15:15:51 INFO DAGScheduler: Job 101 finished: take at <unknown>:0, took 0.898856 s
17/12/19 15:15:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:51 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e8360634df
17/12/19 15:15:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8360634df` AS `zzz25`
WHERE (0 = 1)
17/12/19 15:15:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8360634df`
17/12/19 15:15:51 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:15:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz26`
WHERE (0 = 1)
17/12/19 15:15:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:51 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 15:15:51 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:15:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz27`
WHERE (0 = 1)
17/12/19 15:15:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:15:51 INFO CodeGenerator: Code generated in 12.220415 ms
17/12/19 15:15:51 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:15:51 INFO DAGScheduler: Got job 102 (collect at utils.scala:196) with 2 output partitions
17/12/19 15:15:51 INFO DAGScheduler: Final stage: ResultStage 217 (collect at utils.scala:196)
17/12/19 15:15:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 216)
17/12/19 15:15:51 INFO DAGScheduler: Missing parents: List()
17/12/19 15:15:51 INFO DAGScheduler: Submitting ResultStage 217 (MapPartitionsRDD[436] at collect at utils.scala:196), which has no missing parents
17/12/19 15:15:51 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 136.1 KB, free 1999.7 MB)
17/12/19 15:15:51 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 51.8 KB, free 1999.6 MB)
17/12/19 15:15:51 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:53618 (size: 51.8 KB, free: 2003.9 MB)
17/12/19 15:15:51 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:996
17/12/19 15:15:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 217 (MapPartitionsRDD[436] at collect at utils.scala:196)
17/12/19 15:15:51 INFO TaskSchedulerImpl: Adding task set 217.0 with 2 tasks
17/12/19 15:15:51 INFO TaskSetManager: Starting task 0.0 in stage 217.0 (TID 162, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/19 15:15:51 INFO TaskSetManager: Starting task 1.0 in stage 217.0 (TID 163, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/19 15:15:51 INFO Executor: Running task 0.0 in stage 217.0 (TID 162)
17/12/19 15:15:51 INFO Executor: Running task 1.0 in stage 217.0 (TID 163)
17/12/19 15:15:51 INFO BlockManager: Found block rdd_429_1 locally
17/12/19 15:15:51 INFO BlockManager: Found block rdd_429_0 locally
17/12/19 15:15:51 INFO CodeGenerator: Code generated in 36.386744 ms
17/12/19 15:15:51 INFO Executor: Finished task 0.0 in stage 217.0 (TID 162). 1609 bytes result sent to driver
17/12/19 15:15:51 INFO Executor: Finished task 1.0 in stage 217.0 (TID 163). 1518 bytes result sent to driver
17/12/19 15:15:51 INFO TaskSetManager: Finished task 0.0 in stage 217.0 (TID 162) in 33 ms on localhost (executor driver) (1/2)
17/12/19 15:15:51 INFO TaskSetManager: Finished task 1.0 in stage 217.0 (TID 163) in 32 ms on localhost (executor driver) (2/2)
17/12/19 15:15:51 INFO TaskSchedulerImpl: Removed TaskSet 217.0, whose tasks have all completed, from pool 
17/12/19 15:15:51 INFO DAGScheduler: ResultStage 217 (collect at utils.scala:196) finished in 0.033 s
17/12/19 15:15:51 INFO DAGScheduler: Job 102 finished: collect at utils.scala:196, took 0.051939 s
17/12/19 15:15:51 INFO CodeGenerator: Code generated in 5.979375 ms
17/12/19 15:15:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:15:52 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:15:52 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:15:52 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:15:52 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:15:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:15:52 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:15:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:15:52 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:15:52 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:15:52 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:15:52 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:15:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:15:52 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:15:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:15:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:15:52 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:15:52 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:15:52 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:15:52 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:15:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:15:52 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:20:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:20:11 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:20:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:20:11 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:20:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:20:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:20:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:20:11 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 15:20:11 INFO DAGScheduler: Got job 103 (collect at utils.scala:58) with 1 output partitions
17/12/19 15:20:11 INFO DAGScheduler: Final stage: ResultStage 218 (collect at utils.scala:58)
17/12/19 15:20:11 INFO DAGScheduler: Parents of final stage: List()
17/12/19 15:20:11 INFO DAGScheduler: Missing parents: List()
17/12/19 15:20:11 INFO DAGScheduler: Submitting ResultStage 218 (MapPartitionsRDD[445] at map at utils.scala:55), which has no missing parents
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 8.7 KB, free 1999.6 MB)
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1999.6 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.9 MB)
17/12/19 15:20:11 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 218 (MapPartitionsRDD[445] at map at utils.scala:55)
17/12/19 15:20:11 INFO TaskSchedulerImpl: Adding task set 218.0 with 1 tasks
17/12/19 15:20:11 INFO TaskSetManager: Starting task 0.0 in stage 218.0 (TID 164, localhost, executor driver, partition 0, PROCESS_LOCAL, 7296 bytes)
17/12/19 15:20:11 INFO Executor: Running task 0.0 in stage 218.0 (TID 164)
17/12/19 15:20:11 INFO Executor: Finished task 0.0 in stage 218.0 (TID 164). 1275 bytes result sent to driver
17/12/19 15:20:11 INFO DAGScheduler: ResultStage 218 (collect at utils.scala:58) finished in 0.000 s
17/12/19 15:20:11 INFO DAGScheduler: Job 103 finished: collect at utils.scala:58, took 0.007111 s
17/12/19 15:20:11 INFO TaskSetManager: Finished task 0.0 in stage 218.0 (TID 164) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:20:11 INFO TaskSchedulerImpl: Removed TaskSet 218.0, whose tasks have all completed, from pool 
17/12/19 15:20:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 127.0.0.1:53618 in memory (size: 44.5 KB, free: 2004.0 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.0 MB)
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6894
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6895
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.0 MB)
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6944
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6945
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6951
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6952
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6953
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6954
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6955
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6956
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6957
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6958
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6959
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6960
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6961
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6962
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 6963
17/12/19 15:20:11 INFO ContextCleaner: Cleaned shuffle 34
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.0 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2004.0 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.0 MB)
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 7132
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2004.0 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.0 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 127.0.0.1:53618 in memory (size: 44.5 KB, free: 2004.1 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 127.0.0.1:53618 in memory (size: 46.3 KB, free: 2004.1 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 127.0.0.1:53618 in memory (size: 46.3 KB, free: 2004.2 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 127.0.0.1:53618 in memory (size: 6.2 KB, free: 2004.2 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 127.0.0.1:53618 in memory (size: 6.2 KB, free: 2004.2 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 127.0.0.1:53618 in memory (size: 48.5 KB, free: 2004.2 MB)
17/12/19 15:20:11 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 127.0.0.1:53618 in memory (size: 48.5 KB, free: 2004.3 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 127.0.0.1:53618 in memory (size: 51.8 KB, free: 2004.3 MB)
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 7729
17/12/19 15:20:11 INFO ContextCleaner: Cleaned accumulator 7730
17/12/19 15:20:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:11 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 15:20:11 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 15:20:11 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 15:20:11 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 15:20:11 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 15:20:11 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 293.7 KB, free 2000.6 MB)
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2000.6 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.3 MB)
17/12/19 15:20:11 INFO SparkContext: Created broadcast 152 from sql at <unknown>:0
17/12/19 15:20:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 15:20:11 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 15:20:11 INFO DAGScheduler: Registering RDD 449 (sql at <unknown>:0)
17/12/19 15:20:11 INFO DAGScheduler: Registering RDD 454 (sql at <unknown>:0)
17/12/19 15:20:11 INFO DAGScheduler: Got job 104 (sql at <unknown>:0) with 1 output partitions
17/12/19 15:20:11 INFO DAGScheduler: Final stage: ResultStage 221 (sql at <unknown>:0)
17/12/19 15:20:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 220)
17/12/19 15:20:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 220)
17/12/19 15:20:11 INFO DAGScheduler: Submitting ShuffleMapStage 219 (MapPartitionsRDD[449] at sql at <unknown>:0), which has no missing parents
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 12.1 KB, free 2000.6 MB)
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2000.5 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.3 MB)
17/12/19 15:20:11 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 219 (MapPartitionsRDD[449] at sql at <unknown>:0)
17/12/19 15:20:11 INFO TaskSchedulerImpl: Adding task set 219.0 with 1 tasks
17/12/19 15:20:11 INFO TaskSetManager: Starting task 0.0 in stage 219.0 (TID 165, localhost, executor driver, partition 0, PROCESS_LOCAL, 6679 bytes)
17/12/19 15:20:11 INFO Executor: Running task 0.0 in stage 219.0 (TID 165)
17/12/19 15:20:11 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_1d6f8acd208e72a71257cca72cd9d8539ea2eabfbc0cc14add7f1d8614937b66.csv, range: 0-450, partition values: [empty row]
17/12/19 15:20:11 INFO Executor: Finished task 0.0 in stage 219.0 (TID 165). 1553 bytes result sent to driver
17/12/19 15:20:11 INFO TaskSetManager: Finished task 0.0 in stage 219.0 (TID 165) in 63 ms on localhost (executor driver) (1/1)
17/12/19 15:20:11 INFO TaskSchedulerImpl: Removed TaskSet 219.0, whose tasks have all completed, from pool 
17/12/19 15:20:11 INFO DAGScheduler: ShuffleMapStage 219 (sql at <unknown>:0) finished in 0.063 s
17/12/19 15:20:11 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:20:11 INFO DAGScheduler: running: Set()
17/12/19 15:20:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 220, ResultStage 221)
17/12/19 15:20:11 INFO DAGScheduler: failed: Set()
17/12/19 15:20:11 INFO DAGScheduler: Submitting ShuffleMapStage 220 (MapPartitionsRDD[454] at sql at <unknown>:0), which has no missing parents
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 11.9 KB, free 2000.5 MB)
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2000.5 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.3 MB)
17/12/19 15:20:11 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 220 (MapPartitionsRDD[454] at sql at <unknown>:0)
17/12/19 15:20:11 INFO TaskSchedulerImpl: Adding task set 220.0 with 2 tasks
17/12/19 15:20:11 INFO TaskSetManager: Starting task 0.0 in stage 220.0 (TID 166, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/19 15:20:11 INFO TaskSetManager: Starting task 1.0 in stage 220.0 (TID 167, localhost, executor driver, partition 1, ANY, 5945 bytes)
17/12/19 15:20:11 INFO Executor: Running task 0.0 in stage 220.0 (TID 166)
17/12/19 15:20:11 INFO Executor: Running task 1.0 in stage 220.0 (TID 167)
17/12/19 15:20:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:20:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:20:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:20:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:20:11 INFO MemoryStore: Block rdd_451_1 stored as values in memory (estimated size 544.0 B, free 2000.5 MB)
17/12/19 15:20:11 INFO MemoryStore: Block rdd_451_0 stored as values in memory (estimated size 544.0 B, free 2000.5 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Added rdd_451_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.3 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Added rdd_451_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.3 MB)
17/12/19 15:20:11 INFO Executor: Finished task 1.0 in stage 220.0 (TID 167). 2906 bytes result sent to driver
17/12/19 15:20:11 INFO TaskSetManager: Finished task 1.0 in stage 220.0 (TID 167) in 0 ms on localhost (executor driver) (1/2)
17/12/19 15:20:11 INFO Executor: Finished task 0.0 in stage 220.0 (TID 166). 2906 bytes result sent to driver
17/12/19 15:20:11 INFO TaskSetManager: Finished task 0.0 in stage 220.0 (TID 166) in 0 ms on localhost (executor driver) (2/2)
17/12/19 15:20:11 INFO TaskSchedulerImpl: Removed TaskSet 220.0, whose tasks have all completed, from pool 
17/12/19 15:20:11 INFO DAGScheduler: ShuffleMapStage 220 (sql at <unknown>:0) finished in 0.000 s
17/12/19 15:20:11 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:20:11 INFO DAGScheduler: running: Set()
17/12/19 15:20:11 INFO DAGScheduler: waiting: Set(ResultStage 221)
17/12/19 15:20:11 INFO DAGScheduler: failed: Set()
17/12/19 15:20:11 INFO DAGScheduler: Submitting ResultStage 221 (MapPartitionsRDD[457] at sql at <unknown>:0), which has no missing parents
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 7.0 KB, free 2000.5 MB)
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2000.5 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 15:20:11 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 221 (MapPartitionsRDD[457] at sql at <unknown>:0)
17/12/19 15:20:11 INFO TaskSchedulerImpl: Adding task set 221.0 with 1 tasks
17/12/19 15:20:11 INFO TaskSetManager: Starting task 0.0 in stage 221.0 (TID 168, localhost, executor driver, partition 0, ANY, 5956 bytes)
17/12/19 15:20:11 INFO Executor: Running task 0.0 in stage 221.0 (TID 168)
17/12/19 15:20:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:20:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:20:11 INFO Executor: Finished task 0.0 in stage 221.0 (TID 168). 1707 bytes result sent to driver
17/12/19 15:20:11 INFO DAGScheduler: ResultStage 221 (sql at <unknown>:0) finished in 0.000 s
17/12/19 15:20:11 INFO DAGScheduler: Job 104 finished: sql at <unknown>:0, took 0.096066 s
17/12/19 15:20:11 INFO TaskSetManager: Finished task 0.0 in stage 221.0 (TID 168) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:20:11 INFO TaskSchedulerImpl: Removed TaskSet 221.0, whose tasks have all completed, from pool 
17/12/19 15:20:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:11 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 15:20:11 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:20:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 36 is 145 bytes
17/12/19 15:20:11 INFO DAGScheduler: Registering RDD 461 (collect at utils.scala:196)
17/12/19 15:20:11 INFO DAGScheduler: Got job 105 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:20:11 INFO DAGScheduler: Final stage: ResultStage 224 (collect at utils.scala:196)
17/12/19 15:20:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 223)
17/12/19 15:20:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 223)
17/12/19 15:20:11 INFO DAGScheduler: Submitting ShuffleMapStage 223 (MapPartitionsRDD[461] at collect at utils.scala:196), which has no missing parents
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 11.9 KB, free 2000.5 MB)
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2000.5 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.3 MB)
17/12/19 15:20:11 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 223 (MapPartitionsRDD[461] at collect at utils.scala:196)
17/12/19 15:20:11 INFO TaskSchedulerImpl: Adding task set 223.0 with 2 tasks
17/12/19 15:20:11 INFO TaskSetManager: Starting task 0.0 in stage 223.0 (TID 169, localhost, executor driver, partition 0, PROCESS_LOCAL, 5937 bytes)
17/12/19 15:20:11 INFO TaskSetManager: Starting task 1.0 in stage 223.0 (TID 170, localhost, executor driver, partition 1, PROCESS_LOCAL, 5937 bytes)
17/12/19 15:20:11 INFO Executor: Running task 1.0 in stage 223.0 (TID 170)
17/12/19 15:20:11 INFO Executor: Running task 0.0 in stage 223.0 (TID 169)
17/12/19 15:20:11 INFO BlockManager: Found block rdd_451_1 locally
17/12/19 15:20:11 INFO BlockManager: Found block rdd_451_0 locally
17/12/19 15:20:11 INFO Executor: Finished task 1.0 in stage 223.0 (TID 170). 1792 bytes result sent to driver
17/12/19 15:20:11 INFO TaskSetManager: Finished task 1.0 in stage 223.0 (TID 170) in 0 ms on localhost (executor driver) (1/2)
17/12/19 15:20:11 INFO Executor: Finished task 0.0 in stage 223.0 (TID 169). 1792 bytes result sent to driver
17/12/19 15:20:11 INFO TaskSetManager: Finished task 0.0 in stage 223.0 (TID 169) in 0 ms on localhost (executor driver) (2/2)
17/12/19 15:20:11 INFO TaskSchedulerImpl: Removed TaskSet 223.0, whose tasks have all completed, from pool 
17/12/19 15:20:11 INFO DAGScheduler: ShuffleMapStage 223 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:20:11 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:20:11 INFO DAGScheduler: running: Set()
17/12/19 15:20:11 INFO DAGScheduler: waiting: Set(ResultStage 224)
17/12/19 15:20:11 INFO DAGScheduler: failed: Set()
17/12/19 15:20:11 INFO DAGScheduler: Submitting ResultStage 224 (MapPartitionsRDD[464] at collect at utils.scala:196), which has no missing parents
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 7.0 KB, free 2000.5 MB)
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2000.5 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 15:20:11 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 224 (MapPartitionsRDD[464] at collect at utils.scala:196)
17/12/19 15:20:11 INFO TaskSchedulerImpl: Adding task set 224.0 with 1 tasks
17/12/19 15:20:11 INFO TaskSetManager: Starting task 0.0 in stage 224.0 (TID 171, localhost, executor driver, partition 0, ANY, 5948 bytes)
17/12/19 15:20:11 INFO Executor: Running task 0.0 in stage 224.0 (TID 171)
17/12/19 15:20:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:20:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:20:11 INFO Executor: Finished task 0.0 in stage 224.0 (TID 171). 1884 bytes result sent to driver
17/12/19 15:20:11 INFO TaskSetManager: Finished task 0.0 in stage 224.0 (TID 171) in 16 ms on localhost (executor driver) (1/1)
17/12/19 15:20:11 INFO TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool 
17/12/19 15:20:11 INFO DAGScheduler: ResultStage 224 (collect at utils.scala:196) finished in 0.016 s
17/12/19 15:20:11 INFO DAGScheduler: Job 105 finished: collect at utils.scala:196, took 0.019496 s
17/12/19 15:20:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz28`
WHERE (0 = 1)
17/12/19 15:20:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:20:11 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:20:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 36 is 145 bytes
17/12/19 15:20:11 INFO DAGScheduler: Got job 106 (take at <unknown>:0) with 1 output partitions
17/12/19 15:20:11 INFO DAGScheduler: Final stage: ResultStage 226 (take at <unknown>:0)
17/12/19 15:20:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 225)
17/12/19 15:20:11 INFO DAGScheduler: Missing parents: List()
17/12/19 15:20:11 INFO DAGScheduler: Submitting ResultStage 226 (WorkerRDD[468] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 109.4 KB, free 2000.4 MB)
17/12/19 15:20:11 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 44.6 KB, free 2000.3 MB)
17/12/19 15:20:11 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 127.0.0.1:53618 (size: 44.6 KB, free: 2004.2 MB)
17/12/19 15:20:11 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 226 (WorkerRDD[468] at RDD at rdd.scala:18)
17/12/19 15:20:11 INFO TaskSchedulerImpl: Adding task set 226.0 with 1 tasks
17/12/19 15:20:11 INFO TaskSetManager: Starting task 0.0 in stage 226.0 (TID 172, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:20:11 INFO Executor: Running task 0.0 in stage 226.0 (TID 172)
17/12/19 15:20:11 INFO BlockManager: Found block rdd_451_0 locally
17/12/19 15:20:12 INFO MemoryStore: Block rdd_468_0 stored as values in memory (estimated size 80.0 B, free 2000.3 MB)
17/12/19 15:20:12 INFO BlockManagerInfo: Added rdd_468_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.2 MB)
17/12/19 15:20:12 INFO Executor: Finished task 0.0 in stage 226.0 (TID 172). 2154 bytes result sent to driver
17/12/19 15:20:12 INFO TaskSetManager: Finished task 0.0 in stage 226.0 (TID 172) in 648 ms on localhost (executor driver) (1/1)
17/12/19 15:20:12 INFO TaskSchedulerImpl: Removed TaskSet 226.0, whose tasks have all completed, from pool 
17/12/19 15:20:12 INFO DAGScheduler: ResultStage 226 (take at <unknown>:0) finished in 0.648 s
17/12/19 15:20:12 INFO DAGScheduler: Job 106 finished: take at <unknown>:0, took 0.654098 s
17/12/19 15:20:12 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:20:12 INFO DAGScheduler: Got job 107 (take at <unknown>:0) with 1 output partitions
17/12/19 15:20:12 INFO DAGScheduler: Final stage: ResultStage 228 (take at <unknown>:0)
17/12/19 15:20:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 227)
17/12/19 15:20:12 INFO DAGScheduler: Missing parents: List()
17/12/19 15:20:12 INFO DAGScheduler: Submitting ResultStage 228 (WorkerRDD[468] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:20:12 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 109.4 KB, free 2000.2 MB)
17/12/19 15:20:12 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 44.6 KB, free 2000.2 MB)
17/12/19 15:20:12 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 127.0.0.1:53618 (size: 44.6 KB, free: 2004.2 MB)
17/12/19 15:20:12 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 228 (WorkerRDD[468] at RDD at rdd.scala:18)
17/12/19 15:20:12 INFO TaskSchedulerImpl: Adding task set 228.0 with 1 tasks
17/12/19 15:20:12 INFO TaskSetManager: Starting task 0.0 in stage 228.0 (TID 173, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:20:12 INFO Executor: Running task 0.0 in stage 228.0 (TID 173)
17/12/19 15:20:12 INFO BlockManager: Found block rdd_451_1 locally
17/12/19 15:20:13 INFO MemoryStore: Block rdd_468_1 stored as values in memory (estimated size 80.0 B, free 2000.2 MB)
17/12/19 15:20:13 INFO BlockManagerInfo: Added rdd_468_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.2 MB)
17/12/19 15:20:13 INFO Executor: Finished task 0.0 in stage 228.0 (TID 173). 2154 bytes result sent to driver
17/12/19 15:20:13 INFO TaskSetManager: Finished task 0.0 in stage 228.0 (TID 173) in 718 ms on localhost (executor driver) (1/1)
17/12/19 15:20:13 INFO TaskSchedulerImpl: Removed TaskSet 228.0, whose tasks have all completed, from pool 
17/12/19 15:20:13 INFO DAGScheduler: ResultStage 228 (take at <unknown>:0) finished in 0.718 s
17/12/19 15:20:13 INFO DAGScheduler: Job 107 finished: take at <unknown>:0, took 0.716836 s
17/12/19 15:20:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:13 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e810831e30
17/12/19 15:20:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e810831e30` AS `zzz29`
WHERE (0 = 1)
17/12/19 15:20:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e810831e30`
LIMIT 10
17/12/19 15:20:13 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:20:13 INFO DAGScheduler: Got job 108 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:20:13 INFO DAGScheduler: Final stage: ResultStage 230 (collect at utils.scala:196)
17/12/19 15:20:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 229)
17/12/19 15:20:13 INFO DAGScheduler: Missing parents: List()
17/12/19 15:20:13 INFO DAGScheduler: Submitting ResultStage 230 (MapPartitionsRDD[472] at collect at utils.scala:196), which has no missing parents
17/12/19 15:20:13 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 112.5 KB, free 2000.1 MB)
17/12/19 15:20:13 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 46.4 KB, free 2000.0 MB)
17/12/19 15:20:13 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 127.0.0.1:53618 (size: 46.4 KB, free: 2004.1 MB)
17/12/19 15:20:13 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 230 (MapPartitionsRDD[472] at collect at utils.scala:196)
17/12/19 15:20:13 INFO TaskSchedulerImpl: Adding task set 230.0 with 1 tasks
17/12/19 15:20:13 INFO TaskSetManager: Starting task 0.0 in stage 230.0 (TID 174, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:20:13 INFO Executor: Running task 0.0 in stage 230.0 (TID 174)
17/12/19 15:20:13 INFO BlockManager: Found block rdd_468_0 locally
17/12/19 15:20:13 INFO Executor: Finished task 0.0 in stage 230.0 (TID 174). 1233 bytes result sent to driver
17/12/19 15:20:13 INFO TaskSetManager: Finished task 0.0 in stage 230.0 (TID 174) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:20:13 INFO TaskSchedulerImpl: Removed TaskSet 230.0, whose tasks have all completed, from pool 
17/12/19 15:20:13 INFO DAGScheduler: ResultStage 230 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:20:13 INFO DAGScheduler: Job 108 finished: collect at utils.scala:196, took 0.008878 s
17/12/19 15:20:13 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:20:13 INFO DAGScheduler: Got job 109 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:20:13 INFO DAGScheduler: Final stage: ResultStage 232 (collect at utils.scala:196)
17/12/19 15:20:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 231)
17/12/19 15:20:13 INFO DAGScheduler: Missing parents: List()
17/12/19 15:20:13 INFO DAGScheduler: Submitting ResultStage 232 (MapPartitionsRDD[472] at collect at utils.scala:196), which has no missing parents
17/12/19 15:20:13 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 112.5 KB, free 1999.9 MB)
17/12/19 15:20:13 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 46.4 KB, free 1999.9 MB)
17/12/19 15:20:13 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 127.0.0.1:53618 (size: 46.4 KB, free: 2004.1 MB)
17/12/19 15:20:13 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 232 (MapPartitionsRDD[472] at collect at utils.scala:196)
17/12/19 15:20:13 INFO TaskSchedulerImpl: Adding task set 232.0 with 1 tasks
17/12/19 15:20:13 INFO TaskSetManager: Starting task 0.0 in stage 232.0 (TID 175, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:20:13 INFO Executor: Running task 0.0 in stage 232.0 (TID 175)
17/12/19 15:20:13 INFO BlockManager: Found block rdd_468_1 locally
17/12/19 15:20:13 INFO Executor: Finished task 0.0 in stage 232.0 (TID 175). 1410 bytes result sent to driver
17/12/19 15:20:13 INFO TaskSetManager: Finished task 0.0 in stage 232.0 (TID 175) in 16 ms on localhost (executor driver) (1/1)
17/12/19 15:20:13 INFO TaskSchedulerImpl: Removed TaskSet 232.0, whose tasks have all completed, from pool 
17/12/19 15:20:13 INFO DAGScheduler: ResultStage 232 (collect at utils.scala:196) finished in 0.016 s
17/12/19 15:20:13 INFO DAGScheduler: Job 109 finished: collect at utils.scala:196, took 0.008128 s
17/12/19 15:20:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:13 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `ibudvtvqwi`
LIMIT 10
17/12/19 15:20:13 INFO CodeGenerator: Code generated in 8.332461 ms
17/12/19 15:20:13 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:20:13 INFO DAGScheduler: Got job 110 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:20:13 INFO DAGScheduler: Final stage: ResultStage 234 (collect at utils.scala:196)
17/12/19 15:20:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 233)
17/12/19 15:20:13 INFO DAGScheduler: Missing parents: List()
17/12/19 15:20:13 INFO DAGScheduler: Submitting ResultStage 234 (MapPartitionsRDD[475] at collect at utils.scala:196), which has no missing parents
17/12/19 15:20:13 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 13.3 KB, free 1999.9 MB)
17/12/19 15:20:13 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 6.2 KB, free 1999.9 MB)
17/12/19 15:20:13 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 127.0.0.1:53618 (size: 6.2 KB, free: 2004.1 MB)
17/12/19 15:20:13 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 234 (MapPartitionsRDD[475] at collect at utils.scala:196)
17/12/19 15:20:13 INFO TaskSchedulerImpl: Adding task set 234.0 with 1 tasks
17/12/19 15:20:13 INFO TaskSetManager: Starting task 0.0 in stage 234.0 (TID 176, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:20:13 INFO Executor: Running task 0.0 in stage 234.0 (TID 176)
17/12/19 15:20:13 INFO BlockManager: Found block rdd_451_0 locally
17/12/19 15:20:13 INFO Executor: Finished task 0.0 in stage 234.0 (TID 176). 1398 bytes result sent to driver
17/12/19 15:20:13 INFO TaskSetManager: Finished task 0.0 in stage 234.0 (TID 176) in 15 ms on localhost (executor driver) (1/1)
17/12/19 15:20:13 INFO TaskSchedulerImpl: Removed TaskSet 234.0, whose tasks have all completed, from pool 
17/12/19 15:20:13 INFO DAGScheduler: ResultStage 234 (collect at utils.scala:196) finished in 0.015 s
17/12/19 15:20:13 INFO DAGScheduler: Job 110 finished: collect at utils.scala:196, took 0.009142 s
17/12/19 15:20:13 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:20:13 INFO DAGScheduler: Got job 111 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:20:13 INFO DAGScheduler: Final stage: ResultStage 236 (collect at utils.scala:196)
17/12/19 15:20:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 235)
17/12/19 15:20:13 INFO DAGScheduler: Missing parents: List()
17/12/19 15:20:13 INFO DAGScheduler: Submitting ResultStage 236 (MapPartitionsRDD[475] at collect at utils.scala:196), which has no missing parents
17/12/19 15:20:13 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 13.3 KB, free 1999.8 MB)
17/12/19 15:20:13 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 6.2 KB, free 1999.8 MB)
17/12/19 15:20:13 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 127.0.0.1:53618 (size: 6.2 KB, free: 2004.1 MB)
17/12/19 15:20:13 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 236 (MapPartitionsRDD[475] at collect at utils.scala:196)
17/12/19 15:20:13 INFO TaskSchedulerImpl: Adding task set 236.0 with 1 tasks
17/12/19 15:20:13 INFO TaskSetManager: Starting task 0.0 in stage 236.0 (TID 177, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:20:13 INFO Executor: Running task 0.0 in stage 236.0 (TID 177)
17/12/19 15:20:13 INFO BlockManager: Found block rdd_451_1 locally
17/12/19 15:20:13 INFO Executor: Finished task 0.0 in stage 236.0 (TID 177). 1398 bytes result sent to driver
17/12/19 15:20:13 INFO TaskSetManager: Finished task 0.0 in stage 236.0 (TID 177) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:20:13 INFO TaskSchedulerImpl: Removed TaskSet 236.0, whose tasks have all completed, from pool 
17/12/19 15:20:13 INFO DAGScheduler: ResultStage 236 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:20:13 INFO DAGScheduler: Job 111 finished: collect at utils.scala:196, took 0.005726 s
17/12/19 15:20:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:13 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `wlbrgduvck`
17/12/19 15:20:13 INFO CodeGenerator: Code generated in 7.899376 ms
17/12/19 15:20:13 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:20:13 INFO DAGScheduler: Got job 112 (take at <unknown>:0) with 1 output partitions
17/12/19 15:20:13 INFO DAGScheduler: Final stage: ResultStage 238 (take at <unknown>:0)
17/12/19 15:20:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 237)
17/12/19 15:20:13 INFO DAGScheduler: Missing parents: List()
17/12/19 15:20:13 INFO DAGScheduler: Submitting ResultStage 238 (WorkerRDD[480] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:20:13 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 128.8 KB, free 1999.7 MB)
17/12/19 15:20:13 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 48.7 KB, free 1999.7 MB)
17/12/19 15:20:13 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 127.0.0.1:53618 (size: 48.7 KB, free: 2004.0 MB)
17/12/19 15:20:13 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 238 (WorkerRDD[480] at RDD at rdd.scala:18)
17/12/19 15:20:13 INFO TaskSchedulerImpl: Adding task set 238.0 with 1 tasks
17/12/19 15:20:13 INFO TaskSetManager: Starting task 0.0 in stage 238.0 (TID 178, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:20:13 INFO Executor: Running task 0.0 in stage 238.0 (TID 178)
17/12/19 15:20:13 INFO BlockManager: Found block rdd_451_0 locally
17/12/19 15:20:14 INFO MemoryStore: Block rdd_480_0 stored as values in memory (estimated size 608.0 B, free 1999.7 MB)
17/12/19 15:20:14 INFO BlockManagerInfo: Added rdd_480_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2004.0 MB)
17/12/19 15:20:14 INFO Executor: Finished task 0.0 in stage 238.0 (TID 178). 2686 bytes result sent to driver
17/12/19 15:20:14 INFO TaskSetManager: Finished task 0.0 in stage 238.0 (TID 178) in 973 ms on localhost (executor driver) (1/1)
17/12/19 15:20:14 INFO TaskSchedulerImpl: Removed TaskSet 238.0, whose tasks have all completed, from pool 
17/12/19 15:20:14 INFO DAGScheduler: ResultStage 238 (take at <unknown>:0) finished in 0.973 s
17/12/19 15:20:14 INFO DAGScheduler: Job 112 finished: take at <unknown>:0, took 0.971776 s
17/12/19 15:20:14 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:20:14 INFO DAGScheduler: Got job 113 (take at <unknown>:0) with 1 output partitions
17/12/19 15:20:14 INFO DAGScheduler: Final stage: ResultStage 240 (take at <unknown>:0)
17/12/19 15:20:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 239)
17/12/19 15:20:14 INFO DAGScheduler: Missing parents: List()
17/12/19 15:20:14 INFO DAGScheduler: Submitting ResultStage 240 (WorkerRDD[480] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:20:14 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 128.8 KB, free 1999.5 MB)
17/12/19 15:20:14 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 48.7 KB, free 1999.5 MB)
17/12/19 15:20:14 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 127.0.0.1:53618 (size: 48.7 KB, free: 2004.0 MB)
17/12/19 15:20:14 INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 240 (WorkerRDD[480] at RDD at rdd.scala:18)
17/12/19 15:20:14 INFO TaskSchedulerImpl: Adding task set 240.0 with 1 tasks
17/12/19 15:20:14 INFO TaskSetManager: Starting task 0.0 in stage 240.0 (TID 179, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:20:14 INFO Executor: Running task 0.0 in stage 240.0 (TID 179)
17/12/19 15:20:14 INFO BlockManager: Found block rdd_451_1 locally
17/12/19 15:20:15 INFO MemoryStore: Block rdd_480_1 stored as values in memory (estimated size 608.0 B, free 1999.5 MB)
17/12/19 15:20:15 INFO BlockManagerInfo: Added rdd_480_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2004.0 MB)
17/12/19 15:20:15 INFO Executor: Finished task 0.0 in stage 240.0 (TID 179). 2509 bytes result sent to driver
17/12/19 15:20:15 INFO TaskSetManager: Finished task 0.0 in stage 240.0 (TID 179) in 934 ms on localhost (executor driver) (1/1)
17/12/19 15:20:15 INFO TaskSchedulerImpl: Removed TaskSet 240.0, whose tasks have all completed, from pool 
17/12/19 15:20:15 INFO DAGScheduler: ResultStage 240 (take at <unknown>:0) finished in 0.934 s
17/12/19 15:20:15 INFO DAGScheduler: Job 113 finished: take at <unknown>:0, took 0.949674 s
17/12/19 15:20:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:15 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e849303008
17/12/19 15:20:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e849303008` AS `zzz30`
WHERE (0 = 1)
17/12/19 15:20:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e849303008`
17/12/19 15:20:15 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:20:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz31`
WHERE (0 = 1)
17/12/19 15:20:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:15 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 15:20:15 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:20:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz32`
WHERE (0 = 1)
17/12/19 15:20:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:20:15 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:20:15 INFO DAGScheduler: Got job 114 (collect at utils.scala:196) with 2 output partitions
17/12/19 15:20:15 INFO DAGScheduler: Final stage: ResultStage 242 (collect at utils.scala:196)
17/12/19 15:20:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 241)
17/12/19 15:20:15 INFO DAGScheduler: Missing parents: List()
17/12/19 15:20:15 INFO DAGScheduler: Submitting ResultStage 242 (MapPartitionsRDD[487] at collect at utils.scala:196), which has no missing parents
17/12/19 15:20:15 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 136.4 KB, free 1999.4 MB)
17/12/19 15:20:15 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 52.0 KB, free 1999.3 MB)
17/12/19 15:20:15 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 127.0.0.1:53618 (size: 52.0 KB, free: 2003.9 MB)
17/12/19 15:20:15 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:996
17/12/19 15:20:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 242 (MapPartitionsRDD[487] at collect at utils.scala:196)
17/12/19 15:20:15 INFO TaskSchedulerImpl: Adding task set 242.0 with 2 tasks
17/12/19 15:20:15 INFO TaskSetManager: Starting task 0.0 in stage 242.0 (TID 180, localhost, executor driver, partition 0, PROCESS_LOCAL, 5948 bytes)
17/12/19 15:20:15 INFO TaskSetManager: Starting task 1.0 in stage 242.0 (TID 181, localhost, executor driver, partition 1, PROCESS_LOCAL, 5948 bytes)
17/12/19 15:20:15 INFO Executor: Running task 1.0 in stage 242.0 (TID 181)
17/12/19 15:20:15 INFO Executor: Running task 0.0 in stage 242.0 (TID 180)
17/12/19 15:20:15 INFO BlockManager: Found block rdd_480_0 locally
17/12/19 15:20:15 INFO BlockManager: Found block rdd_480_1 locally
17/12/19 15:20:15 INFO Executor: Finished task 1.0 in stage 242.0 (TID 181). 1453 bytes result sent to driver
17/12/19 15:20:15 INFO Executor: Finished task 0.0 in stage 242.0 (TID 180). 1453 bytes result sent to driver
17/12/19 15:20:15 INFO TaskSetManager: Finished task 1.0 in stage 242.0 (TID 181) in 0 ms on localhost (executor driver) (1/2)
17/12/19 15:20:15 INFO TaskSetManager: Finished task 0.0 in stage 242.0 (TID 180) in 0 ms on localhost (executor driver) (2/2)
17/12/19 15:20:15 INFO TaskSchedulerImpl: Removed TaskSet 242.0, whose tasks have all completed, from pool 
17/12/19 15:20:15 INFO DAGScheduler: ResultStage 242 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:20:15 INFO DAGScheduler: Job 114 finished: collect at utils.scala:196, took 0.010308 s
17/12/19 15:20:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:20:15 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:20:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:20:15 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:20:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:20:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:20:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:20:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:20:15 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:20:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:20:15 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:20:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:20:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:20:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:20:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:20:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:20:15 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:20:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:20:15 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:20:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:20:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:20:15 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:23:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:23:41 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:23:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:23:41 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:23:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:23:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:23:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:23:41 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 15:23:41 INFO DAGScheduler: Got job 115 (collect at utils.scala:58) with 1 output partitions
17/12/19 15:23:41 INFO DAGScheduler: Final stage: ResultStage 243 (collect at utils.scala:58)
17/12/19 15:23:41 INFO DAGScheduler: Parents of final stage: List()
17/12/19 15:23:41 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:41 INFO DAGScheduler: Submitting ResultStage 243 (MapPartitionsRDD[496] at map at utils.scala:55), which has no missing parents
17/12/19 15:23:41 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 8.7 KB, free 1999.3 MB)
17/12/19 15:23:41 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1999.3 MB)
17/12/19 15:23:41 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.9 MB)
17/12/19 15:23:41 INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 243 (MapPartitionsRDD[496] at map at utils.scala:55)
17/12/19 15:23:41 INFO TaskSchedulerImpl: Adding task set 243.0 with 1 tasks
17/12/19 15:23:41 INFO TaskSetManager: Starting task 0.0 in stage 243.0 (TID 182, localhost, executor driver, partition 0, PROCESS_LOCAL, 7440 bytes)
17/12/19 15:23:41 INFO Executor: Running task 0.0 in stage 243.0 (TID 182)
17/12/19 15:23:41 INFO Executor: Finished task 0.0 in stage 243.0 (TID 182). 1331 bytes result sent to driver
17/12/19 15:23:41 INFO TaskSetManager: Finished task 0.0 in stage 243.0 (TID 182) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:23:41 INFO TaskSchedulerImpl: Removed TaskSet 243.0, whose tasks have all completed, from pool 
17/12/19 15:23:41 INFO DAGScheduler: ResultStage 243 (collect at utils.scala:58) finished in 0.000 s
17/12/19 15:23:41 INFO DAGScheduler: Job 115 finished: collect at utils.scala:58, took 0.006038 s
17/12/19 15:23:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:41 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:23:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:42 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 15:23:42 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 15:23:42 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 15:23:42 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 15:23:42 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 15:23:42 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 293.7 KB, free 1999.0 MB)
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1999.0 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2003.9 MB)
17/12/19 15:23:42 INFO SparkContext: Created broadcast 168 from sql at <unknown>:0
17/12/19 15:23:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 15:23:42 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 15:23:42 INFO DAGScheduler: Registering RDD 500 (sql at <unknown>:0)
17/12/19 15:23:42 INFO DAGScheduler: Registering RDD 505 (sql at <unknown>:0)
17/12/19 15:23:42 INFO DAGScheduler: Got job 116 (sql at <unknown>:0) with 1 output partitions
17/12/19 15:23:42 INFO DAGScheduler: Final stage: ResultStage 246 (sql at <unknown>:0)
17/12/19 15:23:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 245)
17/12/19 15:23:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 245)
17/12/19 15:23:42 INFO DAGScheduler: Submitting ShuffleMapStage 244 (MapPartitionsRDD[500] at sql at <unknown>:0), which has no missing parents
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 12.1 KB, free 1999.0 MB)
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1999.0 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2003.9 MB)
17/12/19 15:23:42 INFO SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 244 (MapPartitionsRDD[500] at sql at <unknown>:0)
17/12/19 15:23:42 INFO TaskSchedulerImpl: Adding task set 244.0 with 1 tasks
17/12/19 15:23:42 INFO TaskSetManager: Starting task 0.0 in stage 244.0 (TID 183, localhost, executor driver, partition 0, PROCESS_LOCAL, 6679 bytes)
17/12/19 15:23:42 INFO Executor: Running task 0.0 in stage 244.0 (TID 183)
17/12/19 15:23:42 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_6bd9205c2fbbcde70f4040baea156f4b53d11fa997fc5d60e050517967594add.csv, range: 0-466, partition values: [empty row]
17/12/19 15:23:42 INFO Executor: Finished task 0.0 in stage 244.0 (TID 183). 1632 bytes result sent to driver
17/12/19 15:23:42 INFO TaskSetManager: Finished task 0.0 in stage 244.0 (TID 183) in 15 ms on localhost (executor driver) (1/1)
17/12/19 15:23:42 INFO TaskSchedulerImpl: Removed TaskSet 244.0, whose tasks have all completed, from pool 
17/12/19 15:23:42 INFO DAGScheduler: ShuffleMapStage 244 (sql at <unknown>:0) finished in 0.015 s
17/12/19 15:23:42 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:23:42 INFO DAGScheduler: running: Set()
17/12/19 15:23:42 INFO DAGScheduler: waiting: Set(ShuffleMapStage 245, ResultStage 246)
17/12/19 15:23:42 INFO DAGScheduler: failed: Set()
17/12/19 15:23:42 INFO DAGScheduler: Submitting ShuffleMapStage 245 (MapPartitionsRDD[505] at sql at <unknown>:0), which has no missing parents
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 11.9 KB, free 1999.0 MB)
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1998.9 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2003.9 MB)
17/12/19 15:23:42 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:42 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 245 (MapPartitionsRDD[505] at sql at <unknown>:0)
17/12/19 15:23:42 INFO TaskSchedulerImpl: Adding task set 245.0 with 2 tasks
17/12/19 15:23:42 INFO TaskSetManager: Starting task 0.0 in stage 245.0 (TID 184, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/19 15:23:42 INFO TaskSetManager: Starting task 1.0 in stage 245.0 (TID 185, localhost, executor driver, partition 1, ANY, 5945 bytes)
17/12/19 15:23:42 INFO Executor: Running task 0.0 in stage 245.0 (TID 184)
17/12/19 15:23:42 INFO Executor: Running task 1.0 in stage 245.0 (TID 185)
17/12/19 15:23:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:23:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:23:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:23:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:23:42 INFO MemoryStore: Block rdd_502_0 stored as values in memory (estimated size 544.0 B, free 1998.9 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Added rdd_502_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2003.9 MB)
17/12/19 15:23:42 INFO MemoryStore: Block rdd_502_1 stored as values in memory (estimated size 544.0 B, free 1998.9 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Added rdd_502_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2003.9 MB)
17/12/19 15:23:42 INFO Executor: Finished task 0.0 in stage 245.0 (TID 184). 3064 bytes result sent to driver
17/12/19 15:23:42 INFO TaskSetManager: Finished task 0.0 in stage 245.0 (TID 184) in 16 ms on localhost (executor driver) (1/2)
17/12/19 15:23:42 INFO Executor: Finished task 1.0 in stage 245.0 (TID 185). 3064 bytes result sent to driver
17/12/19 15:23:42 INFO TaskSetManager: Finished task 1.0 in stage 245.0 (TID 185) in 16 ms on localhost (executor driver) (2/2)
17/12/19 15:23:42 INFO TaskSchedulerImpl: Removed TaskSet 245.0, whose tasks have all completed, from pool 
17/12/19 15:23:42 INFO DAGScheduler: ShuffleMapStage 245 (sql at <unknown>:0) finished in 0.016 s
17/12/19 15:23:42 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:23:42 INFO DAGScheduler: running: Set()
17/12/19 15:23:42 INFO DAGScheduler: waiting: Set(ResultStage 246)
17/12/19 15:23:42 INFO DAGScheduler: failed: Set()
17/12/19 15:23:42 INFO DAGScheduler: Submitting ResultStage 246 (MapPartitionsRDD[508] at sql at <unknown>:0), which has no missing parents
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 7.0 KB, free 1998.9 MB)
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1998.9 MB)
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7779
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7780
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7786
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7787
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7788
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7789
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7790
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7791
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7792
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7793
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7794
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7795
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7796
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7797
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7798
17/12/19 15:23:42 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2003.9 MB)
17/12/19 15:23:42 INFO SparkContext: Created broadcast 171 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 246 (MapPartitionsRDD[508] at sql at <unknown>:0)
17/12/19 15:23:42 INFO TaskSchedulerImpl: Adding task set 246.0 with 1 tasks
17/12/19 15:23:42 INFO ContextCleaner: Cleaned shuffle 37
17/12/19 15:23:42 INFO TaskSetManager: Starting task 0.0 in stage 246.0 (TID 186, localhost, executor driver, partition 0, ANY, 5956 bytes)
17/12/19 15:23:42 INFO Executor: Running task 0.0 in stage 246.0 (TID 186)
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2003.9 MB)
17/12/19 15:23:42 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:23:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.9 MB)
17/12/19 15:23:42 INFO Executor: Finished task 0.0 in stage 246.0 (TID 186). 1707 bytes result sent to driver
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.9 MB)
17/12/19 15:23:42 INFO TaskSetManager: Finished task 0.0 in stage 246.0 (TID 186) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:23:42 INFO TaskSchedulerImpl: Removed TaskSet 246.0, whose tasks have all completed, from pool 
17/12/19 15:23:42 INFO DAGScheduler: ResultStage 246 (sql at <unknown>:0) finished in 0.000 s
17/12/19 15:23:42 INFO DAGScheduler: Job 116 finished: sql at <unknown>:0, took 0.061108 s
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 127.0.0.1:53618 in memory (size: 44.6 KB, free: 2003.9 MB)
17/12/19 15:23:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 127.0.0.1:53618 in memory (size: 44.6 KB, free: 2004.0 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 127.0.0.1:53618 in memory (size: 46.4 KB, free: 2004.0 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 127.0.0.1:53618 in memory (size: 46.4 KB, free: 2004.1 MB)
17/12/19 15:23:42 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 127.0.0.1:53618 in memory (size: 6.2 KB, free: 2004.1 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 127.0.0.1:53618 in memory (size: 6.2 KB, free: 2004.1 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 127.0.0.1:53618 in memory (size: 48.7 KB, free: 2004.1 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 127.0.0.1:53618 in memory (size: 48.7 KB, free: 2004.2 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 127.0.0.1:53618 in memory (size: 52.0 KB, free: 2004.2 MB)
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 8564
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 8565
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.2 MB)
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 8614
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 8615
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 8621
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_169_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.2 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/19 15:23:42 INFO ContextCleaner: Cleaned accumulator 7967
17/12/19 15:23:42 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2004.3 MB)
17/12/19 15:23:42 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:23:42 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 39 is 145 bytes
17/12/19 15:23:42 INFO DAGScheduler: Registering RDD 512 (collect at utils.scala:196)
17/12/19 15:23:42 INFO DAGScheduler: Got job 117 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:23:42 INFO DAGScheduler: Final stage: ResultStage 249 (collect at utils.scala:196)
17/12/19 15:23:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 248)
17/12/19 15:23:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 248)
17/12/19 15:23:42 INFO DAGScheduler: Submitting ShuffleMapStage 248 (MapPartitionsRDD[512] at collect at utils.scala:196), which has no missing parents
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 11.9 KB, free 2000.2 MB)
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2000.2 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.2 MB)
17/12/19 15:23:42 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:42 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 248 (MapPartitionsRDD[512] at collect at utils.scala:196)
17/12/19 15:23:42 INFO TaskSchedulerImpl: Adding task set 248.0 with 2 tasks
17/12/19 15:23:42 INFO TaskSetManager: Starting task 0.0 in stage 248.0 (TID 187, localhost, executor driver, partition 0, PROCESS_LOCAL, 5937 bytes)
17/12/19 15:23:42 INFO TaskSetManager: Starting task 1.0 in stage 248.0 (TID 188, localhost, executor driver, partition 1, PROCESS_LOCAL, 5937 bytes)
17/12/19 15:23:42 INFO Executor: Running task 1.0 in stage 248.0 (TID 188)
17/12/19 15:23:42 INFO Executor: Running task 0.0 in stage 248.0 (TID 187)
17/12/19 15:23:42 INFO BlockManager: Found block rdd_502_1 locally
17/12/19 15:23:42 INFO BlockManager: Found block rdd_502_0 locally
17/12/19 15:23:42 INFO Executor: Finished task 0.0 in stage 248.0 (TID 187). 1792 bytes result sent to driver
17/12/19 15:23:42 INFO TaskSetManager: Finished task 0.0 in stage 248.0 (TID 187) in 0 ms on localhost (executor driver) (1/2)
17/12/19 15:23:42 INFO Executor: Finished task 1.0 in stage 248.0 (TID 188). 1792 bytes result sent to driver
17/12/19 15:23:42 INFO TaskSetManager: Finished task 1.0 in stage 248.0 (TID 188) in 0 ms on localhost (executor driver) (2/2)
17/12/19 15:23:42 INFO TaskSchedulerImpl: Removed TaskSet 248.0, whose tasks have all completed, from pool 
17/12/19 15:23:42 INFO DAGScheduler: ShuffleMapStage 248 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:23:42 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:23:42 INFO DAGScheduler: running: Set()
17/12/19 15:23:42 INFO DAGScheduler: waiting: Set(ResultStage 249)
17/12/19 15:23:42 INFO DAGScheduler: failed: Set()
17/12/19 15:23:42 INFO DAGScheduler: Submitting ResultStage 249 (MapPartitionsRDD[515] at collect at utils.scala:196), which has no missing parents
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 7.0 KB, free 2000.2 MB)
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2000.2 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.2 MB)
17/12/19 15:23:42 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 249 (MapPartitionsRDD[515] at collect at utils.scala:196)
17/12/19 15:23:42 INFO TaskSchedulerImpl: Adding task set 249.0 with 1 tasks
17/12/19 15:23:42 INFO TaskSetManager: Starting task 0.0 in stage 249.0 (TID 189, localhost, executor driver, partition 0, ANY, 5948 bytes)
17/12/19 15:23:42 INFO Executor: Running task 0.0 in stage 249.0 (TID 189)
17/12/19 15:23:42 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:23:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:23:42 INFO Executor: Finished task 0.0 in stage 249.0 (TID 189). 1865 bytes result sent to driver
17/12/19 15:23:42 INFO TaskSetManager: Finished task 0.0 in stage 249.0 (TID 189) in 16 ms on localhost (executor driver) (1/1)
17/12/19 15:23:42 INFO TaskSchedulerImpl: Removed TaskSet 249.0, whose tasks have all completed, from pool 
17/12/19 15:23:42 INFO DAGScheduler: ResultStage 249 (collect at utils.scala:196) finished in 0.016 s
17/12/19 15:23:42 INFO DAGScheduler: Job 117 finished: collect at utils.scala:196, took 0.018075 s
17/12/19 15:23:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz33`
WHERE (0 = 1)
17/12/19 15:23:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:23:42 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:23:42 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 39 is 145 bytes
17/12/19 15:23:42 INFO DAGScheduler: Got job 118 (take at <unknown>:0) with 1 output partitions
17/12/19 15:23:42 INFO DAGScheduler: Final stage: ResultStage 251 (take at <unknown>:0)
17/12/19 15:23:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 250)
17/12/19 15:23:42 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:42 INFO DAGScheduler: Submitting ResultStage 251 (WorkerRDD[519] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 111.0 KB, free 2000.1 MB)
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 45.0 KB, free 2000.0 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 127.0.0.1:53618 (size: 45.0 KB, free: 2004.2 MB)
17/12/19 15:23:42 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 251 (WorkerRDD[519] at RDD at rdd.scala:18)
17/12/19 15:23:42 INFO TaskSchedulerImpl: Adding task set 251.0 with 1 tasks
17/12/19 15:23:42 INFO TaskSetManager: Starting task 0.0 in stage 251.0 (TID 190, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:23:42 INFO Executor: Running task 0.0 in stage 251.0 (TID 190)
17/12/19 15:23:42 INFO BlockManager: Found block rdd_502_0 locally
17/12/19 15:23:42 INFO MemoryStore: Block rdd_519_0 stored as values in memory (estimated size 80.0 B, free 2000.0 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Added rdd_519_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.2 MB)
17/12/19 15:23:42 INFO Executor: Finished task 0.0 in stage 251.0 (TID 190). 2241 bytes result sent to driver
17/12/19 15:23:42 INFO TaskSetManager: Finished task 0.0 in stage 251.0 (TID 190) in 769 ms on localhost (executor driver) (1/1)
17/12/19 15:23:42 INFO TaskSchedulerImpl: Removed TaskSet 251.0, whose tasks have all completed, from pool 
17/12/19 15:23:42 INFO DAGScheduler: ResultStage 251 (take at <unknown>:0) finished in 0.769 s
17/12/19 15:23:42 INFO DAGScheduler: Job 118 finished: take at <unknown>:0, took 0.777701 s
17/12/19 15:23:42 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:23:42 INFO DAGScheduler: Got job 119 (take at <unknown>:0) with 1 output partitions
17/12/19 15:23:42 INFO DAGScheduler: Final stage: ResultStage 253 (take at <unknown>:0)
17/12/19 15:23:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 252)
17/12/19 15:23:42 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:42 INFO DAGScheduler: Submitting ResultStage 253 (WorkerRDD[519] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 111.0 KB, free 1999.9 MB)
17/12/19 15:23:42 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 45.0 KB, free 1999.9 MB)
17/12/19 15:23:42 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 127.0.0.1:53618 (size: 45.0 KB, free: 2004.2 MB)
17/12/19 15:23:42 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 253 (WorkerRDD[519] at RDD at rdd.scala:18)
17/12/19 15:23:42 INFO TaskSchedulerImpl: Adding task set 253.0 with 1 tasks
17/12/19 15:23:42 INFO TaskSetManager: Starting task 0.0 in stage 253.0 (TID 191, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:23:42 INFO Executor: Running task 0.0 in stage 253.0 (TID 191)
17/12/19 15:23:43 INFO BlockManager: Found block rdd_502_1 locally
17/12/19 15:23:43 INFO MemoryStore: Block rdd_519_1 stored as values in memory (estimated size 80.0 B, free 1999.9 MB)
17/12/19 15:23:43 INFO BlockManagerInfo: Added rdd_519_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.2 MB)
17/12/19 15:23:43 INFO Executor: Finished task 0.0 in stage 253.0 (TID 191). 2331 bytes result sent to driver
17/12/19 15:23:43 INFO TaskSetManager: Finished task 0.0 in stage 253.0 (TID 191) in 600 ms on localhost (executor driver) (1/1)
17/12/19 15:23:43 INFO TaskSchedulerImpl: Removed TaskSet 253.0, whose tasks have all completed, from pool 
17/12/19 15:23:43 INFO DAGScheduler: ResultStage 253 (take at <unknown>:0) finished in 0.600 s
17/12/19 15:23:43 INFO DAGScheduler: Job 119 finished: take at <unknown>:0, took 0.598418 s
17/12/19 15:23:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:43 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e8307744fd
17/12/19 15:23:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8307744fd` AS `zzz34`
WHERE (0 = 1)
17/12/19 15:23:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8307744fd`
LIMIT 10
17/12/19 15:23:43 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:23:43 INFO DAGScheduler: Got job 120 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:23:43 INFO DAGScheduler: Final stage: ResultStage 255 (collect at utils.scala:196)
17/12/19 15:23:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 254)
17/12/19 15:23:43 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:43 INFO DAGScheduler: Submitting ResultStage 255 (MapPartitionsRDD[523] at collect at utils.scala:196), which has no missing parents
17/12/19 15:23:43 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 114.0 KB, free 1999.8 MB)
17/12/19 15:23:43 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 46.8 KB, free 1999.7 MB)
17/12/19 15:23:43 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 127.0.0.1:53618 (size: 46.8 KB, free: 2004.1 MB)
17/12/19 15:23:43 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 255 (MapPartitionsRDD[523] at collect at utils.scala:196)
17/12/19 15:23:43 INFO TaskSchedulerImpl: Adding task set 255.0 with 1 tasks
17/12/19 15:23:43 INFO TaskSetManager: Starting task 0.0 in stage 255.0 (TID 192, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:23:43 INFO Executor: Running task 0.0 in stage 255.0 (TID 192)
17/12/19 15:23:43 INFO BlockManager: Found block rdd_519_0 locally
17/12/19 15:23:43 INFO Executor: Finished task 0.0 in stage 255.0 (TID 192). 1233 bytes result sent to driver
17/12/19 15:23:43 INFO TaskSetManager: Finished task 0.0 in stage 255.0 (TID 192) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:23:43 INFO TaskSchedulerImpl: Removed TaskSet 255.0, whose tasks have all completed, from pool 
17/12/19 15:23:43 INFO DAGScheduler: ResultStage 255 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:23:43 INFO DAGScheduler: Job 120 finished: collect at utils.scala:196, took 0.008718 s
17/12/19 15:23:43 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:23:43 INFO DAGScheduler: Got job 121 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:23:43 INFO DAGScheduler: Final stage: ResultStage 257 (collect at utils.scala:196)
17/12/19 15:23:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 256)
17/12/19 15:23:43 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:43 INFO DAGScheduler: Submitting ResultStage 257 (MapPartitionsRDD[523] at collect at utils.scala:196), which has no missing parents
17/12/19 15:23:43 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 114.0 KB, free 1999.6 MB)
17/12/19 15:23:43 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 46.8 KB, free 1999.6 MB)
17/12/19 15:23:43 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 127.0.0.1:53618 (size: 46.8 KB, free: 2004.1 MB)
17/12/19 15:23:43 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 257 (MapPartitionsRDD[523] at collect at utils.scala:196)
17/12/19 15:23:43 INFO TaskSchedulerImpl: Adding task set 257.0 with 1 tasks
17/12/19 15:23:43 INFO TaskSetManager: Starting task 0.0 in stage 257.0 (TID 193, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:23:43 INFO Executor: Running task 0.0 in stage 257.0 (TID 193)
17/12/19 15:23:43 INFO BlockManager: Found block rdd_519_1 locally
17/12/19 15:23:43 INFO Executor: Finished task 0.0 in stage 257.0 (TID 193). 1233 bytes result sent to driver
17/12/19 15:23:43 INFO TaskSetManager: Finished task 0.0 in stage 257.0 (TID 193) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:23:43 INFO TaskSchedulerImpl: Removed TaskSet 257.0, whose tasks have all completed, from pool 
17/12/19 15:23:43 INFO DAGScheduler: ResultStage 257 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:23:43 INFO DAGScheduler: Job 121 finished: collect at utils.scala:196, took 0.007916 s
17/12/19 15:23:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:43 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `cradcmhlcl`
LIMIT 10
17/12/19 15:23:43 INFO CodeGenerator: Code generated in 8.746291 ms
17/12/19 15:23:43 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:23:43 INFO DAGScheduler: Got job 122 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:23:43 INFO DAGScheduler: Final stage: ResultStage 259 (collect at utils.scala:196)
17/12/19 15:23:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 258)
17/12/19 15:23:43 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:43 INFO DAGScheduler: Submitting ResultStage 259 (MapPartitionsRDD[526] at collect at utils.scala:196), which has no missing parents
17/12/19 15:23:43 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 13.3 KB, free 1999.6 MB)
17/12/19 15:23:43 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 6.2 KB, free 1999.6 MB)
17/12/19 15:23:43 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 127.0.0.1:53618 (size: 6.2 KB, free: 2004.1 MB)
17/12/19 15:23:43 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 259 (MapPartitionsRDD[526] at collect at utils.scala:196)
17/12/19 15:23:43 INFO TaskSchedulerImpl: Adding task set 259.0 with 1 tasks
17/12/19 15:23:43 INFO TaskSetManager: Starting task 0.0 in stage 259.0 (TID 194, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:23:43 INFO Executor: Running task 0.0 in stage 259.0 (TID 194)
17/12/19 15:23:43 INFO BlockManager: Found block rdd_502_0 locally
17/12/19 15:23:43 INFO Executor: Finished task 0.0 in stage 259.0 (TID 194). 1395 bytes result sent to driver
17/12/19 15:23:43 INFO DAGScheduler: ResultStage 259 (collect at utils.scala:196) finished in 0.016 s
17/12/19 15:23:43 INFO DAGScheduler: Job 122 finished: collect at utils.scala:196, took 0.011609 s
17/12/19 15:23:43 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:23:43 INFO DAGScheduler: Got job 123 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:23:43 INFO DAGScheduler: Final stage: ResultStage 261 (collect at utils.scala:196)
17/12/19 15:23:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 260)
17/12/19 15:23:43 INFO TaskSetManager: Finished task 0.0 in stage 259.0 (TID 194) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:23:43 INFO TaskSchedulerImpl: Removed TaskSet 259.0, whose tasks have all completed, from pool 
17/12/19 15:23:43 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:43 INFO DAGScheduler: Submitting ResultStage 261 (MapPartitionsRDD[526] at collect at utils.scala:196), which has no missing parents
17/12/19 15:23:43 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 13.3 KB, free 1999.5 MB)
17/12/19 15:23:43 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 6.2 KB, free 1999.5 MB)
17/12/19 15:23:43 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 127.0.0.1:53618 (size: 6.2 KB, free: 2004.1 MB)
17/12/19 15:23:43 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 261 (MapPartitionsRDD[526] at collect at utils.scala:196)
17/12/19 15:23:43 INFO TaskSchedulerImpl: Adding task set 261.0 with 1 tasks
17/12/19 15:23:43 INFO TaskSetManager: Starting task 0.0 in stage 261.0 (TID 195, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:23:43 INFO Executor: Running task 0.0 in stage 261.0 (TID 195)
17/12/19 15:23:43 INFO BlockManager: Found block rdd_502_1 locally
17/12/19 15:23:43 INFO Executor: Finished task 0.0 in stage 261.0 (TID 195). 1574 bytes result sent to driver
17/12/19 15:23:43 INFO TaskSetManager: Finished task 0.0 in stage 261.0 (TID 195) in 15 ms on localhost (executor driver) (1/1)
17/12/19 15:23:43 INFO TaskSchedulerImpl: Removed TaskSet 261.0, whose tasks have all completed, from pool 
17/12/19 15:23:43 INFO DAGScheduler: ResultStage 261 (collect at utils.scala:196) finished in 0.015 s
17/12/19 15:23:43 INFO DAGScheduler: Job 123 finished: collect at utils.scala:196, took 0.010766 s
17/12/19 15:23:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:43 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `xuprjaekbu`
17/12/19 15:23:43 INFO CodeGenerator: Code generated in 8.133477 ms
17/12/19 15:23:43 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:23:43 INFO DAGScheduler: Got job 124 (take at <unknown>:0) with 1 output partitions
17/12/19 15:23:43 INFO DAGScheduler: Final stage: ResultStage 263 (take at <unknown>:0)
17/12/19 15:23:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 262)
17/12/19 15:23:43 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:43 INFO DAGScheduler: Submitting ResultStage 263 (WorkerRDD[531] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:23:43 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 130.4 KB, free 1999.4 MB)
17/12/19 15:23:43 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 49.5 KB, free 1999.4 MB)
17/12/19 15:23:43 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 127.0.0.1:53618 (size: 49.5 KB, free: 2004.0 MB)
17/12/19 15:23:43 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 263 (WorkerRDD[531] at RDD at rdd.scala:18)
17/12/19 15:23:43 INFO TaskSchedulerImpl: Adding task set 263.0 with 1 tasks
17/12/19 15:23:43 INFO TaskSetManager: Starting task 0.0 in stage 263.0 (TID 196, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:23:43 INFO Executor: Running task 0.0 in stage 263.0 (TID 196)
17/12/19 15:23:43 INFO BlockManager: Found block rdd_502_0 locally
17/12/19 15:23:44 INFO MemoryStore: Block rdd_531_0 stored as values in memory (estimated size 608.0 B, free 1999.4 MB)
17/12/19 15:23:44 INFO BlockManagerInfo: Added rdd_531_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2004.0 MB)
17/12/19 15:23:44 INFO Executor: Finished task 0.0 in stage 263.0 (TID 196). 2596 bytes result sent to driver
17/12/19 15:23:44 INFO TaskSetManager: Finished task 0.0 in stage 263.0 (TID 196) in 932 ms on localhost (executor driver) (1/1)
17/12/19 15:23:44 INFO TaskSchedulerImpl: Removed TaskSet 263.0, whose tasks have all completed, from pool 
17/12/19 15:23:44 INFO DAGScheduler: ResultStage 263 (take at <unknown>:0) finished in 0.932 s
17/12/19 15:23:44 INFO DAGScheduler: Job 124 finished: take at <unknown>:0, took 0.948169 s
17/12/19 15:23:44 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:23:44 INFO DAGScheduler: Got job 125 (take at <unknown>:0) with 1 output partitions
17/12/19 15:23:44 INFO DAGScheduler: Final stage: ResultStage 265 (take at <unknown>:0)
17/12/19 15:23:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 264)
17/12/19 15:23:44 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:44 INFO DAGScheduler: Submitting ResultStage 265 (WorkerRDD[531] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:23:44 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 130.4 KB, free 1999.2 MB)
17/12/19 15:23:44 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 49.5 KB, free 1999.2 MB)
17/12/19 15:23:44 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 127.0.0.1:53618 (size: 49.5 KB, free: 2004.0 MB)
17/12/19 15:23:44 INFO SparkContext: Created broadcast 181 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 265 (WorkerRDD[531] at RDD at rdd.scala:18)
17/12/19 15:23:44 INFO TaskSchedulerImpl: Adding task set 265.0 with 1 tasks
17/12/19 15:23:44 INFO TaskSetManager: Starting task 0.0 in stage 265.0 (TID 197, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:23:44 INFO Executor: Running task 0.0 in stage 265.0 (TID 197)
17/12/19 15:23:44 INFO BlockManager: Found block rdd_502_1 locally
17/12/19 15:23:45 INFO MemoryStore: Block rdd_531_1 stored as values in memory (estimated size 608.0 B, free 1999.2 MB)
17/12/19 15:23:45 INFO BlockManagerInfo: Added rdd_531_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2004.0 MB)
17/12/19 15:23:45 INFO Executor: Finished task 0.0 in stage 265.0 (TID 197). 2509 bytes result sent to driver
17/12/19 15:23:45 INFO TaskSetManager: Finished task 0.0 in stage 265.0 (TID 197) in 935 ms on localhost (executor driver) (1/1)
17/12/19 15:23:45 INFO TaskSchedulerImpl: Removed TaskSet 265.0, whose tasks have all completed, from pool 
17/12/19 15:23:45 INFO DAGScheduler: ResultStage 265 (take at <unknown>:0) finished in 0.935 s
17/12/19 15:23:45 INFO DAGScheduler: Job 125 finished: take at <unknown>:0, took 0.945159 s
17/12/19 15:23:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:45 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e874f37358
17/12/19 15:23:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e874f37358` AS `zzz35`
WHERE (0 = 1)
17/12/19 15:23:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e874f37358`
17/12/19 15:23:45 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:23:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz36`
WHERE (0 = 1)
17/12/19 15:23:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 15:23:45 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:23:45 INFO DAGScheduler: Got job 126 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:23:45 INFO DAGScheduler: Final stage: ResultStage 267 (collect at utils.scala:196)
17/12/19 15:23:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 266)
17/12/19 15:23:45 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:45 INFO DAGScheduler: Submitting ResultStage 267 (MapPartitionsRDD[536] at collect at utils.scala:196), which has no missing parents
17/12/19 15:23:45 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 134.3 KB, free 1999.1 MB)
17/12/19 15:23:45 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 51.5 KB, free 1999.0 MB)
17/12/19 15:23:45 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 127.0.0.1:53618 (size: 51.5 KB, free: 2003.9 MB)
17/12/19 15:23:45 INFO SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 267 (MapPartitionsRDD[536] at collect at utils.scala:196)
17/12/19 15:23:45 INFO TaskSchedulerImpl: Adding task set 267.0 with 1 tasks
17/12/19 15:23:45 INFO TaskSetManager: Starting task 0.0 in stage 267.0 (TID 198, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:23:45 INFO Executor: Running task 0.0 in stage 267.0 (TID 198)
17/12/19 15:23:45 INFO BlockManager: Found block rdd_531_0 locally
17/12/19 15:23:45 INFO Executor: Finished task 0.0 in stage 267.0 (TID 198). 1458 bytes result sent to driver
17/12/19 15:23:45 INFO TaskSetManager: Finished task 0.0 in stage 267.0 (TID 198) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:23:45 INFO TaskSchedulerImpl: Removed TaskSet 267.0, whose tasks have all completed, from pool 
17/12/19 15:23:45 INFO DAGScheduler: ResultStage 267 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:23:45 INFO DAGScheduler: Job 126 finished: collect at utils.scala:196, took 0.007800 s
17/12/19 15:23:45 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:23:45 INFO DAGScheduler: Got job 127 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:23:45 INFO DAGScheduler: Final stage: ResultStage 269 (collect at utils.scala:196)
17/12/19 15:23:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 268)
17/12/19 15:23:45 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:45 INFO DAGScheduler: Submitting ResultStage 269 (MapPartitionsRDD[536] at collect at utils.scala:196), which has no missing parents
17/12/19 15:23:45 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 134.3 KB, free 1998.9 MB)
17/12/19 15:23:45 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 51.5 KB, free 1998.8 MB)
17/12/19 15:23:45 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 127.0.0.1:53618 (size: 51.5 KB, free: 2003.9 MB)
17/12/19 15:23:45 INFO SparkContext: Created broadcast 183 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 269 (MapPartitionsRDD[536] at collect at utils.scala:196)
17/12/19 15:23:45 INFO TaskSchedulerImpl: Adding task set 269.0 with 1 tasks
17/12/19 15:23:45 INFO TaskSetManager: Starting task 0.0 in stage 269.0 (TID 199, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:23:45 INFO Executor: Running task 0.0 in stage 269.0 (TID 199)
17/12/19 15:23:45 INFO BlockManager: Found block rdd_531_1 locally
17/12/19 15:23:45 INFO Executor: Finished task 0.0 in stage 269.0 (TID 199). 1458 bytes result sent to driver
17/12/19 15:23:45 INFO TaskSetManager: Finished task 0.0 in stage 269.0 (TID 199) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:23:45 INFO TaskSchedulerImpl: Removed TaskSet 269.0, whose tasks have all completed, from pool 
17/12/19 15:23:45 INFO DAGScheduler: ResultStage 269 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:23:45 INFO DAGScheduler: Job 127 finished: collect at utils.scala:196, took 0.008073 s
17/12/19 15:23:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:45 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 15:23:45 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:23:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz37`
WHERE (0 = 1)
17/12/19 15:23:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 15:23:45 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:23:45 INFO DAGScheduler: Got job 128 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:23:45 INFO DAGScheduler: Final stage: ResultStage 271 (collect at utils.scala:196)
17/12/19 15:23:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 270)
17/12/19 15:23:45 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:45 INFO DAGScheduler: Submitting ResultStage 271 (MapPartitionsRDD[540] at collect at utils.scala:196), which has no missing parents
17/12/19 15:23:45 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 137.8 KB, free 1998.7 MB)
17/12/19 15:23:45 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 52.8 KB, free 1998.6 MB)
17/12/19 15:23:45 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 127.0.0.1:53618 (size: 52.8 KB, free: 2003.8 MB)
17/12/19 15:23:45 INFO SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 271 (MapPartitionsRDD[540] at collect at utils.scala:196)
17/12/19 15:23:45 INFO TaskSchedulerImpl: Adding task set 271.0 with 1 tasks
17/12/19 15:23:45 INFO TaskSetManager: Starting task 0.0 in stage 271.0 (TID 200, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:23:45 INFO Executor: Running task 0.0 in stage 271.0 (TID 200)
17/12/19 15:23:45 INFO BlockManager: Found block rdd_531_0 locally
17/12/19 15:23:45 INFO Executor: Finished task 0.0 in stage 271.0 (TID 200). 1423 bytes result sent to driver
17/12/19 15:23:45 INFO TaskSetManager: Finished task 0.0 in stage 271.0 (TID 200) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:23:45 INFO TaskSchedulerImpl: Removed TaskSet 271.0, whose tasks have all completed, from pool 
17/12/19 15:23:45 INFO DAGScheduler: ResultStage 271 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:23:45 INFO DAGScheduler: Job 128 finished: collect at utils.scala:196, took 0.007988 s
17/12/19 15:23:45 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:23:45 INFO DAGScheduler: Got job 129 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:23:45 INFO DAGScheduler: Final stage: ResultStage 273 (collect at utils.scala:196)
17/12/19 15:23:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 272)
17/12/19 15:23:45 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:45 INFO DAGScheduler: Submitting ResultStage 273 (MapPartitionsRDD[540] at collect at utils.scala:196), which has no missing parents
17/12/19 15:23:45 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 137.8 KB, free 1998.5 MB)
17/12/19 15:23:45 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 52.8 KB, free 1998.4 MB)
17/12/19 15:23:45 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 127.0.0.1:53618 (size: 52.8 KB, free: 2003.8 MB)
17/12/19 15:23:45 INFO SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 273 (MapPartitionsRDD[540] at collect at utils.scala:196)
17/12/19 15:23:45 INFO TaskSchedulerImpl: Adding task set 273.0 with 1 tasks
17/12/19 15:23:45 INFO TaskSetManager: Starting task 0.0 in stage 273.0 (TID 201, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:23:45 INFO Executor: Running task 0.0 in stage 273.0 (TID 201)
17/12/19 15:23:45 INFO BlockManager: Found block rdd_531_1 locally
17/12/19 15:23:45 INFO Executor: Finished task 0.0 in stage 273.0 (TID 201). 1588 bytes result sent to driver
17/12/19 15:23:45 INFO TaskSetManager: Finished task 0.0 in stage 273.0 (TID 201) in 6 ms on localhost (executor driver) (1/1)
17/12/19 15:23:45 INFO TaskSchedulerImpl: Removed TaskSet 273.0, whose tasks have all completed, from pool 
17/12/19 15:23:45 INFO DAGScheduler: ResultStage 273 (collect at utils.scala:196) finished in 0.006 s
17/12/19 15:23:45 INFO DAGScheduler: Job 129 finished: collect at utils.scala:196, took 0.008001 s
17/12/19 15:23:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:23:46 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:23:46 INFO DAGScheduler: Got job 130 (collect at utils.scala:196) with 2 output partitions
17/12/19 15:23:46 INFO DAGScheduler: Final stage: ResultStage 275 (collect at utils.scala:196)
17/12/19 15:23:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 274)
17/12/19 15:23:46 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:46 INFO DAGScheduler: Submitting ResultStage 275 (MapPartitionsRDD[543] at collect at utils.scala:196), which has no missing parents
17/12/19 15:23:46 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 137.9 KB, free 1998.3 MB)
17/12/19 15:23:46 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 52.9 KB, free 1998.3 MB)
17/12/19 15:23:46 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 127.0.0.1:53618 (size: 52.9 KB, free: 2003.7 MB)
17/12/19 15:23:46 INFO SparkContext: Created broadcast 186 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 275 (MapPartitionsRDD[543] at collect at utils.scala:196)
17/12/19 15:23:46 INFO TaskSchedulerImpl: Adding task set 275.0 with 2 tasks
17/12/19 15:23:46 INFO TaskSetManager: Starting task 0.0 in stage 275.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 5948 bytes)
17/12/19 15:23:46 INFO TaskSetManager: Starting task 1.0 in stage 275.0 (TID 203, localhost, executor driver, partition 1, PROCESS_LOCAL, 5948 bytes)
17/12/19 15:23:46 INFO Executor: Running task 0.0 in stage 275.0 (TID 202)
17/12/19 15:23:46 INFO Executor: Running task 1.0 in stage 275.0 (TID 203)
17/12/19 15:23:46 INFO BlockManager: Found block rdd_531_1 locally
17/12/19 15:23:46 INFO BlockManager: Found block rdd_531_0 locally
17/12/19 15:23:46 INFO Executor: Finished task 1.0 in stage 275.0 (TID 203). 1446 bytes result sent to driver
17/12/19 15:23:46 INFO Executor: Finished task 0.0 in stage 275.0 (TID 202). 1447 bytes result sent to driver
17/12/19 15:23:46 INFO TaskSetManager: Finished task 1.0 in stage 275.0 (TID 203) in 0 ms on localhost (executor driver) (1/2)
17/12/19 15:23:46 INFO DAGScheduler: ResultStage 275 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:23:46 INFO DAGScheduler: Job 130 finished: collect at utils.scala:196, took 0.012832 s
17/12/19 15:23:46 INFO TaskSetManager: Finished task 0.0 in stage 275.0 (TID 202) in 0 ms on localhost (executor driver) (2/2)
17/12/19 15:23:46 INFO TaskSchedulerImpl: Removed TaskSet 275.0, whose tasks have all completed, from pool 
17/12/19 15:23:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:23:46 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:23:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:23:46 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:23:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:23:46 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:23:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:23:46 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 15:23:46 INFO DAGScheduler: Got job 131 (collect at utils.scala:58) with 1 output partitions
17/12/19 15:23:46 INFO DAGScheduler: Final stage: ResultStage 276 (collect at utils.scala:58)
17/12/19 15:23:46 INFO DAGScheduler: Parents of final stage: List()
17/12/19 15:23:46 INFO DAGScheduler: Missing parents: List()
17/12/19 15:23:46 INFO DAGScheduler: Submitting ResultStage 276 (MapPartitionsRDD[549] at map at utils.scala:55), which has no missing parents
17/12/19 15:23:46 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 8.7 KB, free 1998.3 MB)
17/12/19 15:23:46 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1998.2 MB)
17/12/19 15:23:46 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.7 MB)
17/12/19 15:23:46 INFO SparkContext: Created broadcast 187 from broadcast at DAGScheduler.scala:996
17/12/19 15:23:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 276 (MapPartitionsRDD[549] at map at utils.scala:55)
17/12/19 15:23:46 INFO TaskSchedulerImpl: Adding task set 276.0 with 1 tasks
17/12/19 15:23:46 INFO TaskSetManager: Starting task 0.0 in stage 276.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 7584 bytes)
17/12/19 15:23:46 INFO Executor: Running task 0.0 in stage 276.0 (TID 204)
17/12/19 15:23:46 INFO Executor: Finished task 0.0 in stage 276.0 (TID 204). 1387 bytes result sent to driver
17/12/19 15:23:46 INFO TaskSetManager: Finished task 0.0 in stage 276.0 (TID 204) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:23:46 INFO TaskSchedulerImpl: Removed TaskSet 276.0, whose tasks have all completed, from pool 
17/12/19 15:23:46 INFO DAGScheduler: ResultStage 276 (collect at utils.scala:58) finished in 0.000 s
17/12/19 15:23:46 INFO DAGScheduler: Job 131 finished: collect at utils.scala:58, took 0.005924 s
17/12/19 15:23:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:23:46 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:23:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:23:46 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:23:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:23:46 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:23:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:23:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:23:46 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:23:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:23:46 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:23:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:23:46 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:23:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:23:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:23:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:23:46 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:23:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:23:46 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:23:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:23:46 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:23:46 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:24:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:24:12 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:24:12 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:24:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:24:12 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:24:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:24:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:24:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:27:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:27:14 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:27:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:27:14 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:27:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:27:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:27:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:27:14 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 15:27:14 INFO DAGScheduler: Got job 132 (collect at utils.scala:58) with 1 output partitions
17/12/19 15:27:14 INFO DAGScheduler: Final stage: ResultStage 277 (collect at utils.scala:58)
17/12/19 15:27:14 INFO DAGScheduler: Parents of final stage: List()
17/12/19 15:27:14 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:14 INFO DAGScheduler: Submitting ResultStage 277 (MapPartitionsRDD[559] at map at utils.scala:55), which has no missing parents
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 8.7 KB, free 1998.2 MB)
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1998.2 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.7 MB)
17/12/19 15:27:14 INFO SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 277 (MapPartitionsRDD[559] at map at utils.scala:55)
17/12/19 15:27:14 INFO TaskSchedulerImpl: Adding task set 277.0 with 1 tasks
17/12/19 15:27:14 INFO TaskSetManager: Starting task 0.0 in stage 277.0 (TID 205, localhost, executor driver, partition 0, PROCESS_LOCAL, 7584 bytes)
17/12/19 15:27:14 INFO Executor: Running task 0.0 in stage 277.0 (TID 205)
17/12/19 15:27:14 INFO Executor: Finished task 0.0 in stage 277.0 (TID 205). 1553 bytes result sent to driver
17/12/19 15:27:14 INFO TaskSetManager: Finished task 0.0 in stage 277.0 (TID 205) in 5 ms on localhost (executor driver) (1/1)
17/12/19 15:27:14 INFO TaskSchedulerImpl: Removed TaskSet 277.0, whose tasks have all completed, from pool 
17/12/19 15:27:14 INFO DAGScheduler: ResultStage 277 (collect at utils.scala:58) finished in 0.005 s
17/12/19 15:27:14 INFO DAGScheduler: Job 132 finished: collect at utils.scala:58, took 0.007400 s
17/12/19 15:27:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:14 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:27:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:14 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 15:27:14 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 15:27:14 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 15:27:14 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 15:27:14 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 15:27:14 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 293.7 KB, free 1997.9 MB)
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1997.9 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2003.7 MB)
17/12/19 15:27:14 INFO SparkContext: Created broadcast 189 from sql at <unknown>:0
17/12/19 15:27:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 15:27:14 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 15:27:14 INFO DAGScheduler: Registering RDD 563 (sql at <unknown>:0)
17/12/19 15:27:14 INFO DAGScheduler: Registering RDD 568 (sql at <unknown>:0)
17/12/19 15:27:14 INFO DAGScheduler: Got job 133 (sql at <unknown>:0) with 1 output partitions
17/12/19 15:27:14 INFO DAGScheduler: Final stage: ResultStage 280 (sql at <unknown>:0)
17/12/19 15:27:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 279)
17/12/19 15:27:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 279)
17/12/19 15:27:14 INFO DAGScheduler: Submitting ShuffleMapStage 278 (MapPartitionsRDD[563] at sql at <unknown>:0), which has no missing parents
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 12.1 KB, free 1997.9 MB)
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 8622
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1997.9 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2003.7 MB)
17/12/19 15:27:14 INFO SparkContext: Created broadcast 190 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 278 (MapPartitionsRDD[563] at sql at <unknown>:0)
17/12/19 15:27:14 INFO TaskSchedulerImpl: Adding task set 278.0 with 1 tasks
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.7 MB)
17/12/19 15:27:14 INFO TaskSetManager: Starting task 0.0 in stage 278.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 6679 bytes)
17/12/19 15:27:14 INFO Executor: Running task 0.0 in stage 278.0 (TID 206)
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.7 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 127.0.0.1:53618 in memory (size: 45.0 KB, free: 2003.7 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 127.0.0.1:53618 in memory (size: 45.0 KB, free: 2003.8 MB)
17/12/19 15:27:14 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_f7447a1979ca4f1822eab1dd24b9b56e6ae77e9fa0aab7dc30c2767e3db1e8f1.csv, range: 0-462, partition values: [empty row]
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 127.0.0.1:53618 in memory (size: 46.8 KB, free: 2003.8 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 127.0.0.1:53618 in memory (size: 46.8 KB, free: 2003.9 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 127.0.0.1:53618 in memory (size: 6.2 KB, free: 2003.9 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 127.0.0.1:53618 in memory (size: 6.2 KB, free: 2003.9 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 127.0.0.1:53618 in memory (size: 49.5 KB, free: 2003.9 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 127.0.0.1:53618 in memory (size: 49.5 KB, free: 2004.0 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 127.0.0.1:53618 in memory (size: 51.5 KB, free: 2004.0 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 127.0.0.1:53618 in memory (size: 51.5 KB, free: 2004.1 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 127.0.0.1:53618 in memory (size: 52.8 KB, free: 2004.1 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 127.0.0.1:53618 in memory (size: 52.8 KB, free: 2004.2 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 127.0.0.1:53618 in memory (size: 52.9 KB, free: 2004.2 MB)
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 9594
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 9595
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.2 MB)
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 9644
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 9645
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_188_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.2 MB)
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 9694
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 9695
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 9701
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 8623
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 8624
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 8625
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 8626
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 8627
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 8628
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 8629
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 8630
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 8631
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 8632
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 8633
17/12/19 15:27:14 INFO ContextCleaner: Cleaned shuffle 40
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2004.2 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/19 15:27:14 INFO ContextCleaner: Cleaned accumulator 8802
17/12/19 15:27:14 INFO Executor: Finished task 0.0 in stage 278.0 (TID 206). 1553 bytes result sent to driver
17/12/19 15:27:14 INFO TaskSetManager: Finished task 0.0 in stage 278.0 (TID 206) in 31 ms on localhost (executor driver) (1/1)
17/12/19 15:27:14 INFO TaskSchedulerImpl: Removed TaskSet 278.0, whose tasks have all completed, from pool 
17/12/19 15:27:14 INFO DAGScheduler: ShuffleMapStage 278 (sql at <unknown>:0) finished in 0.031 s
17/12/19 15:27:14 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:27:14 INFO DAGScheduler: running: Set()
17/12/19 15:27:14 INFO DAGScheduler: waiting: Set(ShuffleMapStage 279, ResultStage 280)
17/12/19 15:27:14 INFO DAGScheduler: failed: Set()
17/12/19 15:27:14 INFO DAGScheduler: Submitting ShuffleMapStage 279 (MapPartitionsRDD[568] at sql at <unknown>:0), which has no missing parents
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 11.9 KB, free 1999.9 MB)
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1999.9 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.2 MB)
17/12/19 15:27:14 INFO SparkContext: Created broadcast 191 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 279 (MapPartitionsRDD[568] at sql at <unknown>:0)
17/12/19 15:27:14 INFO TaskSchedulerImpl: Adding task set 279.0 with 2 tasks
17/12/19 15:27:14 INFO TaskSetManager: Starting task 0.0 in stage 279.0 (TID 207, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/19 15:27:14 INFO TaskSetManager: Starting task 1.0 in stage 279.0 (TID 208, localhost, executor driver, partition 1, ANY, 5945 bytes)
17/12/19 15:27:14 INFO Executor: Running task 0.0 in stage 279.0 (TID 207)
17/12/19 15:27:14 INFO Executor: Running task 1.0 in stage 279.0 (TID 208)
17/12/19 15:27:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:27:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:27:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:27:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:27:14 INFO MemoryStore: Block rdd_565_1 stored as values in memory (estimated size 544.0 B, free 1999.9 MB)
17/12/19 15:27:14 INFO MemoryStore: Block rdd_565_0 stored as values in memory (estimated size 544.0 B, free 1999.9 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Added rdd_565_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.2 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Added rdd_565_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.2 MB)
17/12/19 15:27:14 INFO Executor: Finished task 0.0 in stage 279.0 (TID 207). 2906 bytes result sent to driver
17/12/19 15:27:14 INFO TaskSetManager: Finished task 0.0 in stage 279.0 (TID 207) in 0 ms on localhost (executor driver) (1/2)
17/12/19 15:27:14 INFO Executor: Finished task 1.0 in stage 279.0 (TID 208). 3064 bytes result sent to driver
17/12/19 15:27:14 INFO TaskSetManager: Finished task 1.0 in stage 279.0 (TID 208) in 16 ms on localhost (executor driver) (2/2)
17/12/19 15:27:14 INFO TaskSchedulerImpl: Removed TaskSet 279.0, whose tasks have all completed, from pool 
17/12/19 15:27:14 INFO DAGScheduler: ShuffleMapStage 279 (sql at <unknown>:0) finished in 0.016 s
17/12/19 15:27:14 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:27:14 INFO DAGScheduler: running: Set()
17/12/19 15:27:14 INFO DAGScheduler: waiting: Set(ResultStage 280)
17/12/19 15:27:14 INFO DAGScheduler: failed: Set()
17/12/19 15:27:14 INFO DAGScheduler: Submitting ResultStage 280 (MapPartitionsRDD[571] at sql at <unknown>:0), which has no missing parents
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 7.0 KB, free 1999.9 MB)
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1999.9 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.2 MB)
17/12/19 15:27:14 INFO SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 280 (MapPartitionsRDD[571] at sql at <unknown>:0)
17/12/19 15:27:14 INFO TaskSchedulerImpl: Adding task set 280.0 with 1 tasks
17/12/19 15:27:14 INFO TaskSetManager: Starting task 0.0 in stage 280.0 (TID 209, localhost, executor driver, partition 0, ANY, 5956 bytes)
17/12/19 15:27:14 INFO Executor: Running task 0.0 in stage 280.0 (TID 209)
17/12/19 15:27:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:27:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:27:14 INFO Executor: Finished task 0.0 in stage 280.0 (TID 209). 1707 bytes result sent to driver
17/12/19 15:27:14 INFO DAGScheduler: ResultStage 280 (sql at <unknown>:0) finished in 0.000 s
17/12/19 15:27:14 INFO TaskSetManager: Finished task 0.0 in stage 280.0 (TID 209) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:27:14 INFO DAGScheduler: Job 133 finished: sql at <unknown>:0, took 0.059997 s
17/12/19 15:27:14 INFO TaskSchedulerImpl: Removed TaskSet 280.0, whose tasks have all completed, from pool 
17/12/19 15:27:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:14 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 15:27:14 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:27:14 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 145 bytes
17/12/19 15:27:14 INFO DAGScheduler: Registering RDD 575 (collect at utils.scala:196)
17/12/19 15:27:14 INFO DAGScheduler: Got job 134 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:27:14 INFO DAGScheduler: Final stage: ResultStage 283 (collect at utils.scala:196)
17/12/19 15:27:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 282)
17/12/19 15:27:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 282)
17/12/19 15:27:14 INFO DAGScheduler: Submitting ShuffleMapStage 282 (MapPartitionsRDD[575] at collect at utils.scala:196), which has no missing parents
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 11.9 KB, free 1999.9 MB)
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1999.9 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.2 MB)
17/12/19 15:27:14 INFO SparkContext: Created broadcast 193 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 282 (MapPartitionsRDD[575] at collect at utils.scala:196)
17/12/19 15:27:14 INFO TaskSchedulerImpl: Adding task set 282.0 with 2 tasks
17/12/19 15:27:14 INFO TaskSetManager: Starting task 0.0 in stage 282.0 (TID 210, localhost, executor driver, partition 0, PROCESS_LOCAL, 5937 bytes)
17/12/19 15:27:14 INFO TaskSetManager: Starting task 1.0 in stage 282.0 (TID 211, localhost, executor driver, partition 1, PROCESS_LOCAL, 5937 bytes)
17/12/19 15:27:14 INFO Executor: Running task 0.0 in stage 282.0 (TID 210)
17/12/19 15:27:14 INFO Executor: Running task 1.0 in stage 282.0 (TID 211)
17/12/19 15:27:14 INFO BlockManager: Found block rdd_565_0 locally
17/12/19 15:27:14 INFO BlockManager: Found block rdd_565_1 locally
17/12/19 15:27:14 INFO Executor: Finished task 0.0 in stage 282.0 (TID 210). 1792 bytes result sent to driver
17/12/19 15:27:14 INFO TaskSetManager: Finished task 0.0 in stage 282.0 (TID 210) in 0 ms on localhost (executor driver) (1/2)
17/12/19 15:27:14 INFO Executor: Finished task 1.0 in stage 282.0 (TID 211). 1792 bytes result sent to driver
17/12/19 15:27:14 INFO TaskSetManager: Finished task 1.0 in stage 282.0 (TID 211) in 0 ms on localhost (executor driver) (2/2)
17/12/19 15:27:14 INFO TaskSchedulerImpl: Removed TaskSet 282.0, whose tasks have all completed, from pool 
17/12/19 15:27:14 INFO DAGScheduler: ShuffleMapStage 282 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:27:14 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:27:14 INFO DAGScheduler: running: Set()
17/12/19 15:27:14 INFO DAGScheduler: waiting: Set(ResultStage 283)
17/12/19 15:27:14 INFO DAGScheduler: failed: Set()
17/12/19 15:27:14 INFO DAGScheduler: Submitting ResultStage 283 (MapPartitionsRDD[578] at collect at utils.scala:196), which has no missing parents
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 7.0 KB, free 1999.9 MB)
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1999.9 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.2 MB)
17/12/19 15:27:14 INFO SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 283 (MapPartitionsRDD[578] at collect at utils.scala:196)
17/12/19 15:27:14 INFO TaskSchedulerImpl: Adding task set 283.0 with 1 tasks
17/12/19 15:27:14 INFO TaskSetManager: Starting task 0.0 in stage 283.0 (TID 212, localhost, executor driver, partition 0, ANY, 5948 bytes)
17/12/19 15:27:14 INFO Executor: Running task 0.0 in stage 283.0 (TID 212)
17/12/19 15:27:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:27:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:27:14 INFO Executor: Finished task 0.0 in stage 283.0 (TID 212). 1707 bytes result sent to driver
17/12/19 15:27:14 INFO TaskSetManager: Finished task 0.0 in stage 283.0 (TID 212) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:27:14 INFO TaskSchedulerImpl: Removed TaskSet 283.0, whose tasks have all completed, from pool 
17/12/19 15:27:14 INFO DAGScheduler: ResultStage 283 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:27:14 INFO DAGScheduler: Job 134 finished: collect at utils.scala:196, took 0.017898 s
17/12/19 15:27:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz38`
WHERE (0 = 1)
17/12/19 15:27:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:27:14 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:27:14 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 145 bytes
17/12/19 15:27:14 INFO DAGScheduler: Got job 135 (take at <unknown>:0) with 1 output partitions
17/12/19 15:27:14 INFO DAGScheduler: Final stage: ResultStage 285 (take at <unknown>:0)
17/12/19 15:27:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 284)
17/12/19 15:27:14 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:14 INFO DAGScheduler: Submitting ResultStage 285 (WorkerRDD[582] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 111.3 KB, free 1999.8 MB)
17/12/19 15:27:14 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 45.0 KB, free 1999.7 MB)
17/12/19 15:27:14 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 127.0.0.1:53618 (size: 45.0 KB, free: 2004.2 MB)
17/12/19 15:27:14 INFO SparkContext: Created broadcast 195 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 285 (WorkerRDD[582] at RDD at rdd.scala:18)
17/12/19 15:27:14 INFO TaskSchedulerImpl: Adding task set 285.0 with 1 tasks
17/12/19 15:27:14 INFO TaskSetManager: Starting task 0.0 in stage 285.0 (TID 213, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:27:14 INFO Executor: Running task 0.0 in stage 285.0 (TID 213)
17/12/19 15:27:14 INFO BlockManager: Found block rdd_565_0 locally
17/12/19 15:27:15 INFO MemoryStore: Block rdd_582_0 stored as values in memory (estimated size 80.0 B, free 1999.7 MB)
17/12/19 15:27:15 INFO BlockManagerInfo: Added rdd_582_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.2 MB)
17/12/19 15:27:15 INFO Executor: Finished task 0.0 in stage 285.0 (TID 213). 2154 bytes result sent to driver
17/12/19 15:27:15 INFO DAGScheduler: ResultStage 285 (take at <unknown>:0) finished in 0.651 s
17/12/19 15:27:15 INFO DAGScheduler: Job 135 finished: take at <unknown>:0, took 0.645973 s
17/12/19 15:27:15 INFO TaskSetManager: Finished task 0.0 in stage 285.0 (TID 213) in 651 ms on localhost (executor driver) (1/1)
17/12/19 15:27:15 INFO TaskSchedulerImpl: Removed TaskSet 285.0, whose tasks have all completed, from pool 
17/12/19 15:27:15 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:27:15 INFO DAGScheduler: Got job 136 (take at <unknown>:0) with 1 output partitions
17/12/19 15:27:15 INFO DAGScheduler: Final stage: ResultStage 287 (take at <unknown>:0)
17/12/19 15:27:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 286)
17/12/19 15:27:15 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:15 INFO DAGScheduler: Submitting ResultStage 287 (WorkerRDD[582] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:27:15 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 111.3 KB, free 1999.6 MB)
17/12/19 15:27:15 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 45.0 KB, free 1999.6 MB)
17/12/19 15:27:15 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 127.0.0.1:53618 (size: 45.0 KB, free: 2004.1 MB)
17/12/19 15:27:15 INFO SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 287 (WorkerRDD[582] at RDD at rdd.scala:18)
17/12/19 15:27:15 INFO TaskSchedulerImpl: Adding task set 287.0 with 1 tasks
17/12/19 15:27:15 INFO TaskSetManager: Starting task 0.0 in stage 287.0 (TID 214, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:27:15 INFO Executor: Running task 0.0 in stage 287.0 (TID 214)
17/12/19 15:27:15 INFO BlockManager: Found block rdd_565_1 locally
17/12/19 15:27:16 INFO MemoryStore: Block rdd_582_1 stored as values in memory (estimated size 80.0 B, free 1999.6 MB)
17/12/19 15:27:16 INFO BlockManagerInfo: Added rdd_582_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.1 MB)
17/12/19 15:27:16 INFO Executor: Finished task 0.0 in stage 287.0 (TID 214). 2241 bytes result sent to driver
17/12/19 15:27:16 INFO TaskSetManager: Finished task 0.0 in stage 287.0 (TID 214) in 649 ms on localhost (executor driver) (1/1)
17/12/19 15:27:16 INFO TaskSchedulerImpl: Removed TaskSet 287.0, whose tasks have all completed, from pool 
17/12/19 15:27:16 INFO DAGScheduler: ResultStage 287 (take at <unknown>:0) finished in 0.650 s
17/12/19 15:27:16 INFO DAGScheduler: Job 136 finished: take at <unknown>:0, took 0.660091 s
17/12/19 15:27:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:16 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e8cb242d9
17/12/19 15:27:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8cb242d9` AS `zzz39`
WHERE (0 = 1)
17/12/19 15:27:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8cb242d9`
LIMIT 10
17/12/19 15:27:16 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:27:16 INFO DAGScheduler: Got job 137 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:27:16 INFO DAGScheduler: Final stage: ResultStage 289 (collect at utils.scala:196)
17/12/19 15:27:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 288)
17/12/19 15:27:16 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:16 INFO DAGScheduler: Submitting ResultStage 289 (MapPartitionsRDD[586] at collect at utils.scala:196), which has no missing parents
17/12/19 15:27:16 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 114.4 KB, free 1999.4 MB)
17/12/19 15:27:16 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 46.8 KB, free 1999.4 MB)
17/12/19 15:27:16 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 127.0.0.1:53618 (size: 46.8 KB, free: 2004.1 MB)
17/12/19 15:27:16 INFO SparkContext: Created broadcast 197 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 289 (MapPartitionsRDD[586] at collect at utils.scala:196)
17/12/19 15:27:16 INFO TaskSchedulerImpl: Adding task set 289.0 with 1 tasks
17/12/19 15:27:16 INFO TaskSetManager: Starting task 0.0 in stage 289.0 (TID 215, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:27:16 INFO Executor: Running task 0.0 in stage 289.0 (TID 215)
17/12/19 15:27:16 INFO BlockManager: Found block rdd_582_0 locally
17/12/19 15:27:16 INFO Executor: Finished task 0.0 in stage 289.0 (TID 215). 1233 bytes result sent to driver
17/12/19 15:27:16 INFO TaskSetManager: Finished task 0.0 in stage 289.0 (TID 215) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:27:16 INFO TaskSchedulerImpl: Removed TaskSet 289.0, whose tasks have all completed, from pool 
17/12/19 15:27:16 INFO DAGScheduler: ResultStage 289 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:27:16 INFO DAGScheduler: Job 137 finished: collect at utils.scala:196, took 0.008205 s
17/12/19 15:27:16 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:27:16 INFO DAGScheduler: Got job 138 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:27:16 INFO DAGScheduler: Final stage: ResultStage 291 (collect at utils.scala:196)
17/12/19 15:27:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 290)
17/12/19 15:27:16 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:16 INFO DAGScheduler: Submitting ResultStage 291 (MapPartitionsRDD[586] at collect at utils.scala:196), which has no missing parents
17/12/19 15:27:16 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 114.4 KB, free 1999.3 MB)
17/12/19 15:27:16 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 46.8 KB, free 1999.2 MB)
17/12/19 15:27:16 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 127.0.0.1:53618 (size: 46.8 KB, free: 2004.0 MB)
17/12/19 15:27:16 INFO SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 291 (MapPartitionsRDD[586] at collect at utils.scala:196)
17/12/19 15:27:16 INFO TaskSchedulerImpl: Adding task set 291.0 with 1 tasks
17/12/19 15:27:16 INFO TaskSetManager: Starting task 0.0 in stage 291.0 (TID 216, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:27:16 INFO Executor: Running task 0.0 in stage 291.0 (TID 216)
17/12/19 15:27:16 INFO BlockManager: Found block rdd_582_1 locally
17/12/19 15:27:16 INFO Executor: Finished task 0.0 in stage 291.0 (TID 216). 1410 bytes result sent to driver
17/12/19 15:27:16 INFO TaskSetManager: Finished task 0.0 in stage 291.0 (TID 216) in 16 ms on localhost (executor driver) (1/1)
17/12/19 15:27:16 INFO TaskSchedulerImpl: Removed TaskSet 291.0, whose tasks have all completed, from pool 
17/12/19 15:27:16 INFO DAGScheduler: ResultStage 291 (collect at utils.scala:196) finished in 0.016 s
17/12/19 15:27:16 INFO DAGScheduler: Job 138 finished: collect at utils.scala:196, took 0.007347 s
17/12/19 15:27:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:16 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `qrqoxpxmbe`
17/12/19 15:27:16 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:27:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz40`
WHERE (0 = 1)
17/12/19 15:27:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 15:27:16 INFO CodeGenerator: Code generated in 7.496875 ms
17/12/19 15:27:16 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:27:16 INFO DAGScheduler: Got job 139 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:27:16 INFO DAGScheduler: Final stage: ResultStage 293 (collect at utils.scala:196)
17/12/19 15:27:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 292)
17/12/19 15:27:16 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:16 INFO DAGScheduler: Submitting ResultStage 293 (MapPartitionsRDD[590] at collect at utils.scala:196), which has no missing parents
17/12/19 15:27:16 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 13.3 KB, free 1999.2 MB)
17/12/19 15:27:16 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 6.2 KB, free 1999.2 MB)
17/12/19 15:27:16 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 127.0.0.1:53618 (size: 6.2 KB, free: 2004.0 MB)
17/12/19 15:27:16 INFO SparkContext: Created broadcast 199 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 293 (MapPartitionsRDD[590] at collect at utils.scala:196)
17/12/19 15:27:16 INFO TaskSchedulerImpl: Adding task set 293.0 with 1 tasks
17/12/19 15:27:16 INFO TaskSetManager: Starting task 0.0 in stage 293.0 (TID 217, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:27:16 INFO Executor: Running task 0.0 in stage 293.0 (TID 217)
17/12/19 15:27:16 INFO BlockManager: Found block rdd_565_0 locally
17/12/19 15:27:16 INFO Executor: Finished task 0.0 in stage 293.0 (TID 217). 1396 bytes result sent to driver
17/12/19 15:27:16 INFO TaskSetManager: Finished task 0.0 in stage 293.0 (TID 217) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:27:16 INFO TaskSchedulerImpl: Removed TaskSet 293.0, whose tasks have all completed, from pool 
17/12/19 15:27:16 INFO DAGScheduler: ResultStage 293 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:27:16 INFO DAGScheduler: Job 139 finished: collect at utils.scala:196, took 0.006776 s
17/12/19 15:27:16 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:27:16 INFO DAGScheduler: Got job 140 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:27:16 INFO DAGScheduler: Final stage: ResultStage 295 (collect at utils.scala:196)
17/12/19 15:27:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 294)
17/12/19 15:27:16 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:16 INFO DAGScheduler: Submitting ResultStage 295 (MapPartitionsRDD[590] at collect at utils.scala:196), which has no missing parents
17/12/19 15:27:16 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 13.3 KB, free 1999.2 MB)
17/12/19 15:27:16 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 6.2 KB, free 1999.2 MB)
17/12/19 15:27:16 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 127.0.0.1:53618 (size: 6.2 KB, free: 2004.0 MB)
17/12/19 15:27:16 INFO SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 295 (MapPartitionsRDD[590] at collect at utils.scala:196)
17/12/19 15:27:16 INFO TaskSchedulerImpl: Adding task set 295.0 with 1 tasks
17/12/19 15:27:16 INFO TaskSetManager: Starting task 0.0 in stage 295.0 (TID 218, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:27:16 INFO Executor: Running task 0.0 in stage 295.0 (TID 218)
17/12/19 15:27:16 INFO BlockManager: Found block rdd_565_1 locally
17/12/19 15:27:16 INFO Executor: Finished task 0.0 in stage 295.0 (TID 218). 1397 bytes result sent to driver
17/12/19 15:27:16 INFO TaskSetManager: Finished task 0.0 in stage 295.0 (TID 218) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:27:16 INFO TaskSchedulerImpl: Removed TaskSet 295.0, whose tasks have all completed, from pool 
17/12/19 15:27:16 INFO DAGScheduler: ResultStage 295 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:27:16 INFO DAGScheduler: Job 140 finished: collect at utils.scala:196, took 0.006507 s
17/12/19 15:27:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:27:16 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:27:16 INFO DAGScheduler: Got job 141 (take at <unknown>:0) with 1 output partitions
17/12/19 15:27:16 INFO DAGScheduler: Final stage: ResultStage 297 (take at <unknown>:0)
17/12/19 15:27:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 296)
17/12/19 15:27:16 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:16 INFO DAGScheduler: Submitting ResultStage 297 (WorkerRDD[595] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:27:16 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 119.5 KB, free 1999.1 MB)
17/12/19 15:27:16 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 47.4 KB, free 1999.0 MB)
17/12/19 15:27:16 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 127.0.0.1:53618 (size: 47.4 KB, free: 2004.0 MB)
17/12/19 15:27:16 INFO SparkContext: Created broadcast 201 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 297 (WorkerRDD[595] at RDD at rdd.scala:18)
17/12/19 15:27:16 INFO TaskSchedulerImpl: Adding task set 297.0 with 1 tasks
17/12/19 15:27:16 INFO TaskSetManager: Starting task 0.0 in stage 297.0 (TID 219, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:27:16 INFO Executor: Running task 0.0 in stage 297.0 (TID 219)
17/12/19 15:27:16 INFO BlockManager: Found block rdd_565_0 locally
17/12/19 15:27:16 INFO MemoryStore: Block rdd_595_0 stored as values in memory (estimated size 608.0 B, free 1999.0 MB)
17/12/19 15:27:16 INFO BlockManagerInfo: Added rdd_595_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2004.0 MB)
17/12/19 15:27:16 INFO Executor: Finished task 0.0 in stage 297.0 (TID 219). 2509 bytes result sent to driver
17/12/19 15:27:16 INFO TaskSetManager: Finished task 0.0 in stage 297.0 (TID 219) in 651 ms on localhost (executor driver) (1/1)
17/12/19 15:27:16 INFO TaskSchedulerImpl: Removed TaskSet 297.0, whose tasks have all completed, from pool 
17/12/19 15:27:16 INFO DAGScheduler: ResultStage 297 (take at <unknown>:0) finished in 0.651 s
17/12/19 15:27:16 INFO DAGScheduler: Job 141 finished: take at <unknown>:0, took 0.652054 s
17/12/19 15:27:16 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:27:16 INFO DAGScheduler: Got job 142 (take at <unknown>:0) with 1 output partitions
17/12/19 15:27:16 INFO DAGScheduler: Final stage: ResultStage 299 (take at <unknown>:0)
17/12/19 15:27:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 298)
17/12/19 15:27:16 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:16 INFO DAGScheduler: Submitting ResultStage 299 (WorkerRDD[595] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:27:16 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 119.5 KB, free 1998.9 MB)
17/12/19 15:27:16 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 47.4 KB, free 1998.9 MB)
17/12/19 15:27:16 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 127.0.0.1:53618 (size: 47.4 KB, free: 2003.9 MB)
17/12/19 15:27:16 INFO SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 299 (WorkerRDD[595] at RDD at rdd.scala:18)
17/12/19 15:27:16 INFO TaskSchedulerImpl: Adding task set 299.0 with 1 tasks
17/12/19 15:27:16 INFO TaskSetManager: Starting task 0.0 in stage 299.0 (TID 220, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:27:16 INFO Executor: Running task 0.0 in stage 299.0 (TID 220)
17/12/19 15:27:16 INFO BlockManager: Found block rdd_565_1 locally
17/12/19 15:27:17 INFO MemoryStore: Block rdd_595_1 stored as values in memory (estimated size 608.0 B, free 1998.9 MB)
17/12/19 15:27:17 INFO BlockManagerInfo: Added rdd_595_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 15:27:17 INFO Executor: Finished task 0.0 in stage 299.0 (TID 220). 2509 bytes result sent to driver
17/12/19 15:27:17 INFO TaskSetManager: Finished task 0.0 in stage 299.0 (TID 220) in 699 ms on localhost (executor driver) (1/1)
17/12/19 15:27:17 INFO TaskSchedulerImpl: Removed TaskSet 299.0, whose tasks have all completed, from pool 
17/12/19 15:27:17 INFO DAGScheduler: ResultStage 299 (take at <unknown>:0) finished in 0.699 s
17/12/19 15:27:17 INFO DAGScheduler: Job 142 finished: take at <unknown>:0, took 0.695381 s
17/12/19 15:27:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:17 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e825615179
17/12/19 15:27:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e825615179` AS `zzz41`
WHERE (0 = 1)
17/12/19 15:27:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e825615179`
17/12/19 15:27:17 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:27:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz42`
WHERE (0 = 1)
17/12/19 15:27:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 15:27:17 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:27:17 INFO DAGScheduler: Got job 143 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:27:17 INFO DAGScheduler: Final stage: ResultStage 301 (collect at utils.scala:196)
17/12/19 15:27:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 300)
17/12/19 15:27:17 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:17 INFO DAGScheduler: Submitting ResultStage 301 (MapPartitionsRDD[600] at collect at utils.scala:196), which has no missing parents
17/12/19 15:27:17 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 123.4 KB, free 1998.8 MB)
17/12/19 15:27:17 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 49.4 KB, free 1998.7 MB)
17/12/19 15:27:17 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 127.0.0.1:53618 (size: 49.4 KB, free: 2003.9 MB)
17/12/19 15:27:17 INFO SparkContext: Created broadcast 203 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 301 (MapPartitionsRDD[600] at collect at utils.scala:196)
17/12/19 15:27:17 INFO TaskSchedulerImpl: Adding task set 301.0 with 1 tasks
17/12/19 15:27:17 INFO TaskSetManager: Starting task 0.0 in stage 301.0 (TID 221, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:27:17 INFO Executor: Running task 0.0 in stage 301.0 (TID 221)
17/12/19 15:27:17 INFO BlockManager: Found block rdd_595_0 locally
17/12/19 15:27:17 INFO Executor: Finished task 0.0 in stage 301.0 (TID 221). 1458 bytes result sent to driver
17/12/19 15:27:17 INFO TaskSetManager: Finished task 0.0 in stage 301.0 (TID 221) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:27:17 INFO TaskSchedulerImpl: Removed TaskSet 301.0, whose tasks have all completed, from pool 
17/12/19 15:27:17 INFO DAGScheduler: ResultStage 301 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:27:17 INFO DAGScheduler: Job 143 finished: collect at utils.scala:196, took 0.007582 s
17/12/19 15:27:17 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:27:17 INFO DAGScheduler: Got job 144 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:27:17 INFO DAGScheduler: Final stage: ResultStage 303 (collect at utils.scala:196)
17/12/19 15:27:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 302)
17/12/19 15:27:17 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:17 INFO DAGScheduler: Submitting ResultStage 303 (MapPartitionsRDD[600] at collect at utils.scala:196), which has no missing parents
17/12/19 15:27:17 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 123.4 KB, free 1998.6 MB)
17/12/19 15:27:17 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 49.4 KB, free 1998.5 MB)
17/12/19 15:27:17 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 127.0.0.1:53618 (size: 49.4 KB, free: 2003.8 MB)
17/12/19 15:27:17 INFO SparkContext: Created broadcast 204 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 303 (MapPartitionsRDD[600] at collect at utils.scala:196)
17/12/19 15:27:17 INFO TaskSchedulerImpl: Adding task set 303.0 with 1 tasks
17/12/19 15:27:17 INFO TaskSetManager: Starting task 0.0 in stage 303.0 (TID 222, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:27:17 INFO Executor: Running task 0.0 in stage 303.0 (TID 222)
17/12/19 15:27:17 INFO BlockManager: Found block rdd_595_1 locally
17/12/19 15:27:17 INFO Executor: Finished task 0.0 in stage 303.0 (TID 222). 1458 bytes result sent to driver
17/12/19 15:27:17 INFO TaskSetManager: Finished task 0.0 in stage 303.0 (TID 222) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:27:17 INFO TaskSchedulerImpl: Removed TaskSet 303.0, whose tasks have all completed, from pool 
17/12/19 15:27:17 INFO DAGScheduler: ResultStage 303 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:27:17 INFO DAGScheduler: Job 144 finished: collect at utils.scala:196, took 0.008138 s
17/12/19 15:27:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:17 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 15:27:17 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:27:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz43`
WHERE (0 = 1)
17/12/19 15:27:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 15:27:17 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:27:17 INFO DAGScheduler: Got job 145 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:27:17 INFO DAGScheduler: Final stage: ResultStage 305 (collect at utils.scala:196)
17/12/19 15:27:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 304)
17/12/19 15:27:17 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:17 INFO DAGScheduler: Submitting ResultStage 305 (MapPartitionsRDD[604] at collect at utils.scala:196), which has no missing parents
17/12/19 15:27:17 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 126.9 KB, free 1998.4 MB)
17/12/19 15:27:17 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 50.6 KB, free 1998.4 MB)
17/12/19 15:27:17 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 127.0.0.1:53618 (size: 50.6 KB, free: 2003.8 MB)
17/12/19 15:27:17 INFO SparkContext: Created broadcast 205 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 305 (MapPartitionsRDD[604] at collect at utils.scala:196)
17/12/19 15:27:17 INFO TaskSchedulerImpl: Adding task set 305.0 with 1 tasks
17/12/19 15:27:17 INFO TaskSetManager: Starting task 0.0 in stage 305.0 (TID 223, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:27:17 INFO Executor: Running task 0.0 in stage 305.0 (TID 223)
17/12/19 15:27:17 INFO BlockManager: Found block rdd_595_0 locally
17/12/19 15:27:17 INFO Executor: Finished task 0.0 in stage 305.0 (TID 223). 1415 bytes result sent to driver
17/12/19 15:27:17 INFO TaskSetManager: Finished task 0.0 in stage 305.0 (TID 223) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:27:17 INFO TaskSchedulerImpl: Removed TaskSet 305.0, whose tasks have all completed, from pool 
17/12/19 15:27:17 INFO DAGScheduler: ResultStage 305 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:27:17 INFO DAGScheduler: Job 145 finished: collect at utils.scala:196, took 0.009064 s
17/12/19 15:27:17 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:27:17 INFO DAGScheduler: Got job 146 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:27:17 INFO DAGScheduler: Final stage: ResultStage 307 (collect at utils.scala:196)
17/12/19 15:27:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 306)
17/12/19 15:27:17 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:17 INFO DAGScheduler: Submitting ResultStage 307 (MapPartitionsRDD[604] at collect at utils.scala:196), which has no missing parents
17/12/19 15:27:17 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 126.9 KB, free 1998.2 MB)
17/12/19 15:27:17 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 50.6 KB, free 1998.2 MB)
17/12/19 15:27:17 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 127.0.0.1:53618 (size: 50.6 KB, free: 2003.7 MB)
17/12/19 15:27:17 INFO SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 307 (MapPartitionsRDD[604] at collect at utils.scala:196)
17/12/19 15:27:17 INFO TaskSchedulerImpl: Adding task set 307.0 with 1 tasks
17/12/19 15:27:17 INFO TaskSetManager: Starting task 0.0 in stage 307.0 (TID 224, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:27:17 INFO Executor: Running task 0.0 in stage 307.0 (TID 224)
17/12/19 15:27:17 INFO BlockManager: Found block rdd_595_1 locally
17/12/19 15:27:17 INFO Executor: Finished task 0.0 in stage 307.0 (TID 224). 1594 bytes result sent to driver
17/12/19 15:27:17 INFO TaskSetManager: Finished task 0.0 in stage 307.0 (TID 224) in 15 ms on localhost (executor driver) (1/1)
17/12/19 15:27:17 INFO TaskSchedulerImpl: Removed TaskSet 307.0, whose tasks have all completed, from pool 
17/12/19 15:27:17 INFO DAGScheduler: ResultStage 307 (collect at utils.scala:196) finished in 0.015 s
17/12/19 15:27:17 INFO DAGScheduler: Job 146 finished: collect at utils.scala:196, took 0.010007 s
17/12/19 15:27:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:27:17 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:27:17 INFO DAGScheduler: Got job 147 (collect at utils.scala:196) with 2 output partitions
17/12/19 15:27:17 INFO DAGScheduler: Final stage: ResultStage 309 (collect at utils.scala:196)
17/12/19 15:27:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 308)
17/12/19 15:27:17 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:17 INFO DAGScheduler: Submitting ResultStage 309 (MapPartitionsRDD[607] at collect at utils.scala:196), which has no missing parents
17/12/19 15:27:17 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 127.0 KB, free 1998.1 MB)
17/12/19 15:27:17 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 50.7 KB, free 1998.0 MB)
17/12/19 15:27:17 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 127.0.0.1:53618 (size: 50.7 KB, free: 2003.7 MB)
17/12/19 15:27:17 INFO SparkContext: Created broadcast 207 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 309 (MapPartitionsRDD[607] at collect at utils.scala:196)
17/12/19 15:27:17 INFO TaskSchedulerImpl: Adding task set 309.0 with 2 tasks
17/12/19 15:27:17 INFO TaskSetManager: Starting task 0.0 in stage 309.0 (TID 225, localhost, executor driver, partition 0, PROCESS_LOCAL, 5948 bytes)
17/12/19 15:27:17 INFO TaskSetManager: Starting task 1.0 in stage 309.0 (TID 226, localhost, executor driver, partition 1, PROCESS_LOCAL, 5948 bytes)
17/12/19 15:27:17 INFO Executor: Running task 0.0 in stage 309.0 (TID 225)
17/12/19 15:27:17 INFO Executor: Running task 1.0 in stage 309.0 (TID 226)
17/12/19 15:27:17 INFO BlockManager: Found block rdd_595_0 locally
17/12/19 15:27:17 INFO BlockManager: Found block rdd_595_1 locally
17/12/19 15:27:17 INFO Executor: Finished task 0.0 in stage 309.0 (TID 225). 1439 bytes result sent to driver
17/12/19 15:27:17 INFO TaskSetManager: Finished task 0.0 in stage 309.0 (TID 225) in 0 ms on localhost (executor driver) (1/2)
17/12/19 15:27:17 INFO Executor: Finished task 1.0 in stage 309.0 (TID 226). 1460 bytes result sent to driver
17/12/19 15:27:17 INFO TaskSetManager: Finished task 1.0 in stage 309.0 (TID 226) in 0 ms on localhost (executor driver) (2/2)
17/12/19 15:27:17 INFO TaskSchedulerImpl: Removed TaskSet 309.0, whose tasks have all completed, from pool 
17/12/19 15:27:17 INFO DAGScheduler: ResultStage 309 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:27:17 INFO DAGScheduler: Job 147 finished: collect at utils.scala:196, took 0.007982 s
17/12/19 15:27:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:17 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:27:17 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:27:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:27:17 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:27:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:27:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:27:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:27:17 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 15:27:17 INFO DAGScheduler: Got job 148 (collect at utils.scala:58) with 1 output partitions
17/12/19 15:27:17 INFO DAGScheduler: Final stage: ResultStage 310 (collect at utils.scala:58)
17/12/19 15:27:17 INFO DAGScheduler: Parents of final stage: List()
17/12/19 15:27:17 INFO DAGScheduler: Missing parents: List()
17/12/19 15:27:17 INFO DAGScheduler: Submitting ResultStage 310 (MapPartitionsRDD[613] at map at utils.scala:55), which has no missing parents
17/12/19 15:27:17 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 8.7 KB, free 1998.0 MB)
17/12/19 15:27:17 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1998.0 MB)
17/12/19 15:27:17 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.7 MB)
17/12/19 15:27:17 INFO SparkContext: Created broadcast 208 from broadcast at DAGScheduler.scala:996
17/12/19 15:27:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 310 (MapPartitionsRDD[613] at map at utils.scala:55)
17/12/19 15:27:17 INFO TaskSchedulerImpl: Adding task set 310.0 with 1 tasks
17/12/19 15:27:17 INFO TaskSetManager: Starting task 0.0 in stage 310.0 (TID 227, localhost, executor driver, partition 0, PROCESS_LOCAL, 7727 bytes)
17/12/19 15:27:17 INFO Executor: Running task 0.0 in stage 310.0 (TID 227)
17/12/19 15:27:17 INFO Executor: Finished task 0.0 in stage 310.0 (TID 227). 1442 bytes result sent to driver
17/12/19 15:27:17 INFO TaskSetManager: Finished task 0.0 in stage 310.0 (TID 227) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:27:17 INFO TaskSchedulerImpl: Removed TaskSet 310.0, whose tasks have all completed, from pool 
17/12/19 15:27:17 INFO DAGScheduler: ResultStage 310 (collect at utils.scala:58) finished in 0.000 s
17/12/19 15:27:17 INFO DAGScheduler: Job 148 finished: collect at utils.scala:58, took 0.006536 s
17/12/19 15:27:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:17 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:27:17 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:27:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:27:17 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:27:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:27:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:27:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:27:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:17 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:27:17 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:27:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:27:18 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:27:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:27:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:27:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:27:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:27:18 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:27:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:27:18 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:27:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:27:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:27:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:27:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:27:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:27:18 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:27:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:27:18 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:27:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:27:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:27:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 127.0.0.1:53618 in memory (size: 45.0 KB, free: 2003.7 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2003.7 MB)
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 9702
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 9703
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 9704
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 9705
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 9706
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 9707
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 9708
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 9709
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 9710
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 9711
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 9712
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 9713
17/12/19 15:30:02 INFO ContextCleaner: Cleaned shuffle 43
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2003.7 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.7 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.7 MB)
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 9882
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.7 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.8 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 127.0.0.1:53618 in memory (size: 45.0 KB, free: 2003.8 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 127.0.0.1:53618 in memory (size: 46.8 KB, free: 2003.8 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 127.0.0.1:53618 in memory (size: 46.8 KB, free: 2003.9 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 127.0.0.1:53618 in memory (size: 6.2 KB, free: 2003.9 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 127.0.0.1:53618 in memory (size: 6.2 KB, free: 2003.9 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 127.0.0.1:53618 in memory (size: 47.4 KB, free: 2003.9 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 127.0.0.1:53618 in memory (size: 47.4 KB, free: 2004.0 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 127.0.0.1:53618 in memory (size: 49.4 KB, free: 2004.0 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_204_piece0 on 127.0.0.1:53618 in memory (size: 49.4 KB, free: 2004.1 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 127.0.0.1:53618 in memory (size: 50.6 KB, free: 2004.1 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 127.0.0.1:53618 in memory (size: 50.6 KB, free: 2004.2 MB)
17/12/19 15:30:02 INFO BlockManagerInfo: Removed broadcast_207_piece0 on 127.0.0.1:53618 in memory (size: 50.7 KB, free: 2004.2 MB)
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 10674
17/12/19 15:30:02 INFO ContextCleaner: Cleaned accumulator 10675
17/12/19 15:35:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:35:45 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:45 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:45 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:45 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:35:45 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:35:45 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 15:35:45 INFO DAGScheduler: Got job 149 (collect at utils.scala:58) with 1 output partitions
17/12/19 15:35:45 INFO DAGScheduler: Final stage: ResultStage 311 (collect at utils.scala:58)
17/12/19 15:35:45 INFO DAGScheduler: Parents of final stage: List()
17/12/19 15:35:45 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:45 INFO DAGScheduler: Submitting ResultStage 311 (MapPartitionsRDD[623] at map at utils.scala:55), which has no missing parents
17/12/19 15:35:45 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 8.7 KB, free 1999.9 MB)
17/12/19 15:35:45 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1999.9 MB)
17/12/19 15:35:45 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.2 MB)
17/12/19 15:35:45 INFO SparkContext: Created broadcast 209 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 311 (MapPartitionsRDD[623] at map at utils.scala:55)
17/12/19 15:35:45 INFO TaskSchedulerImpl: Adding task set 311.0 with 1 tasks
17/12/19 15:35:45 INFO TaskSetManager: Starting task 0.0 in stage 311.0 (TID 228, localhost, executor driver, partition 0, PROCESS_LOCAL, 7727 bytes)
17/12/19 15:35:45 INFO Executor: Running task 0.0 in stage 311.0 (TID 228)
17/12/19 15:35:45 INFO Executor: Finished task 0.0 in stage 311.0 (TID 228). 1600 bytes result sent to driver
17/12/19 15:35:45 INFO TaskSetManager: Finished task 0.0 in stage 311.0 (TID 228) in 16 ms on localhost (executor driver) (1/1)
17/12/19 15:35:45 INFO TaskSchedulerImpl: Removed TaskSet 311.0, whose tasks have all completed, from pool 
17/12/19 15:35:45 INFO DAGScheduler: ResultStage 311 (collect at utils.scala:58) finished in 0.016 s
17/12/19 15:35:45 INFO DAGScheduler: Job 149 finished: collect at utils.scala:58, took 0.007930 s
17/12/19 15:35:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:45 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:35:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:45 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 15:35:45 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 15:35:45 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 15:35:45 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 15:35:45 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 15:35:45 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 15:35:45 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 293.7 KB, free 1999.6 MB)
17/12/19 15:35:45 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1999.6 MB)
17/12/19 15:35:45 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.2 MB)
17/12/19 15:35:46 INFO SparkContext: Created broadcast 210 from sql at <unknown>:0
17/12/19 15:35:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 15:35:46 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 15:35:46 INFO DAGScheduler: Registering RDD 627 (sql at <unknown>:0)
17/12/19 15:35:46 INFO DAGScheduler: Registering RDD 632 (sql at <unknown>:0)
17/12/19 15:35:46 INFO DAGScheduler: Got job 150 (sql at <unknown>:0) with 1 output partitions
17/12/19 15:35:46 INFO DAGScheduler: Final stage: ResultStage 314 (sql at <unknown>:0)
17/12/19 15:35:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 313)
17/12/19 15:35:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 313)
17/12/19 15:35:46 INFO DAGScheduler: Submitting ShuffleMapStage 312 (MapPartitionsRDD[627] at sql at <unknown>:0), which has no missing parents
17/12/19 15:35:46 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 12.1 KB, free 1999.6 MB)
17/12/19 15:35:46 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1999.6 MB)
17/12/19 15:35:46 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.2 MB)
17/12/19 15:35:46 INFO SparkContext: Created broadcast 211 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 312 (MapPartitionsRDD[627] at sql at <unknown>:0)
17/12/19 15:35:46 INFO TaskSchedulerImpl: Adding task set 312.0 with 1 tasks
17/12/19 15:35:46 INFO TaskSetManager: Starting task 0.0 in stage 312.0 (TID 229, localhost, executor driver, partition 0, PROCESS_LOCAL, 6679 bytes)
17/12/19 15:35:46 INFO Executor: Running task 0.0 in stage 312.0 (TID 229)
17/12/19 15:35:46 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_db4a99774814a533467c1831b5bbf15a4bf6ccadc2e4c9b5ed0fefbea50875bf.csv, range: 0-454, partition values: [empty row]
17/12/19 15:35:46 INFO Executor: Finished task 0.0 in stage 312.0 (TID 229). 1553 bytes result sent to driver
17/12/19 15:35:46 INFO TaskSetManager: Finished task 0.0 in stage 312.0 (TID 229) in 16 ms on localhost (executor driver) (1/1)
17/12/19 15:35:46 INFO TaskSchedulerImpl: Removed TaskSet 312.0, whose tasks have all completed, from pool 
17/12/19 15:35:46 INFO DAGScheduler: ShuffleMapStage 312 (sql at <unknown>:0) finished in 0.016 s
17/12/19 15:35:46 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:35:46 INFO DAGScheduler: running: Set()
17/12/19 15:35:46 INFO DAGScheduler: waiting: Set(ResultStage 314, ShuffleMapStage 313)
17/12/19 15:35:46 INFO DAGScheduler: failed: Set()
17/12/19 15:35:46 INFO DAGScheduler: Submitting ShuffleMapStage 313 (MapPartitionsRDD[632] at sql at <unknown>:0), which has no missing parents
17/12/19 15:35:46 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 11.9 KB, free 1999.6 MB)
17/12/19 15:35:46 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1999.6 MB)
17/12/19 15:35:46 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.2 MB)
17/12/19 15:35:46 INFO SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:46 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 313 (MapPartitionsRDD[632] at sql at <unknown>:0)
17/12/19 15:35:46 INFO TaskSchedulerImpl: Adding task set 313.0 with 2 tasks
17/12/19 15:35:46 INFO TaskSetManager: Starting task 0.0 in stage 313.0 (TID 230, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/19 15:35:46 INFO TaskSetManager: Starting task 1.0 in stage 313.0 (TID 231, localhost, executor driver, partition 1, ANY, 5945 bytes)
17/12/19 15:35:46 INFO Executor: Running task 0.0 in stage 313.0 (TID 230)
17/12/19 15:35:46 INFO Executor: Running task 1.0 in stage 313.0 (TID 231)
17/12/19 15:35:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:35:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:35:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:35:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:35:46 INFO MemoryStore: Block rdd_629_0 stored as values in memory (estimated size 544.0 B, free 1999.6 MB)
17/12/19 15:35:46 INFO MemoryStore: Block rdd_629_1 stored as values in memory (estimated size 544.0 B, free 1999.6 MB)
17/12/19 15:35:46 INFO BlockManagerInfo: Added rdd_629_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.2 MB)
17/12/19 15:35:46 INFO BlockManagerInfo: Added rdd_629_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.2 MB)
17/12/19 15:35:46 INFO Executor: Finished task 0.0 in stage 313.0 (TID 230). 2906 bytes result sent to driver
17/12/19 15:35:46 INFO TaskSetManager: Finished task 0.0 in stage 313.0 (TID 230) in 0 ms on localhost (executor driver) (1/2)
17/12/19 15:35:46 INFO Executor: Finished task 1.0 in stage 313.0 (TID 231). 2906 bytes result sent to driver
17/12/19 15:35:46 INFO TaskSetManager: Finished task 1.0 in stage 313.0 (TID 231) in 0 ms on localhost (executor driver) (2/2)
17/12/19 15:35:46 INFO TaskSchedulerImpl: Removed TaskSet 313.0, whose tasks have all completed, from pool 
17/12/19 15:35:46 INFO DAGScheduler: ShuffleMapStage 313 (sql at <unknown>:0) finished in 0.000 s
17/12/19 15:35:46 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:35:46 INFO DAGScheduler: running: Set()
17/12/19 15:35:46 INFO DAGScheduler: waiting: Set(ResultStage 314)
17/12/19 15:35:46 INFO DAGScheduler: failed: Set()
17/12/19 15:35:46 INFO DAGScheduler: Submitting ResultStage 314 (MapPartitionsRDD[635] at sql at <unknown>:0), which has no missing parents
17/12/19 15:35:46 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 7.0 KB, free 1999.6 MB)
17/12/19 15:35:46 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1999.6 MB)
17/12/19 15:35:46 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.2 MB)
17/12/19 15:35:46 INFO SparkContext: Created broadcast 213 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 314 (MapPartitionsRDD[635] at sql at <unknown>:0)
17/12/19 15:35:46 INFO TaskSchedulerImpl: Adding task set 314.0 with 1 tasks
17/12/19 15:35:46 INFO TaskSetManager: Starting task 0.0 in stage 314.0 (TID 232, localhost, executor driver, partition 0, ANY, 5956 bytes)
17/12/19 15:35:46 INFO Executor: Running task 0.0 in stage 314.0 (TID 232)
17/12/19 15:35:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:35:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:35:46 INFO Executor: Finished task 0.0 in stage 314.0 (TID 232). 1707 bytes result sent to driver
17/12/19 15:35:46 INFO TaskSetManager: Finished task 0.0 in stage 314.0 (TID 232) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:35:46 INFO TaskSchedulerImpl: Removed TaskSet 314.0, whose tasks have all completed, from pool 
17/12/19 15:35:46 INFO DAGScheduler: ResultStage 314 (sql at <unknown>:0) finished in 0.000 s
17/12/19 15:35:46 INFO DAGScheduler: Job 150 finished: sql at <unknown>:0, took 0.048217 s
17/12/19 15:35:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:46 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 15:35:46 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:35:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 45 is 145 bytes
17/12/19 15:35:46 INFO DAGScheduler: Registering RDD 639 (collect at utils.scala:196)
17/12/19 15:35:46 INFO DAGScheduler: Got job 151 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:35:46 INFO DAGScheduler: Final stage: ResultStage 317 (collect at utils.scala:196)
17/12/19 15:35:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 316)
17/12/19 15:35:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 316)
17/12/19 15:35:46 INFO DAGScheduler: Submitting ShuffleMapStage 316 (MapPartitionsRDD[639] at collect at utils.scala:196), which has no missing parents
17/12/19 15:35:46 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 11.9 KB, free 1999.6 MB)
17/12/19 15:35:46 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1999.5 MB)
17/12/19 15:35:46 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.2 MB)
17/12/19 15:35:46 INFO SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:46 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 316 (MapPartitionsRDD[639] at collect at utils.scala:196)
17/12/19 15:35:46 INFO TaskSchedulerImpl: Adding task set 316.0 with 2 tasks
17/12/19 15:35:46 INFO TaskSetManager: Starting task 0.0 in stage 316.0 (TID 233, localhost, executor driver, partition 0, PROCESS_LOCAL, 5937 bytes)
17/12/19 15:35:46 INFO TaskSetManager: Starting task 1.0 in stage 316.0 (TID 234, localhost, executor driver, partition 1, PROCESS_LOCAL, 5937 bytes)
17/12/19 15:35:46 INFO Executor: Running task 0.0 in stage 316.0 (TID 233)
17/12/19 15:35:46 INFO Executor: Running task 1.0 in stage 316.0 (TID 234)
17/12/19 15:35:46 INFO BlockManager: Found block rdd_629_0 locally
17/12/19 15:35:46 INFO BlockManager: Found block rdd_629_1 locally
17/12/19 15:35:46 INFO Executor: Finished task 1.0 in stage 316.0 (TID 234). 1958 bytes result sent to driver
17/12/19 15:35:46 INFO TaskSetManager: Finished task 1.0 in stage 316.0 (TID 234) in 7 ms on localhost (executor driver) (1/2)
17/12/19 15:35:46 INFO Executor: Finished task 0.0 in stage 316.0 (TID 233). 1958 bytes result sent to driver
17/12/19 15:35:46 INFO TaskSetManager: Finished task 0.0 in stage 316.0 (TID 233) in 22 ms on localhost (executor driver) (2/2)
17/12/19 15:35:46 INFO TaskSchedulerImpl: Removed TaskSet 316.0, whose tasks have all completed, from pool 
17/12/19 15:35:46 INFO DAGScheduler: ShuffleMapStage 316 (collect at utils.scala:196) finished in 0.022 s
17/12/19 15:35:46 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:35:46 INFO DAGScheduler: running: Set()
17/12/19 15:35:46 INFO DAGScheduler: waiting: Set(ResultStage 317)
17/12/19 15:35:46 INFO DAGScheduler: failed: Set()
17/12/19 15:35:46 INFO DAGScheduler: Submitting ResultStage 317 (MapPartitionsRDD[642] at collect at utils.scala:196), which has no missing parents
17/12/19 15:35:46 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 7.0 KB, free 1999.5 MB)
17/12/19 15:35:46 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1999.5 MB)
17/12/19 15:35:46 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.2 MB)
17/12/19 15:35:46 INFO SparkContext: Created broadcast 215 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 317 (MapPartitionsRDD[642] at collect at utils.scala:196)
17/12/19 15:35:46 INFO TaskSchedulerImpl: Adding task set 317.0 with 1 tasks
17/12/19 15:35:46 INFO TaskSetManager: Starting task 0.0 in stage 317.0 (TID 235, localhost, executor driver, partition 0, ANY, 5948 bytes)
17/12/19 15:35:46 INFO Executor: Running task 0.0 in stage 317.0 (TID 235)
17/12/19 15:35:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:35:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:35:46 INFO Executor: Finished task 0.0 in stage 317.0 (TID 235). 1707 bytes result sent to driver
17/12/19 15:35:46 INFO TaskSetManager: Finished task 0.0 in stage 317.0 (TID 235) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:35:46 INFO TaskSchedulerImpl: Removed TaskSet 317.0, whose tasks have all completed, from pool 
17/12/19 15:35:46 INFO DAGScheduler: ResultStage 317 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:35:46 INFO DAGScheduler: Job 151 finished: collect at utils.scala:196, took 0.019983 s
17/12/19 15:35:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz44`
WHERE (0 = 1)
17/12/19 15:35:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:35:46 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:35:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 45 is 145 bytes
17/12/19 15:35:46 INFO DAGScheduler: Got job 152 (take at <unknown>:0) with 1 output partitions
17/12/19 15:35:46 INFO DAGScheduler: Final stage: ResultStage 319 (take at <unknown>:0)
17/12/19 15:35:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 318)
17/12/19 15:35:46 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:46 INFO DAGScheduler: Submitting ResultStage 319 (WorkerRDD[646] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:35:46 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 111.3 KB, free 1999.4 MB)
17/12/19 15:35:46 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 45.0 KB, free 1999.4 MB)
17/12/19 15:35:46 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 127.0.0.1:53618 (size: 45.0 KB, free: 2004.1 MB)
17/12/19 15:35:46 INFO SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 319 (WorkerRDD[646] at RDD at rdd.scala:18)
17/12/19 15:35:46 INFO TaskSchedulerImpl: Adding task set 319.0 with 1 tasks
17/12/19 15:35:46 INFO TaskSetManager: Starting task 0.0 in stage 319.0 (TID 236, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:35:46 INFO Executor: Running task 0.0 in stage 319.0 (TID 236)
17/12/19 15:35:46 INFO BlockManager: Found block rdd_629_0 locally
17/12/19 15:35:46 INFO MemoryStore: Block rdd_646_0 stored as values in memory (estimated size 80.0 B, free 1999.4 MB)
17/12/19 15:35:46 INFO BlockManagerInfo: Added rdd_646_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.1 MB)
17/12/19 15:35:46 INFO Executor: Finished task 0.0 in stage 319.0 (TID 236). 2154 bytes result sent to driver
17/12/19 15:35:46 INFO TaskSetManager: Finished task 0.0 in stage 319.0 (TID 236) in 612 ms on localhost (executor driver) (1/1)
17/12/19 15:35:46 INFO TaskSchedulerImpl: Removed TaskSet 319.0, whose tasks have all completed, from pool 
17/12/19 15:35:46 INFO DAGScheduler: ResultStage 319 (take at <unknown>:0) finished in 0.612 s
17/12/19 15:35:46 INFO DAGScheduler: Job 152 finished: take at <unknown>:0, took 0.607790 s
17/12/19 15:35:46 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:35:46 INFO DAGScheduler: Got job 153 (take at <unknown>:0) with 1 output partitions
17/12/19 15:35:46 INFO DAGScheduler: Final stage: ResultStage 321 (take at <unknown>:0)
17/12/19 15:35:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 320)
17/12/19 15:35:46 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:46 INFO DAGScheduler: Submitting ResultStage 321 (WorkerRDD[646] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:35:46 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 111.3 KB, free 1999.3 MB)
17/12/19 15:35:46 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 45.0 KB, free 1999.2 MB)
17/12/19 15:35:46 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 127.0.0.1:53618 (size: 45.0 KB, free: 2004.1 MB)
17/12/19 15:35:46 INFO SparkContext: Created broadcast 217 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 321 (WorkerRDD[646] at RDD at rdd.scala:18)
17/12/19 15:35:46 INFO TaskSchedulerImpl: Adding task set 321.0 with 1 tasks
17/12/19 15:35:46 INFO TaskSetManager: Starting task 0.0 in stage 321.0 (TID 237, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:35:46 INFO Executor: Running task 0.0 in stage 321.0 (TID 237)
17/12/19 15:35:46 INFO BlockManager: Found block rdd_629_1 locally
17/12/19 15:35:47 INFO MemoryStore: Block rdd_646_1 stored as values in memory (estimated size 80.0 B, free 1999.2 MB)
17/12/19 15:35:47 INFO BlockManagerInfo: Added rdd_646_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.1 MB)
17/12/19 15:35:47 INFO Executor: Finished task 0.0 in stage 321.0 (TID 237). 2241 bytes result sent to driver
17/12/19 15:35:47 INFO TaskSetManager: Finished task 0.0 in stage 321.0 (TID 237) in 644 ms on localhost (executor driver) (1/1)
17/12/19 15:35:47 INFO TaskSchedulerImpl: Removed TaskSet 321.0, whose tasks have all completed, from pool 
17/12/19 15:35:47 INFO DAGScheduler: ResultStage 321 (take at <unknown>:0) finished in 0.644 s
17/12/19 15:35:47 INFO DAGScheduler: Job 153 finished: take at <unknown>:0, took 0.650779 s
17/12/19 15:35:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:47 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e852971c7a
17/12/19 15:35:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e852971c7a` AS `zzz45`
WHERE (0 = 1)
17/12/19 15:35:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e852971c7a`
LIMIT 10
17/12/19 15:35:47 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:35:47 INFO DAGScheduler: Got job 154 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:35:47 INFO DAGScheduler: Final stage: ResultStage 323 (collect at utils.scala:196)
17/12/19 15:35:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 322)
17/12/19 15:35:47 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:47 INFO DAGScheduler: Submitting ResultStage 323 (MapPartitionsRDD[650] at collect at utils.scala:196), which has no missing parents
17/12/19 15:35:47 INFO MemoryStore: Block broadcast_218 stored as values in memory (estimated size 114.4 KB, free 1999.1 MB)
17/12/19 15:35:47 INFO MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 46.8 KB, free 1999.1 MB)
17/12/19 15:35:47 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on 127.0.0.1:53618 (size: 46.8 KB, free: 2004.0 MB)
17/12/19 15:35:47 INFO SparkContext: Created broadcast 218 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 323 (MapPartitionsRDD[650] at collect at utils.scala:196)
17/12/19 15:35:47 INFO TaskSchedulerImpl: Adding task set 323.0 with 1 tasks
17/12/19 15:35:47 INFO TaskSetManager: Starting task 0.0 in stage 323.0 (TID 238, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:35:47 INFO Executor: Running task 0.0 in stage 323.0 (TID 238)
17/12/19 15:35:47 INFO BlockManager: Found block rdd_646_0 locally
17/12/19 15:35:47 INFO Executor: Finished task 0.0 in stage 323.0 (TID 238). 1233 bytes result sent to driver
17/12/19 15:35:47 INFO TaskSetManager: Finished task 0.0 in stage 323.0 (TID 238) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:35:47 INFO TaskSchedulerImpl: Removed TaskSet 323.0, whose tasks have all completed, from pool 
17/12/19 15:35:47 INFO DAGScheduler: ResultStage 323 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:35:47 INFO DAGScheduler: Job 154 finished: collect at utils.scala:196, took 0.007527 s
17/12/19 15:35:47 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:35:47 INFO DAGScheduler: Got job 155 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:35:47 INFO DAGScheduler: Final stage: ResultStage 325 (collect at utils.scala:196)
17/12/19 15:35:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 324)
17/12/19 15:35:47 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:47 INFO DAGScheduler: Submitting ResultStage 325 (MapPartitionsRDD[650] at collect at utils.scala:196), which has no missing parents
17/12/19 15:35:47 INFO MemoryStore: Block broadcast_219 stored as values in memory (estimated size 114.4 KB, free 1999.0 MB)
17/12/19 15:35:47 INFO MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 46.8 KB, free 1998.9 MB)
17/12/19 15:35:47 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on 127.0.0.1:53618 (size: 46.8 KB, free: 2004.0 MB)
17/12/19 15:35:47 INFO SparkContext: Created broadcast 219 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 325 (MapPartitionsRDD[650] at collect at utils.scala:196)
17/12/19 15:35:47 INFO TaskSchedulerImpl: Adding task set 325.0 with 1 tasks
17/12/19 15:35:47 INFO TaskSetManager: Starting task 0.0 in stage 325.0 (TID 239, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:35:47 INFO Executor: Running task 0.0 in stage 325.0 (TID 239)
17/12/19 15:35:47 INFO BlockManager: Found block rdd_646_1 locally
17/12/19 15:35:47 INFO Executor: Finished task 0.0 in stage 325.0 (TID 239). 1233 bytes result sent to driver
17/12/19 15:35:47 INFO TaskSetManager: Finished task 0.0 in stage 325.0 (TID 239) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:35:47 INFO TaskSchedulerImpl: Removed TaskSet 325.0, whose tasks have all completed, from pool 
17/12/19 15:35:47 INFO DAGScheduler: ResultStage 325 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:35:47 INFO DAGScheduler: Job 155 finished: collect at utils.scala:196, took 0.007771 s
17/12/19 15:35:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:47 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `wsyxfookab`
17/12/19 15:35:47 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:35:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz46`
WHERE (0 = 1)
17/12/19 15:35:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 15:35:47 INFO CodeGenerator: Code generated in 8.642456 ms
17/12/19 15:35:47 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:35:47 INFO DAGScheduler: Got job 156 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:35:47 INFO DAGScheduler: Final stage: ResultStage 327 (collect at utils.scala:196)
17/12/19 15:35:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 326)
17/12/19 15:35:47 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:47 INFO DAGScheduler: Submitting ResultStage 327 (MapPartitionsRDD[654] at collect at utils.scala:196), which has no missing parents
17/12/19 15:35:47 INFO MemoryStore: Block broadcast_220 stored as values in memory (estimated size 13.3 KB, free 1998.9 MB)
17/12/19 15:35:47 INFO MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 6.2 KB, free 1998.9 MB)
17/12/19 15:35:47 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on 127.0.0.1:53618 (size: 6.2 KB, free: 2004.0 MB)
17/12/19 15:35:47 INFO SparkContext: Created broadcast 220 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 327 (MapPartitionsRDD[654] at collect at utils.scala:196)
17/12/19 15:35:47 INFO TaskSchedulerImpl: Adding task set 327.0 with 1 tasks
17/12/19 15:35:47 INFO TaskSetManager: Starting task 0.0 in stage 327.0 (TID 240, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:35:47 INFO Executor: Running task 0.0 in stage 327.0 (TID 240)
17/12/19 15:35:47 INFO BlockManager: Found block rdd_629_0 locally
17/12/19 15:35:47 INFO Executor: Finished task 0.0 in stage 327.0 (TID 240). 1651 bytes result sent to driver
17/12/19 15:35:47 INFO TaskSetManager: Finished task 0.0 in stage 327.0 (TID 240) in 4 ms on localhost (executor driver) (1/1)
17/12/19 15:35:47 INFO TaskSchedulerImpl: Removed TaskSet 327.0, whose tasks have all completed, from pool 
17/12/19 15:35:47 INFO DAGScheduler: ResultStage 327 (collect at utils.scala:196) finished in 0.004 s
17/12/19 15:35:47 INFO DAGScheduler: Job 156 finished: collect at utils.scala:196, took 0.008016 s
17/12/19 15:35:47 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:35:47 INFO DAGScheduler: Got job 157 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:35:47 INFO DAGScheduler: Final stage: ResultStage 329 (collect at utils.scala:196)
17/12/19 15:35:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 328)
17/12/19 15:35:47 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:47 INFO DAGScheduler: Submitting ResultStage 329 (MapPartitionsRDD[654] at collect at utils.scala:196), which has no missing parents
17/12/19 15:35:47 INFO MemoryStore: Block broadcast_221 stored as values in memory (estimated size 13.3 KB, free 1998.9 MB)
17/12/19 15:35:47 INFO MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 6.2 KB, free 1998.9 MB)
17/12/19 15:35:47 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on 127.0.0.1:53618 (size: 6.2 KB, free: 2004.0 MB)
17/12/19 15:35:47 INFO SparkContext: Created broadcast 221 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 329 (MapPartitionsRDD[654] at collect at utils.scala:196)
17/12/19 15:35:47 INFO TaskSchedulerImpl: Adding task set 329.0 with 1 tasks
17/12/19 15:35:47 INFO TaskSetManager: Starting task 0.0 in stage 329.0 (TID 241, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:35:47 INFO Executor: Running task 0.0 in stage 329.0 (TID 241)
17/12/19 15:35:47 INFO BlockManager: Found block rdd_629_1 locally
17/12/19 15:35:47 INFO Executor: Finished task 0.0 in stage 329.0 (TID 241). 1397 bytes result sent to driver
17/12/19 15:35:47 INFO TaskSetManager: Finished task 0.0 in stage 329.0 (TID 241) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:35:47 INFO TaskSchedulerImpl: Removed TaskSet 329.0, whose tasks have all completed, from pool 
17/12/19 15:35:47 INFO DAGScheduler: ResultStage 329 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:35:47 INFO DAGScheduler: Job 157 finished: collect at utils.scala:196, took 0.005317 s
17/12/19 15:35:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:35:47 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:35:47 INFO DAGScheduler: Got job 158 (take at <unknown>:0) with 1 output partitions
17/12/19 15:35:47 INFO DAGScheduler: Final stage: ResultStage 331 (take at <unknown>:0)
17/12/19 15:35:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 330)
17/12/19 15:35:47 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:47 INFO DAGScheduler: Submitting ResultStage 331 (WorkerRDD[659] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:35:47 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 119.5 KB, free 1998.8 MB)
17/12/19 15:35:47 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 47.4 KB, free 1998.7 MB)
17/12/19 15:35:47 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 127.0.0.1:53618 (size: 47.4 KB, free: 2003.9 MB)
17/12/19 15:35:47 INFO SparkContext: Created broadcast 222 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 331 (WorkerRDD[659] at RDD at rdd.scala:18)
17/12/19 15:35:47 INFO TaskSchedulerImpl: Adding task set 331.0 with 1 tasks
17/12/19 15:35:47 INFO TaskSetManager: Starting task 0.0 in stage 331.0 (TID 242, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:35:47 INFO Executor: Running task 0.0 in stage 331.0 (TID 242)
17/12/19 15:35:47 INFO BlockManager: Found block rdd_629_0 locally
17/12/19 15:35:48 INFO MemoryStore: Block rdd_659_0 stored as values in memory (estimated size 608.0 B, free 1998.7 MB)
17/12/19 15:35:48 INFO BlockManagerInfo: Added rdd_659_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 15:35:48 INFO Executor: Finished task 0.0 in stage 331.0 (TID 242). 2588 bytes result sent to driver
17/12/19 15:35:48 INFO TaskSetManager: Finished task 0.0 in stage 331.0 (TID 242) in 673 ms on localhost (executor driver) (1/1)
17/12/19 15:35:48 INFO TaskSchedulerImpl: Removed TaskSet 331.0, whose tasks have all completed, from pool 
17/12/19 15:35:48 INFO DAGScheduler: ResultStage 331 (take at <unknown>:0) finished in 0.673 s
17/12/19 15:35:48 INFO DAGScheduler: Job 158 finished: take at <unknown>:0, took 0.673737 s
17/12/19 15:35:48 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:35:48 INFO DAGScheduler: Got job 159 (take at <unknown>:0) with 1 output partitions
17/12/19 15:35:48 INFO DAGScheduler: Final stage: ResultStage 333 (take at <unknown>:0)
17/12/19 15:35:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 332)
17/12/19 15:35:48 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:48 INFO DAGScheduler: Submitting ResultStage 333 (WorkerRDD[659] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:35:48 INFO MemoryStore: Block broadcast_223 stored as values in memory (estimated size 119.5 KB, free 1998.6 MB)
17/12/19 15:35:48 INFO MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 47.4 KB, free 1998.6 MB)
17/12/19 15:35:48 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 127.0.0.1:53618 (size: 47.4 KB, free: 2003.9 MB)
17/12/19 15:35:48 INFO SparkContext: Created broadcast 223 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 333 (WorkerRDD[659] at RDD at rdd.scala:18)
17/12/19 15:35:48 INFO TaskSchedulerImpl: Adding task set 333.0 with 1 tasks
17/12/19 15:35:48 INFO TaskSetManager: Starting task 0.0 in stage 333.0 (TID 243, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:35:48 INFO Executor: Running task 0.0 in stage 333.0 (TID 243)
17/12/19 15:35:48 INFO BlockManager: Found block rdd_629_1 locally
17/12/19 15:35:49 INFO MemoryStore: Block rdd_659_1 stored as values in memory (estimated size 608.0 B, free 1998.6 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Added rdd_659_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 15:35:49 INFO Executor: Finished task 0.0 in stage 333.0 (TID 243). 2509 bytes result sent to driver
17/12/19 15:35:49 INFO TaskSetManager: Finished task 0.0 in stage 333.0 (TID 243) in 668 ms on localhost (executor driver) (1/1)
17/12/19 15:35:49 INFO TaskSchedulerImpl: Removed TaskSet 333.0, whose tasks have all completed, from pool 
17/12/19 15:35:49 INFO DAGScheduler: ResultStage 333 (take at <unknown>:0) finished in 0.668 s
17/12/19 15:35:49 INFO DAGScheduler: Job 159 finished: take at <unknown>:0, took 0.676791 s
17/12/19 15:35:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e8454c7d95
17/12/19 15:35:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8454c7d95` AS `zzz47`
WHERE (0 = 1)
17/12/19 15:35:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8454c7d95`
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:35:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz48`
WHERE (0 = 1)
17/12/19 15:35:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 15:35:49 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:35:49 INFO DAGScheduler: Got job 160 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:35:49 INFO DAGScheduler: Final stage: ResultStage 335 (collect at utils.scala:196)
17/12/19 15:35:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 334)
17/12/19 15:35:49 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:49 INFO DAGScheduler: Submitting ResultStage 335 (MapPartitionsRDD[664] at collect at utils.scala:196), which has no missing parents
17/12/19 15:35:49 INFO MemoryStore: Block broadcast_224 stored as values in memory (estimated size 123.4 KB, free 1998.4 MB)
17/12/19 15:35:49 INFO MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 49.3 KB, free 1998.4 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 127.0.0.1:53618 (size: 49.3 KB, free: 2003.8 MB)
17/12/19 15:35:49 INFO SparkContext: Created broadcast 224 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 335 (MapPartitionsRDD[664] at collect at utils.scala:196)
17/12/19 15:35:49 INFO TaskSchedulerImpl: Adding task set 335.0 with 1 tasks
17/12/19 15:35:49 INFO TaskSetManager: Starting task 0.0 in stage 335.0 (TID 244, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:35:49 INFO Executor: Running task 0.0 in stage 335.0 (TID 244)
17/12/19 15:35:49 INFO BlockManager: Found block rdd_659_0 locally
17/12/19 15:35:49 INFO Executor: Finished task 0.0 in stage 335.0 (TID 244). 1616 bytes result sent to driver
17/12/19 15:35:49 INFO TaskSetManager: Finished task 0.0 in stage 335.0 (TID 244) in 15 ms on localhost (executor driver) (1/1)
17/12/19 15:35:49 INFO TaskSchedulerImpl: Removed TaskSet 335.0, whose tasks have all completed, from pool 
17/12/19 15:35:49 INFO DAGScheduler: ResultStage 335 (collect at utils.scala:196) finished in 0.015 s
17/12/19 15:35:49 INFO DAGScheduler: Job 160 finished: collect at utils.scala:196, took 0.008129 s
17/12/19 15:35:49 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:35:49 INFO DAGScheduler: Got job 161 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:35:49 INFO DAGScheduler: Final stage: ResultStage 337 (collect at utils.scala:196)
17/12/19 15:35:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 336)
17/12/19 15:35:49 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:49 INFO DAGScheduler: Submitting ResultStage 337 (MapPartitionsRDD[664] at collect at utils.scala:196), which has no missing parents
17/12/19 15:35:49 INFO MemoryStore: Block broadcast_225 stored as values in memory (estimated size 123.4 KB, free 1998.3 MB)
17/12/19 15:35:49 INFO MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 49.4 KB, free 1998.2 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 127.0.0.1:53618 (size: 49.4 KB, free: 2003.8 MB)
17/12/19 15:35:49 INFO SparkContext: Created broadcast 225 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 337 (MapPartitionsRDD[664] at collect at utils.scala:196)
17/12/19 15:35:49 INFO TaskSchedulerImpl: Adding task set 337.0 with 1 tasks
17/12/19 15:35:49 INFO TaskSetManager: Starting task 0.0 in stage 337.0 (TID 245, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:35:49 INFO Executor: Running task 0.0 in stage 337.0 (TID 245)
17/12/19 15:35:49 INFO BlockManager: Found block rdd_659_1 locally
17/12/19 15:35:49 INFO Executor: Finished task 0.0 in stage 337.0 (TID 245). 1457 bytes result sent to driver
17/12/19 15:35:49 INFO TaskSetManager: Finished task 0.0 in stage 337.0 (TID 245) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:35:49 INFO TaskSchedulerImpl: Removed TaskSet 337.0, whose tasks have all completed, from pool 
17/12/19 15:35:49 INFO DAGScheduler: ResultStage 337 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:35:49 INFO DAGScheduler: Job 161 finished: collect at utils.scala:196, took 0.007748 s
17/12/19 15:35:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:35:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz49`
WHERE (0 = 1)
17/12/19 15:35:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 15:35:49 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:35:49 INFO DAGScheduler: Got job 162 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:35:49 INFO DAGScheduler: Final stage: ResultStage 339 (collect at utils.scala:196)
17/12/19 15:35:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 338)
17/12/19 15:35:49 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:49 INFO DAGScheduler: Submitting ResultStage 339 (MapPartitionsRDD[668] at collect at utils.scala:196), which has no missing parents
17/12/19 15:35:49 INFO MemoryStore: Block broadcast_226 stored as values in memory (estimated size 126.9 KB, free 1998.1 MB)
17/12/19 15:35:49 INFO MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 50.6 KB, free 1998.0 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 127.0.0.1:53618 (size: 50.6 KB, free: 2003.8 MB)
17/12/19 15:35:49 INFO SparkContext: Created broadcast 226 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 339 (MapPartitionsRDD[668] at collect at utils.scala:196)
17/12/19 15:35:49 INFO TaskSchedulerImpl: Adding task set 339.0 with 1 tasks
17/12/19 15:35:49 INFO TaskSetManager: Starting task 0.0 in stage 339.0 (TID 246, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:35:49 INFO Executor: Running task 0.0 in stage 339.0 (TID 246)
17/12/19 15:35:49 INFO BlockManager: Found block rdd_659_0 locally
17/12/19 15:35:49 INFO Executor: Finished task 0.0 in stage 339.0 (TID 246). 1422 bytes result sent to driver
17/12/19 15:35:49 INFO TaskSetManager: Finished task 0.0 in stage 339.0 (TID 246) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:35:49 INFO TaskSchedulerImpl: Removed TaskSet 339.0, whose tasks have all completed, from pool 
17/12/19 15:35:49 INFO DAGScheduler: ResultStage 339 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:35:49 INFO DAGScheduler: Job 162 finished: collect at utils.scala:196, took 0.008941 s
17/12/19 15:35:49 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:35:49 INFO DAGScheduler: Got job 163 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:35:49 INFO DAGScheduler: Final stage: ResultStage 341 (collect at utils.scala:196)
17/12/19 15:35:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 340)
17/12/19 15:35:49 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:49 INFO DAGScheduler: Submitting ResultStage 341 (MapPartitionsRDD[668] at collect at utils.scala:196), which has no missing parents
17/12/19 15:35:49 INFO MemoryStore: Block broadcast_227 stored as values in memory (estimated size 126.9 KB, free 1997.9 MB)
17/12/19 15:35:49 INFO MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 50.6 KB, free 1997.9 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 127.0.0.1:53618 (size: 50.6 KB, free: 2003.7 MB)
17/12/19 15:35:49 INFO SparkContext: Created broadcast 227 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 341 (MapPartitionsRDD[668] at collect at utils.scala:196)
17/12/19 15:35:49 INFO TaskSchedulerImpl: Adding task set 341.0 with 1 tasks
17/12/19 15:35:49 INFO TaskSetManager: Starting task 0.0 in stage 341.0 (TID 247, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 15:35:49 INFO Executor: Running task 0.0 in stage 341.0 (TID 247)
17/12/19 15:35:49 INFO BlockManager: Found block rdd_659_1 locally
17/12/19 15:35:49 INFO Executor: Finished task 0.0 in stage 341.0 (TID 247). 1573 bytes result sent to driver
17/12/19 15:35:49 INFO TaskSetManager: Finished task 0.0 in stage 341.0 (TID 247) in 16 ms on localhost (executor driver) (1/1)
17/12/19 15:35:49 INFO TaskSchedulerImpl: Removed TaskSet 341.0, whose tasks have all completed, from pool 
17/12/19 15:35:49 INFO DAGScheduler: ResultStage 341 (collect at utils.scala:196) finished in 0.016 s
17/12/19 15:35:49 INFO DAGScheduler: Job 163 finished: collect at utils.scala:196, took 0.006753 s
17/12/19 15:35:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:35:49 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:35:49 INFO DAGScheduler: Got job 164 (collect at utils.scala:196) with 2 output partitions
17/12/19 15:35:49 INFO DAGScheduler: Final stage: ResultStage 343 (collect at utils.scala:196)
17/12/19 15:35:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 342)
17/12/19 15:35:49 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:49 INFO DAGScheduler: Submitting ResultStage 343 (MapPartitionsRDD[671] at collect at utils.scala:196), which has no missing parents
17/12/19 15:35:49 INFO MemoryStore: Block broadcast_228 stored as values in memory (estimated size 127.0 KB, free 1997.7 MB)
17/12/19 15:35:49 INFO MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 50.7 KB, free 1997.7 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on 127.0.0.1:53618 (size: 50.7 KB, free: 2003.7 MB)
17/12/19 15:35:49 INFO SparkContext: Created broadcast 228 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 343 (MapPartitionsRDD[671] at collect at utils.scala:196)
17/12/19 15:35:49 INFO TaskSchedulerImpl: Adding task set 343.0 with 2 tasks
17/12/19 15:35:49 INFO TaskSetManager: Starting task 0.0 in stage 343.0 (TID 248, localhost, executor driver, partition 0, PROCESS_LOCAL, 5948 bytes)
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_219_piece0 on 127.0.0.1:53618 in memory (size: 46.8 KB, free: 2003.7 MB)
17/12/19 15:35:49 INFO TaskSetManager: Starting task 1.0 in stage 343.0 (TID 249, localhost, executor driver, partition 1, PROCESS_LOCAL, 5948 bytes)
17/12/19 15:35:49 INFO Executor: Running task 0.0 in stage 343.0 (TID 248)
17/12/19 15:35:49 INFO Executor: Running task 1.0 in stage 343.0 (TID 249)
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 127.0.0.1:53618 in memory (size: 6.2 KB, free: 2003.7 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_221_piece0 on 127.0.0.1:53618 in memory (size: 6.2 KB, free: 2003.7 MB)
17/12/19 15:35:49 INFO BlockManager: Found block rdd_659_1 locally
17/12/19 15:35:49 INFO BlockManager: Found block rdd_659_0 locally
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_222_piece0 on 127.0.0.1:53618 in memory (size: 47.4 KB, free: 2003.8 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 127.0.0.1:53618 in memory (size: 47.4 KB, free: 2003.8 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_224_piece0 on 127.0.0.1:53618 in memory (size: 49.3 KB, free: 2003.9 MB)
17/12/19 15:35:49 INFO Executor: Finished task 0.0 in stage 343.0 (TID 248). 1446 bytes result sent to driver
17/12/19 15:35:49 INFO Executor: Finished task 1.0 in stage 343.0 (TID 249). 1439 bytes result sent to driver
17/12/19 15:35:49 INFO TaskSetManager: Finished task 0.0 in stage 343.0 (TID 248) in 0 ms on localhost (executor driver) (1/2)
17/12/19 15:35:49 INFO TaskSetManager: Finished task 1.0 in stage 343.0 (TID 249) in 0 ms on localhost (executor driver) (2/2)
17/12/19 15:35:49 INFO TaskSchedulerImpl: Removed TaskSet 343.0, whose tasks have all completed, from pool 
17/12/19 15:35:49 INFO DAGScheduler: ResultStage 343 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:35:49 INFO DAGScheduler: Job 164 finished: collect at utils.scala:196, took 0.022116 s
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 127.0.0.1:53618 in memory (size: 49.4 KB, free: 2003.9 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 127.0.0.1:53618 in memory (size: 50.6 KB, free: 2003.9 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_227_piece0 on 127.0.0.1:53618 in memory (size: 50.6 KB, free: 2004.0 MB)
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10724
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10725
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.0 MB)
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10774
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10775
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10781
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10782
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10783
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10784
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10785
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10786
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10787
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10788
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10789
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10790
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10791
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10792
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10793
17/12/19 15:35:49 INFO ContextCleaner: Cleaned shuffle 46
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.0 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2004.0 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_213_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.0 MB)
17/12/19 15:35:49 INFO ContextCleaner: Cleaned accumulator 10962
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_214_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2004.0 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_215_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.0 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_216_piece0 on 127.0.0.1:53618 in memory (size: 45.0 KB, free: 2004.1 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_217_piece0 on 127.0.0.1:53618 in memory (size: 45.0 KB, free: 2004.1 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Removed broadcast_218_piece0 on 127.0.0.1:53618 in memory (size: 46.8 KB, free: 2004.2 MB)
17/12/19 15:35:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:35:49 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 15:35:49 INFO DAGScheduler: Got job 165 (collect at utils.scala:58) with 1 output partitions
17/12/19 15:35:49 INFO DAGScheduler: Final stage: ResultStage 344 (collect at utils.scala:58)
17/12/19 15:35:49 INFO DAGScheduler: Parents of final stage: List()
17/12/19 15:35:49 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:49 INFO DAGScheduler: Submitting ResultStage 344 (MapPartitionsRDD[677] at map at utils.scala:55), which has no missing parents
17/12/19 15:35:49 INFO MemoryStore: Block broadcast_229 stored as values in memory (estimated size 8.7 KB, free 1999.4 MB)
17/12/19 15:35:49 INFO MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1999.4 MB)
17/12/19 15:35:49 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.2 MB)
17/12/19 15:35:49 INFO SparkContext: Created broadcast 229 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 344 (MapPartitionsRDD[677] at map at utils.scala:55)
17/12/19 15:35:49 INFO TaskSchedulerImpl: Adding task set 344.0 with 1 tasks
17/12/19 15:35:49 INFO TaskSetManager: Starting task 0.0 in stage 344.0 (TID 250, localhost, executor driver, partition 0, PROCESS_LOCAL, 7871 bytes)
17/12/19 15:35:49 INFO Executor: Running task 0.0 in stage 344.0 (TID 250)
17/12/19 15:35:49 INFO Executor: Finished task 0.0 in stage 344.0 (TID 250). 1498 bytes result sent to driver
17/12/19 15:35:49 INFO TaskSetManager: Finished task 0.0 in stage 344.0 (TID 250) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:35:49 INFO TaskSchedulerImpl: Removed TaskSet 344.0, whose tasks have all completed, from pool 
17/12/19 15:35:49 INFO DAGScheduler: ResultStage 344 (collect at utils.scala:58) finished in 0.000 s
17/12/19 15:35:49 INFO DAGScheduler: Job 165 finished: collect at utils.scala:58, took 0.006925 s
17/12/19 15:35:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:35:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:35:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:35:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:49 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:49 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:35:49 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:35:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:35:54 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:54 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:35:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:35:54 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 15:35:54 INFO DAGScheduler: Got job 166 (collect at utils.scala:58) with 1 output partitions
17/12/19 15:35:54 INFO DAGScheduler: Final stage: ResultStage 345 (collect at utils.scala:58)
17/12/19 15:35:54 INFO DAGScheduler: Parents of final stage: List()
17/12/19 15:35:54 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:54 INFO DAGScheduler: Submitting ResultStage 345 (MapPartitionsRDD[687] at map at utils.scala:55), which has no missing parents
17/12/19 15:35:54 INFO MemoryStore: Block broadcast_230 stored as values in memory (estimated size 8.7 KB, free 1999.4 MB)
17/12/19 15:35:54 INFO MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1999.4 MB)
17/12/19 15:35:54 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.2 MB)
17/12/19 15:35:54 INFO SparkContext: Created broadcast 230 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 345 (MapPartitionsRDD[687] at map at utils.scala:55)
17/12/19 15:35:54 INFO TaskSchedulerImpl: Adding task set 345.0 with 1 tasks
17/12/19 15:35:54 INFO TaskSetManager: Starting task 0.0 in stage 345.0 (TID 251, localhost, executor driver, partition 0, PROCESS_LOCAL, 7871 bytes)
17/12/19 15:35:54 INFO Executor: Running task 0.0 in stage 345.0 (TID 251)
17/12/19 15:35:54 INFO Executor: Finished task 0.0 in stage 345.0 (TID 251). 1498 bytes result sent to driver
17/12/19 15:35:54 INFO TaskSetManager: Finished task 0.0 in stage 345.0 (TID 251) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:35:54 INFO TaskSchedulerImpl: Removed TaskSet 345.0, whose tasks have all completed, from pool 
17/12/19 15:35:54 INFO DAGScheduler: ResultStage 345 (collect at utils.scala:58) finished in 0.000 s
17/12/19 15:35:54 INFO DAGScheduler: Job 166 finished: collect at utils.scala:58, took 0.006154 s
17/12/19 15:35:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:54 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:35:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:54 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 15:35:54 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 15:35:54 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 15:35:54 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 15:35:54 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 15:35:54 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 15:35:54 INFO MemoryStore: Block broadcast_231 stored as values in memory (estimated size 293.7 KB, free 1999.1 MB)
17/12/19 15:35:54 INFO MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1999.1 MB)
17/12/19 15:35:54 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.1 MB)
17/12/19 15:35:54 INFO SparkContext: Created broadcast 231 from sql at <unknown>:0
17/12/19 15:35:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 15:35:55 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 15:35:55 INFO DAGScheduler: Registering RDD 691 (sql at <unknown>:0)
17/12/19 15:35:55 INFO DAGScheduler: Registering RDD 696 (sql at <unknown>:0)
17/12/19 15:35:55 INFO DAGScheduler: Got job 167 (sql at <unknown>:0) with 1 output partitions
17/12/19 15:35:55 INFO DAGScheduler: Final stage: ResultStage 348 (sql at <unknown>:0)
17/12/19 15:35:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 347)
17/12/19 15:35:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 347)
17/12/19 15:35:55 INFO DAGScheduler: Submitting ShuffleMapStage 346 (MapPartitionsRDD[691] at sql at <unknown>:0), which has no missing parents
17/12/19 15:35:55 INFO MemoryStore: Block broadcast_232 stored as values in memory (estimated size 12.1 KB, free 1999.1 MB)
17/12/19 15:35:55 INFO MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1999.1 MB)
17/12/19 15:35:55 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.1 MB)
17/12/19 15:35:55 INFO SparkContext: Created broadcast 232 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 346 (MapPartitionsRDD[691] at sql at <unknown>:0)
17/12/19 15:35:55 INFO TaskSchedulerImpl: Adding task set 346.0 with 1 tasks
17/12/19 15:35:55 INFO TaskSetManager: Starting task 0.0 in stage 346.0 (TID 252, localhost, executor driver, partition 0, PROCESS_LOCAL, 6680 bytes)
17/12/19 15:35:55 INFO Executor: Running task 0.0 in stage 346.0 (TID 252)
17/12/19 15:35:55 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_7ff5c3bc4c5797d1dbad238939684a53908aa513581beee551afcdd209cc2ea1.csv, range: 0-468, partition values: [empty row]
17/12/19 15:35:55 INFO Executor: Finished task 0.0 in stage 346.0 (TID 252). 1632 bytes result sent to driver
17/12/19 15:35:55 INFO TaskSetManager: Finished task 0.0 in stage 346.0 (TID 252) in 39 ms on localhost (executor driver) (1/1)
17/12/19 15:35:55 INFO TaskSchedulerImpl: Removed TaskSet 346.0, whose tasks have all completed, from pool 
17/12/19 15:35:55 INFO DAGScheduler: ShuffleMapStage 346 (sql at <unknown>:0) finished in 0.039 s
17/12/19 15:35:55 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:35:55 INFO DAGScheduler: running: Set()
17/12/19 15:35:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 347, ResultStage 348)
17/12/19 15:35:55 INFO DAGScheduler: failed: Set()
17/12/19 15:35:55 INFO DAGScheduler: Submitting ShuffleMapStage 347 (MapPartitionsRDD[696] at sql at <unknown>:0), which has no missing parents
17/12/19 15:35:55 INFO MemoryStore: Block broadcast_233 stored as values in memory (estimated size 11.9 KB, free 1999.1 MB)
17/12/19 15:35:55 INFO MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1999.1 MB)
17/12/19 15:35:55 INFO BlockManagerInfo: Added broadcast_233_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.1 MB)
17/12/19 15:35:55 INFO SparkContext: Created broadcast 233 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 347 (MapPartitionsRDD[696] at sql at <unknown>:0)
17/12/19 15:35:55 INFO TaskSchedulerImpl: Adding task set 347.0 with 2 tasks
17/12/19 15:35:55 INFO TaskSetManager: Starting task 0.0 in stage 347.0 (TID 253, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 15:35:55 INFO TaskSetManager: Starting task 1.0 in stage 347.0 (TID 254, localhost, executor driver, partition 1, ANY, 5946 bytes)
17/12/19 15:35:55 INFO Executor: Running task 0.0 in stage 347.0 (TID 253)
17/12/19 15:35:55 INFO Executor: Running task 1.0 in stage 347.0 (TID 254)
17/12/19 15:35:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:35:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:35:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:35:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:35:55 INFO MemoryStore: Block rdd_693_0 stored as values in memory (estimated size 544.0 B, free 1999.1 MB)
17/12/19 15:35:55 INFO MemoryStore: Block rdd_693_1 stored as values in memory (estimated size 544.0 B, free 1999.1 MB)
17/12/19 15:35:55 INFO BlockManagerInfo: Added rdd_693_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.1 MB)
17/12/19 15:35:55 INFO BlockManagerInfo: Added rdd_693_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.1 MB)
17/12/19 15:35:55 INFO Executor: Finished task 0.0 in stage 347.0 (TID 253). 3072 bytes result sent to driver
17/12/19 15:35:55 INFO TaskSetManager: Finished task 0.0 in stage 347.0 (TID 253) in 10 ms on localhost (executor driver) (1/2)
17/12/19 15:35:55 INFO Executor: Finished task 1.0 in stage 347.0 (TID 254). 3072 bytes result sent to driver
17/12/19 15:35:55 INFO TaskSetManager: Finished task 1.0 in stage 347.0 (TID 254) in 11 ms on localhost (executor driver) (2/2)
17/12/19 15:35:55 INFO TaskSchedulerImpl: Removed TaskSet 347.0, whose tasks have all completed, from pool 
17/12/19 15:35:55 INFO DAGScheduler: ShuffleMapStage 347 (sql at <unknown>:0) finished in 0.011 s
17/12/19 15:35:55 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:35:55 INFO DAGScheduler: running: Set()
17/12/19 15:35:55 INFO DAGScheduler: waiting: Set(ResultStage 348)
17/12/19 15:35:55 INFO DAGScheduler: failed: Set()
17/12/19 15:35:55 INFO DAGScheduler: Submitting ResultStage 348 (MapPartitionsRDD[699] at sql at <unknown>:0), which has no missing parents
17/12/19 15:35:55 INFO MemoryStore: Block broadcast_234 stored as values in memory (estimated size 7.0 KB, free 1999.1 MB)
17/12/19 15:35:55 INFO MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1999.1 MB)
17/12/19 15:35:55 INFO BlockManagerInfo: Added broadcast_234_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.1 MB)
17/12/19 15:35:55 INFO SparkContext: Created broadcast 234 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 348 (MapPartitionsRDD[699] at sql at <unknown>:0)
17/12/19 15:35:55 INFO TaskSchedulerImpl: Adding task set 348.0 with 1 tasks
17/12/19 15:35:55 INFO TaskSetManager: Starting task 0.0 in stage 348.0 (TID 255, localhost, executor driver, partition 0, ANY, 5957 bytes)
17/12/19 15:35:55 INFO Executor: Running task 0.0 in stage 348.0 (TID 255)
17/12/19 15:35:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:35:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:35:55 INFO Executor: Finished task 0.0 in stage 348.0 (TID 255). 1873 bytes result sent to driver
17/12/19 15:35:55 INFO TaskSetManager: Finished task 0.0 in stage 348.0 (TID 255) in 2 ms on localhost (executor driver) (1/1)
17/12/19 15:35:55 INFO TaskSchedulerImpl: Removed TaskSet 348.0, whose tasks have all completed, from pool 
17/12/19 15:35:55 INFO DAGScheduler: ResultStage 348 (sql at <unknown>:0) finished in 0.002 s
17/12/19 15:35:55 INFO DAGScheduler: Job 167 finished: sql at <unknown>:0, took 0.048179 s
17/12/19 15:35:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:55 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 15:35:55 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:35:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 48 is 145 bytes
17/12/19 15:35:55 INFO DAGScheduler: Registering RDD 703 (collect at utils.scala:196)
17/12/19 15:35:55 INFO DAGScheduler: Got job 168 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:35:55 INFO DAGScheduler: Final stage: ResultStage 351 (collect at utils.scala:196)
17/12/19 15:35:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 350)
17/12/19 15:35:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 350)
17/12/19 15:35:55 INFO DAGScheduler: Submitting ShuffleMapStage 350 (MapPartitionsRDD[703] at collect at utils.scala:196), which has no missing parents
17/12/19 15:35:55 INFO MemoryStore: Block broadcast_235 stored as values in memory (estimated size 11.9 KB, free 1999.1 MB)
17/12/19 15:35:55 INFO MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1999.0 MB)
17/12/19 15:35:55 INFO BlockManagerInfo: Added broadcast_235_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.1 MB)
17/12/19 15:35:55 INFO SparkContext: Created broadcast 235 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 350 (MapPartitionsRDD[703] at collect at utils.scala:196)
17/12/19 15:35:55 INFO TaskSchedulerImpl: Adding task set 350.0 with 2 tasks
17/12/19 15:35:55 INFO TaskSetManager: Starting task 0.0 in stage 350.0 (TID 256, localhost, executor driver, partition 0, PROCESS_LOCAL, 5938 bytes)
17/12/19 15:35:55 INFO TaskSetManager: Starting task 1.0 in stage 350.0 (TID 257, localhost, executor driver, partition 1, PROCESS_LOCAL, 5938 bytes)
17/12/19 15:35:55 INFO Executor: Running task 0.0 in stage 350.0 (TID 256)
17/12/19 15:35:55 INFO Executor: Running task 1.0 in stage 350.0 (TID 257)
17/12/19 15:35:55 INFO BlockManager: Found block rdd_693_0 locally
17/12/19 15:35:55 INFO BlockManager: Found block rdd_693_1 locally
17/12/19 15:35:55 INFO Executor: Finished task 1.0 in stage 350.0 (TID 257). 1950 bytes result sent to driver
17/12/19 15:35:55 INFO TaskSetManager: Finished task 1.0 in stage 350.0 (TID 257) in 16 ms on localhost (executor driver) (1/2)
17/12/19 15:35:55 INFO Executor: Finished task 0.0 in stage 350.0 (TID 256). 1871 bytes result sent to driver
17/12/19 15:35:55 INFO TaskSetManager: Finished task 0.0 in stage 350.0 (TID 256) in 16 ms on localhost (executor driver) (2/2)
17/12/19 15:35:55 INFO TaskSchedulerImpl: Removed TaskSet 350.0, whose tasks have all completed, from pool 
17/12/19 15:35:55 INFO DAGScheduler: ShuffleMapStage 350 (collect at utils.scala:196) finished in 0.016 s
17/12/19 15:35:55 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:35:55 INFO DAGScheduler: running: Set()
17/12/19 15:35:55 INFO DAGScheduler: waiting: Set(ResultStage 351)
17/12/19 15:35:55 INFO DAGScheduler: failed: Set()
17/12/19 15:35:55 INFO DAGScheduler: Submitting ResultStage 351 (MapPartitionsRDD[706] at collect at utils.scala:196), which has no missing parents
17/12/19 15:35:55 INFO MemoryStore: Block broadcast_236 stored as values in memory (estimated size 7.0 KB, free 1999.0 MB)
17/12/19 15:35:55 INFO MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1999.0 MB)
17/12/19 15:35:55 INFO BlockManagerInfo: Added broadcast_236_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.1 MB)
17/12/19 15:35:55 INFO SparkContext: Created broadcast 236 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 351 (MapPartitionsRDD[706] at collect at utils.scala:196)
17/12/19 15:35:55 INFO TaskSchedulerImpl: Adding task set 351.0 with 1 tasks
17/12/19 15:35:55 INFO TaskSetManager: Starting task 0.0 in stage 351.0 (TID 258, localhost, executor driver, partition 0, ANY, 5949 bytes)
17/12/19 15:35:55 INFO Executor: Running task 0.0 in stage 351.0 (TID 258)
17/12/19 15:35:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:35:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:35:55 INFO Executor: Finished task 0.0 in stage 351.0 (TID 258). 1707 bytes result sent to driver
17/12/19 15:35:55 INFO TaskSetManager: Finished task 0.0 in stage 351.0 (TID 258) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:35:55 INFO TaskSchedulerImpl: Removed TaskSet 351.0, whose tasks have all completed, from pool 
17/12/19 15:35:55 INFO DAGScheduler: ResultStage 351 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:35:55 INFO DAGScheduler: Job 168 finished: collect at utils.scala:196, took 0.018488 s
17/12/19 15:35:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz50`
WHERE (0 = 1)
17/12/19 15:35:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:35:55 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:35:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 48 is 145 bytes
17/12/19 15:35:55 INFO DAGScheduler: Got job 169 (take at <unknown>:0) with 1 output partitions
17/12/19 15:35:55 INFO DAGScheduler: Final stage: ResultStage 353 (take at <unknown>:0)
17/12/19 15:35:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 352)
17/12/19 15:35:55 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:55 INFO DAGScheduler: Submitting ResultStage 353 (WorkerRDD[710] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:35:55 INFO MemoryStore: Block broadcast_237 stored as values in memory (estimated size 111.0 KB, free 1998.9 MB)
17/12/19 15:35:55 INFO MemoryStore: Block broadcast_237_piece0 stored as bytes in memory (estimated size 45.0 KB, free 1998.9 MB)
17/12/19 15:35:55 INFO BlockManagerInfo: Added broadcast_237_piece0 in memory on 127.0.0.1:53618 (size: 45.0 KB, free: 2004.1 MB)
17/12/19 15:35:55 INFO SparkContext: Created broadcast 237 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 353 (WorkerRDD[710] at RDD at rdd.scala:18)
17/12/19 15:35:55 INFO TaskSchedulerImpl: Adding task set 353.0 with 1 tasks
17/12/19 15:35:55 INFO TaskSetManager: Starting task 0.0 in stage 353.0 (TID 259, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:35:55 INFO Executor: Running task 0.0 in stage 353.0 (TID 259)
17/12/19 15:35:55 INFO BlockManager: Found block rdd_693_0 locally
17/12/19 15:35:55 INFO MemoryStore: Block rdd_710_0 stored as values in memory (estimated size 80.0 B, free 1998.9 MB)
17/12/19 15:35:55 INFO BlockManagerInfo: Added rdd_710_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.1 MB)
17/12/19 15:35:55 INFO Executor: Finished task 0.0 in stage 353.0 (TID 259). 2154 bytes result sent to driver
17/12/19 15:35:55 INFO TaskSetManager: Finished task 0.0 in stage 353.0 (TID 259) in 636 ms on localhost (executor driver) (1/1)
17/12/19 15:35:55 INFO TaskSchedulerImpl: Removed TaskSet 353.0, whose tasks have all completed, from pool 
17/12/19 15:35:55 INFO DAGScheduler: ResultStage 353 (take at <unknown>:0) finished in 0.636 s
17/12/19 15:35:55 INFO DAGScheduler: Job 169 finished: take at <unknown>:0, took 0.637394 s
17/12/19 15:35:55 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:35:55 INFO DAGScheduler: Got job 170 (take at <unknown>:0) with 1 output partitions
17/12/19 15:35:55 INFO DAGScheduler: Final stage: ResultStage 355 (take at <unknown>:0)
17/12/19 15:35:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 354)
17/12/19 15:35:55 INFO DAGScheduler: Missing parents: List()
17/12/19 15:35:55 INFO DAGScheduler: Submitting ResultStage 355 (WorkerRDD[710] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:35:55 INFO MemoryStore: Block broadcast_238 stored as values in memory (estimated size 111.0 KB, free 1998.8 MB)
17/12/19 15:35:55 INFO MemoryStore: Block broadcast_238_piece0 stored as bytes in memory (estimated size 45.1 KB, free 1998.7 MB)
17/12/19 15:35:55 INFO BlockManagerInfo: Added broadcast_238_piece0 in memory on 127.0.0.1:53618 (size: 45.1 KB, free: 2004.0 MB)
17/12/19 15:35:55 INFO SparkContext: Created broadcast 238 from broadcast at DAGScheduler.scala:996
17/12/19 15:35:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 355 (WorkerRDD[710] at RDD at rdd.scala:18)
17/12/19 15:35:55 INFO TaskSchedulerImpl: Adding task set 355.0 with 1 tasks
17/12/19 15:35:55 INFO TaskSetManager: Starting task 0.0 in stage 355.0 (TID 260, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:35:55 INFO Executor: Running task 0.0 in stage 355.0 (TID 260)
17/12/19 15:35:55 INFO BlockManager: Found block rdd_693_1 locally
17/12/19 15:35:56 INFO MemoryStore: Block rdd_710_1 stored as values in memory (estimated size 80.0 B, free 1998.7 MB)
17/12/19 15:35:56 INFO BlockManagerInfo: Added rdd_710_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.0 MB)
17/12/19 15:35:56 INFO Executor: Finished task 0.0 in stage 355.0 (TID 260). 2241 bytes result sent to driver
17/12/19 15:35:56 INFO TaskSetManager: Finished task 0.0 in stage 355.0 (TID 260) in 700 ms on localhost (executor driver) (1/1)
17/12/19 15:35:56 INFO TaskSchedulerImpl: Removed TaskSet 355.0, whose tasks have all completed, from pool 
17/12/19 15:35:56 INFO DAGScheduler: ResultStage 355 (take at <unknown>:0) finished in 0.700 s
17/12/19 15:35:56 INFO DAGScheduler: Job 170 finished: take at <unknown>:0, took 0.708010 s
17/12/19 15:35:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:56 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e868d4200
17/12/19 15:35:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e868d4200` AS `zzz51`
WHERE (0 = 1)
17/12/19 15:35:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:35:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:35:56 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:56 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:56 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:35:56 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:35:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:35:56 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:36:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:36:29 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:36:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:36:29 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:36:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:36:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:36:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:36:29 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 15:36:29 INFO DAGScheduler: Got job 171 (collect at utils.scala:58) with 1 output partitions
17/12/19 15:36:29 INFO DAGScheduler: Final stage: ResultStage 356 (collect at utils.scala:58)
17/12/19 15:36:29 INFO DAGScheduler: Parents of final stage: List()
17/12/19 15:36:29 INFO DAGScheduler: Missing parents: List()
17/12/19 15:36:29 INFO DAGScheduler: Submitting ResultStage 356 (MapPartitionsRDD[719] at map at utils.scala:55), which has no missing parents
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_239 stored as values in memory (estimated size 8.7 KB, free 1998.7 MB)
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_239_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1998.7 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Added broadcast_239_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.0 MB)
17/12/19 15:36:29 INFO SparkContext: Created broadcast 239 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 356 (MapPartitionsRDD[719] at map at utils.scala:55)
17/12/19 15:36:29 INFO TaskSchedulerImpl: Adding task set 356.0 with 1 tasks
17/12/19 15:36:29 INFO TaskSetManager: Starting task 0.0 in stage 356.0 (TID 261, localhost, executor driver, partition 0, PROCESS_LOCAL, 7942 bytes)
17/12/19 15:36:29 INFO Executor: Running task 0.0 in stage 356.0 (TID 261)
17/12/19 15:36:29 INFO Executor: Finished task 0.0 in stage 356.0 (TID 261). 1525 bytes result sent to driver
17/12/19 15:36:29 INFO TaskSetManager: Finished task 0.0 in stage 356.0 (TID 261) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:36:29 INFO TaskSchedulerImpl: Removed TaskSet 356.0, whose tasks have all completed, from pool 
17/12/19 15:36:29 INFO DAGScheduler: ResultStage 356 (collect at utils.scala:58) finished in 0.000 s
17/12/19 15:36:29 INFO DAGScheduler: Job 171 finished: collect at utils.scala:58, took 0.006478 s
17/12/19 15:36:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:29 INFO MapPartitionsRDD: Removing RDD 693 from persistence list
17/12/19 15:36:29 INFO BlockManager: Removing RDD 693
17/12/19 15:36:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:29 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:36:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:29 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 15:36:29 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 15:36:29 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 15:36:29 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 15:36:29 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 15:36:29 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_240 stored as values in memory (estimated size 293.7 KB, free 1998.4 MB)
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_240_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1998.4 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Added broadcast_240_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.0 MB)
17/12/19 15:36:29 INFO SparkContext: Created broadcast 240 from sql at <unknown>:0
17/12/19 15:36:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 15:36:29 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 15:36:29 INFO DAGScheduler: Registering RDD 723 (sql at <unknown>:0)
17/12/19 15:36:29 INFO DAGScheduler: Registering RDD 728 (sql at <unknown>:0)
17/12/19 15:36:29 INFO DAGScheduler: Got job 172 (sql at <unknown>:0) with 1 output partitions
17/12/19 15:36:29 INFO DAGScheduler: Final stage: ResultStage 359 (sql at <unknown>:0)
17/12/19 15:36:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 358)
17/12/19 15:36:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 358)
17/12/19 15:36:29 INFO DAGScheduler: Submitting ShuffleMapStage 357 (MapPartitionsRDD[723] at sql at <unknown>:0), which has no missing parents
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_241 stored as values in memory (estimated size 12.1 KB, free 1998.4 MB)
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_241_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1998.4 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Added broadcast_241_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.0 MB)
17/12/19 15:36:29 INFO SparkContext: Created broadcast 241 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 357 (MapPartitionsRDD[723] at sql at <unknown>:0)
17/12/19 15:36:29 INFO TaskSchedulerImpl: Adding task set 357.0 with 1 tasks
17/12/19 15:36:29 INFO TaskSetManager: Starting task 0.0 in stage 357.0 (TID 262, localhost, executor driver, partition 0, PROCESS_LOCAL, 6680 bytes)
17/12/19 15:36:29 INFO Executor: Running task 0.0 in stage 357.0 (TID 262)
17/12/19 15:36:29 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_c62dfe8fc95af88b97bf1dd9a280a517af6aab8d6db9ccee7d5b2ce9f45f0936.csv, range: 0-456, partition values: [empty row]
17/12/19 15:36:29 INFO Executor: Finished task 0.0 in stage 357.0 (TID 262). 1632 bytes result sent to driver
17/12/19 15:36:29 INFO TaskSetManager: Finished task 0.0 in stage 357.0 (TID 262) in 445 ms on localhost (executor driver) (1/1)
17/12/19 15:36:29 INFO TaskSchedulerImpl: Removed TaskSet 357.0, whose tasks have all completed, from pool 
17/12/19 15:36:29 INFO DAGScheduler: ShuffleMapStage 357 (sql at <unknown>:0) finished in 0.445 s
17/12/19 15:36:29 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:36:29 INFO DAGScheduler: running: Set()
17/12/19 15:36:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 358, ResultStage 359)
17/12/19 15:36:29 INFO DAGScheduler: failed: Set()
17/12/19 15:36:29 INFO DAGScheduler: Submitting ShuffleMapStage 358 (MapPartitionsRDD[728] at sql at <unknown>:0), which has no missing parents
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_242 stored as values in memory (estimated size 11.9 KB, free 1998.4 MB)
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_242_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1998.4 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Added broadcast_242_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.0 MB)
17/12/19 15:36:29 INFO SparkContext: Created broadcast 242 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:29 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 358 (MapPartitionsRDD[728] at sql at <unknown>:0)
17/12/19 15:36:29 INFO TaskSchedulerImpl: Adding task set 358.0 with 2 tasks
17/12/19 15:36:29 INFO TaskSetManager: Starting task 0.0 in stage 358.0 (TID 263, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 15:36:29 INFO TaskSetManager: Starting task 1.0 in stage 358.0 (TID 264, localhost, executor driver, partition 1, ANY, 5946 bytes)
17/12/19 15:36:29 INFO Executor: Running task 1.0 in stage 358.0 (TID 264)
17/12/19 15:36:29 INFO Executor: Running task 0.0 in stage 358.0 (TID 263)
17/12/19 15:36:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:36:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:36:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:36:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:36:29 INFO MemoryStore: Block rdd_725_1 stored as values in memory (estimated size 544.0 B, free 1998.4 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Added rdd_725_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.0 MB)
17/12/19 15:36:29 INFO MemoryStore: Block rdd_725_0 stored as values in memory (estimated size 544.0 B, free 1998.4 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Added rdd_725_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.0 MB)
17/12/19 15:36:29 INFO Executor: Finished task 0.0 in stage 358.0 (TID 263). 3151 bytes result sent to driver
17/12/19 15:36:29 INFO TaskSetManager: Finished task 0.0 in stage 358.0 (TID 263) in 35 ms on localhost (executor driver) (1/2)
17/12/19 15:36:29 INFO Executor: Finished task 1.0 in stage 358.0 (TID 264). 3072 bytes result sent to driver
17/12/19 15:36:29 INFO TaskSetManager: Finished task 1.0 in stage 358.0 (TID 264) in 35 ms on localhost (executor driver) (2/2)
17/12/19 15:36:29 INFO TaskSchedulerImpl: Removed TaskSet 358.0, whose tasks have all completed, from pool 
17/12/19 15:36:29 INFO DAGScheduler: ShuffleMapStage 358 (sql at <unknown>:0) finished in 0.035 s
17/12/19 15:36:29 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:36:29 INFO DAGScheduler: running: Set()
17/12/19 15:36:29 INFO DAGScheduler: waiting: Set(ResultStage 359)
17/12/19 15:36:29 INFO DAGScheduler: failed: Set()
17/12/19 15:36:29 INFO DAGScheduler: Submitting ResultStage 359 (MapPartitionsRDD[731] at sql at <unknown>:0), which has no missing parents
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_243 stored as values in memory (estimated size 7.0 KB, free 1998.4 MB)
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_243_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1998.4 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Added broadcast_243_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.0 MB)
17/12/19 15:36:29 INFO SparkContext: Created broadcast 243 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 359 (MapPartitionsRDD[731] at sql at <unknown>:0)
17/12/19 15:36:29 INFO TaskSchedulerImpl: Adding task set 359.0 with 1 tasks
17/12/19 15:36:29 INFO TaskSetManager: Starting task 0.0 in stage 359.0 (TID 265, localhost, executor driver, partition 0, ANY, 5957 bytes)
17/12/19 15:36:29 INFO Executor: Running task 0.0 in stage 359.0 (TID 265)
17/12/19 15:36:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:36:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:36:29 INFO Executor: Finished task 0.0 in stage 359.0 (TID 265). 1707 bytes result sent to driver
17/12/19 15:36:29 INFO TaskSetManager: Finished task 0.0 in stage 359.0 (TID 265) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:36:29 INFO TaskSchedulerImpl: Removed TaskSet 359.0, whose tasks have all completed, from pool 
17/12/19 15:36:29 INFO DAGScheduler: ResultStage 359 (sql at <unknown>:0) finished in 0.000 s
17/12/19 15:36:29 INFO DAGScheduler: Job 172 finished: sql at <unknown>:0, took 0.492974 s
17/12/19 15:36:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:29 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 15:36:29 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:36:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 51 is 145 bytes
17/12/19 15:36:29 INFO DAGScheduler: Registering RDD 735 (collect at utils.scala:196)
17/12/19 15:36:29 INFO DAGScheduler: Got job 173 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:36:29 INFO DAGScheduler: Final stage: ResultStage 362 (collect at utils.scala:196)
17/12/19 15:36:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 361)
17/12/19 15:36:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 361)
17/12/19 15:36:29 INFO DAGScheduler: Submitting ShuffleMapStage 361 (MapPartitionsRDD[735] at collect at utils.scala:196), which has no missing parents
17/12/19 15:36:29 INFO BlockManagerInfo: Removed broadcast_236_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.0 MB)
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_244 stored as values in memory (estimated size 11.9 KB, free 1998.4 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Removed broadcast_228_piece0 on 127.0.0.1:53618 in memory (size: 50.7 KB, free: 2004.0 MB)
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11754
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11755
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_244_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1998.5 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Added broadcast_244_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.0 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Removed broadcast_229_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.0 MB)
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11804
17/12/19 15:36:29 INFO SparkContext: Created broadcast 244 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11805
17/12/19 15:36:29 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 361 (MapPartitionsRDD[735] at collect at utils.scala:196)
17/12/19 15:36:29 INFO TaskSchedulerImpl: Adding task set 361.0 with 2 tasks
17/12/19 15:36:29 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.0 MB)
17/12/19 15:36:29 INFO TaskSetManager: Starting task 0.0 in stage 361.0 (TID 266, localhost, executor driver, partition 0, PROCESS_LOCAL, 5938 bytes)
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11854
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11855
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11861
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11862
17/12/19 15:36:29 INFO TaskSetManager: Starting task 1.0 in stage 361.0 (TID 267, localhost, executor driver, partition 1, PROCESS_LOCAL, 5938 bytes)
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11863
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11864
17/12/19 15:36:29 INFO Executor: Running task 0.0 in stage 361.0 (TID 266)
17/12/19 15:36:29 INFO Executor: Running task 1.0 in stage 361.0 (TID 267)
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11865
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11866
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11867
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11868
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11869
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11870
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11871
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11872
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 11873
17/12/19 15:36:29 INFO BlockManager: Found block rdd_725_0 locally
17/12/19 15:36:29 INFO BlockManager: Found block rdd_725_1 locally
17/12/19 15:36:29 INFO ContextCleaner: Cleaned shuffle 49
17/12/19 15:36:29 INFO BlockManagerInfo: Removed broadcast_232_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.0 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Removed broadcast_233_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2004.0 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Removed broadcast_234_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.0 MB)
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12042
17/12/19 15:36:29 INFO BlockManagerInfo: Removed broadcast_235_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2004.0 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Removed broadcast_237_piece0 on 127.0.0.1:53618 in memory (size: 45.0 KB, free: 2004.1 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Removed broadcast_238_piece0 on 127.0.0.1:53618 in memory (size: 45.1 KB, free: 2004.1 MB)
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12272
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12273
17/12/19 15:36:29 INFO BlockManagerInfo: Removed broadcast_239_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.1 MB)
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12322
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12323
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12329
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12330
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12331
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12332
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12333
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12334
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12335
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12336
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12337
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12338
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12339
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12340
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12341
17/12/19 15:36:29 INFO ContextCleaner: Cleaned shuffle 52
17/12/19 15:36:29 INFO BlockManagerInfo: Removed broadcast_241_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.1 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Removed broadcast_242_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2004.2 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Removed broadcast_243_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.2 MB)
17/12/19 15:36:29 INFO ContextCleaner: Cleaned accumulator 12510
17/12/19 15:36:29 INFO Executor: Finished task 1.0 in stage 361.0 (TID 267). 1958 bytes result sent to driver
17/12/19 15:36:29 INFO TaskSetManager: Finished task 1.0 in stage 361.0 (TID 267) in 13 ms on localhost (executor driver) (1/2)
17/12/19 15:36:29 INFO Executor: Finished task 0.0 in stage 361.0 (TID 266). 1958 bytes result sent to driver
17/12/19 15:36:29 INFO TaskSetManager: Finished task 0.0 in stage 361.0 (TID 266) in 16 ms on localhost (executor driver) (2/2)
17/12/19 15:36:29 INFO TaskSchedulerImpl: Removed TaskSet 361.0, whose tasks have all completed, from pool 
17/12/19 15:36:29 INFO DAGScheduler: ShuffleMapStage 361 (collect at utils.scala:196) finished in 0.016 s
17/12/19 15:36:29 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:36:29 INFO DAGScheduler: running: Set()
17/12/19 15:36:29 INFO DAGScheduler: waiting: Set(ResultStage 362)
17/12/19 15:36:29 INFO DAGScheduler: failed: Set()
17/12/19 15:36:29 INFO DAGScheduler: Submitting ResultStage 362 (MapPartitionsRDD[738] at collect at utils.scala:196), which has no missing parents
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_245 stored as values in memory (estimated size 7.0 KB, free 1999.0 MB)
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_245_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1999.0 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Added broadcast_245_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.2 MB)
17/12/19 15:36:29 INFO SparkContext: Created broadcast 245 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 362 (MapPartitionsRDD[738] at collect at utils.scala:196)
17/12/19 15:36:29 INFO TaskSchedulerImpl: Adding task set 362.0 with 1 tasks
17/12/19 15:36:29 INFO TaskSetManager: Starting task 0.0 in stage 362.0 (TID 268, localhost, executor driver, partition 0, ANY, 5949 bytes)
17/12/19 15:36:29 INFO Executor: Running task 0.0 in stage 362.0 (TID 268)
17/12/19 15:36:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:36:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:36:29 INFO Executor: Finished task 0.0 in stage 362.0 (TID 268). 1873 bytes result sent to driver
17/12/19 15:36:29 INFO TaskSetManager: Finished task 0.0 in stage 362.0 (TID 268) in 3 ms on localhost (executor driver) (1/1)
17/12/19 15:36:29 INFO TaskSchedulerImpl: Removed TaskSet 362.0, whose tasks have all completed, from pool 
17/12/19 15:36:29 INFO DAGScheduler: ResultStage 362 (collect at utils.scala:196) finished in 0.003 s
17/12/19 15:36:29 INFO DAGScheduler: Job 173 finished: collect at utils.scala:196, took 0.032436 s
17/12/19 15:36:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz52`
WHERE (0 = 1)
17/12/19 15:36:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:36:29 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:36:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 51 is 145 bytes
17/12/19 15:36:29 INFO DAGScheduler: Got job 174 (take at <unknown>:0) with 1 output partitions
17/12/19 15:36:29 INFO DAGScheduler: Final stage: ResultStage 364 (take at <unknown>:0)
17/12/19 15:36:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 363)
17/12/19 15:36:29 INFO DAGScheduler: Missing parents: List()
17/12/19 15:36:29 INFO DAGScheduler: Submitting ResultStage 364 (WorkerRDD[742] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_246 stored as values in memory (estimated size 111.0 KB, free 1998.9 MB)
17/12/19 15:36:29 INFO MemoryStore: Block broadcast_246_piece0 stored as bytes in memory (estimated size 45.1 KB, free 1998.8 MB)
17/12/19 15:36:29 INFO BlockManagerInfo: Added broadcast_246_piece0 in memory on 127.0.0.1:53618 (size: 45.1 KB, free: 2004.1 MB)
17/12/19 15:36:29 INFO SparkContext: Created broadcast 246 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 364 (WorkerRDD[742] at RDD at rdd.scala:18)
17/12/19 15:36:29 INFO TaskSchedulerImpl: Adding task set 364.0 with 1 tasks
17/12/19 15:36:29 INFO TaskSetManager: Starting task 0.0 in stage 364.0 (TID 269, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:36:29 INFO Executor: Running task 0.0 in stage 364.0 (TID 269)
17/12/19 15:36:29 INFO BlockManager: Found block rdd_725_0 locally
17/12/19 15:36:30 INFO MemoryStore: Block rdd_742_0 stored as values in memory (estimated size 80.0 B, free 1998.8 MB)
17/12/19 15:36:30 INFO BlockManagerInfo: Added rdd_742_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.1 MB)
17/12/19 15:36:30 INFO Executor: Finished task 0.0 in stage 364.0 (TID 269). 2241 bytes result sent to driver
17/12/19 15:36:30 INFO TaskSetManager: Finished task 0.0 in stage 364.0 (TID 269) in 639 ms on localhost (executor driver) (1/1)
17/12/19 15:36:30 INFO TaskSchedulerImpl: Removed TaskSet 364.0, whose tasks have all completed, from pool 
17/12/19 15:36:30 INFO DAGScheduler: ResultStage 364 (take at <unknown>:0) finished in 0.639 s
17/12/19 15:36:30 INFO DAGScheduler: Job 174 finished: take at <unknown>:0, took 0.649580 s
17/12/19 15:36:30 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:36:30 INFO DAGScheduler: Got job 175 (take at <unknown>:0) with 1 output partitions
17/12/19 15:36:30 INFO DAGScheduler: Final stage: ResultStage 366 (take at <unknown>:0)
17/12/19 15:36:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 365)
17/12/19 15:36:30 INFO DAGScheduler: Missing parents: List()
17/12/19 15:36:30 INFO DAGScheduler: Submitting ResultStage 366 (WorkerRDD[742] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:36:30 INFO MemoryStore: Block broadcast_247 stored as values in memory (estimated size 111.0 KB, free 1998.7 MB)
17/12/19 15:36:30 INFO MemoryStore: Block broadcast_247_piece0 stored as bytes in memory (estimated size 45.1 KB, free 1998.7 MB)
17/12/19 15:36:30 INFO BlockManagerInfo: Added broadcast_247_piece0 in memory on 127.0.0.1:53618 (size: 45.1 KB, free: 2004.1 MB)
17/12/19 15:36:30 INFO SparkContext: Created broadcast 247 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 366 (WorkerRDD[742] at RDD at rdd.scala:18)
17/12/19 15:36:30 INFO TaskSchedulerImpl: Adding task set 366.0 with 1 tasks
17/12/19 15:36:30 INFO TaskSetManager: Starting task 0.0 in stage 366.0 (TID 270, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:36:30 INFO Executor: Running task 0.0 in stage 366.0 (TID 270)
17/12/19 15:36:30 INFO BlockManager: Found block rdd_725_1 locally
17/12/19 15:36:31 INFO MemoryStore: Block rdd_742_1 stored as values in memory (estimated size 80.0 B, free 1998.7 MB)
17/12/19 15:36:31 INFO BlockManagerInfo: Added rdd_742_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.1 MB)
17/12/19 15:36:31 INFO Executor: Finished task 0.0 in stage 366.0 (TID 270). 2233 bytes result sent to driver
17/12/19 15:36:31 INFO TaskSetManager: Finished task 0.0 in stage 366.0 (TID 270) in 661 ms on localhost (executor driver) (1/1)
17/12/19 15:36:31 INFO TaskSchedulerImpl: Removed TaskSet 366.0, whose tasks have all completed, from pool 
17/12/19 15:36:31 INFO DAGScheduler: ResultStage 366 (take at <unknown>:0) finished in 0.661 s
17/12/19 15:36:31 INFO DAGScheduler: Job 175 finished: take at <unknown>:0, took 0.651081 s
17/12/19 15:36:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:31 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e8663a265d
17/12/19 15:36:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8663a265d` AS `zzz53`
WHERE (0 = 1)
17/12/19 15:36:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8663a265d`
LIMIT 10
17/12/19 15:36:31 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:36:31 INFO DAGScheduler: Got job 176 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:36:31 INFO DAGScheduler: Final stage: ResultStage 368 (collect at utils.scala:196)
17/12/19 15:36:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 367)
17/12/19 15:36:31 INFO DAGScheduler: Missing parents: List()
17/12/19 15:36:31 INFO DAGScheduler: Submitting ResultStage 368 (MapPartitionsRDD[746] at collect at utils.scala:196), which has no missing parents
17/12/19 15:36:31 INFO MemoryStore: Block broadcast_248 stored as values in memory (estimated size 114.1 KB, free 1998.6 MB)
17/12/19 15:36:31 INFO MemoryStore: Block broadcast_248_piece0 stored as bytes in memory (estimated size 46.9 KB, free 1998.5 MB)
17/12/19 15:36:31 INFO BlockManagerInfo: Added broadcast_248_piece0 in memory on 127.0.0.1:53618 (size: 46.9 KB, free: 2004.0 MB)
17/12/19 15:36:31 INFO SparkContext: Created broadcast 248 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 368 (MapPartitionsRDD[746] at collect at utils.scala:196)
17/12/19 15:36:31 INFO TaskSchedulerImpl: Adding task set 368.0 with 1 tasks
17/12/19 15:36:31 INFO TaskSetManager: Starting task 0.0 in stage 368.0 (TID 271, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 15:36:31 INFO Executor: Running task 0.0 in stage 368.0 (TID 271)
17/12/19 15:36:31 INFO BlockManager: Found block rdd_742_0 locally
17/12/19 15:36:31 INFO Executor: Finished task 0.0 in stage 368.0 (TID 271). 1233 bytes result sent to driver
17/12/19 15:36:31 INFO TaskSetManager: Finished task 0.0 in stage 368.0 (TID 271) in 1 ms on localhost (executor driver) (1/1)
17/12/19 15:36:31 INFO TaskSchedulerImpl: Removed TaskSet 368.0, whose tasks have all completed, from pool 
17/12/19 15:36:31 INFO DAGScheduler: ResultStage 368 (collect at utils.scala:196) finished in 0.001 s
17/12/19 15:36:31 INFO DAGScheduler: Job 176 finished: collect at utils.scala:196, took 0.007017 s
17/12/19 15:36:31 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:36:31 INFO DAGScheduler: Got job 177 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:36:31 INFO DAGScheduler: Final stage: ResultStage 370 (collect at utils.scala:196)
17/12/19 15:36:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 369)
17/12/19 15:36:31 INFO DAGScheduler: Missing parents: List()
17/12/19 15:36:31 INFO DAGScheduler: Submitting ResultStage 370 (MapPartitionsRDD[746] at collect at utils.scala:196), which has no missing parents
17/12/19 15:36:31 INFO MemoryStore: Block broadcast_249 stored as values in memory (estimated size 114.1 KB, free 1998.4 MB)
17/12/19 15:36:31 INFO MemoryStore: Block broadcast_249_piece0 stored as bytes in memory (estimated size 46.9 KB, free 1998.4 MB)
17/12/19 15:36:31 INFO BlockManagerInfo: Added broadcast_249_piece0 in memory on 127.0.0.1:53618 (size: 46.9 KB, free: 2004.0 MB)
17/12/19 15:36:31 INFO SparkContext: Created broadcast 249 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 370 (MapPartitionsRDD[746] at collect at utils.scala:196)
17/12/19 15:36:31 INFO TaskSchedulerImpl: Adding task set 370.0 with 1 tasks
17/12/19 15:36:31 INFO TaskSetManager: Starting task 0.0 in stage 370.0 (TID 272, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 15:36:31 INFO Executor: Running task 0.0 in stage 370.0 (TID 272)
17/12/19 15:36:31 INFO BlockManager: Found block rdd_742_1 locally
17/12/19 15:36:31 INFO Executor: Finished task 0.0 in stage 370.0 (TID 272). 1233 bytes result sent to driver
17/12/19 15:36:31 INFO TaskSetManager: Finished task 0.0 in stage 370.0 (TID 272) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:36:31 INFO TaskSchedulerImpl: Removed TaskSet 370.0, whose tasks have all completed, from pool 
17/12/19 15:36:31 INFO DAGScheduler: ResultStage 370 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:36:31 INFO DAGScheduler: Job 177 finished: collect at utils.scala:196, took 0.006617 s
17/12/19 15:36:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:31 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `xnrcuwmemo`
17/12/19 15:36:31 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:36:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz54`
WHERE (0 = 1)
17/12/19 15:36:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:36:31 INFO CodeGenerator: Code generated in 7.43986 ms
17/12/19 15:36:31 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:36:31 INFO DAGScheduler: Got job 178 (take at <unknown>:0) with 1 output partitions
17/12/19 15:36:31 INFO DAGScheduler: Final stage: ResultStage 372 (take at <unknown>:0)
17/12/19 15:36:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 371)
17/12/19 15:36:31 INFO DAGScheduler: Missing parents: List()
17/12/19 15:36:31 INFO DAGScheduler: Submitting ResultStage 372 (WorkerRDD[752] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:36:31 INFO MemoryStore: Block broadcast_250 stored as values in memory (estimated size 119.2 KB, free 1998.2 MB)
17/12/19 15:36:31 INFO MemoryStore: Block broadcast_250_piece0 stored as bytes in memory (estimated size 47.5 KB, free 1998.2 MB)
17/12/19 15:36:31 INFO BlockManagerInfo: Added broadcast_250_piece0 in memory on 127.0.0.1:53618 (size: 47.5 KB, free: 2003.9 MB)
17/12/19 15:36:31 INFO SparkContext: Created broadcast 250 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 372 (WorkerRDD[752] at RDD at rdd.scala:18)
17/12/19 15:36:31 INFO TaskSchedulerImpl: Adding task set 372.0 with 1 tasks
17/12/19 15:36:31 INFO TaskSetManager: Starting task 0.0 in stage 372.0 (TID 273, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:36:31 INFO Executor: Running task 0.0 in stage 372.0 (TID 273)
17/12/19 15:36:31 INFO BlockManager: Found block rdd_725_0 locally
17/12/19 15:36:32 INFO MemoryStore: Block rdd_752_0 stored as values in memory (estimated size 608.0 B, free 1998.2 MB)
17/12/19 15:36:32 INFO BlockManagerInfo: Added rdd_752_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 15:36:32 INFO Executor: Finished task 0.0 in stage 372.0 (TID 273). 2509 bytes result sent to driver
17/12/19 15:36:32 INFO TaskSetManager: Finished task 0.0 in stage 372.0 (TID 273) in 695 ms on localhost (executor driver) (1/1)
17/12/19 15:36:32 INFO TaskSchedulerImpl: Removed TaskSet 372.0, whose tasks have all completed, from pool 
17/12/19 15:36:32 INFO DAGScheduler: ResultStage 372 (take at <unknown>:0) finished in 0.695 s
17/12/19 15:36:32 INFO DAGScheduler: Job 178 finished: take at <unknown>:0, took 0.690737 s
17/12/19 15:36:32 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:36:32 INFO DAGScheduler: Got job 179 (take at <unknown>:0) with 1 output partitions
17/12/19 15:36:32 INFO DAGScheduler: Final stage: ResultStage 374 (take at <unknown>:0)
17/12/19 15:36:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 373)
17/12/19 15:36:32 INFO DAGScheduler: Missing parents: List()
17/12/19 15:36:32 INFO DAGScheduler: Submitting ResultStage 374 (WorkerRDD[752] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:36:32 INFO MemoryStore: Block broadcast_251 stored as values in memory (estimated size 119.2 KB, free 1998.1 MB)
17/12/19 15:36:32 INFO MemoryStore: Block broadcast_251_piece0 stored as bytes in memory (estimated size 47.5 KB, free 1998.0 MB)
17/12/19 15:36:32 INFO BlockManagerInfo: Added broadcast_251_piece0 in memory on 127.0.0.1:53618 (size: 47.5 KB, free: 2003.9 MB)
17/12/19 15:36:32 INFO SparkContext: Created broadcast 251 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 374 (WorkerRDD[752] at RDD at rdd.scala:18)
17/12/19 15:36:32 INFO TaskSchedulerImpl: Adding task set 374.0 with 1 tasks
17/12/19 15:36:32 INFO TaskSetManager: Starting task 0.0 in stage 374.0 (TID 274, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:36:32 INFO Executor: Running task 0.0 in stage 374.0 (TID 274)
17/12/19 15:36:32 INFO BlockManager: Found block rdd_725_1 locally
17/12/19 15:36:32 INFO MemoryStore: Block rdd_752_1 stored as values in memory (estimated size 608.0 B, free 1998.0 MB)
17/12/19 15:36:32 INFO BlockManagerInfo: Added rdd_752_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 15:36:32 INFO Executor: Finished task 0.0 in stage 374.0 (TID 274). 2675 bytes result sent to driver
17/12/19 15:36:32 INFO TaskSetManager: Finished task 0.0 in stage 374.0 (TID 274) in 667 ms on localhost (executor driver) (1/1)
17/12/19 15:36:32 INFO TaskSchedulerImpl: Removed TaskSet 374.0, whose tasks have all completed, from pool 
17/12/19 15:36:32 INFO DAGScheduler: ResultStage 374 (take at <unknown>:0) finished in 0.667 s
17/12/19 15:36:32 INFO DAGScheduler: Job 179 finished: take at <unknown>:0, took 0.679424 s
17/12/19 15:36:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:32 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e8337351aa
17/12/19 15:36:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8337351aa` AS `zzz55`
WHERE (0 = 1)
17/12/19 15:36:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8337351aa`
17/12/19 15:36:32 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:36:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz56`
WHERE (0 = 1)
17/12/19 15:36:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 15:36:32 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:36:32 INFO DAGScheduler: Got job 180 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:36:32 INFO DAGScheduler: Final stage: ResultStage 376 (collect at utils.scala:196)
17/12/19 15:36:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 375)
17/12/19 15:36:32 INFO DAGScheduler: Missing parents: List()
17/12/19 15:36:32 INFO DAGScheduler: Submitting ResultStage 376 (MapPartitionsRDD[757] at collect at utils.scala:196), which has no missing parents
17/12/19 15:36:32 INFO MemoryStore: Block broadcast_252 stored as values in memory (estimated size 123.0 KB, free 1997.9 MB)
17/12/19 15:36:32 INFO MemoryStore: Block broadcast_252_piece0 stored as bytes in memory (estimated size 49.4 KB, free 1997.9 MB)
17/12/19 15:36:32 INFO BlockManagerInfo: Added broadcast_252_piece0 in memory on 127.0.0.1:53618 (size: 49.4 KB, free: 2003.8 MB)
17/12/19 15:36:32 INFO SparkContext: Created broadcast 252 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 376 (MapPartitionsRDD[757] at collect at utils.scala:196)
17/12/19 15:36:32 INFO TaskSchedulerImpl: Adding task set 376.0 with 1 tasks
17/12/19 15:36:32 INFO TaskSetManager: Starting task 0.0 in stage 376.0 (TID 275, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 15:36:32 INFO Executor: Running task 0.0 in stage 376.0 (TID 275)
17/12/19 15:36:32 INFO BlockManager: Found block rdd_752_0 locally
17/12/19 15:36:32 INFO Executor: Finished task 0.0 in stage 376.0 (TID 275). 1458 bytes result sent to driver
17/12/19 15:36:32 INFO TaskSetManager: Finished task 0.0 in stage 376.0 (TID 275) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:36:32 INFO TaskSchedulerImpl: Removed TaskSet 376.0, whose tasks have all completed, from pool 
17/12/19 15:36:32 INFO DAGScheduler: ResultStage 376 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:36:32 INFO DAGScheduler: Job 180 finished: collect at utils.scala:196, took 0.008023 s
17/12/19 15:36:32 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:36:32 INFO DAGScheduler: Got job 181 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:36:32 INFO DAGScheduler: Final stage: ResultStage 378 (collect at utils.scala:196)
17/12/19 15:36:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 377)
17/12/19 15:36:32 INFO DAGScheduler: Missing parents: List()
17/12/19 15:36:32 INFO DAGScheduler: Submitting ResultStage 378 (MapPartitionsRDD[757] at collect at utils.scala:196), which has no missing parents
17/12/19 15:36:32 INFO MemoryStore: Block broadcast_253 stored as values in memory (estimated size 123.0 KB, free 1997.7 MB)
17/12/19 15:36:32 INFO MemoryStore: Block broadcast_253_piece0 stored as bytes in memory (estimated size 49.4 KB, free 1997.7 MB)
17/12/19 15:36:32 INFO BlockManagerInfo: Added broadcast_253_piece0 in memory on 127.0.0.1:53618 (size: 49.4 KB, free: 2003.8 MB)
17/12/19 15:36:32 INFO SparkContext: Created broadcast 253 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 378 (MapPartitionsRDD[757] at collect at utils.scala:196)
17/12/19 15:36:32 INFO TaskSchedulerImpl: Adding task set 378.0 with 1 tasks
17/12/19 15:36:32 INFO TaskSetManager: Starting task 0.0 in stage 378.0 (TID 276, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 15:36:32 INFO Executor: Running task 0.0 in stage 378.0 (TID 276)
17/12/19 15:36:32 INFO BlockManager: Found block rdd_752_1 locally
17/12/19 15:36:32 INFO Executor: Finished task 0.0 in stage 378.0 (TID 276). 1457 bytes result sent to driver
17/12/19 15:36:32 INFO TaskSetManager: Finished task 0.0 in stage 378.0 (TID 276) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:36:32 INFO TaskSchedulerImpl: Removed TaskSet 378.0, whose tasks have all completed, from pool 
17/12/19 15:36:32 INFO DAGScheduler: ResultStage 378 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:36:32 INFO DAGScheduler: Job 181 finished: collect at utils.scala:196, took 0.007305 s
17/12/19 15:36:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:32 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 15:36:32 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:36:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz57`
WHERE (0 = 1)
17/12/19 15:36:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 15:36:32 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:36:32 INFO DAGScheduler: Got job 182 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:36:32 INFO DAGScheduler: Final stage: ResultStage 380 (collect at utils.scala:196)
17/12/19 15:36:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 379)
17/12/19 15:36:32 INFO DAGScheduler: Missing parents: List()
17/12/19 15:36:32 INFO DAGScheduler: Submitting ResultStage 380 (MapPartitionsRDD[761] at collect at utils.scala:196), which has no missing parents
17/12/19 15:36:32 INFO MemoryStore: Block broadcast_254 stored as values in memory (estimated size 126.5 KB, free 1997.6 MB)
17/12/19 15:36:32 INFO MemoryStore: Block broadcast_254_piece0 stored as bytes in memory (estimated size 50.7 KB, free 1997.5 MB)
17/12/19 15:36:32 INFO BlockManagerInfo: Added broadcast_254_piece0 in memory on 127.0.0.1:53618 (size: 50.7 KB, free: 2003.7 MB)
17/12/19 15:36:32 INFO SparkContext: Created broadcast 254 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 380 (MapPartitionsRDD[761] at collect at utils.scala:196)
17/12/19 15:36:32 INFO TaskSchedulerImpl: Adding task set 380.0 with 1 tasks
17/12/19 15:36:32 INFO TaskSetManager: Starting task 0.0 in stage 380.0 (TID 277, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 15:36:32 INFO Executor: Running task 0.0 in stage 380.0 (TID 277)
17/12/19 15:36:32 INFO BlockManager: Found block rdd_752_0 locally
17/12/19 15:36:32 INFO Executor: Finished task 0.0 in stage 380.0 (TID 277). 1415 bytes result sent to driver
17/12/19 15:36:32 INFO TaskSetManager: Finished task 0.0 in stage 380.0 (TID 277) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:36:32 INFO TaskSchedulerImpl: Removed TaskSet 380.0, whose tasks have all completed, from pool 
17/12/19 15:36:32 INFO DAGScheduler: ResultStage 380 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:36:32 INFO DAGScheduler: Job 182 finished: collect at utils.scala:196, took 0.008874 s
17/12/19 15:36:32 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:36:32 INFO DAGScheduler: Got job 183 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:36:32 INFO DAGScheduler: Final stage: ResultStage 382 (collect at utils.scala:196)
17/12/19 15:36:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 381)
17/12/19 15:36:32 INFO DAGScheduler: Missing parents: List()
17/12/19 15:36:32 INFO DAGScheduler: Submitting ResultStage 382 (MapPartitionsRDD[761] at collect at utils.scala:196), which has no missing parents
17/12/19 15:36:32 INFO MemoryStore: Block broadcast_255 stored as values in memory (estimated size 126.5 KB, free 1997.4 MB)
17/12/19 15:36:32 INFO MemoryStore: Block broadcast_255_piece0 stored as bytes in memory (estimated size 50.7 KB, free 1997.3 MB)
17/12/19 15:36:32 INFO BlockManagerInfo: Added broadcast_255_piece0 in memory on 127.0.0.1:53618 (size: 50.7 KB, free: 2003.7 MB)
17/12/19 15:36:32 INFO SparkContext: Created broadcast 255 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 382 (MapPartitionsRDD[761] at collect at utils.scala:196)
17/12/19 15:36:32 INFO TaskSchedulerImpl: Adding task set 382.0 with 1 tasks
17/12/19 15:36:32 INFO TaskSetManager: Starting task 0.0 in stage 382.0 (TID 278, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 15:36:32 INFO Executor: Running task 0.0 in stage 382.0 (TID 278)
17/12/19 15:36:32 INFO BlockManager: Found block rdd_752_1 locally
17/12/19 15:36:32 INFO Executor: Finished task 0.0 in stage 382.0 (TID 278). 1426 bytes result sent to driver
17/12/19 15:36:32 INFO TaskSetManager: Finished task 0.0 in stage 382.0 (TID 278) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:36:32 INFO TaskSchedulerImpl: Removed TaskSet 382.0, whose tasks have all completed, from pool 
17/12/19 15:36:32 INFO DAGScheduler: ResultStage 382 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:36:32 INFO DAGScheduler: Job 183 finished: collect at utils.scala:196, took 0.011102 s
17/12/19 15:36:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:36:32 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:36:32 INFO DAGScheduler: Got job 184 (collect at utils.scala:196) with 2 output partitions
17/12/19 15:36:32 INFO DAGScheduler: Final stage: ResultStage 384 (collect at utils.scala:196)
17/12/19 15:36:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 383)
17/12/19 15:36:32 INFO DAGScheduler: Missing parents: List()
17/12/19 15:36:32 INFO DAGScheduler: Submitting ResultStage 384 (MapPartitionsRDD[764] at collect at utils.scala:196), which has no missing parents
17/12/19 15:36:32 INFO MemoryStore: Block broadcast_256 stored as values in memory (estimated size 126.7 KB, free 1997.2 MB)
17/12/19 15:36:32 INFO MemoryStore: Block broadcast_256_piece0 stored as bytes in memory (estimated size 50.7 KB, free 1997.2 MB)
17/12/19 15:36:32 INFO BlockManagerInfo: Added broadcast_256_piece0 in memory on 127.0.0.1:53618 (size: 50.7 KB, free: 2003.6 MB)
17/12/19 15:36:32 INFO SparkContext: Created broadcast 256 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 384 (MapPartitionsRDD[764] at collect at utils.scala:196)
17/12/19 15:36:32 INFO TaskSchedulerImpl: Adding task set 384.0 with 2 tasks
17/12/19 15:36:32 INFO TaskSetManager: Starting task 0.0 in stage 384.0 (TID 279, localhost, executor driver, partition 0, PROCESS_LOCAL, 5949 bytes)
17/12/19 15:36:32 INFO TaskSetManager: Starting task 1.0 in stage 384.0 (TID 280, localhost, executor driver, partition 1, PROCESS_LOCAL, 5949 bytes)
17/12/19 15:36:32 INFO Executor: Running task 1.0 in stage 384.0 (TID 280)
17/12/19 15:36:32 INFO Executor: Running task 0.0 in stage 384.0 (TID 279)
17/12/19 15:36:32 INFO BlockManager: Found block rdd_752_0 locally
17/12/19 15:36:32 INFO BlockManager: Found block rdd_752_1 locally
17/12/19 15:36:32 INFO Executor: Finished task 0.0 in stage 384.0 (TID 279). 1616 bytes result sent to driver
17/12/19 15:36:32 INFO Executor: Finished task 1.0 in stage 384.0 (TID 280). 1627 bytes result sent to driver
17/12/19 15:36:32 INFO TaskSetManager: Finished task 1.0 in stage 384.0 (TID 280) in 15 ms on localhost (executor driver) (1/2)
17/12/19 15:36:32 INFO TaskSetManager: Finished task 0.0 in stage 384.0 (TID 279) in 15 ms on localhost (executor driver) (2/2)
17/12/19 15:36:32 INFO TaskSchedulerImpl: Removed TaskSet 384.0, whose tasks have all completed, from pool 
17/12/19 15:36:32 INFO DAGScheduler: ResultStage 384 (collect at utils.scala:196) finished in 0.015 s
17/12/19 15:36:32 INFO DAGScheduler: Job 184 finished: collect at utils.scala:196, took 0.009895 s
17/12/19 15:36:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:36:32 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:36:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:36:32 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:36:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:36:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:36:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:36:33 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 15:36:33 INFO DAGScheduler: Got job 185 (collect at utils.scala:58) with 1 output partitions
17/12/19 15:36:33 INFO DAGScheduler: Final stage: ResultStage 385 (collect at utils.scala:58)
17/12/19 15:36:33 INFO DAGScheduler: Parents of final stage: List()
17/12/19 15:36:33 INFO DAGScheduler: Missing parents: List()
17/12/19 15:36:33 INFO DAGScheduler: Submitting ResultStage 385 (MapPartitionsRDD[770] at map at utils.scala:55), which has no missing parents
17/12/19 15:36:33 INFO MemoryStore: Block broadcast_257 stored as values in memory (estimated size 8.7 KB, free 1997.2 MB)
17/12/19 15:36:33 INFO MemoryStore: Block broadcast_257_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1997.2 MB)
17/12/19 15:36:33 INFO BlockManagerInfo: Added broadcast_257_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.6 MB)
17/12/19 15:36:33 INFO SparkContext: Created broadcast 257 from broadcast at DAGScheduler.scala:996
17/12/19 15:36:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 385 (MapPartitionsRDD[770] at map at utils.scala:55)
17/12/19 15:36:33 INFO TaskSchedulerImpl: Adding task set 385.0 with 1 tasks
17/12/19 15:36:33 INFO TaskSetManager: Starting task 0.0 in stage 385.0 (TID 281, localhost, executor driver, partition 0, PROCESS_LOCAL, 8086 bytes)
17/12/19 15:36:33 INFO Executor: Running task 0.0 in stage 385.0 (TID 281)
17/12/19 15:36:33 INFO Executor: Finished task 0.0 in stage 385.0 (TID 281). 1581 bytes result sent to driver
17/12/19 15:36:33 INFO TaskSetManager: Finished task 0.0 in stage 385.0 (TID 281) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:36:33 INFO TaskSchedulerImpl: Removed TaskSet 385.0, whose tasks have all completed, from pool 
17/12/19 15:36:33 INFO DAGScheduler: ResultStage 385 (collect at utils.scala:58) finished in 0.000 s
17/12/19 15:36:33 INFO DAGScheduler: Job 185 finished: collect at utils.scala:58, took 0.006545 s
17/12/19 15:36:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:33 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:36:33 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:36:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:36:33 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:36:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:36:33 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:36:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:36:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:33 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:36:33 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:36:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:36:33 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:36:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:36:33 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:36:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:36:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:33 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:36:33 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:36:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:36:33 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:36:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:36:33 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:36:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:36:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:33 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:36:33 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:36:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:36:33 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:36:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:36:33 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:36:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:36:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:36:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:36:41 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:36:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:36:41 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:36:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:36:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:36:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:39:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:39:07 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:39:07 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:39:07 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:39:07 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:39:07 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:39:07 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:39:07 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 15:39:07 INFO DAGScheduler: Got job 186 (collect at utils.scala:58) with 1 output partitions
17/12/19 15:39:07 INFO DAGScheduler: Final stage: ResultStage 386 (collect at utils.scala:58)
17/12/19 15:39:07 INFO DAGScheduler: Parents of final stage: List()
17/12/19 15:39:07 INFO DAGScheduler: Missing parents: List()
17/12/19 15:39:07 INFO DAGScheduler: Submitting ResultStage 386 (MapPartitionsRDD[781] at map at utils.scala:55), which has no missing parents
17/12/19 15:39:07 INFO MemoryStore: Block broadcast_258 stored as values in memory (estimated size 8.7 KB, free 1997.1 MB)
17/12/19 15:39:07 INFO MemoryStore: Block broadcast_258_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1997.1 MB)
17/12/19 15:39:07 INFO BlockManagerInfo: Added broadcast_258_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.6 MB)
17/12/19 15:39:07 INFO SparkContext: Created broadcast 258 from broadcast at DAGScheduler.scala:996
17/12/19 15:39:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 386 (MapPartitionsRDD[781] at map at utils.scala:55)
17/12/19 15:39:07 INFO TaskSchedulerImpl: Adding task set 386.0 with 1 tasks
17/12/19 15:39:07 INFO TaskSetManager: Starting task 0.0 in stage 386.0 (TID 282, localhost, executor driver, partition 0, PROCESS_LOCAL, 8086 bytes)
17/12/19 15:39:07 INFO Executor: Running task 0.0 in stage 386.0 (TID 282)
17/12/19 15:39:07 INFO Executor: Finished task 0.0 in stage 386.0 (TID 282). 1581 bytes result sent to driver
17/12/19 15:39:07 INFO TaskSetManager: Finished task 0.0 in stage 386.0 (TID 282) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:39:07 INFO TaskSchedulerImpl: Removed TaskSet 386.0, whose tasks have all completed, from pool 
17/12/19 15:39:07 INFO DAGScheduler: ResultStage 386 (collect at utils.scala:58) finished in 0.000 s
17/12/19 15:39:07 INFO DAGScheduler: Job 186 finished: collect at utils.scala:58, took 0.006219 s
17/12/19 15:39:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:08 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:39:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:08 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 15:39:08 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 15:39:08 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 15:39:08 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 15:39:08 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 15:39:08 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 15:39:08 INFO MemoryStore: Block broadcast_259 stored as values in memory (estimated size 293.7 KB, free 1996.9 MB)
17/12/19 15:39:08 INFO MemoryStore: Block broadcast_259_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1996.8 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Added broadcast_259_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2003.6 MB)
17/12/19 15:39:08 INFO SparkContext: Created broadcast 259 from sql at <unknown>:0
17/12/19 15:39:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 15:39:08 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 15:39:08 INFO DAGScheduler: Registering RDD 785 (sql at <unknown>:0)
17/12/19 15:39:08 INFO DAGScheduler: Registering RDD 790 (sql at <unknown>:0)
17/12/19 15:39:08 INFO DAGScheduler: Got job 187 (sql at <unknown>:0) with 1 output partitions
17/12/19 15:39:08 INFO DAGScheduler: Final stage: ResultStage 389 (sql at <unknown>:0)
17/12/19 15:39:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 388)
17/12/19 15:39:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 388)
17/12/19 15:39:08 INFO DAGScheduler: Submitting ShuffleMapStage 387 (MapPartitionsRDD[785] at sql at <unknown>:0), which has no missing parents
17/12/19 15:39:08 INFO MemoryStore: Block broadcast_260 stored as values in memory (estimated size 12.1 KB, free 1996.8 MB)
17/12/19 15:39:08 INFO MemoryStore: Block broadcast_260_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1996.8 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Added broadcast_260_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2003.6 MB)
17/12/19 15:39:08 INFO SparkContext: Created broadcast 260 from broadcast at DAGScheduler.scala:996
17/12/19 15:39:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 387 (MapPartitionsRDD[785] at sql at <unknown>:0)
17/12/19 15:39:08 INFO TaskSchedulerImpl: Adding task set 387.0 with 1 tasks
17/12/19 15:39:08 INFO TaskSetManager: Starting task 0.0 in stage 387.0 (TID 283, localhost, executor driver, partition 0, PROCESS_LOCAL, 6680 bytes)
17/12/19 15:39:08 INFO Executor: Running task 0.0 in stage 387.0 (TID 283)
17/12/19 15:39:08 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_0aa602dd4d3a8dce751770459e9e7901e127656b4ebb86b027c4d3032d5b0a30.csv, range: 0-454, partition values: [empty row]
17/12/19 15:39:08 INFO Executor: Finished task 0.0 in stage 387.0 (TID 283). 1632 bytes result sent to driver
17/12/19 15:39:08 INFO TaskSetManager: Finished task 0.0 in stage 387.0 (TID 283) in 16 ms on localhost (executor driver) (1/1)
17/12/19 15:39:08 INFO TaskSchedulerImpl: Removed TaskSet 387.0, whose tasks have all completed, from pool 
17/12/19 15:39:08 INFO DAGScheduler: ShuffleMapStage 387 (sql at <unknown>:0) finished in 0.016 s
17/12/19 15:39:08 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:39:08 INFO DAGScheduler: running: Set()
17/12/19 15:39:08 INFO DAGScheduler: waiting: Set(ResultStage 389, ShuffleMapStage 388)
17/12/19 15:39:08 INFO DAGScheduler: failed: Set()
17/12/19 15:39:08 INFO DAGScheduler: Submitting ShuffleMapStage 388 (MapPartitionsRDD[790] at sql at <unknown>:0), which has no missing parents
17/12/19 15:39:08 INFO MemoryStore: Block broadcast_261 stored as values in memory (estimated size 11.9 KB, free 1996.8 MB)
17/12/19 15:39:08 INFO MemoryStore: Block broadcast_261_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1996.8 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Added broadcast_261_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2003.6 MB)
17/12/19 15:39:08 INFO SparkContext: Created broadcast 261 from broadcast at DAGScheduler.scala:996
17/12/19 15:39:08 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 388 (MapPartitionsRDD[790] at sql at <unknown>:0)
17/12/19 15:39:08 INFO TaskSchedulerImpl: Adding task set 388.0 with 2 tasks
17/12/19 15:39:08 INFO TaskSetManager: Starting task 0.0 in stage 388.0 (TID 284, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 15:39:08 INFO TaskSetManager: Starting task 1.0 in stage 388.0 (TID 285, localhost, executor driver, partition 1, ANY, 5946 bytes)
17/12/19 15:39:08 INFO Executor: Running task 0.0 in stage 388.0 (TID 284)
17/12/19 15:39:08 INFO Executor: Running task 1.0 in stage 388.0 (TID 285)
17/12/19 15:39:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:39:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:39:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:39:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:39:08 INFO MemoryStore: Block rdd_787_0 stored as values in memory (estimated size 544.0 B, free 1996.8 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Added rdd_787_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2003.6 MB)
17/12/19 15:39:08 INFO MemoryStore: Block rdd_787_1 stored as values in memory (estimated size 544.0 B, free 1996.8 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Added rdd_787_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2003.6 MB)
17/12/19 15:39:08 INFO Executor: Finished task 1.0 in stage 388.0 (TID 285). 2985 bytes result sent to driver
17/12/19 15:39:08 INFO TaskSetManager: Finished task 1.0 in stage 388.0 (TID 285) in 15 ms on localhost (executor driver) (1/2)
17/12/19 15:39:08 INFO Executor: Finished task 0.0 in stage 388.0 (TID 284). 3064 bytes result sent to driver
17/12/19 15:39:08 INFO TaskSetManager: Finished task 0.0 in stage 388.0 (TID 284) in 15 ms on localhost (executor driver) (2/2)
17/12/19 15:39:08 INFO TaskSchedulerImpl: Removed TaskSet 388.0, whose tasks have all completed, from pool 
17/12/19 15:39:08 INFO DAGScheduler: ShuffleMapStage 388 (sql at <unknown>:0) finished in 0.015 s
17/12/19 15:39:08 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:39:08 INFO DAGScheduler: running: Set()
17/12/19 15:39:08 INFO DAGScheduler: waiting: Set(ResultStage 389)
17/12/19 15:39:08 INFO DAGScheduler: failed: Set()
17/12/19 15:39:08 INFO DAGScheduler: Submitting ResultStage 389 (MapPartitionsRDD[793] at sql at <unknown>:0), which has no missing parents
17/12/19 15:39:08 INFO MemoryStore: Block broadcast_262 stored as values in memory (estimated size 7.0 KB, free 1996.8 MB)
17/12/19 15:39:08 INFO MemoryStore: Block broadcast_262_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1996.8 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Added broadcast_262_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2003.6 MB)
17/12/19 15:39:08 INFO SparkContext: Created broadcast 262 from broadcast at DAGScheduler.scala:996
17/12/19 15:39:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 389 (MapPartitionsRDD[793] at sql at <unknown>:0)
17/12/19 15:39:08 INFO TaskSchedulerImpl: Adding task set 389.0 with 1 tasks
17/12/19 15:39:08 INFO TaskSetManager: Starting task 0.0 in stage 389.0 (TID 286, localhost, executor driver, partition 0, ANY, 5957 bytes)
17/12/19 15:39:08 INFO Executor: Running task 0.0 in stage 389.0 (TID 286)
17/12/19 15:39:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:39:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:39:08 INFO Executor: Finished task 0.0 in stage 389.0 (TID 286). 1707 bytes result sent to driver
17/12/19 15:39:08 INFO TaskSetManager: Finished task 0.0 in stage 389.0 (TID 286) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:39:08 INFO TaskSchedulerImpl: Removed TaskSet 389.0, whose tasks have all completed, from pool 
17/12/19 15:39:08 INFO DAGScheduler: ResultStage 389 (sql at <unknown>:0) finished in 0.000 s
17/12/19 15:39:08 INFO DAGScheduler: Job 187 finished: sql at <unknown>:0, took 0.046964 s
17/12/19 15:39:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:08 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13255
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_244_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.6 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_245_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.6 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_246_piece0 on 127.0.0.1:53618 in memory (size: 45.1 KB, free: 2003.6 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_247_piece0 on 127.0.0.1:53618 in memory (size: 45.1 KB, free: 2003.7 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_248_piece0 on 127.0.0.1:53618 in memory (size: 46.9 KB, free: 2003.7 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_249_piece0 on 127.0.0.1:53618 in memory (size: 46.9 KB, free: 2003.8 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_250_piece0 on 127.0.0.1:53618 in memory (size: 47.5 KB, free: 2003.8 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_251_piece0 on 127.0.0.1:53618 in memory (size: 47.5 KB, free: 2003.9 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_252_piece0 on 127.0.0.1:53618 in memory (size: 49.4 KB, free: 2003.9 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_253_piece0 on 127.0.0.1:53618 in memory (size: 49.4 KB, free: 2004.0 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_254_piece0 on 127.0.0.1:53618 in memory (size: 50.7 KB, free: 2004.0 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_255_piece0 on 127.0.0.1:53618 in memory (size: 50.7 KB, free: 2004.1 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_256_piece0 on 127.0.0.1:53618 in memory (size: 50.7 KB, free: 2004.1 MB)
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13204
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13205
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_257_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.1 MB)
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13254
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_258_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.1 MB)
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13304
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13305
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13311
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13312
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13313
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13314
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13315
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13316
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13317
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13318
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13319
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13320
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13321
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13322
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13323
17/12/19 15:39:08 INFO ContextCleaner: Cleaned shuffle 55
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_260_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.1 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_261_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2004.1 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Removed broadcast_262_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.1 MB)
17/12/19 15:39:08 INFO ContextCleaner: Cleaned accumulator 13492
17/12/19 15:39:08 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:39:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 54 is 145 bytes
17/12/19 15:39:08 INFO DAGScheduler: Registering RDD 797 (collect at utils.scala:196)
17/12/19 15:39:08 INFO DAGScheduler: Got job 188 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:39:08 INFO DAGScheduler: Final stage: ResultStage 392 (collect at utils.scala:196)
17/12/19 15:39:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 391)
17/12/19 15:39:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 391)
17/12/19 15:39:08 INFO DAGScheduler: Submitting ShuffleMapStage 391 (MapPartitionsRDD[797] at collect at utils.scala:196), which has no missing parents
17/12/19 15:39:08 INFO MemoryStore: Block broadcast_263 stored as values in memory (estimated size 11.9 KB, free 1998.7 MB)
17/12/19 15:39:08 INFO MemoryStore: Block broadcast_263_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1998.7 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Added broadcast_263_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.1 MB)
17/12/19 15:39:08 INFO SparkContext: Created broadcast 263 from broadcast at DAGScheduler.scala:996
17/12/19 15:39:08 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 391 (MapPartitionsRDD[797] at collect at utils.scala:196)
17/12/19 15:39:08 INFO TaskSchedulerImpl: Adding task set 391.0 with 2 tasks
17/12/19 15:39:08 INFO TaskSetManager: Starting task 0.0 in stage 391.0 (TID 287, localhost, executor driver, partition 0, PROCESS_LOCAL, 5938 bytes)
17/12/19 15:39:08 INFO TaskSetManager: Starting task 1.0 in stage 391.0 (TID 288, localhost, executor driver, partition 1, PROCESS_LOCAL, 5938 bytes)
17/12/19 15:39:08 INFO Executor: Running task 1.0 in stage 391.0 (TID 288)
17/12/19 15:39:08 INFO Executor: Running task 0.0 in stage 391.0 (TID 287)
17/12/19 15:39:08 INFO BlockManager: Found block rdd_787_0 locally
17/12/19 15:39:08 INFO BlockManager: Found block rdd_787_1 locally
17/12/19 15:39:08 INFO Executor: Finished task 0.0 in stage 391.0 (TID 287). 1950 bytes result sent to driver
17/12/19 15:39:08 INFO TaskSetManager: Finished task 0.0 in stage 391.0 (TID 287) in 16 ms on localhost (executor driver) (1/2)
17/12/19 15:39:08 INFO Executor: Finished task 1.0 in stage 391.0 (TID 288). 1950 bytes result sent to driver
17/12/19 15:39:08 INFO TaskSetManager: Finished task 1.0 in stage 391.0 (TID 288) in 16 ms on localhost (executor driver) (2/2)
17/12/19 15:39:08 INFO TaskSchedulerImpl: Removed TaskSet 391.0, whose tasks have all completed, from pool 
17/12/19 15:39:08 INFO DAGScheduler: ShuffleMapStage 391 (collect at utils.scala:196) finished in 0.016 s
17/12/19 15:39:08 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:39:08 INFO DAGScheduler: running: Set()
17/12/19 15:39:08 INFO DAGScheduler: waiting: Set(ResultStage 392)
17/12/19 15:39:08 INFO DAGScheduler: failed: Set()
17/12/19 15:39:08 INFO DAGScheduler: Submitting ResultStage 392 (MapPartitionsRDD[800] at collect at utils.scala:196), which has no missing parents
17/12/19 15:39:08 INFO MemoryStore: Block broadcast_264 stored as values in memory (estimated size 7.0 KB, free 1998.7 MB)
17/12/19 15:39:08 INFO MemoryStore: Block broadcast_264_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1998.7 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Added broadcast_264_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.1 MB)
17/12/19 15:39:08 INFO SparkContext: Created broadcast 264 from broadcast at DAGScheduler.scala:996
17/12/19 15:39:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 392 (MapPartitionsRDD[800] at collect at utils.scala:196)
17/12/19 15:39:08 INFO TaskSchedulerImpl: Adding task set 392.0 with 1 tasks
17/12/19 15:39:08 INFO TaskSetManager: Starting task 0.0 in stage 392.0 (TID 289, localhost, executor driver, partition 0, ANY, 5949 bytes)
17/12/19 15:39:08 INFO Executor: Running task 0.0 in stage 392.0 (TID 289)
17/12/19 15:39:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:39:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:39:08 INFO Executor: Finished task 0.0 in stage 392.0 (TID 289). 1707 bytes result sent to driver
17/12/19 15:39:08 INFO TaskSetManager: Finished task 0.0 in stage 392.0 (TID 289) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:39:08 INFO TaskSchedulerImpl: Removed TaskSet 392.0, whose tasks have all completed, from pool 
17/12/19 15:39:08 INFO DAGScheduler: ResultStage 392 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:39:08 INFO DAGScheduler: Job 188 finished: collect at utils.scala:196, took 0.016545 s
17/12/19 15:39:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz58`
WHERE (0 = 1)
17/12/19 15:39:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:39:08 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:39:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 54 is 145 bytes
17/12/19 15:39:08 INFO DAGScheduler: Got job 189 (take at <unknown>:0) with 1 output partitions
17/12/19 15:39:08 INFO DAGScheduler: Final stage: ResultStage 394 (take at <unknown>:0)
17/12/19 15:39:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 393)
17/12/19 15:39:08 INFO DAGScheduler: Missing parents: List()
17/12/19 15:39:08 INFO DAGScheduler: Submitting ResultStage 394 (WorkerRDD[804] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:39:08 INFO MemoryStore: Block broadcast_265 stored as values in memory (estimated size 109.1 KB, free 1998.6 MB)
17/12/19 15:39:08 INFO MemoryStore: Block broadcast_265_piece0 stored as bytes in memory (estimated size 44.2 KB, free 1998.5 MB)
17/12/19 15:39:08 INFO BlockManagerInfo: Added broadcast_265_piece0 in memory on 127.0.0.1:53618 (size: 44.2 KB, free: 2004.1 MB)
17/12/19 15:39:08 INFO SparkContext: Created broadcast 265 from broadcast at DAGScheduler.scala:996
17/12/19 15:39:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 394 (WorkerRDD[804] at RDD at rdd.scala:18)
17/12/19 15:39:08 INFO TaskSchedulerImpl: Adding task set 394.0 with 1 tasks
17/12/19 15:39:08 INFO TaskSetManager: Starting task 0.0 in stage 394.0 (TID 290, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:39:08 INFO Executor: Running task 0.0 in stage 394.0 (TID 290)
17/12/19 15:39:08 INFO BlockManager: Found block rdd_787_0 locally
17/12/19 15:39:09 INFO MemoryStore: Block rdd_804_0 stored as values in memory (estimated size 80.0 B, free 1998.5 MB)
17/12/19 15:39:09 INFO BlockManagerInfo: Added rdd_804_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.1 MB)
17/12/19 15:39:09 INFO Executor: Finished task 0.0 in stage 394.0 (TID 290). 2154 bytes result sent to driver
17/12/19 15:39:09 INFO TaskSetManager: Finished task 0.0 in stage 394.0 (TID 290) in 725 ms on localhost (executor driver) (1/1)
17/12/19 15:39:09 INFO TaskSchedulerImpl: Removed TaskSet 394.0, whose tasks have all completed, from pool 
17/12/19 15:39:09 INFO DAGScheduler: ResultStage 394 (take at <unknown>:0) finished in 0.725 s
17/12/19 15:39:09 INFO DAGScheduler: Job 189 finished: take at <unknown>:0, took 0.724936 s
17/12/19 15:39:09 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:39:09 INFO DAGScheduler: Got job 190 (take at <unknown>:0) with 1 output partitions
17/12/19 15:39:09 INFO DAGScheduler: Final stage: ResultStage 396 (take at <unknown>:0)
17/12/19 15:39:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 395)
17/12/19 15:39:09 INFO DAGScheduler: Missing parents: List()
17/12/19 15:39:09 INFO DAGScheduler: Submitting ResultStage 396 (WorkerRDD[804] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:39:09 INFO MemoryStore: Block broadcast_266 stored as values in memory (estimated size 109.1 KB, free 1998.4 MB)
17/12/19 15:39:09 INFO MemoryStore: Block broadcast_266_piece0 stored as bytes in memory (estimated size 44.2 KB, free 1998.4 MB)
17/12/19 15:39:09 INFO BlockManagerInfo: Added broadcast_266_piece0 in memory on 127.0.0.1:53618 (size: 44.2 KB, free: 2004.0 MB)
17/12/19 15:39:09 INFO SparkContext: Created broadcast 266 from broadcast at DAGScheduler.scala:996
17/12/19 15:39:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 396 (WorkerRDD[804] at RDD at rdd.scala:18)
17/12/19 15:39:09 INFO TaskSchedulerImpl: Adding task set 396.0 with 1 tasks
17/12/19 15:39:09 INFO TaskSetManager: Starting task 0.0 in stage 396.0 (TID 291, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:39:09 INFO Executor: Running task 0.0 in stage 396.0 (TID 291)
17/12/19 15:39:09 INFO BlockManager: Found block rdd_787_1 locally
17/12/19 15:39:09 INFO MemoryStore: Block rdd_804_1 stored as values in memory (estimated size 80.0 B, free 1998.4 MB)
17/12/19 15:39:09 INFO BlockManagerInfo: Added rdd_804_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2004.0 MB)
17/12/19 15:39:09 INFO Executor: Finished task 0.0 in stage 396.0 (TID 291). 2154 bytes result sent to driver
17/12/19 15:39:09 INFO TaskSetManager: Finished task 0.0 in stage 396.0 (TID 291) in 701 ms on localhost (executor driver) (1/1)
17/12/19 15:39:09 INFO TaskSchedulerImpl: Removed TaskSet 396.0, whose tasks have all completed, from pool 
17/12/19 15:39:09 INFO DAGScheduler: ResultStage 396 (take at <unknown>:0) finished in 0.701 s
17/12/19 15:39:09 INFO DAGScheduler: Job 190 finished: take at <unknown>:0, took 0.712519 s
17/12/19 15:39:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:09 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e85825723c
17/12/19 15:39:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e85825723c` AS `zzz59`
WHERE (0 = 1)
17/12/19 15:39:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e85825723c`
LIMIT 10
17/12/19 15:39:09 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:39:09 INFO DAGScheduler: Got job 191 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:39:09 INFO DAGScheduler: Final stage: ResultStage 398 (collect at utils.scala:196)
17/12/19 15:39:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 397)
17/12/19 15:39:09 INFO DAGScheduler: Missing parents: List()
17/12/19 15:39:09 INFO DAGScheduler: Submitting ResultStage 398 (MapPartitionsRDD[808] at collect at utils.scala:196), which has no missing parents
17/12/19 15:39:09 INFO MemoryStore: Block broadcast_267 stored as values in memory (estimated size 112.2 KB, free 1998.3 MB)
17/12/19 15:39:09 INFO MemoryStore: Block broadcast_267_piece0 stored as bytes in memory (estimated size 46.1 KB, free 1998.2 MB)
17/12/19 15:39:09 INFO BlockManagerInfo: Added broadcast_267_piece0 in memory on 127.0.0.1:53618 (size: 46.1 KB, free: 2004.0 MB)
17/12/19 15:39:09 INFO SparkContext: Created broadcast 267 from broadcast at DAGScheduler.scala:996
17/12/19 15:39:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 398 (MapPartitionsRDD[808] at collect at utils.scala:196)
17/12/19 15:39:09 INFO TaskSchedulerImpl: Adding task set 398.0 with 1 tasks
17/12/19 15:39:09 INFO TaskSetManager: Starting task 0.0 in stage 398.0 (TID 292, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 15:39:09 INFO Executor: Running task 0.0 in stage 398.0 (TID 292)
17/12/19 15:39:09 INFO BlockManager: Found block rdd_804_0 locally
17/12/19 15:39:09 INFO Executor: Finished task 0.0 in stage 398.0 (TID 292). 1233 bytes result sent to driver
17/12/19 15:39:09 INFO TaskSetManager: Finished task 0.0 in stage 398.0 (TID 292) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:39:09 INFO TaskSchedulerImpl: Removed TaskSet 398.0, whose tasks have all completed, from pool 
17/12/19 15:39:09 INFO DAGScheduler: ResultStage 398 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:39:09 INFO DAGScheduler: Job 191 finished: collect at utils.scala:196, took 0.006562 s
17/12/19 15:39:09 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:39:09 INFO DAGScheduler: Got job 192 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:39:09 INFO DAGScheduler: Final stage: ResultStage 400 (collect at utils.scala:196)
17/12/19 15:39:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 399)
17/12/19 15:39:09 INFO DAGScheduler: Missing parents: List()
17/12/19 15:39:09 INFO DAGScheduler: Submitting ResultStage 400 (MapPartitionsRDD[808] at collect at utils.scala:196), which has no missing parents
17/12/19 15:39:09 INFO MemoryStore: Block broadcast_268 stored as values in memory (estimated size 112.2 KB, free 1998.1 MB)
17/12/19 15:39:09 INFO MemoryStore: Block broadcast_268_piece0 stored as bytes in memory (estimated size 46.1 KB, free 1998.1 MB)
17/12/19 15:39:09 INFO BlockManagerInfo: Added broadcast_268_piece0 in memory on 127.0.0.1:53618 (size: 46.1 KB, free: 2004.0 MB)
17/12/19 15:39:09 INFO SparkContext: Created broadcast 268 from broadcast at DAGScheduler.scala:996
17/12/19 15:39:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 400 (MapPartitionsRDD[808] at collect at utils.scala:196)
17/12/19 15:39:09 INFO TaskSchedulerImpl: Adding task set 400.0 with 1 tasks
17/12/19 15:39:09 INFO TaskSetManager: Starting task 0.0 in stage 400.0 (TID 293, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 15:39:09 INFO Executor: Running task 0.0 in stage 400.0 (TID 293)
17/12/19 15:39:09 INFO BlockManager: Found block rdd_804_1 locally
17/12/19 15:39:09 INFO Executor: Finished task 0.0 in stage 400.0 (TID 293). 1233 bytes result sent to driver
17/12/19 15:39:09 INFO TaskSetManager: Finished task 0.0 in stage 400.0 (TID 293) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:39:09 INFO TaskSchedulerImpl: Removed TaskSet 400.0, whose tasks have all completed, from pool 
17/12/19 15:39:09 INFO DAGScheduler: ResultStage 400 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:39:09 INFO DAGScheduler: Job 192 finished: collect at utils.scala:196, took 0.006046 s
17/12/19 15:39:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:09 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `ehdgerlele`
17/12/19 15:39:09 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:39:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz60`
WHERE (0 = 1)
17/12/19 15:39:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:39:09 INFO CodeGenerator: Code generated in 7.587871 ms
17/12/19 15:39:09 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:39:09 INFO DAGScheduler: Got job 193 (take at <unknown>:0) with 1 output partitions
17/12/19 15:39:09 INFO DAGScheduler: Final stage: ResultStage 402 (take at <unknown>:0)
17/12/19 15:39:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 401)
17/12/19 15:39:09 INFO DAGScheduler: Missing parents: List()
17/12/19 15:39:09 INFO DAGScheduler: Submitting ResultStage 402 (WorkerRDD[814] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:39:09 INFO MemoryStore: Block broadcast_269 stored as values in memory (estimated size 117.3 KB, free 1997.9 MB)
17/12/19 15:39:09 INFO MemoryStore: Block broadcast_269_piece0 stored as bytes in memory (estimated size 46.8 KB, free 1997.9 MB)
17/12/19 15:39:09 INFO BlockManagerInfo: Added broadcast_269_piece0 in memory on 127.0.0.1:53618 (size: 46.8 KB, free: 2003.9 MB)
17/12/19 15:39:09 INFO SparkContext: Created broadcast 269 from broadcast at DAGScheduler.scala:996
17/12/19 15:39:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 402 (WorkerRDD[814] at RDD at rdd.scala:18)
17/12/19 15:39:09 INFO TaskSchedulerImpl: Adding task set 402.0 with 1 tasks
17/12/19 15:39:09 INFO TaskSetManager: Starting task 0.0 in stage 402.0 (TID 294, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:39:09 INFO Executor: Running task 0.0 in stage 402.0 (TID 294)
17/12/19 15:39:09 INFO BlockManager: Found block rdd_787_0 locally
17/12/19 15:39:10 INFO MemoryStore: Block rdd_814_0 stored as values in memory (estimated size 608.0 B, free 1997.9 MB)
17/12/19 15:39:10 INFO BlockManagerInfo: Added rdd_814_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 15:39:10 INFO Executor: Finished task 0.0 in stage 402.0 (TID 294). 2509 bytes result sent to driver
17/12/19 15:39:10 INFO TaskSetManager: Finished task 0.0 in stage 402.0 (TID 294) in 692 ms on localhost (executor driver) (1/1)
17/12/19 15:39:10 INFO TaskSchedulerImpl: Removed TaskSet 402.0, whose tasks have all completed, from pool 
17/12/19 15:39:10 INFO DAGScheduler: ResultStage 402 (take at <unknown>:0) finished in 0.692 s
17/12/19 15:39:10 INFO DAGScheduler: Job 193 finished: take at <unknown>:0, took 0.687802 s
17/12/19 15:39:10 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:39:10 INFO DAGScheduler: Got job 194 (take at <unknown>:0) with 1 output partitions
17/12/19 15:39:10 INFO DAGScheduler: Final stage: ResultStage 404 (take at <unknown>:0)
17/12/19 15:39:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 403)
17/12/19 15:39:10 INFO DAGScheduler: Missing parents: List()
17/12/19 15:39:10 INFO DAGScheduler: Submitting ResultStage 404 (WorkerRDD[814] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:39:10 INFO MemoryStore: Block broadcast_270 stored as values in memory (estimated size 117.3 KB, free 1997.8 MB)
17/12/19 15:39:10 INFO MemoryStore: Block broadcast_270_piece0 stored as bytes in memory (estimated size 46.8 KB, free 1997.7 MB)
17/12/19 15:39:10 INFO BlockManagerInfo: Added broadcast_270_piece0 in memory on 127.0.0.1:53618 (size: 46.8 KB, free: 2003.9 MB)
17/12/19 15:39:10 INFO SparkContext: Created broadcast 270 from broadcast at DAGScheduler.scala:996
17/12/19 15:39:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 404 (WorkerRDD[814] at RDD at rdd.scala:18)
17/12/19 15:39:10 INFO TaskSchedulerImpl: Adding task set 404.0 with 1 tasks
17/12/19 15:39:10 INFO TaskSetManager: Starting task 0.0 in stage 404.0 (TID 295, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:39:10 INFO Executor: Running task 0.0 in stage 404.0 (TID 295)
17/12/19 15:39:10 INFO BlockManager: Found block rdd_787_1 locally
17/12/19 15:39:11 INFO MemoryStore: Block rdd_814_1 stored as values in memory (estimated size 608.0 B, free 1997.7 MB)
17/12/19 15:39:11 INFO BlockManagerInfo: Added rdd_814_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 15:39:11 INFO Executor: Finished task 0.0 in stage 404.0 (TID 295). 2509 bytes result sent to driver
17/12/19 15:39:11 INFO TaskSetManager: Finished task 0.0 in stage 404.0 (TID 295) in 646 ms on localhost (executor driver) (1/1)
17/12/19 15:39:11 INFO TaskSchedulerImpl: Removed TaskSet 404.0, whose tasks have all completed, from pool 
17/12/19 15:39:11 INFO DAGScheduler: ResultStage 404 (take at <unknown>:0) finished in 0.646 s
17/12/19 15:39:11 INFO DAGScheduler: Job 194 finished: take at <unknown>:0, took 0.642659 s
17/12/19 15:39:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:11 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e85e1e138c
17/12/19 15:39:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e85e1e138c` AS `zzz61`
WHERE (0 = 1)
17/12/19 15:39:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e85e1e138c`
17/12/19 15:39:11 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:39:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz62`
WHERE (0 = 1)
17/12/19 15:39:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:11 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 15:39:11 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:39:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz63`
WHERE (0 = 1)
17/12/19 15:39:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:39:11 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:39:11 INFO DAGScheduler: Got job 195 (collect at utils.scala:196) with 2 output partitions
17/12/19 15:39:11 INFO DAGScheduler: Final stage: ResultStage 406 (collect at utils.scala:196)
17/12/19 15:39:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 405)
17/12/19 15:39:11 INFO DAGScheduler: Missing parents: List()
17/12/19 15:39:11 INFO DAGScheduler: Submitting ResultStage 406 (MapPartitionsRDD[821] at collect at utils.scala:196), which has no missing parents
17/12/19 15:39:11 INFO MemoryStore: Block broadcast_271 stored as values in memory (estimated size 124.8 KB, free 1997.6 MB)
17/12/19 15:39:11 INFO MemoryStore: Block broadcast_271_piece0 stored as bytes in memory (estimated size 50.0 KB, free 1997.6 MB)
17/12/19 15:39:11 INFO BlockManagerInfo: Added broadcast_271_piece0 in memory on 127.0.0.1:53618 (size: 50.0 KB, free: 2003.8 MB)
17/12/19 15:39:11 INFO SparkContext: Created broadcast 271 from broadcast at DAGScheduler.scala:996
17/12/19 15:39:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 406 (MapPartitionsRDD[821] at collect at utils.scala:196)
17/12/19 15:39:11 INFO TaskSchedulerImpl: Adding task set 406.0 with 2 tasks
17/12/19 15:39:11 INFO TaskSetManager: Starting task 0.0 in stage 406.0 (TID 296, localhost, executor driver, partition 0, PROCESS_LOCAL, 5949 bytes)
17/12/19 15:39:11 INFO TaskSetManager: Starting task 1.0 in stage 406.0 (TID 297, localhost, executor driver, partition 1, PROCESS_LOCAL, 5949 bytes)
17/12/19 15:39:11 INFO Executor: Running task 0.0 in stage 406.0 (TID 296)
17/12/19 15:39:11 INFO Executor: Running task 1.0 in stage 406.0 (TID 297)
17/12/19 15:39:11 INFO BlockManager: Found block rdd_814_1 locally
17/12/19 15:39:11 INFO BlockManager: Found block rdd_814_0 locally
17/12/19 15:39:11 INFO Executor: Finished task 1.0 in stage 406.0 (TID 297). 1609 bytes result sent to driver
17/12/19 15:39:11 INFO Executor: Finished task 0.0 in stage 406.0 (TID 296). 1628 bytes result sent to driver
17/12/19 15:39:11 INFO TaskSetManager: Finished task 1.0 in stage 406.0 (TID 297) in 16 ms on localhost (executor driver) (1/2)
17/12/19 15:39:11 INFO DAGScheduler: ResultStage 406 (collect at utils.scala:196) finished in 0.016 s
17/12/19 15:39:11 INFO DAGScheduler: Job 195 finished: collect at utils.scala:196, took 0.009990 s
17/12/19 15:39:11 INFO TaskSetManager: Finished task 0.0 in stage 406.0 (TID 296) in 16 ms on localhost (executor driver) (2/2)
17/12/19 15:39:11 INFO TaskSchedulerImpl: Removed TaskSet 406.0, whose tasks have all completed, from pool 
17/12/19 15:39:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:39:11 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:39:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:39:11 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:39:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:39:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:39:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:39:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:39:11 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:39:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:39:11 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:39:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:39:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:39:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:39:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:39:11 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:39:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:39:11 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:39:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:39:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:39:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:39:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:39:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:39:11 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:39:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:39:11 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:39:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:39:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:39:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:48:39 INFO BlockManagerInfo: Removed broadcast_263_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.8 MB)
17/12/19 15:48:39 INFO BlockManagerInfo: Removed broadcast_271_piece0 on 127.0.0.1:53618 in memory (size: 50.0 KB, free: 2003.9 MB)
17/12/19 15:48:39 INFO BlockManagerInfo: Removed broadcast_264_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.9 MB)
17/12/19 15:48:39 INFO BlockManagerInfo: Removed broadcast_265_piece0 on 127.0.0.1:53618 in memory (size: 44.2 KB, free: 2003.9 MB)
17/12/19 15:48:39 INFO BlockManagerInfo: Removed broadcast_266_piece0 on 127.0.0.1:53618 in memory (size: 44.2 KB, free: 2004.0 MB)
17/12/19 15:48:39 INFO BlockManagerInfo: Removed broadcast_267_piece0 on 127.0.0.1:53618 in memory (size: 46.1 KB, free: 2004.0 MB)
17/12/19 15:48:39 INFO BlockManagerInfo: Removed broadcast_268_piece0 on 127.0.0.1:53618 in memory (size: 46.1 KB, free: 2004.0 MB)
17/12/19 15:48:39 INFO BlockManagerInfo: Removed broadcast_269_piece0 on 127.0.0.1:53618 in memory (size: 46.8 KB, free: 2004.1 MB)
17/12/19 15:48:39 INFO BlockManagerInfo: Removed broadcast_270_piece0 on 127.0.0.1:53618 in memory (size: 46.8 KB, free: 2004.1 MB)
17/12/19 15:52:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:51 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:52:51 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:52:51 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:52:51 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:52:51 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:52:51 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:52:51 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:52:51 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 15:52:51 INFO DAGScheduler: Got job 196 (collect at utils.scala:58) with 1 output partitions
17/12/19 15:52:51 INFO DAGScheduler: Final stage: ResultStage 407 (collect at utils.scala:58)
17/12/19 15:52:51 INFO DAGScheduler: Parents of final stage: List()
17/12/19 15:52:51 INFO DAGScheduler: Missing parents: List()
17/12/19 15:52:51 INFO DAGScheduler: Submitting ResultStage 407 (MapPartitionsRDD[831] at map at utils.scala:55), which has no missing parents
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_272 stored as values in memory (estimated size 8.7 KB, free 1998.7 MB)
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_272_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1998.7 MB)
17/12/19 15:52:51 INFO BlockManagerInfo: Added broadcast_272_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.1 MB)
17/12/19 15:52:51 INFO SparkContext: Created broadcast 272 from broadcast at DAGScheduler.scala:996
17/12/19 15:52:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 407 (MapPartitionsRDD[831] at map at utils.scala:55)
17/12/19 15:52:51 INFO TaskSchedulerImpl: Adding task set 407.0 with 1 tasks
17/12/19 15:52:51 INFO TaskSetManager: Starting task 0.0 in stage 407.0 (TID 298, localhost, executor driver, partition 0, PROCESS_LOCAL, 8230 bytes)
17/12/19 15:52:51 INFO Executor: Running task 0.0 in stage 407.0 (TID 298)
17/12/19 15:52:51 INFO Executor: Finished task 0.0 in stage 407.0 (TID 298). 1637 bytes result sent to driver
17/12/19 15:52:51 INFO TaskSetManager: Finished task 0.0 in stage 407.0 (TID 298) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:52:51 INFO TaskSchedulerImpl: Removed TaskSet 407.0, whose tasks have all completed, from pool 
17/12/19 15:52:51 INFO DAGScheduler: ResultStage 407 (collect at utils.scala:58) finished in 0.000 s
17/12/19 15:52:51 INFO DAGScheduler: Job 196 finished: collect at utils.scala:58, took 0.007834 s
17/12/19 15:52:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:51 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:52:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:51 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 15:52:51 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 15:52:51 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 15:52:51 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 15:52:51 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 15:52:51 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_273 stored as values in memory (estimated size 293.7 KB, free 1998.4 MB)
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_273_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1998.4 MB)
17/12/19 15:52:51 INFO BlockManagerInfo: Added broadcast_273_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.1 MB)
17/12/19 15:52:51 INFO SparkContext: Created broadcast 273 from sql at <unknown>:0
17/12/19 15:52:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 15:52:51 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 15:52:51 INFO DAGScheduler: Registering RDD 835 (sql at <unknown>:0)
17/12/19 15:52:51 INFO DAGScheduler: Registering RDD 840 (sql at <unknown>:0)
17/12/19 15:52:51 INFO DAGScheduler: Got job 197 (sql at <unknown>:0) with 1 output partitions
17/12/19 15:52:51 INFO DAGScheduler: Final stage: ResultStage 410 (sql at <unknown>:0)
17/12/19 15:52:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 409)
17/12/19 15:52:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 409)
17/12/19 15:52:51 INFO DAGScheduler: Submitting ShuffleMapStage 408 (MapPartitionsRDD[835] at sql at <unknown>:0), which has no missing parents
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_274 stored as values in memory (estimated size 12.1 KB, free 1998.4 MB)
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_274_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1998.3 MB)
17/12/19 15:52:51 INFO BlockManagerInfo: Added broadcast_274_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.1 MB)
17/12/19 15:52:51 INFO SparkContext: Created broadcast 274 from broadcast at DAGScheduler.scala:996
17/12/19 15:52:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 408 (MapPartitionsRDD[835] at sql at <unknown>:0)
17/12/19 15:52:51 INFO TaskSchedulerImpl: Adding task set 408.0 with 1 tasks
17/12/19 15:52:51 INFO TaskSetManager: Starting task 0.0 in stage 408.0 (TID 299, localhost, executor driver, partition 0, PROCESS_LOCAL, 6680 bytes)
17/12/19 15:52:51 INFO Executor: Running task 0.0 in stage 408.0 (TID 299)
17/12/19 15:52:51 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_2a27182c60fe9de98bf6dddafaef3b04dda82af3346ec1ef22cfa4eb0abe6a03.csv, range: 0-458, partition values: [empty row]
17/12/19 15:52:51 INFO Executor: Finished task 0.0 in stage 408.0 (TID 299). 1719 bytes result sent to driver
17/12/19 15:52:51 INFO TaskSetManager: Finished task 0.0 in stage 408.0 (TID 299) in 32 ms on localhost (executor driver) (1/1)
17/12/19 15:52:51 INFO TaskSchedulerImpl: Removed TaskSet 408.0, whose tasks have all completed, from pool 
17/12/19 15:52:51 INFO DAGScheduler: ShuffleMapStage 408 (sql at <unknown>:0) finished in 0.032 s
17/12/19 15:52:51 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:52:51 INFO DAGScheduler: running: Set()
17/12/19 15:52:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 409, ResultStage 410)
17/12/19 15:52:51 INFO DAGScheduler: failed: Set()
17/12/19 15:52:51 INFO DAGScheduler: Submitting ShuffleMapStage 409 (MapPartitionsRDD[840] at sql at <unknown>:0), which has no missing parents
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_275 stored as values in memory (estimated size 11.9 KB, free 1998.3 MB)
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_275_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1998.3 MB)
17/12/19 15:52:51 INFO BlockManagerInfo: Added broadcast_275_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.1 MB)
17/12/19 15:52:51 INFO SparkContext: Created broadcast 275 from broadcast at DAGScheduler.scala:996
17/12/19 15:52:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 409 (MapPartitionsRDD[840] at sql at <unknown>:0)
17/12/19 15:52:51 INFO TaskSchedulerImpl: Adding task set 409.0 with 2 tasks
17/12/19 15:52:51 INFO TaskSetManager: Starting task 0.0 in stage 409.0 (TID 300, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 15:52:51 INFO TaskSetManager: Starting task 1.0 in stage 409.0 (TID 301, localhost, executor driver, partition 1, ANY, 5946 bytes)
17/12/19 15:52:51 INFO Executor: Running task 0.0 in stage 409.0 (TID 300)
17/12/19 15:52:51 INFO Executor: Running task 1.0 in stage 409.0 (TID 301)
17/12/19 15:52:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:52:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:52:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 15:52:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:52:51 INFO MemoryStore: Block rdd_837_0 stored as values in memory (estimated size 544.0 B, free 1998.3 MB)
17/12/19 15:52:51 INFO BlockManagerInfo: Added rdd_837_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.1 MB)
17/12/19 15:52:51 INFO MemoryStore: Block rdd_837_1 stored as values in memory (estimated size 544.0 B, free 1998.3 MB)
17/12/19 15:52:51 INFO BlockManagerInfo: Added rdd_837_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.1 MB)
17/12/19 15:52:51 INFO Executor: Finished task 0.0 in stage 409.0 (TID 300). 3064 bytes result sent to driver
17/12/19 15:52:51 INFO TaskSetManager: Finished task 0.0 in stage 409.0 (TID 300) in 15 ms on localhost (executor driver) (1/2)
17/12/19 15:52:51 INFO Executor: Finished task 1.0 in stage 409.0 (TID 301). 2985 bytes result sent to driver
17/12/19 15:52:51 INFO TaskSetManager: Finished task 1.0 in stage 409.0 (TID 301) in 15 ms on localhost (executor driver) (2/2)
17/12/19 15:52:51 INFO DAGScheduler: ShuffleMapStage 409 (sql at <unknown>:0) finished in 0.015 s
17/12/19 15:52:51 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:52:51 INFO DAGScheduler: running: Set()
17/12/19 15:52:51 INFO DAGScheduler: waiting: Set(ResultStage 410)
17/12/19 15:52:51 INFO DAGScheduler: failed: Set()
17/12/19 15:52:51 INFO TaskSchedulerImpl: Removed TaskSet 409.0, whose tasks have all completed, from pool 
17/12/19 15:52:51 INFO DAGScheduler: Submitting ResultStage 410 (MapPartitionsRDD[843] at sql at <unknown>:0), which has no missing parents
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_276 stored as values in memory (estimated size 7.0 KB, free 1998.3 MB)
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_276_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1998.3 MB)
17/12/19 15:52:51 INFO BlockManagerInfo: Added broadcast_276_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.1 MB)
17/12/19 15:52:51 INFO SparkContext: Created broadcast 276 from broadcast at DAGScheduler.scala:996
17/12/19 15:52:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 410 (MapPartitionsRDD[843] at sql at <unknown>:0)
17/12/19 15:52:51 INFO TaskSchedulerImpl: Adding task set 410.0 with 1 tasks
17/12/19 15:52:51 INFO TaskSetManager: Starting task 0.0 in stage 410.0 (TID 302, localhost, executor driver, partition 0, ANY, 5957 bytes)
17/12/19 15:52:51 INFO Executor: Running task 0.0 in stage 410.0 (TID 302)
17/12/19 15:52:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:52:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:52:51 INFO Executor: Finished task 0.0 in stage 410.0 (TID 302). 1865 bytes result sent to driver
17/12/19 15:52:51 INFO TaskSetManager: Finished task 0.0 in stage 410.0 (TID 302) in 16 ms on localhost (executor driver) (1/1)
17/12/19 15:52:51 INFO TaskSchedulerImpl: Removed TaskSet 410.0, whose tasks have all completed, from pool 
17/12/19 15:52:51 INFO DAGScheduler: ResultStage 410 (sql at <unknown>:0) finished in 0.016 s
17/12/19 15:52:51 INFO DAGScheduler: Job 197 finished: sql at <unknown>:0, took 0.051695 s
17/12/19 15:52:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:51 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 15:52:51 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:52:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 57 is 145 bytes
17/12/19 15:52:51 INFO DAGScheduler: Registering RDD 847 (collect at utils.scala:196)
17/12/19 15:52:51 INFO DAGScheduler: Got job 198 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:52:51 INFO DAGScheduler: Final stage: ResultStage 413 (collect at utils.scala:196)
17/12/19 15:52:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 412)
17/12/19 15:52:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 412)
17/12/19 15:52:51 INFO DAGScheduler: Submitting ShuffleMapStage 412 (MapPartitionsRDD[847] at collect at utils.scala:196), which has no missing parents
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_277 stored as values in memory (estimated size 11.9 KB, free 1998.3 MB)
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_277_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1998.3 MB)
17/12/19 15:52:51 INFO BlockManagerInfo: Added broadcast_277_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.1 MB)
17/12/19 15:52:51 INFO SparkContext: Created broadcast 277 from broadcast at DAGScheduler.scala:996
17/12/19 15:52:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 412 (MapPartitionsRDD[847] at collect at utils.scala:196)
17/12/19 15:52:51 INFO TaskSchedulerImpl: Adding task set 412.0 with 2 tasks
17/12/19 15:52:51 INFO TaskSetManager: Starting task 0.0 in stage 412.0 (TID 303, localhost, executor driver, partition 0, PROCESS_LOCAL, 5938 bytes)
17/12/19 15:52:51 INFO TaskSetManager: Starting task 1.0 in stage 412.0 (TID 304, localhost, executor driver, partition 1, PROCESS_LOCAL, 5938 bytes)
17/12/19 15:52:51 INFO Executor: Running task 0.0 in stage 412.0 (TID 303)
17/12/19 15:52:51 INFO Executor: Running task 1.0 in stage 412.0 (TID 304)
17/12/19 15:52:51 INFO BlockManager: Found block rdd_837_0 locally
17/12/19 15:52:51 INFO BlockManager: Found block rdd_837_1 locally
17/12/19 15:52:51 INFO Executor: Finished task 0.0 in stage 412.0 (TID 303). 1871 bytes result sent to driver
17/12/19 15:52:51 INFO TaskSetManager: Finished task 0.0 in stage 412.0 (TID 303) in 16 ms on localhost (executor driver) (1/2)
17/12/19 15:52:51 INFO Executor: Finished task 1.0 in stage 412.0 (TID 304). 1950 bytes result sent to driver
17/12/19 15:52:51 INFO TaskSetManager: Finished task 1.0 in stage 412.0 (TID 304) in 16 ms on localhost (executor driver) (2/2)
17/12/19 15:52:51 INFO TaskSchedulerImpl: Removed TaskSet 412.0, whose tasks have all completed, from pool 
17/12/19 15:52:51 INFO DAGScheduler: ShuffleMapStage 412 (collect at utils.scala:196) finished in 0.016 s
17/12/19 15:52:51 INFO DAGScheduler: looking for newly runnable stages
17/12/19 15:52:51 INFO DAGScheduler: running: Set()
17/12/19 15:52:51 INFO DAGScheduler: waiting: Set(ResultStage 413)
17/12/19 15:52:51 INFO DAGScheduler: failed: Set()
17/12/19 15:52:51 INFO DAGScheduler: Submitting ResultStage 413 (MapPartitionsRDD[850] at collect at utils.scala:196), which has no missing parents
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_278 stored as values in memory (estimated size 7.0 KB, free 1998.3 MB)
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_278_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1998.3 MB)
17/12/19 15:52:51 INFO BlockManagerInfo: Added broadcast_278_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.1 MB)
17/12/19 15:52:51 INFO SparkContext: Created broadcast 278 from broadcast at DAGScheduler.scala:996
17/12/19 15:52:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 413 (MapPartitionsRDD[850] at collect at utils.scala:196)
17/12/19 15:52:51 INFO TaskSchedulerImpl: Adding task set 413.0 with 1 tasks
17/12/19 15:52:51 INFO TaskSetManager: Starting task 0.0 in stage 413.0 (TID 305, localhost, executor driver, partition 0, ANY, 5949 bytes)
17/12/19 15:52:51 INFO Executor: Running task 0.0 in stage 413.0 (TID 305)
17/12/19 15:52:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 15:52:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 15:52:51 INFO Executor: Finished task 0.0 in stage 413.0 (TID 305). 1707 bytes result sent to driver
17/12/19 15:52:51 INFO TaskSetManager: Finished task 0.0 in stage 413.0 (TID 305) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:52:51 INFO TaskSchedulerImpl: Removed TaskSet 413.0, whose tasks have all completed, from pool 
17/12/19 15:52:51 INFO DAGScheduler: ResultStage 413 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:52:51 INFO DAGScheduler: Job 198 finished: collect at utils.scala:196, took 0.017452 s
17/12/19 15:52:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz64`
WHERE (0 = 1)
17/12/19 15:52:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:51 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `rjxoifhfks`
17/12/19 15:52:51 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:52:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz65`
WHERE (0 = 1)
17/12/19 15:52:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:52:51 INFO CodeGenerator: Code generated in 8.033795 ms
17/12/19 15:52:51 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:52:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 57 is 145 bytes
17/12/19 15:52:51 INFO DAGScheduler: Got job 199 (take at <unknown>:0) with 1 output partitions
17/12/19 15:52:51 INFO DAGScheduler: Final stage: ResultStage 415 (take at <unknown>:0)
17/12/19 15:52:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 414)
17/12/19 15:52:51 INFO DAGScheduler: Missing parents: List()
17/12/19 15:52:51 INFO DAGScheduler: Submitting ResultStage 415 (WorkerRDD[856] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_279 stored as values in memory (estimated size 117.6 KB, free 1998.2 MB)
17/12/19 15:52:51 INFO MemoryStore: Block broadcast_279_piece0 stored as bytes in memory (estimated size 47.1 KB, free 1998.1 MB)
17/12/19 15:52:51 INFO BlockManagerInfo: Added broadcast_279_piece0 in memory on 127.0.0.1:53618 (size: 47.1 KB, free: 2004.0 MB)
17/12/19 15:52:51 INFO SparkContext: Created broadcast 279 from broadcast at DAGScheduler.scala:996
17/12/19 15:52:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 415 (WorkerRDD[856] at RDD at rdd.scala:18)
17/12/19 15:52:51 INFO TaskSchedulerImpl: Adding task set 415.0 with 1 tasks
17/12/19 15:52:51 INFO TaskSetManager: Starting task 0.0 in stage 415.0 (TID 306, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:52:51 INFO Executor: Running task 0.0 in stage 415.0 (TID 306)
17/12/19 15:52:51 INFO BlockManager: Found block rdd_837_0 locally
17/12/19 15:52:52 INFO MemoryStore: Block rdd_856_0 stored as values in memory (estimated size 608.0 B, free 1998.1 MB)
17/12/19 15:52:52 INFO BlockManagerInfo: Added rdd_856_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2004.0 MB)
17/12/19 15:52:52 INFO Executor: Finished task 0.0 in stage 415.0 (TID 306). 2509 bytes result sent to driver
17/12/19 15:52:52 INFO TaskSetManager: Finished task 0.0 in stage 415.0 (TID 306) in 614 ms on localhost (executor driver) (1/1)
17/12/19 15:52:52 INFO TaskSchedulerImpl: Removed TaskSet 415.0, whose tasks have all completed, from pool 
17/12/19 15:52:52 INFO DAGScheduler: ResultStage 415 (take at <unknown>:0) finished in 0.614 s
17/12/19 15:52:52 INFO DAGScheduler: Job 199 finished: take at <unknown>:0, took 0.624492 s
17/12/19 15:52:52 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:52:52 INFO DAGScheduler: Got job 200 (take at <unknown>:0) with 1 output partitions
17/12/19 15:52:52 INFO DAGScheduler: Final stage: ResultStage 417 (take at <unknown>:0)
17/12/19 15:52:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 416)
17/12/19 15:52:52 INFO DAGScheduler: Missing parents: List()
17/12/19 15:52:52 INFO DAGScheduler: Submitting ResultStage 417 (WorkerRDD[856] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:52:52 INFO MemoryStore: Block broadcast_280 stored as values in memory (estimated size 117.6 KB, free 1998.0 MB)
17/12/19 15:52:52 INFO MemoryStore: Block broadcast_280_piece0 stored as bytes in memory (estimated size 47.1 KB, free 1998.0 MB)
17/12/19 15:52:52 INFO BlockManagerInfo: Added broadcast_280_piece0 in memory on 127.0.0.1:53618 (size: 47.1 KB, free: 2004.0 MB)
17/12/19 15:52:52 INFO SparkContext: Created broadcast 280 from broadcast at DAGScheduler.scala:996
17/12/19 15:52:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 417 (WorkerRDD[856] at RDD at rdd.scala:18)
17/12/19 15:52:52 INFO TaskSchedulerImpl: Adding task set 417.0 with 1 tasks
17/12/19 15:52:52 INFO TaskSetManager: Starting task 0.0 in stage 417.0 (TID 307, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:52:52 INFO Executor: Running task 0.0 in stage 417.0 (TID 307)
17/12/19 15:52:52 INFO BlockManager: Found block rdd_837_1 locally
17/12/19 15:52:52 INFO MemoryStore: Block rdd_856_1 stored as values in memory (estimated size 608.0 B, free 1998.0 MB)
17/12/19 15:52:52 INFO BlockManagerInfo: Added rdd_856_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2004.0 MB)
17/12/19 15:52:52 INFO Executor: Finished task 0.0 in stage 417.0 (TID 307). 2509 bytes result sent to driver
17/12/19 15:52:52 INFO TaskSetManager: Finished task 0.0 in stage 417.0 (TID 307) in 645 ms on localhost (executor driver) (1/1)
17/12/19 15:52:52 INFO TaskSchedulerImpl: Removed TaskSet 417.0, whose tasks have all completed, from pool 
17/12/19 15:52:52 INFO DAGScheduler: ResultStage 417 (take at <unknown>:0) finished in 0.645 s
17/12/19 15:52:52 INFO DAGScheduler: Job 200 finished: take at <unknown>:0, took 0.656239 s
17/12/19 15:52:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:52 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e811a27b87
17/12/19 15:52:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e811a27b87` AS `zzz66`
WHERE (0 = 1)
17/12/19 15:52:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e811a27b87`
17/12/19 15:52:52 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:52:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz67`
WHERE (0 = 1)
17/12/19 15:52:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:52 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 15:52:52 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 15:52:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz68`
WHERE (0 = 1)
17/12/19 15:52:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:52:53 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:52:53 INFO DAGScheduler: Got job 201 (collect at utils.scala:196) with 2 output partitions
17/12/19 15:52:53 INFO DAGScheduler: Final stage: ResultStage 419 (collect at utils.scala:196)
17/12/19 15:52:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 418)
17/12/19 15:52:53 INFO DAGScheduler: Missing parents: List()
17/12/19 15:52:53 INFO DAGScheduler: Submitting ResultStage 419 (MapPartitionsRDD[863] at collect at utils.scala:196), which has no missing parents
17/12/19 15:52:53 INFO MemoryStore: Block broadcast_281 stored as values in memory (estimated size 125.1 KB, free 1997.8 MB)
17/12/19 15:52:53 INFO MemoryStore: Block broadcast_281_piece0 stored as bytes in memory (estimated size 50.3 KB, free 1997.8 MB)
17/12/19 15:52:53 INFO BlockManagerInfo: Added broadcast_281_piece0 in memory on 127.0.0.1:53618 (size: 50.3 KB, free: 2003.9 MB)
17/12/19 15:52:53 INFO SparkContext: Created broadcast 281 from broadcast at DAGScheduler.scala:996
17/12/19 15:52:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 419 (MapPartitionsRDD[863] at collect at utils.scala:196)
17/12/19 15:52:53 INFO TaskSchedulerImpl: Adding task set 419.0 with 2 tasks
17/12/19 15:52:53 INFO TaskSetManager: Starting task 0.0 in stage 419.0 (TID 308, localhost, executor driver, partition 0, PROCESS_LOCAL, 5949 bytes)
17/12/19 15:52:53 INFO TaskSetManager: Starting task 1.0 in stage 419.0 (TID 309, localhost, executor driver, partition 1, PROCESS_LOCAL, 5949 bytes)
17/12/19 15:52:53 INFO Executor: Running task 0.0 in stage 419.0 (TID 308)
17/12/19 15:52:53 INFO Executor: Running task 1.0 in stage 419.0 (TID 309)
17/12/19 15:52:53 INFO BlockManager: Found block rdd_856_1 locally
17/12/19 15:52:53 INFO Executor: Finished task 1.0 in stage 419.0 (TID 309). 1439 bytes result sent to driver
17/12/19 15:52:53 INFO BlockManager: Found block rdd_856_0 locally
17/12/19 15:52:53 INFO Executor: Finished task 0.0 in stage 419.0 (TID 308). 1597 bytes result sent to driver
17/12/19 15:52:53 INFO TaskSetManager: Finished task 1.0 in stage 419.0 (TID 309) in 15 ms on localhost (executor driver) (1/2)
17/12/19 15:52:53 INFO DAGScheduler: ResultStage 419 (collect at utils.scala:196) finished in 0.015 s
17/12/19 15:52:53 INFO DAGScheduler: Job 201 finished: collect at utils.scala:196, took 0.019950 s
17/12/19 15:52:53 INFO TaskSetManager: Finished task 0.0 in stage 419.0 (TID 308) in 15 ms on localhost (executor driver) (2/2)
17/12/19 15:52:53 INFO TaskSchedulerImpl: Removed TaskSet 419.0, whose tasks have all completed, from pool 
17/12/19 15:52:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 15:52:53 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:52:53 INFO DAGScheduler: Got job 202 (take at <unknown>:0) with 1 output partitions
17/12/19 15:52:53 INFO DAGScheduler: Final stage: ResultStage 421 (take at <unknown>:0)
17/12/19 15:52:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 420)
17/12/19 15:52:53 INFO DAGScheduler: Missing parents: List()
17/12/19 15:52:53 INFO DAGScheduler: Submitting ResultStage 421 (WorkerRDD[868] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:52:53 INFO MemoryStore: Block broadcast_282 stored as values in memory (estimated size 225.5 KB, free 1997.6 MB)
17/12/19 15:52:53 INFO MemoryStore: Block broadcast_282_piece0 stored as bytes in memory (estimated size 89.9 KB, free 1997.5 MB)
17/12/19 15:52:53 INFO BlockManagerInfo: Added broadcast_282_piece0 in memory on 127.0.0.1:53618 (size: 89.9 KB, free: 2003.9 MB)
17/12/19 15:52:53 INFO SparkContext: Created broadcast 282 from broadcast at DAGScheduler.scala:996
17/12/19 15:52:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 421 (WorkerRDD[868] at RDD at rdd.scala:18)
17/12/19 15:52:53 INFO TaskSchedulerImpl: Adding task set 421.0 with 1 tasks
17/12/19 15:52:53 INFO TaskSetManager: Starting task 0.0 in stage 421.0 (TID 310, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:52:53 INFO Executor: Running task 0.0 in stage 421.0 (TID 310)
17/12/19 15:52:53 INFO BlockManager: Found block rdd_856_0 locally
17/12/19 15:52:53 INFO MemoryStore: Block rdd_868_0 stored as values in memory (estimated size 80.0 B, free 1997.5 MB)
17/12/19 15:52:53 INFO BlockManagerInfo: Added rdd_868_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.9 MB)
17/12/19 15:52:53 INFO Executor: Finished task 0.0 in stage 421.0 (TID 310). 2400 bytes result sent to driver
17/12/19 15:52:53 INFO TaskSetManager: Finished task 0.0 in stage 421.0 (TID 310) in 664 ms on localhost (executor driver) (1/1)
17/12/19 15:52:53 INFO TaskSchedulerImpl: Removed TaskSet 421.0, whose tasks have all completed, from pool 
17/12/19 15:52:53 INFO DAGScheduler: ResultStage 421 (take at <unknown>:0) finished in 0.664 s
17/12/19 15:52:53 INFO DAGScheduler: Job 202 finished: take at <unknown>:0, took 0.681882 s
17/12/19 15:52:53 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 15:52:53 INFO DAGScheduler: Got job 203 (take at <unknown>:0) with 1 output partitions
17/12/19 15:52:53 INFO DAGScheduler: Final stage: ResultStage 423 (take at <unknown>:0)
17/12/19 15:52:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 422)
17/12/19 15:52:53 INFO DAGScheduler: Missing parents: List()
17/12/19 15:52:53 INFO DAGScheduler: Submitting ResultStage 423 (WorkerRDD[868] at RDD at rdd.scala:18), which has no missing parents
17/12/19 15:52:53 INFO MemoryStore: Block broadcast_283 stored as values in memory (estimated size 225.5 KB, free 1997.3 MB)
17/12/19 15:52:53 INFO MemoryStore: Block broadcast_283_piece0 stored as bytes in memory (estimated size 89.9 KB, free 1997.2 MB)
17/12/19 15:52:53 INFO BlockManagerInfo: Added broadcast_283_piece0 in memory on 127.0.0.1:53618 (size: 89.9 KB, free: 2003.8 MB)
17/12/19 15:52:53 INFO SparkContext: Created broadcast 283 from broadcast at DAGScheduler.scala:996
17/12/19 15:52:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 423 (WorkerRDD[868] at RDD at rdd.scala:18)
17/12/19 15:52:53 INFO TaskSchedulerImpl: Adding task set 423.0 with 1 tasks
17/12/19 15:52:53 INFO TaskSetManager: Starting task 0.0 in stage 423.0 (TID 311, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 15:52:53 INFO Executor: Running task 0.0 in stage 423.0 (TID 311)
17/12/19 15:52:53 INFO BlockManager: Found block rdd_856_1 locally
17/12/19 15:52:54 INFO MemoryStore: Block rdd_868_1 stored as values in memory (estimated size 80.0 B, free 1997.2 MB)
17/12/19 15:52:54 INFO BlockManagerInfo: Added rdd_868_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.8 MB)
17/12/19 15:52:54 INFO Executor: Finished task 0.0 in stage 423.0 (TID 311). 2400 bytes result sent to driver
17/12/19 15:52:54 INFO TaskSetManager: Finished task 0.0 in stage 423.0 (TID 311) in 695 ms on localhost (executor driver) (1/1)
17/12/19 15:52:54 INFO TaskSchedulerImpl: Removed TaskSet 423.0, whose tasks have all completed, from pool 
17/12/19 15:52:54 INFO DAGScheduler: ResultStage 423 (take at <unknown>:0) finished in 0.695 s
17/12/19 15:52:54 INFO DAGScheduler: Job 203 finished: take at <unknown>:0, took 0.690164 s
17/12/19 15:52:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:54 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e855dd133c
17/12/19 15:52:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e855dd133c` AS `zzz69`
WHERE (0 = 1)
17/12/19 15:52:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e855dd133c`
LIMIT 10
17/12/19 15:52:54 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:52:54 INFO DAGScheduler: Got job 204 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:52:54 INFO DAGScheduler: Final stage: ResultStage 425 (collect at utils.scala:196)
17/12/19 15:52:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 424)
17/12/19 15:52:54 INFO DAGScheduler: Missing parents: List()
17/12/19 15:52:54 INFO DAGScheduler: Submitting ResultStage 425 (MapPartitionsRDD[872] at collect at utils.scala:196), which has no missing parents
17/12/19 15:52:54 INFO MemoryStore: Block broadcast_284 stored as values in memory (estimated size 226.6 KB, free 1997.0 MB)
17/12/19 15:52:54 INFO MemoryStore: Block broadcast_284_piece0 stored as bytes in memory (estimated size 90.7 KB, free 1996.9 MB)
17/12/19 15:52:54 INFO BlockManagerInfo: Added broadcast_284_piece0 in memory on 127.0.0.1:53618 (size: 90.7 KB, free: 2003.7 MB)
17/12/19 15:52:54 INFO SparkContext: Created broadcast 284 from broadcast at DAGScheduler.scala:996
17/12/19 15:52:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 425 (MapPartitionsRDD[872] at collect at utils.scala:196)
17/12/19 15:52:54 INFO TaskSchedulerImpl: Adding task set 425.0 with 1 tasks
17/12/19 15:52:54 INFO TaskSetManager: Starting task 0.0 in stage 425.0 (TID 312, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 15:52:54 INFO Executor: Running task 0.0 in stage 425.0 (TID 312)
17/12/19 15:52:54 INFO BlockManager: Found block rdd_868_0 locally
17/12/19 15:52:54 INFO Executor: Finished task 0.0 in stage 425.0 (TID 312). 1479 bytes result sent to driver
17/12/19 15:52:54 INFO DAGScheduler: ResultStage 425 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:52:54 INFO DAGScheduler: Job 204 finished: collect at utils.scala:196, took 0.009696 s
17/12/19 15:52:54 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 15:52:54 INFO TaskSetManager: Finished task 0.0 in stage 425.0 (TID 312) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:52:54 INFO TaskSchedulerImpl: Removed TaskSet 425.0, whose tasks have all completed, from pool 
17/12/19 15:52:54 INFO DAGScheduler: Got job 205 (collect at utils.scala:196) with 1 output partitions
17/12/19 15:52:54 INFO DAGScheduler: Final stage: ResultStage 427 (collect at utils.scala:196)
17/12/19 15:52:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 426)
17/12/19 15:52:54 INFO DAGScheduler: Missing parents: List()
17/12/19 15:52:54 INFO DAGScheduler: Submitting ResultStage 427 (MapPartitionsRDD[872] at collect at utils.scala:196), which has no missing parents
17/12/19 15:52:54 INFO MemoryStore: Block broadcast_285 stored as values in memory (estimated size 226.6 KB, free 1996.6 MB)
17/12/19 15:52:54 INFO MemoryStore: Block broadcast_285_piece0 stored as bytes in memory (estimated size 90.7 KB, free 1996.6 MB)
17/12/19 15:52:54 INFO BlockManagerInfo: Added broadcast_285_piece0 in memory on 127.0.0.1:53618 (size: 90.7 KB, free: 2003.6 MB)
17/12/19 15:52:54 INFO SparkContext: Created broadcast 285 from broadcast at DAGScheduler.scala:996
17/12/19 15:52:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 427 (MapPartitionsRDD[872] at collect at utils.scala:196)
17/12/19 15:52:54 INFO TaskSchedulerImpl: Adding task set 427.0 with 1 tasks
17/12/19 15:52:54 INFO TaskSetManager: Starting task 0.0 in stage 427.0 (TID 313, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 15:52:54 INFO Executor: Running task 0.0 in stage 427.0 (TID 313)
17/12/19 15:52:54 INFO BlockManager: Found block rdd_868_1 locally
17/12/19 15:52:54 INFO Executor: Finished task 0.0 in stage 427.0 (TID 313). 1479 bytes result sent to driver
17/12/19 15:52:54 INFO TaskSetManager: Finished task 0.0 in stage 427.0 (TID 313) in 0 ms on localhost (executor driver) (1/1)
17/12/19 15:52:54 INFO TaskSchedulerImpl: Removed TaskSet 427.0, whose tasks have all completed, from pool 
17/12/19 15:52:54 INFO DAGScheduler: ResultStage 427 (collect at utils.scala:196) finished in 0.000 s
17/12/19 15:52:54 INFO DAGScheduler: Job 205 finished: collect at utils.scala:196, took 0.008862 s
17/12/19 15:52:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:52:54 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:52:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:52:54 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:52:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:52:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:52:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:52:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:52:54 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:52:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:52:54 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:52:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:52:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:52:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:52:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:52:54 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:52:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:52:54 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:52:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:52:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:52:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 15:52:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 15:52:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 15:52:54 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:52:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:52:54 INFO HiveMetaStore: 0: get_database: default
17/12/19 15:52:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 15:52:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 15:52:54 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:00:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:26 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:00:26 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:00:26 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:00:26 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:00:26 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:00:26 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:00:26 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:00:26 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 16:00:26 INFO DAGScheduler: Got job 206 (collect at utils.scala:58) with 1 output partitions
17/12/19 16:00:26 INFO DAGScheduler: Final stage: ResultStage 428 (collect at utils.scala:58)
17/12/19 16:00:26 INFO DAGScheduler: Parents of final stage: List()
17/12/19 16:00:26 INFO DAGScheduler: Missing parents: List()
17/12/19 16:00:26 INFO DAGScheduler: Submitting ResultStage 428 (MapPartitionsRDD[882] at map at utils.scala:55), which has no missing parents
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_286 stored as values in memory (estimated size 8.7 KB, free 1996.5 MB)
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_286_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1996.5 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Added broadcast_286_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.6 MB)
17/12/19 16:00:26 INFO SparkContext: Created broadcast 286 from broadcast at DAGScheduler.scala:996
17/12/19 16:00:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 428 (MapPartitionsRDD[882] at map at utils.scala:55)
17/12/19 16:00:26 INFO TaskSchedulerImpl: Adding task set 428.0 with 1 tasks
17/12/19 16:00:26 INFO TaskSetManager: Starting task 0.0 in stage 428.0 (TID 314, localhost, executor driver, partition 0, PROCESS_LOCAL, 8374 bytes)
17/12/19 16:00:26 INFO Executor: Running task 0.0 in stage 428.0 (TID 314)
17/12/19 16:00:26 INFO Executor: Finished task 0.0 in stage 428.0 (TID 314). 1693 bytes result sent to driver
17/12/19 16:00:26 INFO TaskSetManager: Finished task 0.0 in stage 428.0 (TID 314) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:00:26 INFO TaskSchedulerImpl: Removed TaskSet 428.0, whose tasks have all completed, from pool 
17/12/19 16:00:26 INFO DAGScheduler: ResultStage 428 (collect at utils.scala:58) finished in 0.000 s
17/12/19 16:00:26 INFO DAGScheduler: Job 206 finished: collect at utils.scala:58, took 0.006016 s
17/12/19 16:00:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 13991
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 13992
17/12/19 16:00:26 INFO BlockManagerInfo: Removed broadcast_272_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2003.6 MB)
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14041
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14042
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14048
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14049
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14050
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14051
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14052
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14053
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14054
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14055
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14056
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14057
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14058
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14059
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14060
17/12/19 16:00:26 INFO ContextCleaner: Cleaned shuffle 58
17/12/19 16:00:26 INFO BlockManagerInfo: Removed broadcast_274_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2003.6 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Removed broadcast_275_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.6 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Removed broadcast_276_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.6 MB)
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14229
17/12/19 16:00:26 INFO BlockManagerInfo: Removed broadcast_277_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.6 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Removed broadcast_278_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.6 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Removed broadcast_279_piece0 on 127.0.0.1:53618 in memory (size: 47.1 KB, free: 2003.7 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Removed broadcast_280_piece0 on 127.0.0.1:53618 in memory (size: 47.1 KB, free: 2003.7 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Removed broadcast_281_piece0 on 127.0.0.1:53618 in memory (size: 50.3 KB, free: 2003.8 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Removed broadcast_282_piece0 on 127.0.0.1:53618 in memory (size: 89.9 KB, free: 2003.8 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Removed broadcast_283_piece0 on 127.0.0.1:53618 in memory (size: 89.9 KB, free: 2003.9 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Removed broadcast_284_piece0 on 127.0.0.1:53618 in memory (size: 90.7 KB, free: 2004.0 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Removed broadcast_285_piece0 on 127.0.0.1:53618 in memory (size: 90.7 KB, free: 2004.1 MB)
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14729
17/12/19 16:00:26 INFO ContextCleaner: Cleaned accumulator 14730
17/12/19 16:00:26 INFO BlockManagerInfo: Removed broadcast_286_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.1 MB)
17/12/19 16:00:26 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:00:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:26 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 16:00:26 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 16:00:26 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 16:00:26 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 16:00:26 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 16:00:26 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_287 stored as values in memory (estimated size 293.7 KB, free 1998.1 MB)
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_287_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1998.1 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Added broadcast_287_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.1 MB)
17/12/19 16:00:26 INFO SparkContext: Created broadcast 287 from sql at <unknown>:0
17/12/19 16:00:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 16:00:26 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 16:00:26 INFO DAGScheduler: Registering RDD 886 (sql at <unknown>:0)
17/12/19 16:00:26 INFO DAGScheduler: Registering RDD 891 (sql at <unknown>:0)
17/12/19 16:00:26 INFO DAGScheduler: Got job 207 (sql at <unknown>:0) with 1 output partitions
17/12/19 16:00:26 INFO DAGScheduler: Final stage: ResultStage 431 (sql at <unknown>:0)
17/12/19 16:00:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 430)
17/12/19 16:00:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 430)
17/12/19 16:00:26 INFO DAGScheduler: Submitting ShuffleMapStage 429 (MapPartitionsRDD[886] at sql at <unknown>:0), which has no missing parents
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_288 stored as values in memory (estimated size 12.1 KB, free 1998.1 MB)
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_288_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1998.0 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Added broadcast_288_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.1 MB)
17/12/19 16:00:26 INFO SparkContext: Created broadcast 288 from broadcast at DAGScheduler.scala:996
17/12/19 16:00:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 429 (MapPartitionsRDD[886] at sql at <unknown>:0)
17/12/19 16:00:26 INFO TaskSchedulerImpl: Adding task set 429.0 with 1 tasks
17/12/19 16:00:26 INFO TaskSetManager: Starting task 0.0 in stage 429.0 (TID 315, localhost, executor driver, partition 0, PROCESS_LOCAL, 6680 bytes)
17/12/19 16:00:26 INFO Executor: Running task 0.0 in stage 429.0 (TID 315)
17/12/19 16:00:26 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_d3e52b0f49bdb2fbe01bee499451fa45cfe0525bc3ba9ce04e5c1cac5caeaa85.csv, range: 0-460, partition values: [empty row]
17/12/19 16:00:26 INFO Executor: Finished task 0.0 in stage 429.0 (TID 315). 1632 bytes result sent to driver
17/12/19 16:00:26 INFO TaskSetManager: Finished task 0.0 in stage 429.0 (TID 315) in 16 ms on localhost (executor driver) (1/1)
17/12/19 16:00:26 INFO TaskSchedulerImpl: Removed TaskSet 429.0, whose tasks have all completed, from pool 
17/12/19 16:00:26 INFO DAGScheduler: ShuffleMapStage 429 (sql at <unknown>:0) finished in 0.016 s
17/12/19 16:00:26 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:00:26 INFO DAGScheduler: running: Set()
17/12/19 16:00:26 INFO DAGScheduler: waiting: Set(ShuffleMapStage 430, ResultStage 431)
17/12/19 16:00:26 INFO DAGScheduler: failed: Set()
17/12/19 16:00:26 INFO DAGScheduler: Submitting ShuffleMapStage 430 (MapPartitionsRDD[891] at sql at <unknown>:0), which has no missing parents
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_289 stored as values in memory (estimated size 11.9 KB, free 1998.0 MB)
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_289_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1998.0 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Added broadcast_289_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.1 MB)
17/12/19 16:00:26 INFO SparkContext: Created broadcast 289 from broadcast at DAGScheduler.scala:996
17/12/19 16:00:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 430 (MapPartitionsRDD[891] at sql at <unknown>:0)
17/12/19 16:00:26 INFO TaskSchedulerImpl: Adding task set 430.0 with 2 tasks
17/12/19 16:00:26 INFO TaskSetManager: Starting task 0.0 in stage 430.0 (TID 316, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 16:00:26 INFO TaskSetManager: Starting task 1.0 in stage 430.0 (TID 317, localhost, executor driver, partition 1, ANY, 5946 bytes)
17/12/19 16:00:26 INFO Executor: Running task 0.0 in stage 430.0 (TID 316)
17/12/19 16:00:26 INFO Executor: Running task 1.0 in stage 430.0 (TID 317)
17/12/19 16:00:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:00:26 INFO MemoryStore: Block rdd_888_0 stored as values in memory (estimated size 544.0 B, free 1998.0 MB)
17/12/19 16:00:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:00:26 INFO BlockManagerInfo: Added rdd_888_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.1 MB)
17/12/19 16:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:00:26 INFO MemoryStore: Block rdd_888_1 stored as values in memory (estimated size 544.0 B, free 1998.0 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Added rdd_888_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.1 MB)
17/12/19 16:00:26 INFO Executor: Finished task 0.0 in stage 430.0 (TID 316). 3064 bytes result sent to driver
17/12/19 16:00:26 INFO TaskSetManager: Finished task 0.0 in stage 430.0 (TID 316) in 15 ms on localhost (executor driver) (1/2)
17/12/19 16:00:26 INFO Executor: Finished task 1.0 in stage 430.0 (TID 317). 2985 bytes result sent to driver
17/12/19 16:00:26 INFO TaskSetManager: Finished task 1.0 in stage 430.0 (TID 317) in 15 ms on localhost (executor driver) (2/2)
17/12/19 16:00:26 INFO TaskSchedulerImpl: Removed TaskSet 430.0, whose tasks have all completed, from pool 
17/12/19 16:00:26 INFO DAGScheduler: ShuffleMapStage 430 (sql at <unknown>:0) finished in 0.015 s
17/12/19 16:00:26 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:00:26 INFO DAGScheduler: running: Set()
17/12/19 16:00:26 INFO DAGScheduler: waiting: Set(ResultStage 431)
17/12/19 16:00:26 INFO DAGScheduler: failed: Set()
17/12/19 16:00:26 INFO DAGScheduler: Submitting ResultStage 431 (MapPartitionsRDD[894] at sql at <unknown>:0), which has no missing parents
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_290 stored as values in memory (estimated size 7.0 KB, free 1998.0 MB)
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_290_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1998.0 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Added broadcast_290_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.1 MB)
17/12/19 16:00:26 INFO SparkContext: Created broadcast 290 from broadcast at DAGScheduler.scala:996
17/12/19 16:00:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 431 (MapPartitionsRDD[894] at sql at <unknown>:0)
17/12/19 16:00:26 INFO TaskSchedulerImpl: Adding task set 431.0 with 1 tasks
17/12/19 16:00:26 INFO TaskSetManager: Starting task 0.0 in stage 431.0 (TID 318, localhost, executor driver, partition 0, ANY, 5957 bytes)
17/12/19 16:00:26 INFO Executor: Running task 0.0 in stage 431.0 (TID 318)
17/12/19 16:00:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:00:26 INFO Executor: Finished task 0.0 in stage 431.0 (TID 318). 1707 bytes result sent to driver
17/12/19 16:00:26 INFO TaskSetManager: Finished task 0.0 in stage 431.0 (TID 318) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:00:26 INFO TaskSchedulerImpl: Removed TaskSet 431.0, whose tasks have all completed, from pool 
17/12/19 16:00:26 INFO DAGScheduler: ResultStage 431 (sql at <unknown>:0) finished in 0.000 s
17/12/19 16:00:26 INFO DAGScheduler: Job 207 finished: sql at <unknown>:0, took 0.041952 s
17/12/19 16:00:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:26 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 16:00:26 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:00:26 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 60 is 145 bytes
17/12/19 16:00:26 INFO DAGScheduler: Registering RDD 898 (collect at utils.scala:196)
17/12/19 16:00:26 INFO DAGScheduler: Got job 208 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:00:26 INFO DAGScheduler: Final stage: ResultStage 434 (collect at utils.scala:196)
17/12/19 16:00:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 433)
17/12/19 16:00:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 433)
17/12/19 16:00:26 INFO DAGScheduler: Submitting ShuffleMapStage 433 (MapPartitionsRDD[898] at collect at utils.scala:196), which has no missing parents
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_291 stored as values in memory (estimated size 11.9 KB, free 1998.0 MB)
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_291_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1998.0 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Added broadcast_291_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.1 MB)
17/12/19 16:00:26 INFO SparkContext: Created broadcast 291 from broadcast at DAGScheduler.scala:996
17/12/19 16:00:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 433 (MapPartitionsRDD[898] at collect at utils.scala:196)
17/12/19 16:00:26 INFO TaskSchedulerImpl: Adding task set 433.0 with 2 tasks
17/12/19 16:00:26 INFO TaskSetManager: Starting task 0.0 in stage 433.0 (TID 319, localhost, executor driver, partition 0, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:00:26 INFO TaskSetManager: Starting task 1.0 in stage 433.0 (TID 320, localhost, executor driver, partition 1, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:00:26 INFO Executor: Running task 0.0 in stage 433.0 (TID 319)
17/12/19 16:00:26 INFO Executor: Running task 1.0 in stage 433.0 (TID 320)
17/12/19 16:00:26 INFO BlockManager: Found block rdd_888_0 locally
17/12/19 16:00:26 INFO BlockManager: Found block rdd_888_1 locally
17/12/19 16:00:26 INFO Executor: Finished task 1.0 in stage 433.0 (TID 320). 1792 bytes result sent to driver
17/12/19 16:00:26 INFO TaskSetManager: Finished task 1.0 in stage 433.0 (TID 320) in 0 ms on localhost (executor driver) (1/2)
17/12/19 16:00:26 INFO Executor: Finished task 0.0 in stage 433.0 (TID 319). 1792 bytes result sent to driver
17/12/19 16:00:26 INFO TaskSetManager: Finished task 0.0 in stage 433.0 (TID 319) in 0 ms on localhost (executor driver) (2/2)
17/12/19 16:00:26 INFO TaskSchedulerImpl: Removed TaskSet 433.0, whose tasks have all completed, from pool 
17/12/19 16:00:26 INFO DAGScheduler: ShuffleMapStage 433 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:00:26 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:00:26 INFO DAGScheduler: running: Set()
17/12/19 16:00:26 INFO DAGScheduler: waiting: Set(ResultStage 434)
17/12/19 16:00:26 INFO DAGScheduler: failed: Set()
17/12/19 16:00:26 INFO DAGScheduler: Submitting ResultStage 434 (MapPartitionsRDD[901] at collect at utils.scala:196), which has no missing parents
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_292 stored as values in memory (estimated size 7.0 KB, free 1998.0 MB)
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_292_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1998.0 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Added broadcast_292_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.1 MB)
17/12/19 16:00:26 INFO SparkContext: Created broadcast 292 from broadcast at DAGScheduler.scala:996
17/12/19 16:00:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 434 (MapPartitionsRDD[901] at collect at utils.scala:196)
17/12/19 16:00:26 INFO TaskSchedulerImpl: Adding task set 434.0 with 1 tasks
17/12/19 16:00:26 INFO TaskSetManager: Starting task 0.0 in stage 434.0 (TID 321, localhost, executor driver, partition 0, ANY, 5949 bytes)
17/12/19 16:00:26 INFO Executor: Running task 0.0 in stage 434.0 (TID 321)
17/12/19 16:00:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:00:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:00:26 INFO Executor: Finished task 0.0 in stage 434.0 (TID 321). 1707 bytes result sent to driver
17/12/19 16:00:26 INFO TaskSetManager: Finished task 0.0 in stage 434.0 (TID 321) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:00:26 INFO TaskSchedulerImpl: Removed TaskSet 434.0, whose tasks have all completed, from pool 
17/12/19 16:00:26 INFO DAGScheduler: ResultStage 434 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:00:26 INFO DAGScheduler: Job 208 finished: collect at utils.scala:196, took 0.020054 s
17/12/19 16:00:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz70`
WHERE (0 = 1)
17/12/19 16:00:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:26 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `ibtkjgxiuy`
17/12/19 16:00:26 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:00:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz71`
WHERE (0 = 1)
17/12/19 16:00:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:00:26 INFO CodeGenerator: Code generated in 6.664308 ms
17/12/19 16:00:26 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:00:26 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 60 is 145 bytes
17/12/19 16:00:26 INFO DAGScheduler: Got job 209 (take at <unknown>:0) with 1 output partitions
17/12/19 16:00:26 INFO DAGScheduler: Final stage: ResultStage 436 (take at <unknown>:0)
17/12/19 16:00:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 435)
17/12/19 16:00:26 INFO DAGScheduler: Missing parents: List()
17/12/19 16:00:26 INFO DAGScheduler: Submitting ResultStage 436 (WorkerRDD[907] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_293 stored as values in memory (estimated size 118.3 KB, free 1997.9 MB)
17/12/19 16:00:26 INFO MemoryStore: Block broadcast_293_piece0 stored as bytes in memory (estimated size 47.2 KB, free 1997.8 MB)
17/12/19 16:00:26 INFO BlockManagerInfo: Added broadcast_293_piece0 in memory on 127.0.0.1:53618 (size: 47.2 KB, free: 2004.0 MB)
17/12/19 16:00:26 INFO SparkContext: Created broadcast 293 from broadcast at DAGScheduler.scala:996
17/12/19 16:00:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 436 (WorkerRDD[907] at RDD at rdd.scala:18)
17/12/19 16:00:26 INFO TaskSchedulerImpl: Adding task set 436.0 with 1 tasks
17/12/19 16:00:26 INFO TaskSetManager: Starting task 0.0 in stage 436.0 (TID 322, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:00:26 INFO Executor: Running task 0.0 in stage 436.0 (TID 322)
17/12/19 16:00:26 INFO BlockManager: Found block rdd_888_0 locally
17/12/19 16:00:27 INFO MemoryStore: Block rdd_907_0 stored as values in memory (estimated size 608.0 B, free 1997.8 MB)
17/12/19 16:00:27 INFO BlockManagerInfo: Added rdd_907_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2004.0 MB)
17/12/19 16:00:27 INFO Executor: Finished task 0.0 in stage 436.0 (TID 322). 2509 bytes result sent to driver
17/12/19 16:00:27 INFO TaskSetManager: Finished task 0.0 in stage 436.0 (TID 322) in 634 ms on localhost (executor driver) (1/1)
17/12/19 16:00:27 INFO TaskSchedulerImpl: Removed TaskSet 436.0, whose tasks have all completed, from pool 
17/12/19 16:00:27 INFO DAGScheduler: ResultStage 436 (take at <unknown>:0) finished in 0.634 s
17/12/19 16:00:27 INFO DAGScheduler: Job 209 finished: take at <unknown>:0, took 0.632921 s
17/12/19 16:00:27 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:00:27 INFO DAGScheduler: Got job 210 (take at <unknown>:0) with 1 output partitions
17/12/19 16:00:27 INFO DAGScheduler: Final stage: ResultStage 438 (take at <unknown>:0)
17/12/19 16:00:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 437)
17/12/19 16:00:27 INFO DAGScheduler: Missing parents: List()
17/12/19 16:00:27 INFO DAGScheduler: Submitting ResultStage 438 (WorkerRDD[907] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:00:27 INFO MemoryStore: Block broadcast_294 stored as values in memory (estimated size 118.3 KB, free 1997.7 MB)
17/12/19 16:00:27 INFO MemoryStore: Block broadcast_294_piece0 stored as bytes in memory (estimated size 47.2 KB, free 1997.7 MB)
17/12/19 16:00:27 INFO BlockManagerInfo: Added broadcast_294_piece0 in memory on 127.0.0.1:53618 (size: 47.2 KB, free: 2004.0 MB)
17/12/19 16:00:27 INFO SparkContext: Created broadcast 294 from broadcast at DAGScheduler.scala:996
17/12/19 16:00:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 438 (WorkerRDD[907] at RDD at rdd.scala:18)
17/12/19 16:00:27 INFO TaskSchedulerImpl: Adding task set 438.0 with 1 tasks
17/12/19 16:00:27 INFO TaskSetManager: Starting task 0.0 in stage 438.0 (TID 323, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:00:27 INFO Executor: Running task 0.0 in stage 438.0 (TID 323)
17/12/19 16:00:27 INFO BlockManager: Found block rdd_888_1 locally
17/12/19 16:00:27 INFO MemoryStore: Block rdd_907_1 stored as values in memory (estimated size 608.0 B, free 1997.7 MB)
17/12/19 16:00:27 INFO BlockManagerInfo: Added rdd_907_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2004.0 MB)
17/12/19 16:00:27 INFO Executor: Finished task 0.0 in stage 438.0 (TID 323). 2509 bytes result sent to driver
17/12/19 16:00:27 INFO TaskSetManager: Finished task 0.0 in stage 438.0 (TID 323) in 649 ms on localhost (executor driver) (1/1)
17/12/19 16:00:27 INFO TaskSchedulerImpl: Removed TaskSet 438.0, whose tasks have all completed, from pool 
17/12/19 16:00:27 INFO DAGScheduler: ResultStage 438 (take at <unknown>:0) finished in 0.650 s
17/12/19 16:00:27 INFO DAGScheduler: Job 210 finished: take at <unknown>:0, took 0.652607 s
17/12/19 16:00:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:27 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e868165ad
17/12/19 16:00:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e868165ad` AS `zzz72`
WHERE (0 = 1)
17/12/19 16:00:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e868165ad`
17/12/19 16:00:27 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:00:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz73`
WHERE (0 = 1)
17/12/19 16:00:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:27 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 16:00:27 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:00:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz74`
WHERE (0 = 1)
17/12/19 16:00:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:00:27 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:00:27 INFO DAGScheduler: Got job 211 (collect at utils.scala:196) with 2 output partitions
17/12/19 16:00:27 INFO DAGScheduler: Final stage: ResultStage 440 (collect at utils.scala:196)
17/12/19 16:00:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 439)
17/12/19 16:00:27 INFO DAGScheduler: Missing parents: List()
17/12/19 16:00:27 INFO DAGScheduler: Submitting ResultStage 440 (MapPartitionsRDD[914] at collect at utils.scala:196), which has no missing parents
17/12/19 16:00:27 INFO MemoryStore: Block broadcast_295 stored as values in memory (estimated size 125.8 KB, free 1997.5 MB)
17/12/19 16:00:27 INFO MemoryStore: Block broadcast_295_piece0 stored as bytes in memory (estimated size 50.4 KB, free 1997.5 MB)
17/12/19 16:00:27 INFO BlockManagerInfo: Added broadcast_295_piece0 in memory on 127.0.0.1:53618 (size: 50.4 KB, free: 2003.9 MB)
17/12/19 16:00:27 INFO SparkContext: Created broadcast 295 from broadcast at DAGScheduler.scala:996
17/12/19 16:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 440 (MapPartitionsRDD[914] at collect at utils.scala:196)
17/12/19 16:00:27 INFO TaskSchedulerImpl: Adding task set 440.0 with 2 tasks
17/12/19 16:00:27 INFO TaskSetManager: Starting task 0.0 in stage 440.0 (TID 324, localhost, executor driver, partition 0, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:00:27 INFO TaskSetManager: Starting task 1.0 in stage 440.0 (TID 325, localhost, executor driver, partition 1, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:00:27 INFO Executor: Running task 0.0 in stage 440.0 (TID 324)
17/12/19 16:00:27 INFO Executor: Running task 1.0 in stage 440.0 (TID 325)
17/12/19 16:00:27 INFO BlockManager: Found block rdd_907_0 locally
17/12/19 16:00:27 INFO Executor: Finished task 0.0 in stage 440.0 (TID 324). 1616 bytes result sent to driver
17/12/19 16:00:27 INFO TaskSetManager: Finished task 0.0 in stage 440.0 (TID 324) in 15 ms on localhost (executor driver) (1/2)
17/12/19 16:00:27 INFO BlockManager: Found block rdd_907_1 locally
17/12/19 16:00:27 INFO Executor: Finished task 1.0 in stage 440.0 (TID 325). 1616 bytes result sent to driver
17/12/19 16:00:27 INFO TaskSetManager: Finished task 1.0 in stage 440.0 (TID 325) in 15 ms on localhost (executor driver) (2/2)
17/12/19 16:00:27 INFO TaskSchedulerImpl: Removed TaskSet 440.0, whose tasks have all completed, from pool 
17/12/19 16:00:27 INFO DAGScheduler: ResultStage 440 (collect at utils.scala:196) finished in 0.015 s
17/12/19 16:00:27 INFO DAGScheduler: Job 211 finished: collect at utils.scala:196, took 0.012555 s
17/12/19 16:00:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:00:27 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:00:27 INFO DAGScheduler: Got job 212 (take at <unknown>:0) with 1 output partitions
17/12/19 16:00:27 INFO DAGScheduler: Final stage: ResultStage 442 (take at <unknown>:0)
17/12/19 16:00:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 441)
17/12/19 16:00:27 INFO DAGScheduler: Missing parents: List()
17/12/19 16:00:27 INFO DAGScheduler: Submitting ResultStage 442 (WorkerRDD[919] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:00:27 INFO MemoryStore: Block broadcast_296 stored as values in memory (estimated size 226.9 KB, free 1997.3 MB)
17/12/19 16:00:27 INFO MemoryStore: Block broadcast_296_piece0 stored as bytes in memory (estimated size 90.9 KB, free 1997.2 MB)
17/12/19 16:00:27 INFO BlockManagerInfo: Added broadcast_296_piece0 in memory on 127.0.0.1:53618 (size: 90.9 KB, free: 2003.8 MB)
17/12/19 16:00:27 INFO SparkContext: Created broadcast 296 from broadcast at DAGScheduler.scala:996
17/12/19 16:00:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 442 (WorkerRDD[919] at RDD at rdd.scala:18)
17/12/19 16:00:27 INFO TaskSchedulerImpl: Adding task set 442.0 with 1 tasks
17/12/19 16:00:27 INFO TaskSetManager: Starting task 0.0 in stage 442.0 (TID 326, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:00:27 INFO Executor: Running task 0.0 in stage 442.0 (TID 326)
17/12/19 16:00:27 INFO BlockManager: Found block rdd_907_0 locally
17/12/19 16:00:28 INFO MemoryStore: Block rdd_919_0 stored as values in memory (estimated size 80.0 B, free 1997.2 MB)
17/12/19 16:00:28 INFO BlockManagerInfo: Added rdd_919_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.8 MB)
17/12/19 16:00:28 INFO Executor: Finished task 0.0 in stage 442.0 (TID 326). 2577 bytes result sent to driver
17/12/19 16:00:28 INFO TaskSetManager: Finished task 0.0 in stage 442.0 (TID 326) in 658 ms on localhost (executor driver) (1/1)
17/12/19 16:00:28 INFO TaskSchedulerImpl: Removed TaskSet 442.0, whose tasks have all completed, from pool 
17/12/19 16:00:28 INFO DAGScheduler: ResultStage 442 (take at <unknown>:0) finished in 0.658 s
17/12/19 16:00:28 INFO DAGScheduler: Job 212 finished: take at <unknown>:0, took 0.663966 s
17/12/19 16:00:28 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:00:28 INFO DAGScheduler: Got job 213 (take at <unknown>:0) with 1 output partitions
17/12/19 16:00:28 INFO DAGScheduler: Final stage: ResultStage 444 (take at <unknown>:0)
17/12/19 16:00:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 443)
17/12/19 16:00:28 INFO DAGScheduler: Missing parents: List()
17/12/19 16:00:28 INFO DAGScheduler: Submitting ResultStage 444 (WorkerRDD[919] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:00:28 INFO MemoryStore: Block broadcast_297 stored as values in memory (estimated size 226.9 KB, free 1997.0 MB)
17/12/19 16:00:28 INFO MemoryStore: Block broadcast_297_piece0 stored as bytes in memory (estimated size 90.9 KB, free 1996.9 MB)
17/12/19 16:00:28 INFO BlockManagerInfo: Added broadcast_297_piece0 in memory on 127.0.0.1:53618 (size: 90.9 KB, free: 2003.7 MB)
17/12/19 16:00:28 INFO SparkContext: Created broadcast 297 from broadcast at DAGScheduler.scala:996
17/12/19 16:00:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 444 (WorkerRDD[919] at RDD at rdd.scala:18)
17/12/19 16:00:28 INFO TaskSchedulerImpl: Adding task set 444.0 with 1 tasks
17/12/19 16:00:28 INFO TaskSetManager: Starting task 0.0 in stage 444.0 (TID 327, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:00:28 INFO Executor: Running task 0.0 in stage 444.0 (TID 327)
17/12/19 16:00:28 INFO BlockManager: Found block rdd_907_1 locally
17/12/19 16:00:29 INFO MemoryStore: Block rdd_919_1 stored as values in memory (estimated size 80.0 B, free 1996.9 MB)
17/12/19 16:00:29 INFO BlockManagerInfo: Added rdd_919_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.7 MB)
17/12/19 16:00:29 INFO Executor: Finished task 0.0 in stage 444.0 (TID 327). 2400 bytes result sent to driver
17/12/19 16:00:29 INFO TaskSetManager: Finished task 0.0 in stage 444.0 (TID 327) in 610 ms on localhost (executor driver) (1/1)
17/12/19 16:00:29 INFO TaskSchedulerImpl: Removed TaskSet 444.0, whose tasks have all completed, from pool 
17/12/19 16:00:29 INFO DAGScheduler: ResultStage 444 (take at <unknown>:0) finished in 0.610 s
17/12/19 16:00:29 INFO DAGScheduler: Job 213 finished: take at <unknown>:0, took 0.614494 s
17/12/19 16:00:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e843b5e0e
17/12/19 16:00:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e843b5e0e` AS `zzz75`
WHERE (0 = 1)
17/12/19 16:00:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e843b5e0e`
LIMIT 10
17/12/19 16:00:29 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:00:29 INFO DAGScheduler: Got job 214 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:00:29 INFO DAGScheduler: Final stage: ResultStage 446 (collect at utils.scala:196)
17/12/19 16:00:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 445)
17/12/19 16:00:29 INFO DAGScheduler: Missing parents: List()
17/12/19 16:00:29 INFO DAGScheduler: Submitting ResultStage 446 (MapPartitionsRDD[923] at collect at utils.scala:196), which has no missing parents
17/12/19 16:00:29 INFO MemoryStore: Block broadcast_298 stored as values in memory (estimated size 227.9 KB, free 1996.6 MB)
17/12/19 16:00:29 INFO MemoryStore: Block broadcast_298_piece0 stored as bytes in memory (estimated size 91.6 KB, free 1996.6 MB)
17/12/19 16:00:29 INFO BlockManagerInfo: Added broadcast_298_piece0 in memory on 127.0.0.1:53618 (size: 91.6 KB, free: 2003.7 MB)
17/12/19 16:00:29 INFO SparkContext: Created broadcast 298 from broadcast at DAGScheduler.scala:996
17/12/19 16:00:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 446 (MapPartitionsRDD[923] at collect at utils.scala:196)
17/12/19 16:00:29 INFO TaskSchedulerImpl: Adding task set 446.0 with 1 tasks
17/12/19 16:00:29 INFO TaskSetManager: Starting task 0.0 in stage 446.0 (TID 328, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:00:29 INFO Executor: Running task 0.0 in stage 446.0 (TID 328)
17/12/19 16:00:29 INFO BlockManager: Found block rdd_919_0 locally
17/12/19 16:00:29 INFO Executor: Finished task 0.0 in stage 446.0 (TID 328). 1479 bytes result sent to driver
17/12/19 16:00:29 INFO TaskSetManager: Finished task 0.0 in stage 446.0 (TID 328) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:00:29 INFO TaskSchedulerImpl: Removed TaskSet 446.0, whose tasks have all completed, from pool 
17/12/19 16:00:29 INFO DAGScheduler: ResultStage 446 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:00:29 INFO DAGScheduler: Job 214 finished: collect at utils.scala:196, took 0.008999 s
17/12/19 16:00:29 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:00:29 INFO DAGScheduler: Got job 215 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:00:29 INFO DAGScheduler: Final stage: ResultStage 448 (collect at utils.scala:196)
17/12/19 16:00:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 447)
17/12/19 16:00:29 INFO DAGScheduler: Missing parents: List()
17/12/19 16:00:29 INFO DAGScheduler: Submitting ResultStage 448 (MapPartitionsRDD[923] at collect at utils.scala:196), which has no missing parents
17/12/19 16:00:29 INFO MemoryStore: Block broadcast_299 stored as values in memory (estimated size 227.9 KB, free 1996.3 MB)
17/12/19 16:00:29 INFO MemoryStore: Block broadcast_299_piece0 stored as bytes in memory (estimated size 91.6 KB, free 1996.2 MB)
17/12/19 16:00:29 INFO BlockManagerInfo: Added broadcast_299_piece0 in memory on 127.0.0.1:53618 (size: 91.6 KB, free: 2003.6 MB)
17/12/19 16:00:29 INFO SparkContext: Created broadcast 299 from broadcast at DAGScheduler.scala:996
17/12/19 16:00:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 448 (MapPartitionsRDD[923] at collect at utils.scala:196)
17/12/19 16:00:29 INFO TaskSchedulerImpl: Adding task set 448.0 with 1 tasks
17/12/19 16:00:29 INFO TaskSetManager: Starting task 0.0 in stage 448.0 (TID 329, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:00:29 INFO Executor: Running task 0.0 in stage 448.0 (TID 329)
17/12/19 16:00:29 INFO BlockManager: Found block rdd_919_1 locally
17/12/19 16:00:29 INFO Executor: Finished task 0.0 in stage 448.0 (TID 329). 1479 bytes result sent to driver
17/12/19 16:00:29 INFO TaskSetManager: Finished task 0.0 in stage 448.0 (TID 329) in 15 ms on localhost (executor driver) (1/1)
17/12/19 16:00:29 INFO TaskSchedulerImpl: Removed TaskSet 448.0, whose tasks have all completed, from pool 
17/12/19 16:00:29 INFO DAGScheduler: ResultStage 448 (collect at utils.scala:196) finished in 0.015 s
17/12/19 16:00:29 INFO DAGScheduler: Job 215 finished: collect at utils.scala:196, took 0.009130 s
17/12/19 16:00:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:00:29 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:00:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:00:29 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:00:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:00:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:00:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:00:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:00:29 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:00:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:00:29 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:00:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:00:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:00:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:00:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:00:29 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:00:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:00:29 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:00:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:00:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:00:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:00:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:00:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:00:29 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:00:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:00:29 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:00:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:00:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:00:29 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:17:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:17:16 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:16 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:17:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:17:16 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 16:17:16 INFO DAGScheduler: Got job 216 (collect at utils.scala:58) with 1 output partitions
17/12/19 16:17:16 INFO DAGScheduler: Final stage: ResultStage 449 (collect at utils.scala:58)
17/12/19 16:17:16 INFO DAGScheduler: Parents of final stage: List()
17/12/19 16:17:16 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:16 INFO DAGScheduler: Submitting ResultStage 449 (MapPartitionsRDD[933] at map at utils.scala:55), which has no missing parents
17/12/19 16:17:16 INFO MemoryStore: Block broadcast_300 stored as values in memory (estimated size 8.7 KB, free 1996.2 MB)
17/12/19 16:17:16 INFO MemoryStore: Block broadcast_300_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1996.2 MB)
17/12/19 16:17:16 INFO BlockManagerInfo: Added broadcast_300_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.6 MB)
17/12/19 16:17:16 INFO SparkContext: Created broadcast 300 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 449 (MapPartitionsRDD[933] at map at utils.scala:55)
17/12/19 16:17:16 INFO TaskSchedulerImpl: Adding task set 449.0 with 1 tasks
17/12/19 16:17:16 INFO TaskSetManager: Starting task 0.0 in stage 449.0 (TID 330, localhost, executor driver, partition 0, PROCESS_LOCAL, 8516 bytes)
17/12/19 16:17:16 INFO Executor: Running task 0.0 in stage 449.0 (TID 330)
17/12/19 16:17:16 INFO Executor: Finished task 0.0 in stage 449.0 (TID 330). 1905 bytes result sent to driver
17/12/19 16:17:16 INFO TaskSetManager: Finished task 0.0 in stage 449.0 (TID 330) in 16 ms on localhost (executor driver) (1/1)
17/12/19 16:17:16 INFO TaskSchedulerImpl: Removed TaskSet 449.0, whose tasks have all completed, from pool 
17/12/19 16:17:16 INFO DAGScheduler: ResultStage 449 (collect at utils.scala:58) finished in 0.016 s
17/12/19 16:17:16 INFO DAGScheduler: Job 216 finished: collect at utils.scala:58, took 0.010770 s
17/12/19 16:17:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:16 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:17:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:16 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 16:17:16 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 16:17:16 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 16:17:16 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 16:17:16 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 16:17:16 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 16:17:16 INFO MemoryStore: Block broadcast_301 stored as values in memory (estimated size 293.7 KB, free 1995.9 MB)
17/12/19 16:17:16 INFO BlockManagerInfo: Removed broadcast_288_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2003.6 MB)
17/12/19 16:17:16 INFO BlockManagerInfo: Removed broadcast_300_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2003.6 MB)
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 15517
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 15518
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14779
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14780
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14786
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14787
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14788
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14789
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14790
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14791
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14792
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14793
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14794
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14795
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14796
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14797
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14798
17/12/19 16:17:16 INFO ContextCleaner: Cleaned shuffle 61
17/12/19 16:17:16 INFO BlockManagerInfo: Removed broadcast_289_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.6 MB)
17/12/19 16:17:16 INFO BlockManagerInfo: Removed broadcast_290_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.6 MB)
17/12/19 16:17:16 INFO ContextCleaner: Cleaned accumulator 14967
17/12/19 16:17:16 INFO BlockManagerInfo: Removed broadcast_291_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.6 MB)
17/12/19 16:17:16 INFO BlockManagerInfo: Removed broadcast_292_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.6 MB)
17/12/19 16:17:16 INFO MemoryStore: Block broadcast_301_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1996.0 MB)
17/12/19 16:17:16 INFO BlockManagerInfo: Added broadcast_301_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2003.6 MB)
17/12/19 16:17:16 INFO BlockManagerInfo: Removed broadcast_293_piece0 on 127.0.0.1:53618 in memory (size: 47.2 KB, free: 2003.6 MB)
17/12/19 16:17:16 INFO BlockManagerInfo: Removed broadcast_294_piece0 on 127.0.0.1:53618 in memory (size: 47.2 KB, free: 2003.7 MB)
17/12/19 16:17:16 INFO SparkContext: Created broadcast 301 from sql at <unknown>:0
17/12/19 16:17:17 INFO BlockManagerInfo: Removed broadcast_295_piece0 on 127.0.0.1:53618 in memory (size: 50.4 KB, free: 2003.7 MB)
17/12/19 16:17:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 16:17:17 INFO BlockManagerInfo: Removed broadcast_296_piece0 on 127.0.0.1:53618 in memory (size: 90.9 KB, free: 2003.8 MB)
17/12/19 16:17:17 INFO BlockManagerInfo: Removed broadcast_297_piece0 on 127.0.0.1:53618 in memory (size: 90.9 KB, free: 2003.9 MB)
17/12/19 16:17:17 INFO BlockManagerInfo: Removed broadcast_298_piece0 on 127.0.0.1:53618 in memory (size: 91.6 KB, free: 2004.0 MB)
17/12/19 16:17:17 INFO BlockManagerInfo: Removed broadcast_299_piece0 on 127.0.0.1:53618 in memory (size: 91.6 KB, free: 2004.1 MB)
17/12/19 16:17:17 INFO ContextCleaner: Cleaned accumulator 15467
17/12/19 16:17:17 INFO ContextCleaner: Cleaned accumulator 15468
17/12/19 16:17:17 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 16:17:17 INFO DAGScheduler: Registering RDD 937 (sql at <unknown>:0)
17/12/19 16:17:17 INFO DAGScheduler: Registering RDD 942 (sql at <unknown>:0)
17/12/19 16:17:17 INFO DAGScheduler: Got job 217 (sql at <unknown>:0) with 1 output partitions
17/12/19 16:17:17 INFO DAGScheduler: Final stage: ResultStage 452 (sql at <unknown>:0)
17/12/19 16:17:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 451)
17/12/19 16:17:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 451)
17/12/19 16:17:17 INFO DAGScheduler: Submitting ShuffleMapStage 450 (MapPartitionsRDD[937] at sql at <unknown>:0), which has no missing parents
17/12/19 16:17:17 INFO MemoryStore: Block broadcast_302 stored as values in memory (estimated size 12.1 KB, free 1997.7 MB)
17/12/19 16:17:17 INFO MemoryStore: Block broadcast_302_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1997.7 MB)
17/12/19 16:17:17 INFO BlockManagerInfo: Added broadcast_302_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.1 MB)
17/12/19 16:17:17 INFO SparkContext: Created broadcast 302 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 450 (MapPartitionsRDD[937] at sql at <unknown>:0)
17/12/19 16:17:17 INFO TaskSchedulerImpl: Adding task set 450.0 with 1 tasks
17/12/19 16:17:17 INFO TaskSetManager: Starting task 0.0 in stage 450.0 (TID 331, localhost, executor driver, partition 0, PROCESS_LOCAL, 6680 bytes)
17/12/19 16:17:17 INFO Executor: Running task 0.0 in stage 450.0 (TID 331)
17/12/19 16:17:17 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_ce12f45c7b6ab67e1f885565f5bf17d5c081c3cc5b571013e06a67fb3a82147c.csv, range: 0-466, partition values: [empty row]
17/12/19 16:17:17 INFO Executor: Finished task 0.0 in stage 450.0 (TID 331). 1553 bytes result sent to driver
17/12/19 16:17:17 INFO TaskSetManager: Finished task 0.0 in stage 450.0 (TID 331) in 31 ms on localhost (executor driver) (1/1)
17/12/19 16:17:17 INFO TaskSchedulerImpl: Removed TaskSet 450.0, whose tasks have all completed, from pool 
17/12/19 16:17:17 INFO DAGScheduler: ShuffleMapStage 450 (sql at <unknown>:0) finished in 0.031 s
17/12/19 16:17:17 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:17:17 INFO DAGScheduler: running: Set()
17/12/19 16:17:17 INFO DAGScheduler: waiting: Set(ResultStage 452, ShuffleMapStage 451)
17/12/19 16:17:17 INFO DAGScheduler: failed: Set()
17/12/19 16:17:17 INFO DAGScheduler: Submitting ShuffleMapStage 451 (MapPartitionsRDD[942] at sql at <unknown>:0), which has no missing parents
17/12/19 16:17:17 INFO MemoryStore: Block broadcast_303 stored as values in memory (estimated size 11.9 KB, free 1997.7 MB)
17/12/19 16:17:17 INFO MemoryStore: Block broadcast_303_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1997.7 MB)
17/12/19 16:17:17 INFO BlockManagerInfo: Added broadcast_303_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.0 MB)
17/12/19 16:17:17 INFO SparkContext: Created broadcast 303 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 451 (MapPartitionsRDD[942] at sql at <unknown>:0)
17/12/19 16:17:17 INFO TaskSchedulerImpl: Adding task set 451.0 with 2 tasks
17/12/19 16:17:17 INFO TaskSetManager: Starting task 0.0 in stage 451.0 (TID 332, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 16:17:17 INFO TaskSetManager: Starting task 1.0 in stage 451.0 (TID 333, localhost, executor driver, partition 1, ANY, 5946 bytes)
17/12/19 16:17:17 INFO Executor: Running task 0.0 in stage 451.0 (TID 332)
17/12/19 16:17:17 INFO Executor: Running task 1.0 in stage 451.0 (TID 333)
17/12/19 16:17:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:17:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:17:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:17:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:17:17 INFO MemoryStore: Block rdd_939_0 stored as values in memory (estimated size 544.0 B, free 1997.7 MB)
17/12/19 16:17:17 INFO BlockManagerInfo: Added rdd_939_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.0 MB)
17/12/19 16:17:17 INFO MemoryStore: Block rdd_939_1 stored as values in memory (estimated size 544.0 B, free 1997.7 MB)
17/12/19 16:17:17 INFO BlockManagerInfo: Added rdd_939_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.0 MB)
17/12/19 16:17:17 INFO Executor: Finished task 0.0 in stage 451.0 (TID 332). 3064 bytes result sent to driver
17/12/19 16:17:17 INFO TaskSetManager: Finished task 0.0 in stage 451.0 (TID 332) in 16 ms on localhost (executor driver) (1/2)
17/12/19 16:17:17 INFO Executor: Finished task 1.0 in stage 451.0 (TID 333). 2985 bytes result sent to driver
17/12/19 16:17:17 INFO TaskSetManager: Finished task 1.0 in stage 451.0 (TID 333) in 16 ms on localhost (executor driver) (2/2)
17/12/19 16:17:17 INFO TaskSchedulerImpl: Removed TaskSet 451.0, whose tasks have all completed, from pool 
17/12/19 16:17:17 INFO DAGScheduler: ShuffleMapStage 451 (sql at <unknown>:0) finished in 0.016 s
17/12/19 16:17:17 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:17:17 INFO DAGScheduler: running: Set()
17/12/19 16:17:17 INFO DAGScheduler: waiting: Set(ResultStage 452)
17/12/19 16:17:17 INFO DAGScheduler: failed: Set()
17/12/19 16:17:17 INFO DAGScheduler: Submitting ResultStage 452 (MapPartitionsRDD[945] at sql at <unknown>:0), which has no missing parents
17/12/19 16:17:17 INFO MemoryStore: Block broadcast_304 stored as values in memory (estimated size 7.0 KB, free 1997.7 MB)
17/12/19 16:17:17 INFO MemoryStore: Block broadcast_304_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1997.7 MB)
17/12/19 16:17:17 INFO BlockManagerInfo: Added broadcast_304_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.0 MB)
17/12/19 16:17:17 INFO SparkContext: Created broadcast 304 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 452 (MapPartitionsRDD[945] at sql at <unknown>:0)
17/12/19 16:17:17 INFO TaskSchedulerImpl: Adding task set 452.0 with 1 tasks
17/12/19 16:17:17 INFO TaskSetManager: Starting task 0.0 in stage 452.0 (TID 334, localhost, executor driver, partition 0, ANY, 5957 bytes)
17/12/19 16:17:17 INFO Executor: Running task 0.0 in stage 452.0 (TID 334)
17/12/19 16:17:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:17:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:17:17 INFO Executor: Finished task 0.0 in stage 452.0 (TID 334). 1707 bytes result sent to driver
17/12/19 16:17:17 INFO TaskSetManager: Finished task 0.0 in stage 452.0 (TID 334) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:17:17 INFO TaskSchedulerImpl: Removed TaskSet 452.0, whose tasks have all completed, from pool 
17/12/19 16:17:17 INFO DAGScheduler: ResultStage 452 (sql at <unknown>:0) finished in 0.000 s
17/12/19 16:17:17 INFO DAGScheduler: Job 217 finished: sql at <unknown>:0, took 0.054820 s
17/12/19 16:17:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:17 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 16:17:17 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:17:17 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 63 is 145 bytes
17/12/19 16:17:17 INFO DAGScheduler: Registering RDD 949 (collect at utils.scala:196)
17/12/19 16:17:17 INFO DAGScheduler: Got job 218 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:17:17 INFO DAGScheduler: Final stage: ResultStage 455 (collect at utils.scala:196)
17/12/19 16:17:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 454)
17/12/19 16:17:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 454)
17/12/19 16:17:17 INFO DAGScheduler: Submitting ShuffleMapStage 454 (MapPartitionsRDD[949] at collect at utils.scala:196), which has no missing parents
17/12/19 16:17:17 INFO MemoryStore: Block broadcast_305 stored as values in memory (estimated size 11.9 KB, free 1997.7 MB)
17/12/19 16:17:17 INFO MemoryStore: Block broadcast_305_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1997.7 MB)
17/12/19 16:17:17 INFO BlockManagerInfo: Added broadcast_305_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.0 MB)
17/12/19 16:17:17 INFO SparkContext: Created broadcast 305 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 454 (MapPartitionsRDD[949] at collect at utils.scala:196)
17/12/19 16:17:17 INFO TaskSchedulerImpl: Adding task set 454.0 with 2 tasks
17/12/19 16:17:17 INFO TaskSetManager: Starting task 0.0 in stage 454.0 (TID 335, localhost, executor driver, partition 0, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:17:17 INFO TaskSetManager: Starting task 1.0 in stage 454.0 (TID 336, localhost, executor driver, partition 1, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:17:17 INFO Executor: Running task 1.0 in stage 454.0 (TID 336)
17/12/19 16:17:17 INFO Executor: Running task 0.0 in stage 454.0 (TID 335)
17/12/19 16:17:17 INFO BlockManager: Found block rdd_939_0 locally
17/12/19 16:17:17 INFO BlockManager: Found block rdd_939_1 locally
17/12/19 16:17:17 INFO Executor: Finished task 1.0 in stage 454.0 (TID 336). 1792 bytes result sent to driver
17/12/19 16:17:17 INFO TaskSetManager: Finished task 1.0 in stage 454.0 (TID 336) in 0 ms on localhost (executor driver) (1/2)
17/12/19 16:17:17 INFO Executor: Finished task 0.0 in stage 454.0 (TID 335). 1792 bytes result sent to driver
17/12/19 16:17:17 INFO TaskSetManager: Finished task 0.0 in stage 454.0 (TID 335) in 0 ms on localhost (executor driver) (2/2)
17/12/19 16:17:17 INFO TaskSchedulerImpl: Removed TaskSet 454.0, whose tasks have all completed, from pool 
17/12/19 16:17:17 INFO DAGScheduler: ShuffleMapStage 454 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:17:17 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:17:17 INFO DAGScheduler: running: Set()
17/12/19 16:17:17 INFO DAGScheduler: waiting: Set(ResultStage 455)
17/12/19 16:17:17 INFO DAGScheduler: failed: Set()
17/12/19 16:17:17 INFO DAGScheduler: Submitting ResultStage 455 (MapPartitionsRDD[952] at collect at utils.scala:196), which has no missing parents
17/12/19 16:17:17 INFO MemoryStore: Block broadcast_306 stored as values in memory (estimated size 7.0 KB, free 1997.7 MB)
17/12/19 16:17:17 INFO MemoryStore: Block broadcast_306_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1997.7 MB)
17/12/19 16:17:17 INFO BlockManagerInfo: Added broadcast_306_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.0 MB)
17/12/19 16:17:17 INFO SparkContext: Created broadcast 306 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 455 (MapPartitionsRDD[952] at collect at utils.scala:196)
17/12/19 16:17:17 INFO TaskSchedulerImpl: Adding task set 455.0 with 1 tasks
17/12/19 16:17:17 INFO TaskSetManager: Starting task 0.0 in stage 455.0 (TID 337, localhost, executor driver, partition 0, ANY, 5949 bytes)
17/12/19 16:17:17 INFO Executor: Running task 0.0 in stage 455.0 (TID 337)
17/12/19 16:17:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:17:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:17:17 INFO Executor: Finished task 0.0 in stage 455.0 (TID 337). 1707 bytes result sent to driver
17/12/19 16:17:17 INFO TaskSetManager: Finished task 0.0 in stage 455.0 (TID 337) in 15 ms on localhost (executor driver) (1/1)
17/12/19 16:17:17 INFO TaskSchedulerImpl: Removed TaskSet 455.0, whose tasks have all completed, from pool 
17/12/19 16:17:17 INFO DAGScheduler: ResultStage 455 (collect at utils.scala:196) finished in 0.015 s
17/12/19 16:17:17 INFO DAGScheduler: Job 218 finished: collect at utils.scala:196, took 0.021869 s
17/12/19 16:17:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz76`
WHERE (0 = 1)
17/12/19 16:17:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:17 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `wpyhvphjus`
17/12/19 16:17:17 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:17:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz77`
WHERE (0 = 1)
17/12/19 16:17:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:17:17 INFO CodeGenerator: Code generated in 8.277713 ms
17/12/19 16:17:17 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:17:17 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 63 is 145 bytes
17/12/19 16:17:17 INFO DAGScheduler: Got job 219 (take at <unknown>:0) with 1 output partitions
17/12/19 16:17:17 INFO DAGScheduler: Final stage: ResultStage 457 (take at <unknown>:0)
17/12/19 16:17:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 456)
17/12/19 16:17:17 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:17 INFO DAGScheduler: Submitting ResultStage 457 (WorkerRDD[958] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:17:17 INFO MemoryStore: Block broadcast_307 stored as values in memory (estimated size 118.3 KB, free 1997.6 MB)
17/12/19 16:17:17 INFO MemoryStore: Block broadcast_307_piece0 stored as bytes in memory (estimated size 47.1 KB, free 1997.5 MB)
17/12/19 16:17:17 INFO BlockManagerInfo: Added broadcast_307_piece0 in memory on 127.0.0.1:53618 (size: 47.1 KB, free: 2004.0 MB)
17/12/19 16:17:17 INFO SparkContext: Created broadcast 307 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 457 (WorkerRDD[958] at RDD at rdd.scala:18)
17/12/19 16:17:17 INFO TaskSchedulerImpl: Adding task set 457.0 with 1 tasks
17/12/19 16:17:17 INFO TaskSetManager: Starting task 0.0 in stage 457.0 (TID 338, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:17:17 INFO Executor: Running task 0.0 in stage 457.0 (TID 338)
17/12/19 16:17:17 INFO BlockManager: Found block rdd_939_0 locally
17/12/19 16:17:17 INFO MemoryStore: Block rdd_958_0 stored as values in memory (estimated size 608.0 B, free 1997.5 MB)
17/12/19 16:17:17 INFO BlockManagerInfo: Added rdd_958_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2004.0 MB)
17/12/19 16:17:17 INFO Executor: Finished task 0.0 in stage 457.0 (TID 338). 2509 bytes result sent to driver
17/12/19 16:17:17 INFO TaskSetManager: Finished task 0.0 in stage 457.0 (TID 338) in 651 ms on localhost (executor driver) (1/1)
17/12/19 16:17:17 INFO TaskSchedulerImpl: Removed TaskSet 457.0, whose tasks have all completed, from pool 
17/12/19 16:17:17 INFO DAGScheduler: ResultStage 457 (take at <unknown>:0) finished in 0.652 s
17/12/19 16:17:17 INFO DAGScheduler: Job 219 finished: take at <unknown>:0, took 0.646913 s
17/12/19 16:17:17 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:17:17 INFO DAGScheduler: Got job 220 (take at <unknown>:0) with 1 output partitions
17/12/19 16:17:17 INFO DAGScheduler: Final stage: ResultStage 459 (take at <unknown>:0)
17/12/19 16:17:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 458)
17/12/19 16:17:17 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:17 INFO DAGScheduler: Submitting ResultStage 459 (WorkerRDD[958] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:17:17 INFO MemoryStore: Block broadcast_308 stored as values in memory (estimated size 118.3 KB, free 1997.4 MB)
17/12/19 16:17:17 INFO MemoryStore: Block broadcast_308_piece0 stored as bytes in memory (estimated size 47.1 KB, free 1997.4 MB)
17/12/19 16:17:17 INFO BlockManagerInfo: Added broadcast_308_piece0 in memory on 127.0.0.1:53618 (size: 47.1 KB, free: 2003.9 MB)
17/12/19 16:17:17 INFO SparkContext: Created broadcast 308 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 459 (WorkerRDD[958] at RDD at rdd.scala:18)
17/12/19 16:17:17 INFO TaskSchedulerImpl: Adding task set 459.0 with 1 tasks
17/12/19 16:17:17 INFO TaskSetManager: Starting task 0.0 in stage 459.0 (TID 339, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:17:17 INFO Executor: Running task 0.0 in stage 459.0 (TID 339)
17/12/19 16:17:17 INFO BlockManager: Found block rdd_939_1 locally
17/12/19 16:17:18 INFO MemoryStore: Block rdd_958_1 stored as values in memory (estimated size 608.0 B, free 1997.4 MB)
17/12/19 16:17:18 INFO BlockManagerInfo: Added rdd_958_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 16:17:18 INFO Executor: Finished task 0.0 in stage 459.0 (TID 339). 2596 bytes result sent to driver
17/12/19 16:17:18 INFO TaskSetManager: Finished task 0.0 in stage 459.0 (TID 339) in 639 ms on localhost (executor driver) (1/1)
17/12/19 16:17:18 INFO TaskSchedulerImpl: Removed TaskSet 459.0, whose tasks have all completed, from pool 
17/12/19 16:17:18 INFO DAGScheduler: ResultStage 459 (take at <unknown>:0) finished in 0.639 s
17/12/19 16:17:18 INFO DAGScheduler: Job 220 finished: take at <unknown>:0, took 0.656172 s
17/12/19 16:17:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:18 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e81aeb1a6a
17/12/19 16:17:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e81aeb1a6a` AS `zzz78`
WHERE (0 = 1)
17/12/19 16:17:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e81aeb1a6a`
17/12/19 16:17:18 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:17:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz79`
WHERE (0 = 1)
17/12/19 16:17:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:18 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 16:17:18 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:17:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz80`
WHERE (0 = 1)
17/12/19 16:17:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:17:18 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:17:18 INFO DAGScheduler: Got job 221 (collect at utils.scala:196) with 2 output partitions
17/12/19 16:17:18 INFO DAGScheduler: Final stage: ResultStage 461 (collect at utils.scala:196)
17/12/19 16:17:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 460)
17/12/19 16:17:18 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:18 INFO DAGScheduler: Submitting ResultStage 461 (MapPartitionsRDD[965] at collect at utils.scala:196), which has no missing parents
17/12/19 16:17:18 INFO MemoryStore: Block broadcast_309 stored as values in memory (estimated size 125.8 KB, free 1997.2 MB)
17/12/19 16:17:18 INFO MemoryStore: Block broadcast_309_piece0 stored as bytes in memory (estimated size 50.4 KB, free 1997.2 MB)
17/12/19 16:17:18 INFO BlockManagerInfo: Added broadcast_309_piece0 in memory on 127.0.0.1:53618 (size: 50.4 KB, free: 2003.9 MB)
17/12/19 16:17:18 INFO SparkContext: Created broadcast 309 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 461 (MapPartitionsRDD[965] at collect at utils.scala:196)
17/12/19 16:17:18 INFO TaskSchedulerImpl: Adding task set 461.0 with 2 tasks
17/12/19 16:17:18 INFO TaskSetManager: Starting task 0.0 in stage 461.0 (TID 340, localhost, executor driver, partition 0, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:17:18 INFO TaskSetManager: Starting task 1.0 in stage 461.0 (TID 341, localhost, executor driver, partition 1, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:17:18 INFO Executor: Running task 1.0 in stage 461.0 (TID 341)
17/12/19 16:17:18 INFO Executor: Running task 0.0 in stage 461.0 (TID 340)
17/12/19 16:17:18 INFO BlockManager: Found block rdd_958_1 locally
17/12/19 16:17:18 INFO BlockManager: Found block rdd_958_0 locally
17/12/19 16:17:18 INFO Executor: Finished task 0.0 in stage 461.0 (TID 340). 1444 bytes result sent to driver
17/12/19 16:17:18 INFO TaskSetManager: Finished task 0.0 in stage 461.0 (TID 340) in 16 ms on localhost (executor driver) (1/2)
17/12/19 16:17:18 INFO Executor: Finished task 1.0 in stage 461.0 (TID 341). 1597 bytes result sent to driver
17/12/19 16:17:18 INFO TaskSetManager: Finished task 1.0 in stage 461.0 (TID 341) in 16 ms on localhost (executor driver) (2/2)
17/12/19 16:17:18 INFO TaskSchedulerImpl: Removed TaskSet 461.0, whose tasks have all completed, from pool 
17/12/19 16:17:18 INFO DAGScheduler: ResultStage 461 (collect at utils.scala:196) finished in 0.016 s
17/12/19 16:17:18 INFO DAGScheduler: Job 221 finished: collect at utils.scala:196, took 0.009861 s
17/12/19 16:17:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:17:18 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:17:18 INFO DAGScheduler: Got job 222 (take at <unknown>:0) with 1 output partitions
17/12/19 16:17:18 INFO DAGScheduler: Final stage: ResultStage 463 (take at <unknown>:0)
17/12/19 16:17:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 462)
17/12/19 16:17:18 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:18 INFO DAGScheduler: Submitting ResultStage 463 (WorkerRDD[970] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:17:18 INFO MemoryStore: Block broadcast_310 stored as values in memory (estimated size 226.9 KB, free 1997.0 MB)
17/12/19 16:17:18 INFO MemoryStore: Block broadcast_310_piece0 stored as bytes in memory (estimated size 90.8 KB, free 1996.9 MB)
17/12/19 16:17:18 INFO BlockManagerInfo: Added broadcast_310_piece0 in memory on 127.0.0.1:53618 (size: 90.8 KB, free: 2003.8 MB)
17/12/19 16:17:18 INFO SparkContext: Created broadcast 310 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 463 (WorkerRDD[970] at RDD at rdd.scala:18)
17/12/19 16:17:18 INFO TaskSchedulerImpl: Adding task set 463.0 with 1 tasks
17/12/19 16:17:18 INFO TaskSetManager: Starting task 0.0 in stage 463.0 (TID 342, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:17:18 INFO Executor: Running task 0.0 in stage 463.0 (TID 342)
17/12/19 16:17:18 INFO BlockManager: Found block rdd_958_0 locally
17/12/19 16:17:19 INFO MemoryStore: Block rdd_970_0 stored as values in memory (estimated size 80.0 B, free 1996.9 MB)
17/12/19 16:17:19 INFO BlockManagerInfo: Added rdd_970_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.8 MB)
17/12/19 16:17:19 INFO Executor: Finished task 0.0 in stage 463.0 (TID 342). 2400 bytes result sent to driver
17/12/19 16:17:19 INFO TaskSetManager: Finished task 0.0 in stage 463.0 (TID 342) in 643 ms on localhost (executor driver) (1/1)
17/12/19 16:17:19 INFO TaskSchedulerImpl: Removed TaskSet 463.0, whose tasks have all completed, from pool 
17/12/19 16:17:19 INFO DAGScheduler: ResultStage 463 (take at <unknown>:0) finished in 0.643 s
17/12/19 16:17:19 INFO DAGScheduler: Job 222 finished: take at <unknown>:0, took 0.653931 s
17/12/19 16:17:19 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:17:19 INFO DAGScheduler: Got job 223 (take at <unknown>:0) with 1 output partitions
17/12/19 16:17:19 INFO DAGScheduler: Final stage: ResultStage 465 (take at <unknown>:0)
17/12/19 16:17:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 464)
17/12/19 16:17:19 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:19 INFO DAGScheduler: Submitting ResultStage 465 (WorkerRDD[970] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:17:19 INFO MemoryStore: Block broadcast_311 stored as values in memory (estimated size 226.9 KB, free 1996.6 MB)
17/12/19 16:17:19 INFO MemoryStore: Block broadcast_311_piece0 stored as bytes in memory (estimated size 90.8 KB, free 1996.6 MB)
17/12/19 16:17:19 INFO BlockManagerInfo: Added broadcast_311_piece0 in memory on 127.0.0.1:53618 (size: 90.8 KB, free: 2003.7 MB)
17/12/19 16:17:19 INFO SparkContext: Created broadcast 311 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 465 (WorkerRDD[970] at RDD at rdd.scala:18)
17/12/19 16:17:19 INFO TaskSchedulerImpl: Adding task set 465.0 with 1 tasks
17/12/19 16:17:19 INFO TaskSetManager: Starting task 0.0 in stage 465.0 (TID 343, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:17:19 INFO Executor: Running task 0.0 in stage 465.0 (TID 343)
17/12/19 16:17:19 INFO BlockManager: Found block rdd_958_1 locally
17/12/19 16:17:20 INFO MemoryStore: Block rdd_970_1 stored as values in memory (estimated size 80.0 B, free 1996.6 MB)
17/12/19 16:17:20 INFO BlockManagerInfo: Added rdd_970_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.7 MB)
17/12/19 16:17:20 INFO Executor: Finished task 0.0 in stage 465.0 (TID 343). 2400 bytes result sent to driver
17/12/19 16:17:20 INFO TaskSetManager: Finished task 0.0 in stage 465.0 (TID 343) in 663 ms on localhost (executor driver) (1/1)
17/12/19 16:17:20 INFO TaskSchedulerImpl: Removed TaskSet 465.0, whose tasks have all completed, from pool 
17/12/19 16:17:20 INFO DAGScheduler: ResultStage 465 (take at <unknown>:0) finished in 0.663 s
17/12/19 16:17:20 INFO DAGScheduler: Job 223 finished: take at <unknown>:0, took 0.653442 s
17/12/19 16:17:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:20 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e885978aa
17/12/19 16:17:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e885978aa` AS `zzz81`
WHERE (0 = 1)
17/12/19 16:17:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e885978aa`
LIMIT 10
17/12/19 16:17:20 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:17:20 INFO DAGScheduler: Got job 224 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:17:20 INFO DAGScheduler: Final stage: ResultStage 467 (collect at utils.scala:196)
17/12/19 16:17:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 466)
17/12/19 16:17:20 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:20 INFO DAGScheduler: Submitting ResultStage 467 (MapPartitionsRDD[974] at collect at utils.scala:196), which has no missing parents
17/12/19 16:17:20 INFO MemoryStore: Block broadcast_312 stored as values in memory (estimated size 227.9 KB, free 1996.3 MB)
17/12/19 16:17:20 INFO MemoryStore: Block broadcast_312_piece0 stored as bytes in memory (estimated size 91.6 KB, free 1996.2 MB)
17/12/19 16:17:20 INFO BlockManagerInfo: Added broadcast_312_piece0 in memory on 127.0.0.1:53618 (size: 91.6 KB, free: 2003.6 MB)
17/12/19 16:17:20 INFO SparkContext: Created broadcast 312 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 467 (MapPartitionsRDD[974] at collect at utils.scala:196)
17/12/19 16:17:20 INFO TaskSchedulerImpl: Adding task set 467.0 with 1 tasks
17/12/19 16:17:20 INFO TaskSetManager: Starting task 0.0 in stage 467.0 (TID 344, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:17:20 INFO Executor: Running task 0.0 in stage 467.0 (TID 344)
17/12/19 16:17:20 INFO BlockManager: Found block rdd_970_0 locally
17/12/19 16:17:20 INFO Executor: Finished task 0.0 in stage 467.0 (TID 344). 1479 bytes result sent to driver
17/12/19 16:17:20 INFO TaskSetManager: Finished task 0.0 in stage 467.0 (TID 344) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:17:20 INFO TaskSchedulerImpl: Removed TaskSet 467.0, whose tasks have all completed, from pool 
17/12/19 16:17:20 INFO DAGScheduler: ResultStage 467 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:17:20 INFO DAGScheduler: Job 224 finished: collect at utils.scala:196, took 0.007899 s
17/12/19 16:17:20 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:17:20 INFO DAGScheduler: Got job 225 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:17:20 INFO DAGScheduler: Final stage: ResultStage 469 (collect at utils.scala:196)
17/12/19 16:17:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 468)
17/12/19 16:17:20 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:20 INFO DAGScheduler: Submitting ResultStage 469 (MapPartitionsRDD[974] at collect at utils.scala:196), which has no missing parents
17/12/19 16:17:20 INFO MemoryStore: Block broadcast_313 stored as values in memory (estimated size 227.9 KB, free 1996.0 MB)
17/12/19 16:17:20 INFO MemoryStore: Block broadcast_313_piece0 stored as bytes in memory (estimated size 91.6 KB, free 1995.9 MB)
17/12/19 16:17:20 INFO BlockManagerInfo: Added broadcast_313_piece0 in memory on 127.0.0.1:53618 (size: 91.6 KB, free: 2003.5 MB)
17/12/19 16:17:20 INFO SparkContext: Created broadcast 313 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 469 (MapPartitionsRDD[974] at collect at utils.scala:196)
17/12/19 16:17:20 INFO TaskSchedulerImpl: Adding task set 469.0 with 1 tasks
17/12/19 16:17:20 INFO TaskSetManager: Starting task 0.0 in stage 469.0 (TID 345, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:17:20 INFO Executor: Running task 0.0 in stage 469.0 (TID 345)
17/12/19 16:17:20 INFO BlockManager: Found block rdd_970_1 locally
17/12/19 16:17:20 INFO Executor: Finished task 0.0 in stage 469.0 (TID 345). 1566 bytes result sent to driver
17/12/19 16:17:20 INFO TaskSetManager: Finished task 0.0 in stage 469.0 (TID 345) in 4 ms on localhost (executor driver) (1/1)
17/12/19 16:17:20 INFO TaskSchedulerImpl: Removed TaskSet 469.0, whose tasks have all completed, from pool 
17/12/19 16:17:20 INFO DAGScheduler: ResultStage 469 (collect at utils.scala:196) finished in 0.004 s
17/12/19 16:17:20 INFO DAGScheduler: Job 225 finished: collect at utils.scala:196, took 0.008271 s
17/12/19 16:17:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:17:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:17:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:17:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:17:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:17:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:17:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:17:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:17:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:17:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:17:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:17:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:17:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:28 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:17:28 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:28 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:28 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:28 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:17:28 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:17:28 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 16:17:28 INFO DAGScheduler: Got job 226 (collect at utils.scala:58) with 1 output partitions
17/12/19 16:17:28 INFO DAGScheduler: Final stage: ResultStage 470 (collect at utils.scala:58)
17/12/19 16:17:28 INFO DAGScheduler: Parents of final stage: List()
17/12/19 16:17:28 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:28 INFO DAGScheduler: Submitting ResultStage 470 (MapPartitionsRDD[984] at map at utils.scala:55), which has no missing parents
17/12/19 16:17:28 INFO MemoryStore: Block broadcast_314 stored as values in memory (estimated size 8.7 KB, free 1995.9 MB)
17/12/19 16:17:28 INFO MemoryStore: Block broadcast_314_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1995.9 MB)
17/12/19 16:17:28 INFO BlockManagerInfo: Added broadcast_314_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.5 MB)
17/12/19 16:17:28 INFO SparkContext: Created broadcast 314 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 470 (MapPartitionsRDD[984] at map at utils.scala:55)
17/12/19 16:17:28 INFO TaskSchedulerImpl: Adding task set 470.0 with 1 tasks
17/12/19 16:17:28 INFO TaskSetManager: Starting task 0.0 in stage 470.0 (TID 346, localhost, executor driver, partition 0, PROCESS_LOCAL, 8659 bytes)
17/12/19 16:17:28 INFO Executor: Running task 0.0 in stage 470.0 (TID 346)
17/12/19 16:17:28 INFO Executor: Finished task 0.0 in stage 470.0 (TID 346). 1802 bytes result sent to driver
17/12/19 16:17:28 INFO TaskSetManager: Finished task 0.0 in stage 470.0 (TID 346) in 1 ms on localhost (executor driver) (1/1)
17/12/19 16:17:28 INFO TaskSchedulerImpl: Removed TaskSet 470.0, whose tasks have all completed, from pool 
17/12/19 16:17:28 INFO DAGScheduler: ResultStage 470 (collect at utils.scala:58) finished in 0.001 s
17/12/19 16:17:28 INFO DAGScheduler: Job 226 finished: collect at utils.scala:58, took 0.005759 s
17/12/19 16:17:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:29 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:17:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:29 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 16:17:29 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 16:17:29 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 16:17:29 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 16:17:29 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 16:17:29 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 16:17:29 INFO MemoryStore: Block broadcast_315 stored as values in memory (estimated size 293.7 KB, free 1995.6 MB)
17/12/19 16:17:29 INFO MemoryStore: Block broadcast_315_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1995.6 MB)
17/12/19 16:17:29 INFO BlockManagerInfo: Added broadcast_315_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2003.5 MB)
17/12/19 16:17:29 INFO SparkContext: Created broadcast 315 from sql at <unknown>:0
17/12/19 16:17:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 15525
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 15526
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 15527
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 15531
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 15533
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 15534
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 15535
17/12/19 16:17:29 INFO BlockManagerInfo: Removed broadcast_313_piece0 on 127.0.0.1:53618 in memory (size: 91.6 KB, free: 2003.6 MB)
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 16205
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 16206
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 15524
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 15532
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 15536
17/12/19 16:17:29 INFO BlockManagerInfo: Removed broadcast_314_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2003.6 MB)
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 16255
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 16256
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 16262
17/12/19 16:17:29 INFO BlockManagerInfo: Removed broadcast_308_piece0 on 127.0.0.1:53618 in memory (size: 47.1 KB, free: 2003.6 MB)
17/12/19 16:17:29 INFO BlockManagerInfo: Removed broadcast_309_piece0 on 127.0.0.1:53618 in memory (size: 50.4 KB, free: 2003.7 MB)
17/12/19 16:17:29 INFO BlockManagerInfo: Removed broadcast_310_piece0 on 127.0.0.1:53618 in memory (size: 90.8 KB, free: 2003.8 MB)
17/12/19 16:17:29 INFO BlockManagerInfo: Removed broadcast_311_piece0 on 127.0.0.1:53618 in memory (size: 90.8 KB, free: 2003.9 MB)
17/12/19 16:17:29 INFO BlockManagerInfo: Removed broadcast_312_piece0 on 127.0.0.1:53618 in memory (size: 91.6 KB, free: 2004.0 MB)
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 15528
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 15529
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 15530
17/12/19 16:17:29 INFO ContextCleaner: Cleaned shuffle 64
17/12/19 16:17:29 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 16:17:29 INFO DAGScheduler: Registering RDD 988 (sql at <unknown>:0)
17/12/19 16:17:29 INFO DAGScheduler: Registering RDD 993 (sql at <unknown>:0)
17/12/19 16:17:29 INFO DAGScheduler: Got job 227 (sql at <unknown>:0) with 1 output partitions
17/12/19 16:17:29 INFO DAGScheduler: Final stage: ResultStage 473 (sql at <unknown>:0)
17/12/19 16:17:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 472)
17/12/19 16:17:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 472)
17/12/19 16:17:29 INFO BlockManagerInfo: Removed broadcast_302_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2004.0 MB)
17/12/19 16:17:29 INFO DAGScheduler: Submitting ShuffleMapStage 471 (MapPartitionsRDD[988] at sql at <unknown>:0), which has no missing parents
17/12/19 16:17:29 INFO MemoryStore: Block broadcast_316 stored as values in memory (estimated size 12.1 KB, free 1997.2 MB)
17/12/19 16:17:29 INFO MemoryStore: Block broadcast_316_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1997.2 MB)
17/12/19 16:17:29 INFO BlockManagerInfo: Added broadcast_316_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.0 MB)
17/12/19 16:17:29 INFO SparkContext: Created broadcast 316 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 471 (MapPartitionsRDD[988] at sql at <unknown>:0)
17/12/19 16:17:29 INFO TaskSchedulerImpl: Adding task set 471.0 with 1 tasks
17/12/19 16:17:29 INFO BlockManagerInfo: Removed broadcast_303_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2004.0 MB)
17/12/19 16:17:29 INFO TaskSetManager: Starting task 0.0 in stage 471.0 (TID 347, localhost, executor driver, partition 0, PROCESS_LOCAL, 6680 bytes)
17/12/19 16:17:29 INFO Executor: Running task 0.0 in stage 471.0 (TID 347)
17/12/19 16:17:29 INFO BlockManagerInfo: Removed broadcast_304_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.0 MB)
17/12/19 16:17:29 INFO ContextCleaner: Cleaned accumulator 15705
17/12/19 16:17:29 INFO BlockManagerInfo: Removed broadcast_305_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2004.0 MB)
17/12/19 16:17:29 INFO BlockManagerInfo: Removed broadcast_306_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2004.0 MB)
17/12/19 16:17:29 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_24e1342e22727c33f4d7c1248fd84022bf1b65231d2a511719c35322f85065be.csv, range: 0-462, partition values: [empty row]
17/12/19 16:17:29 INFO BlockManagerInfo: Removed broadcast_307_piece0 on 127.0.0.1:53618 in memory (size: 47.1 KB, free: 2004.0 MB)
17/12/19 16:17:29 INFO Executor: Finished task 0.0 in stage 471.0 (TID 347). 1553 bytes result sent to driver
17/12/19 16:17:29 INFO TaskSetManager: Finished task 0.0 in stage 471.0 (TID 347) in 15 ms on localhost (executor driver) (1/1)
17/12/19 16:17:29 INFO TaskSchedulerImpl: Removed TaskSet 471.0, whose tasks have all completed, from pool 
17/12/19 16:17:29 INFO DAGScheduler: ShuffleMapStage 471 (sql at <unknown>:0) finished in 0.015 s
17/12/19 16:17:29 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:17:29 INFO DAGScheduler: running: Set()
17/12/19 16:17:29 INFO DAGScheduler: waiting: Set(ResultStage 473, ShuffleMapStage 472)
17/12/19 16:17:29 INFO DAGScheduler: failed: Set()
17/12/19 16:17:29 INFO DAGScheduler: Submitting ShuffleMapStage 472 (MapPartitionsRDD[993] at sql at <unknown>:0), which has no missing parents
17/12/19 16:17:29 INFO MemoryStore: Block broadcast_317 stored as values in memory (estimated size 11.9 KB, free 1997.4 MB)
17/12/19 16:17:29 INFO MemoryStore: Block broadcast_317_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1997.4 MB)
17/12/19 16:17:29 INFO BlockManagerInfo: Added broadcast_317_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.0 MB)
17/12/19 16:17:29 INFO SparkContext: Created broadcast 317 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:29 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 472 (MapPartitionsRDD[993] at sql at <unknown>:0)
17/12/19 16:17:29 INFO TaskSchedulerImpl: Adding task set 472.0 with 2 tasks
17/12/19 16:17:29 INFO TaskSetManager: Starting task 0.0 in stage 472.0 (TID 348, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 16:17:29 INFO TaskSetManager: Starting task 1.0 in stage 472.0 (TID 349, localhost, executor driver, partition 1, ANY, 5946 bytes)
17/12/19 16:17:29 INFO Executor: Running task 0.0 in stage 472.0 (TID 348)
17/12/19 16:17:29 INFO Executor: Running task 1.0 in stage 472.0 (TID 349)
17/12/19 16:17:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:17:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:17:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:17:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:17:29 INFO MemoryStore: Block rdd_990_0 stored as values in memory (estimated size 544.0 B, free 1997.4 MB)
17/12/19 16:17:29 INFO BlockManagerInfo: Added rdd_990_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.0 MB)
17/12/19 16:17:29 INFO MemoryStore: Block rdd_990_1 stored as values in memory (estimated size 544.0 B, free 1997.4 MB)
17/12/19 16:17:29 INFO BlockManagerInfo: Added rdd_990_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.0 MB)
17/12/19 16:17:29 INFO Executor: Finished task 0.0 in stage 472.0 (TID 348). 3064 bytes result sent to driver
17/12/19 16:17:29 INFO TaskSetManager: Finished task 0.0 in stage 472.0 (TID 348) in 16 ms on localhost (executor driver) (1/2)
17/12/19 16:17:29 INFO Executor: Finished task 1.0 in stage 472.0 (TID 349). 3064 bytes result sent to driver
17/12/19 16:17:29 INFO TaskSetManager: Finished task 1.0 in stage 472.0 (TID 349) in 16 ms on localhost (executor driver) (2/2)
17/12/19 16:17:29 INFO TaskSchedulerImpl: Removed TaskSet 472.0, whose tasks have all completed, from pool 
17/12/19 16:17:29 INFO DAGScheduler: ShuffleMapStage 472 (sql at <unknown>:0) finished in 0.016 s
17/12/19 16:17:29 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:17:29 INFO DAGScheduler: running: Set()
17/12/19 16:17:29 INFO DAGScheduler: waiting: Set(ResultStage 473)
17/12/19 16:17:29 INFO DAGScheduler: failed: Set()
17/12/19 16:17:29 INFO DAGScheduler: Submitting ResultStage 473 (MapPartitionsRDD[996] at sql at <unknown>:0), which has no missing parents
17/12/19 16:17:29 INFO MemoryStore: Block broadcast_318 stored as values in memory (estimated size 7.0 KB, free 1997.4 MB)
17/12/19 16:17:29 INFO MemoryStore: Block broadcast_318_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1997.4 MB)
17/12/19 16:17:29 INFO BlockManagerInfo: Added broadcast_318_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.0 MB)
17/12/19 16:17:29 INFO SparkContext: Created broadcast 318 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 473 (MapPartitionsRDD[996] at sql at <unknown>:0)
17/12/19 16:17:29 INFO TaskSchedulerImpl: Adding task set 473.0 with 1 tasks
17/12/19 16:17:29 INFO TaskSetManager: Starting task 0.0 in stage 473.0 (TID 350, localhost, executor driver, partition 0, ANY, 5957 bytes)
17/12/19 16:17:29 INFO Executor: Running task 0.0 in stage 473.0 (TID 350)
17/12/19 16:17:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:17:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:17:29 INFO Executor: Finished task 0.0 in stage 473.0 (TID 350). 1707 bytes result sent to driver
17/12/19 16:17:29 INFO TaskSetManager: Finished task 0.0 in stage 473.0 (TID 350) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:17:29 INFO TaskSchedulerImpl: Removed TaskSet 473.0, whose tasks have all completed, from pool 
17/12/19 16:17:29 INFO DAGScheduler: ResultStage 473 (sql at <unknown>:0) finished in 0.000 s
17/12/19 16:17:29 INFO DAGScheduler: Job 227 finished: sql at <unknown>:0, took 0.045377 s
17/12/19 16:17:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:29 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 16:17:29 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:17:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 66 is 145 bytes
17/12/19 16:17:29 INFO DAGScheduler: Registering RDD 1000 (collect at utils.scala:196)
17/12/19 16:17:29 INFO DAGScheduler: Got job 228 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:17:29 INFO DAGScheduler: Final stage: ResultStage 476 (collect at utils.scala:196)
17/12/19 16:17:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 475)
17/12/19 16:17:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 475)
17/12/19 16:17:29 INFO DAGScheduler: Submitting ShuffleMapStage 475 (MapPartitionsRDD[1000] at collect at utils.scala:196), which has no missing parents
17/12/19 16:17:29 INFO MemoryStore: Block broadcast_319 stored as values in memory (estimated size 11.9 KB, free 1997.4 MB)
17/12/19 16:17:29 INFO MemoryStore: Block broadcast_319_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1997.4 MB)
17/12/19 16:17:29 INFO BlockManagerInfo: Added broadcast_319_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.0 MB)
17/12/19 16:17:29 INFO SparkContext: Created broadcast 319 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:29 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 475 (MapPartitionsRDD[1000] at collect at utils.scala:196)
17/12/19 16:17:29 INFO TaskSchedulerImpl: Adding task set 475.0 with 2 tasks
17/12/19 16:17:29 INFO TaskSetManager: Starting task 0.0 in stage 475.0 (TID 351, localhost, executor driver, partition 0, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:17:29 INFO TaskSetManager: Starting task 1.0 in stage 475.0 (TID 352, localhost, executor driver, partition 1, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:17:29 INFO Executor: Running task 1.0 in stage 475.0 (TID 352)
17/12/19 16:17:29 INFO Executor: Running task 0.0 in stage 475.0 (TID 351)
17/12/19 16:17:29 INFO BlockManager: Found block rdd_990_0 locally
17/12/19 16:17:29 INFO BlockManager: Found block rdd_990_1 locally
17/12/19 16:17:29 INFO Executor: Finished task 1.0 in stage 475.0 (TID 352). 1792 bytes result sent to driver
17/12/19 16:17:29 INFO TaskSetManager: Finished task 1.0 in stage 475.0 (TID 352) in 0 ms on localhost (executor driver) (1/2)
17/12/19 16:17:29 INFO Executor: Finished task 0.0 in stage 475.0 (TID 351). 1792 bytes result sent to driver
17/12/19 16:17:29 INFO TaskSetManager: Finished task 0.0 in stage 475.0 (TID 351) in 0 ms on localhost (executor driver) (2/2)
17/12/19 16:17:29 INFO TaskSchedulerImpl: Removed TaskSet 475.0, whose tasks have all completed, from pool 
17/12/19 16:17:29 INFO DAGScheduler: ShuffleMapStage 475 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:17:29 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:17:29 INFO DAGScheduler: running: Set()
17/12/19 16:17:29 INFO DAGScheduler: waiting: Set(ResultStage 476)
17/12/19 16:17:29 INFO DAGScheduler: failed: Set()
17/12/19 16:17:29 INFO DAGScheduler: Submitting ResultStage 476 (MapPartitionsRDD[1003] at collect at utils.scala:196), which has no missing parents
17/12/19 16:17:29 INFO MemoryStore: Block broadcast_320 stored as values in memory (estimated size 7.0 KB, free 1997.4 MB)
17/12/19 16:17:29 INFO MemoryStore: Block broadcast_320_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1997.4 MB)
17/12/19 16:17:29 INFO BlockManagerInfo: Added broadcast_320_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.0 MB)
17/12/19 16:17:29 INFO SparkContext: Created broadcast 320 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 476 (MapPartitionsRDD[1003] at collect at utils.scala:196)
17/12/19 16:17:29 INFO TaskSchedulerImpl: Adding task set 476.0 with 1 tasks
17/12/19 16:17:29 INFO TaskSetManager: Starting task 0.0 in stage 476.0 (TID 353, localhost, executor driver, partition 0, ANY, 5949 bytes)
17/12/19 16:17:29 INFO Executor: Running task 0.0 in stage 476.0 (TID 353)
17/12/19 16:17:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:17:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:17:29 INFO Executor: Finished task 0.0 in stage 476.0 (TID 353). 1707 bytes result sent to driver
17/12/19 16:17:29 INFO TaskSetManager: Finished task 0.0 in stage 476.0 (TID 353) in 16 ms on localhost (executor driver) (1/1)
17/12/19 16:17:29 INFO TaskSchedulerImpl: Removed TaskSet 476.0, whose tasks have all completed, from pool 
17/12/19 16:17:29 INFO DAGScheduler: ResultStage 476 (collect at utils.scala:196) finished in 0.016 s
17/12/19 16:17:29 INFO DAGScheduler: Job 228 finished: collect at utils.scala:196, took 0.016711 s
17/12/19 16:17:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz82`
WHERE (0 = 1)
17/12/19 16:17:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:29 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `letxosmlzh`
17/12/19 16:17:29 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:17:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz83`
WHERE (0 = 1)
17/12/19 16:17:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:17:29 INFO CodeGenerator: Code generated in 5.852508 ms
17/12/19 16:17:29 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:17:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 66 is 145 bytes
17/12/19 16:17:29 INFO DAGScheduler: Got job 229 (take at <unknown>:0) with 1 output partitions
17/12/19 16:17:29 INFO DAGScheduler: Final stage: ResultStage 478 (take at <unknown>:0)
17/12/19 16:17:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 477)
17/12/19 16:17:29 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:29 INFO DAGScheduler: Submitting ResultStage 478 (WorkerRDD[1009] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:17:29 INFO MemoryStore: Block broadcast_321 stored as values in memory (estimated size 124.9 KB, free 1997.2 MB)
17/12/19 16:17:29 INFO MemoryStore: Block broadcast_321_piece0 stored as bytes in memory (estimated size 48.9 KB, free 1997.2 MB)
17/12/19 16:17:29 INFO BlockManagerInfo: Added broadcast_321_piece0 in memory on 127.0.0.1:53618 (size: 48.9 KB, free: 2004.0 MB)
17/12/19 16:17:29 INFO SparkContext: Created broadcast 321 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 478 (WorkerRDD[1009] at RDD at rdd.scala:18)
17/12/19 16:17:29 INFO TaskSchedulerImpl: Adding task set 478.0 with 1 tasks
17/12/19 16:17:29 INFO TaskSetManager: Starting task 0.0 in stage 478.0 (TID 354, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:17:29 INFO Executor: Running task 0.0 in stage 478.0 (TID 354)
17/12/19 16:17:29 INFO BlockManager: Found block rdd_990_0 locally
17/12/19 16:17:30 INFO MemoryStore: Block rdd_1009_0 stored as values in memory (estimated size 608.0 B, free 1997.2 MB)
17/12/19 16:17:30 INFO BlockManagerInfo: Added rdd_1009_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2004.0 MB)
17/12/19 16:17:30 INFO Executor: Finished task 0.0 in stage 478.0 (TID 354). 2509 bytes result sent to driver
17/12/19 16:17:30 INFO TaskSetManager: Finished task 0.0 in stage 478.0 (TID 354) in 724 ms on localhost (executor driver) (1/1)
17/12/19 16:17:30 INFO TaskSchedulerImpl: Removed TaskSet 478.0, whose tasks have all completed, from pool 
17/12/19 16:17:30 INFO DAGScheduler: ResultStage 478 (take at <unknown>:0) finished in 0.724 s
17/12/19 16:17:30 INFO DAGScheduler: Job 229 finished: take at <unknown>:0, took 0.730249 s
17/12/19 16:17:30 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:17:30 INFO DAGScheduler: Got job 230 (take at <unknown>:0) with 1 output partitions
17/12/19 16:17:30 INFO DAGScheduler: Final stage: ResultStage 480 (take at <unknown>:0)
17/12/19 16:17:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 479)
17/12/19 16:17:30 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:30 INFO DAGScheduler: Submitting ResultStage 480 (WorkerRDD[1009] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:17:30 INFO MemoryStore: Block broadcast_322 stored as values in memory (estimated size 124.9 KB, free 1997.1 MB)
17/12/19 16:17:30 INFO MemoryStore: Block broadcast_322_piece0 stored as bytes in memory (estimated size 48.9 KB, free 1997.0 MB)
17/12/19 16:17:30 INFO BlockManagerInfo: Added broadcast_322_piece0 in memory on 127.0.0.1:53618 (size: 48.9 KB, free: 2003.9 MB)
17/12/19 16:17:30 INFO SparkContext: Created broadcast 322 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 480 (WorkerRDD[1009] at RDD at rdd.scala:18)
17/12/19 16:17:30 INFO TaskSchedulerImpl: Adding task set 480.0 with 1 tasks
17/12/19 16:17:30 INFO TaskSetManager: Starting task 0.0 in stage 480.0 (TID 355, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:17:30 INFO Executor: Running task 0.0 in stage 480.0 (TID 355)
17/12/19 16:17:30 INFO BlockManager: Found block rdd_990_1 locally
17/12/19 16:17:30 INFO MemoryStore: Block rdd_1009_1 stored as values in memory (estimated size 608.0 B, free 1997.0 MB)
17/12/19 16:17:30 INFO BlockManagerInfo: Added rdd_1009_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 16:17:30 INFO Executor: Finished task 0.0 in stage 480.0 (TID 355). 2509 bytes result sent to driver
17/12/19 16:17:30 INFO TaskSetManager: Finished task 0.0 in stage 480.0 (TID 355) in 650 ms on localhost (executor driver) (1/1)
17/12/19 16:17:30 INFO TaskSchedulerImpl: Removed TaskSet 480.0, whose tasks have all completed, from pool 
17/12/19 16:17:30 INFO DAGScheduler: ResultStage 480 (take at <unknown>:0) finished in 0.650 s
17/12/19 16:17:30 INFO DAGScheduler: Job 230 finished: take at <unknown>:0, took 0.662793 s
17/12/19 16:17:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e82cad4a7d
17/12/19 16:17:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e82cad4a7d` AS `zzz84`
WHERE (0 = 1)
17/12/19 16:17:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e82cad4a7d`
17/12/19 16:17:30 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:17:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz85`
WHERE (0 = 1)
17/12/19 16:17:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:30 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 16:17:30 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:17:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz86`
WHERE (0 = 1)
17/12/19 16:17:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:17:30 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:17:30 INFO DAGScheduler: Got job 231 (collect at utils.scala:196) with 2 output partitions
17/12/19 16:17:30 INFO DAGScheduler: Final stage: ResultStage 482 (collect at utils.scala:196)
17/12/19 16:17:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 481)
17/12/19 16:17:30 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:30 INFO DAGScheduler: Submitting ResultStage 482 (MapPartitionsRDD[1016] at collect at utils.scala:196), which has no missing parents
17/12/19 16:17:30 INFO MemoryStore: Block broadcast_323 stored as values in memory (estimated size 132.4 KB, free 1996.9 MB)
17/12/19 16:17:30 INFO MemoryStore: Block broadcast_323_piece0 stored as bytes in memory (estimated size 52.4 KB, free 1996.8 MB)
17/12/19 16:17:30 INFO BlockManagerInfo: Added broadcast_323_piece0 in memory on 127.0.0.1:53618 (size: 52.4 KB, free: 2003.9 MB)
17/12/19 16:17:30 INFO SparkContext: Created broadcast 323 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 482 (MapPartitionsRDD[1016] at collect at utils.scala:196)
17/12/19 16:17:30 INFO TaskSchedulerImpl: Adding task set 482.0 with 2 tasks
17/12/19 16:17:30 INFO TaskSetManager: Starting task 0.0 in stage 482.0 (TID 356, localhost, executor driver, partition 0, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:17:30 INFO TaskSetManager: Starting task 1.0 in stage 482.0 (TID 357, localhost, executor driver, partition 1, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:17:30 INFO Executor: Running task 0.0 in stage 482.0 (TID 356)
17/12/19 16:17:30 INFO Executor: Running task 1.0 in stage 482.0 (TID 357)
17/12/19 16:17:30 INFO BlockManager: Found block rdd_1009_1 locally
17/12/19 16:17:30 INFO Executor: Finished task 1.0 in stage 482.0 (TID 357). 1642 bytes result sent to driver
17/12/19 16:17:30 INFO BlockManager: Found block rdd_1009_0 locally
17/12/19 16:17:30 INFO Executor: Finished task 0.0 in stage 482.0 (TID 356). 1537 bytes result sent to driver
17/12/19 16:17:30 INFO TaskSetManager: Finished task 1.0 in stage 482.0 (TID 357) in 15 ms on localhost (executor driver) (1/2)
17/12/19 16:17:30 INFO DAGScheduler: ResultStage 482 (collect at utils.scala:196) finished in 0.015 s
17/12/19 16:17:30 INFO DAGScheduler: Job 231 finished: collect at utils.scala:196, took 0.018453 s
17/12/19 16:17:30 INFO TaskSetManager: Finished task 0.0 in stage 482.0 (TID 356) in 15 ms on localhost (executor driver) (2/2)
17/12/19 16:17:30 INFO TaskSchedulerImpl: Removed TaskSet 482.0, whose tasks have all completed, from pool 
17/12/19 16:17:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:17:30 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:17:30 INFO DAGScheduler: Got job 232 (take at <unknown>:0) with 1 output partitions
17/12/19 16:17:30 INFO DAGScheduler: Final stage: ResultStage 484 (take at <unknown>:0)
17/12/19 16:17:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 483)
17/12/19 16:17:30 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:30 INFO DAGScheduler: Submitting ResultStage 484 (WorkerRDD[1021] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:17:30 INFO MemoryStore: Block broadcast_324 stored as values in memory (estimated size 240.5 KB, free 1996.6 MB)
17/12/19 16:17:30 INFO MemoryStore: Block broadcast_324_piece0 stored as bytes in memory (estimated size 94.7 KB, free 1996.5 MB)
17/12/19 16:17:30 INFO BlockManagerInfo: Added broadcast_324_piece0 in memory on 127.0.0.1:53618 (size: 94.7 KB, free: 2003.8 MB)
17/12/19 16:17:30 INFO SparkContext: Created broadcast 324 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 484 (WorkerRDD[1021] at RDD at rdd.scala:18)
17/12/19 16:17:30 INFO TaskSchedulerImpl: Adding task set 484.0 with 1 tasks
17/12/19 16:17:30 INFO TaskSetManager: Starting task 0.0 in stage 484.0 (TID 358, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:17:30 INFO Executor: Running task 0.0 in stage 484.0 (TID 358)
17/12/19 16:17:30 INFO BlockManager: Found block rdd_1009_0 locally
17/12/19 16:17:31 INFO MemoryStore: Block rdd_1021_0 stored as values in memory (estimated size 80.0 B, free 1996.5 MB)
17/12/19 16:17:31 INFO BlockManagerInfo: Added rdd_1021_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.8 MB)
17/12/19 16:17:31 INFO Executor: Finished task 0.0 in stage 484.0 (TID 358). 2400 bytes result sent to driver
17/12/19 16:17:31 INFO TaskSetManager: Finished task 0.0 in stage 484.0 (TID 358) in 665 ms on localhost (executor driver) (1/1)
17/12/19 16:17:31 INFO TaskSchedulerImpl: Removed TaskSet 484.0, whose tasks have all completed, from pool 
17/12/19 16:17:31 INFO DAGScheduler: ResultStage 484 (take at <unknown>:0) finished in 0.665 s
17/12/19 16:17:31 INFO DAGScheduler: Job 232 finished: take at <unknown>:0, took 0.668085 s
17/12/19 16:17:31 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:17:31 INFO DAGScheduler: Got job 233 (take at <unknown>:0) with 1 output partitions
17/12/19 16:17:31 INFO DAGScheduler: Final stage: ResultStage 486 (take at <unknown>:0)
17/12/19 16:17:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 485)
17/12/19 16:17:31 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:31 INFO DAGScheduler: Submitting ResultStage 486 (WorkerRDD[1021] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:17:31 INFO MemoryStore: Block broadcast_325 stored as values in memory (estimated size 240.5 KB, free 1996.3 MB)
17/12/19 16:17:31 INFO MemoryStore: Block broadcast_325_piece0 stored as bytes in memory (estimated size 94.7 KB, free 1996.2 MB)
17/12/19 16:17:31 INFO BlockManagerInfo: Added broadcast_325_piece0 in memory on 127.0.0.1:53618 (size: 94.7 KB, free: 2003.7 MB)
17/12/19 16:17:31 INFO SparkContext: Created broadcast 325 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 486 (WorkerRDD[1021] at RDD at rdd.scala:18)
17/12/19 16:17:31 INFO TaskSchedulerImpl: Adding task set 486.0 with 1 tasks
17/12/19 16:17:31 INFO TaskSetManager: Starting task 0.0 in stage 486.0 (TID 359, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:17:31 INFO Executor: Running task 0.0 in stage 486.0 (TID 359)
17/12/19 16:17:31 INFO BlockManager: Found block rdd_1009_1 locally
17/12/19 16:17:32 INFO MemoryStore: Block rdd_1021_1 stored as values in memory (estimated size 80.0 B, free 1996.2 MB)
17/12/19 16:17:32 INFO BlockManagerInfo: Added rdd_1021_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.7 MB)
17/12/19 16:17:32 INFO Executor: Finished task 0.0 in stage 486.0 (TID 359). 2400 bytes result sent to driver
17/12/19 16:17:32 INFO TaskSetManager: Finished task 0.0 in stage 486.0 (TID 359) in 651 ms on localhost (executor driver) (1/1)
17/12/19 16:17:32 INFO TaskSchedulerImpl: Removed TaskSet 486.0, whose tasks have all completed, from pool 
17/12/19 16:17:32 INFO DAGScheduler: ResultStage 486 (take at <unknown>:0) finished in 0.651 s
17/12/19 16:17:32 INFO DAGScheduler: Job 233 finished: take at <unknown>:0, took 0.651623 s
17/12/19 16:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:32 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e83f7657b7
17/12/19 16:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e83f7657b7` AS `zzz87`
WHERE (0 = 1)
17/12/19 16:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e83f7657b7`
LIMIT 10
17/12/19 16:17:32 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:17:32 INFO DAGScheduler: Got job 234 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:17:32 INFO DAGScheduler: Final stage: ResultStage 488 (collect at utils.scala:196)
17/12/19 16:17:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 487)
17/12/19 16:17:32 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:32 INFO DAGScheduler: Submitting ResultStage 488 (MapPartitionsRDD[1025] at collect at utils.scala:196), which has no missing parents
17/12/19 16:17:32 INFO MemoryStore: Block broadcast_326 stored as values in memory (estimated size 241.5 KB, free 1996.0 MB)
17/12/19 16:17:32 INFO MemoryStore: Block broadcast_326_piece0 stored as bytes in memory (estimated size 95.5 KB, free 1995.9 MB)
17/12/19 16:17:32 INFO BlockManagerInfo: Added broadcast_326_piece0 in memory on 127.0.0.1:53618 (size: 95.5 KB, free: 2003.6 MB)
17/12/19 16:17:32 INFO SparkContext: Created broadcast 326 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 488 (MapPartitionsRDD[1025] at collect at utils.scala:196)
17/12/19 16:17:32 INFO TaskSchedulerImpl: Adding task set 488.0 with 1 tasks
17/12/19 16:17:32 INFO TaskSetManager: Starting task 0.0 in stage 488.0 (TID 360, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:17:32 INFO Executor: Running task 0.0 in stage 488.0 (TID 360)
17/12/19 16:17:32 INFO BlockManager: Found block rdd_1021_0 locally
17/12/19 16:17:32 INFO Executor: Finished task 0.0 in stage 488.0 (TID 360). 1479 bytes result sent to driver
17/12/19 16:17:32 INFO TaskSetManager: Finished task 0.0 in stage 488.0 (TID 360) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:17:32 INFO TaskSchedulerImpl: Removed TaskSet 488.0, whose tasks have all completed, from pool 
17/12/19 16:17:32 INFO DAGScheduler: ResultStage 488 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:17:32 INFO DAGScheduler: Job 234 finished: collect at utils.scala:196, took 0.006946 s
17/12/19 16:17:32 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:17:32 INFO DAGScheduler: Got job 235 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:17:32 INFO DAGScheduler: Final stage: ResultStage 490 (collect at utils.scala:196)
17/12/19 16:17:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 489)
17/12/19 16:17:32 INFO DAGScheduler: Missing parents: List()
17/12/19 16:17:32 INFO DAGScheduler: Submitting ResultStage 490 (MapPartitionsRDD[1025] at collect at utils.scala:196), which has no missing parents
17/12/19 16:17:32 INFO MemoryStore: Block broadcast_327 stored as values in memory (estimated size 241.5 KB, free 1995.6 MB)
17/12/19 16:17:32 INFO MemoryStore: Block broadcast_327_piece0 stored as bytes in memory (estimated size 95.5 KB, free 1995.5 MB)
17/12/19 16:17:32 INFO BlockManagerInfo: Added broadcast_327_piece0 in memory on 127.0.0.1:53618 (size: 95.5 KB, free: 2003.5 MB)
17/12/19 16:17:32 INFO SparkContext: Created broadcast 327 from broadcast at DAGScheduler.scala:996
17/12/19 16:17:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 490 (MapPartitionsRDD[1025] at collect at utils.scala:196)
17/12/19 16:17:32 INFO TaskSchedulerImpl: Adding task set 490.0 with 1 tasks
17/12/19 16:17:32 INFO TaskSetManager: Starting task 0.0 in stage 490.0 (TID 361, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:17:32 INFO Executor: Running task 0.0 in stage 490.0 (TID 361)
17/12/19 16:17:32 INFO BlockManager: Found block rdd_1021_1 locally
17/12/19 16:17:32 INFO Executor: Finished task 0.0 in stage 490.0 (TID 361). 1479 bytes result sent to driver
17/12/19 16:17:32 INFO TaskSetManager: Finished task 0.0 in stage 490.0 (TID 361) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:17:32 INFO TaskSchedulerImpl: Removed TaskSet 490.0, whose tasks have all completed, from pool 
17/12/19 16:17:32 INFO DAGScheduler: ResultStage 490 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:17:32 INFO DAGScheduler: Job 235 finished: collect at utils.scala:196, took 0.007216 s
17/12/19 16:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:17:32 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:32 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:17:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:17:32 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:32 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:17:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:17:32 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:32 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:17:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:17:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:17:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:17:32 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:32 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:17:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:17:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:17:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:18:39 INFO ContextCleaner: Cleaned accumulator 16272
17/12/19 16:18:39 INFO BlockManagerInfo: Removed broadcast_327_piece0 on 127.0.0.1:53618 in memory (size: 95.5 KB, free: 2003.6 MB)
17/12/19 16:18:39 INFO ContextCleaner: Cleaned accumulator 16268
17/12/19 16:18:39 INFO ContextCleaner: Cleaned accumulator 16269
17/12/19 16:18:39 INFO ContextCleaner: Cleaned accumulator 16270
17/12/19 16:18:39 INFO ContextCleaner: Cleaned accumulator 16271
17/12/19 16:18:39 INFO BlockManagerInfo: Removed broadcast_316_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2003.6 MB)
17/12/19 16:18:39 INFO BlockManagerInfo: Removed broadcast_321_piece0 on 127.0.0.1:53618 in memory (size: 48.9 KB, free: 2003.6 MB)
17/12/19 16:18:39 INFO ContextCleaner: Cleaned accumulator 16263
17/12/19 16:18:39 INFO ContextCleaner: Cleaned accumulator 16264
17/12/19 16:18:39 INFO ContextCleaner: Cleaned accumulator 16265
17/12/19 16:18:39 INFO ContextCleaner: Cleaned accumulator 16266
17/12/19 16:18:39 INFO ContextCleaner: Cleaned accumulator 16267
17/12/19 16:18:39 INFO ContextCleaner: Cleaned accumulator 16273
17/12/19 16:18:39 INFO ContextCleaner: Cleaned accumulator 16274
17/12/19 16:18:39 INFO ContextCleaner: Cleaned shuffle 67
17/12/19 16:18:39 INFO BlockManagerInfo: Removed broadcast_317_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.6 MB)
17/12/19 16:18:39 INFO BlockManagerInfo: Removed broadcast_322_piece0 on 127.0.0.1:53618 in memory (size: 48.9 KB, free: 2003.7 MB)
17/12/19 16:18:39 INFO BlockManagerInfo: Removed broadcast_324_piece0 on 127.0.0.1:53618 in memory (size: 94.7 KB, free: 2003.8 MB)
17/12/19 16:18:39 INFO BlockManagerInfo: Removed broadcast_325_piece0 on 127.0.0.1:53618 in memory (size: 94.7 KB, free: 2003.9 MB)
17/12/19 16:18:39 INFO BlockManagerInfo: Removed broadcast_318_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.9 MB)
17/12/19 16:18:39 INFO ContextCleaner: Cleaned accumulator 16443
17/12/19 16:18:39 INFO BlockManagerInfo: Removed broadcast_319_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.9 MB)
17/12/19 16:18:39 INFO BlockManagerInfo: Removed broadcast_320_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.9 MB)
17/12/19 16:18:39 INFO BlockManagerInfo: Removed broadcast_323_piece0 on 127.0.0.1:53618 in memory (size: 52.4 KB, free: 2003.9 MB)
17/12/19 16:18:39 INFO BlockManagerInfo: Removed broadcast_326_piece0 on 127.0.0.1:53618 in memory (size: 95.5 KB, free: 2004.0 MB)
17/12/19 16:24:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:24:01 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:24:01 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:24:01 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:24:01 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:24:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:24:01 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:24:01 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 16:24:01 INFO DAGScheduler: Got job 236 (collect at utils.scala:58) with 1 output partitions
17/12/19 16:24:01 INFO DAGScheduler: Final stage: ResultStage 491 (collect at utils.scala:58)
17/12/19 16:24:01 INFO DAGScheduler: Parents of final stage: List()
17/12/19 16:24:01 INFO DAGScheduler: Missing parents: List()
17/12/19 16:24:01 INFO DAGScheduler: Submitting ResultStage 491 (MapPartitionsRDD[1035] at map at utils.scala:55), which has no missing parents
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_328 stored as values in memory (estimated size 8.7 KB, free 1997.4 MB)
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_328_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1997.4 MB)
17/12/19 16:24:01 INFO BlockManagerInfo: Added broadcast_328_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2004.0 MB)
17/12/19 16:24:01 INFO SparkContext: Created broadcast 328 from broadcast at DAGScheduler.scala:996
17/12/19 16:24:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 491 (MapPartitionsRDD[1035] at map at utils.scala:55)
17/12/19 16:24:01 INFO TaskSchedulerImpl: Adding task set 491.0 with 1 tasks
17/12/19 16:24:01 INFO TaskSetManager: Starting task 0.0 in stage 491.0 (TID 362, localhost, executor driver, partition 0, PROCESS_LOCAL, 8803 bytes)
17/12/19 16:24:01 INFO Executor: Running task 0.0 in stage 491.0 (TID 362)
17/12/19 16:24:01 INFO Executor: Finished task 0.0 in stage 491.0 (TID 362). 1858 bytes result sent to driver
17/12/19 16:24:01 INFO TaskSetManager: Finished task 0.0 in stage 491.0 (TID 362) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:24:01 INFO TaskSchedulerImpl: Removed TaskSet 491.0, whose tasks have all completed, from pool 
17/12/19 16:24:01 INFO DAGScheduler: ResultStage 491 (collect at utils.scala:58) finished in 0.000 s
17/12/19 16:24:01 INFO DAGScheduler: Job 236 finished: collect at utils.scala:58, took 0.006951 s
17/12/19 16:24:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:01 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:24:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:01 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 16:24:01 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 16:24:01 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 16:24:01 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 16:24:01 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 16:24:01 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_329 stored as values in memory (estimated size 293.7 KB, free 1997.1 MB)
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_329_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1997.1 MB)
17/12/19 16:24:01 INFO BlockManagerInfo: Added broadcast_329_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.0 MB)
17/12/19 16:24:01 INFO SparkContext: Created broadcast 329 from sql at <unknown>:0
17/12/19 16:24:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 16:24:01 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 16:24:01 INFO DAGScheduler: Registering RDD 1039 (sql at <unknown>:0)
17/12/19 16:24:01 INFO DAGScheduler: Registering RDD 1044 (sql at <unknown>:0)
17/12/19 16:24:01 INFO DAGScheduler: Got job 237 (sql at <unknown>:0) with 1 output partitions
17/12/19 16:24:01 INFO DAGScheduler: Final stage: ResultStage 494 (sql at <unknown>:0)
17/12/19 16:24:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 493)
17/12/19 16:24:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 493)
17/12/19 16:24:01 INFO DAGScheduler: Submitting ShuffleMapStage 492 (MapPartitionsRDD[1039] at sql at <unknown>:0), which has no missing parents
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_330 stored as values in memory (estimated size 12.1 KB, free 1997.1 MB)
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_330_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1997.1 MB)
17/12/19 16:24:01 INFO BlockManagerInfo: Added broadcast_330_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.0 MB)
17/12/19 16:24:01 INFO SparkContext: Created broadcast 330 from broadcast at DAGScheduler.scala:996
17/12/19 16:24:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 492 (MapPartitionsRDD[1039] at sql at <unknown>:0)
17/12/19 16:24:01 INFO TaskSchedulerImpl: Adding task set 492.0 with 1 tasks
17/12/19 16:24:01 INFO TaskSetManager: Starting task 0.0 in stage 492.0 (TID 363, localhost, executor driver, partition 0, PROCESS_LOCAL, 6680 bytes)
17/12/19 16:24:01 INFO Executor: Running task 0.0 in stage 492.0 (TID 363)
17/12/19 16:24:01 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_51432a775a12565a9d850c65db77a7e05353cb090fec9c542619f6168c293ef4.csv, range: 0-462, partition values: [empty row]
17/12/19 16:24:01 INFO Executor: Finished task 0.0 in stage 492.0 (TID 363). 1632 bytes result sent to driver
17/12/19 16:24:01 INFO TaskSetManager: Finished task 0.0 in stage 492.0 (TID 363) in 32 ms on localhost (executor driver) (1/1)
17/12/19 16:24:01 INFO TaskSchedulerImpl: Removed TaskSet 492.0, whose tasks have all completed, from pool 
17/12/19 16:24:01 INFO DAGScheduler: ShuffleMapStage 492 (sql at <unknown>:0) finished in 0.032 s
17/12/19 16:24:01 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:24:01 INFO DAGScheduler: running: Set()
17/12/19 16:24:01 INFO DAGScheduler: waiting: Set(ResultStage 494, ShuffleMapStage 493)
17/12/19 16:24:01 INFO DAGScheduler: failed: Set()
17/12/19 16:24:01 INFO DAGScheduler: Submitting ShuffleMapStage 493 (MapPartitionsRDD[1044] at sql at <unknown>:0), which has no missing parents
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_331 stored as values in memory (estimated size 11.9 KB, free 1997.1 MB)
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_331_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1997.1 MB)
17/12/19 16:24:01 INFO BlockManagerInfo: Added broadcast_331_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.0 MB)
17/12/19 16:24:01 INFO SparkContext: Created broadcast 331 from broadcast at DAGScheduler.scala:996
17/12/19 16:24:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 493 (MapPartitionsRDD[1044] at sql at <unknown>:0)
17/12/19 16:24:01 INFO TaskSchedulerImpl: Adding task set 493.0 with 2 tasks
17/12/19 16:24:01 INFO TaskSetManager: Starting task 0.0 in stage 493.0 (TID 364, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 16:24:01 INFO TaskSetManager: Starting task 1.0 in stage 493.0 (TID 365, localhost, executor driver, partition 1, ANY, 5946 bytes)
17/12/19 16:24:01 INFO Executor: Running task 0.0 in stage 493.0 (TID 364)
17/12/19 16:24:01 INFO Executor: Running task 1.0 in stage 493.0 (TID 365)
17/12/19 16:24:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:24:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:24:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:24:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:24:01 INFO MemoryStore: Block rdd_1041_1 stored as values in memory (estimated size 544.0 B, free 1997.1 MB)
17/12/19 16:24:01 INFO MemoryStore: Block rdd_1041_0 stored as values in memory (estimated size 544.0 B, free 1997.1 MB)
17/12/19 16:24:01 INFO BlockManagerInfo: Added rdd_1041_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.0 MB)
17/12/19 16:24:01 INFO BlockManagerInfo: Added rdd_1041_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.0 MB)
17/12/19 16:24:01 INFO Executor: Finished task 0.0 in stage 493.0 (TID 364). 2906 bytes result sent to driver
17/12/19 16:24:01 INFO TaskSetManager: Finished task 0.0 in stage 493.0 (TID 364) in 0 ms on localhost (executor driver) (1/2)
17/12/19 16:24:01 INFO Executor: Finished task 1.0 in stage 493.0 (TID 365). 3064 bytes result sent to driver
17/12/19 16:24:01 INFO TaskSetManager: Finished task 1.0 in stage 493.0 (TID 365) in 15 ms on localhost (executor driver) (2/2)
17/12/19 16:24:01 INFO TaskSchedulerImpl: Removed TaskSet 493.0, whose tasks have all completed, from pool 
17/12/19 16:24:01 INFO DAGScheduler: ShuffleMapStage 493 (sql at <unknown>:0) finished in 0.015 s
17/12/19 16:24:01 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:24:01 INFO DAGScheduler: running: Set()
17/12/19 16:24:01 INFO DAGScheduler: waiting: Set(ResultStage 494)
17/12/19 16:24:01 INFO DAGScheduler: failed: Set()
17/12/19 16:24:01 INFO DAGScheduler: Submitting ResultStage 494 (MapPartitionsRDD[1047] at sql at <unknown>:0), which has no missing parents
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_332 stored as values in memory (estimated size 7.0 KB, free 1997.1 MB)
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_332_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1997.1 MB)
17/12/19 16:24:01 INFO BlockManagerInfo: Added broadcast_332_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.0 MB)
17/12/19 16:24:01 INFO SparkContext: Created broadcast 332 from broadcast at DAGScheduler.scala:996
17/12/19 16:24:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 494 (MapPartitionsRDD[1047] at sql at <unknown>:0)
17/12/19 16:24:01 INFO TaskSchedulerImpl: Adding task set 494.0 with 1 tasks
17/12/19 16:24:01 INFO TaskSetManager: Starting task 0.0 in stage 494.0 (TID 366, localhost, executor driver, partition 0, ANY, 5957 bytes)
17/12/19 16:24:01 INFO Executor: Running task 0.0 in stage 494.0 (TID 366)
17/12/19 16:24:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:24:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:24:01 INFO Executor: Finished task 0.0 in stage 494.0 (TID 366). 1707 bytes result sent to driver
17/12/19 16:24:01 INFO TaskSetManager: Finished task 0.0 in stage 494.0 (TID 366) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:24:01 INFO TaskSchedulerImpl: Removed TaskSet 494.0, whose tasks have all completed, from pool 
17/12/19 16:24:01 INFO DAGScheduler: ResultStage 494 (sql at <unknown>:0) finished in 0.000 s
17/12/19 16:24:01 INFO DAGScheduler: Job 237 finished: sql at <unknown>:0, took 0.045422 s
17/12/19 16:24:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:01 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 16:24:01 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:24:01 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 69 is 145 bytes
17/12/19 16:24:01 INFO DAGScheduler: Registering RDD 1051 (collect at utils.scala:196)
17/12/19 16:24:01 INFO DAGScheduler: Got job 238 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:24:01 INFO DAGScheduler: Final stage: ResultStage 497 (collect at utils.scala:196)
17/12/19 16:24:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 496)
17/12/19 16:24:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 496)
17/12/19 16:24:01 INFO DAGScheduler: Submitting ShuffleMapStage 496 (MapPartitionsRDD[1051] at collect at utils.scala:196), which has no missing parents
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_333 stored as values in memory (estimated size 11.9 KB, free 1997.1 MB)
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_333_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1997.0 MB)
17/12/19 16:24:01 INFO BlockManagerInfo: Added broadcast_333_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.0 MB)
17/12/19 16:24:01 INFO SparkContext: Created broadcast 333 from broadcast at DAGScheduler.scala:996
17/12/19 16:24:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 496 (MapPartitionsRDD[1051] at collect at utils.scala:196)
17/12/19 16:24:01 INFO TaskSchedulerImpl: Adding task set 496.0 with 2 tasks
17/12/19 16:24:01 INFO TaskSetManager: Starting task 0.0 in stage 496.0 (TID 367, localhost, executor driver, partition 0, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:24:01 INFO TaskSetManager: Starting task 1.0 in stage 496.0 (TID 368, localhost, executor driver, partition 1, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:24:01 INFO Executor: Running task 1.0 in stage 496.0 (TID 368)
17/12/19 16:24:01 INFO Executor: Running task 0.0 in stage 496.0 (TID 367)
17/12/19 16:24:01 INFO BlockManager: Found block rdd_1041_0 locally
17/12/19 16:24:01 INFO BlockManager: Found block rdd_1041_1 locally
17/12/19 16:24:01 INFO Executor: Finished task 0.0 in stage 496.0 (TID 367). 1969 bytes result sent to driver
17/12/19 16:24:01 INFO TaskSetManager: Finished task 0.0 in stage 496.0 (TID 367) in 16 ms on localhost (executor driver) (1/2)
17/12/19 16:24:01 INFO Executor: Finished task 1.0 in stage 496.0 (TID 368). 1969 bytes result sent to driver
17/12/19 16:24:01 INFO TaskSetManager: Finished task 1.0 in stage 496.0 (TID 368) in 16 ms on localhost (executor driver) (2/2)
17/12/19 16:24:01 INFO TaskSchedulerImpl: Removed TaskSet 496.0, whose tasks have all completed, from pool 
17/12/19 16:24:01 INFO DAGScheduler: ShuffleMapStage 496 (collect at utils.scala:196) finished in 0.016 s
17/12/19 16:24:01 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:24:01 INFO DAGScheduler: running: Set()
17/12/19 16:24:01 INFO DAGScheduler: waiting: Set(ResultStage 497)
17/12/19 16:24:01 INFO DAGScheduler: failed: Set()
17/12/19 16:24:01 INFO DAGScheduler: Submitting ResultStage 497 (MapPartitionsRDD[1054] at collect at utils.scala:196), which has no missing parents
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_334 stored as values in memory (estimated size 7.0 KB, free 1997.0 MB)
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_334_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1997.0 MB)
17/12/19 16:24:01 INFO BlockManagerInfo: Added broadcast_334_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.0 MB)
17/12/19 16:24:01 INFO SparkContext: Created broadcast 334 from broadcast at DAGScheduler.scala:996
17/12/19 16:24:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 497 (MapPartitionsRDD[1054] at collect at utils.scala:196)
17/12/19 16:24:01 INFO TaskSchedulerImpl: Adding task set 497.0 with 1 tasks
17/12/19 16:24:01 INFO TaskSetManager: Starting task 0.0 in stage 497.0 (TID 369, localhost, executor driver, partition 0, ANY, 5949 bytes)
17/12/19 16:24:01 INFO Executor: Running task 0.0 in stage 497.0 (TID 369)
17/12/19 16:24:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:24:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:24:01 INFO Executor: Finished task 0.0 in stage 497.0 (TID 369). 1707 bytes result sent to driver
17/12/19 16:24:01 INFO TaskSetManager: Finished task 0.0 in stage 497.0 (TID 369) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:24:01 INFO TaskSchedulerImpl: Removed TaskSet 497.0, whose tasks have all completed, from pool 
17/12/19 16:24:01 INFO DAGScheduler: ResultStage 497 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:24:01 INFO DAGScheduler: Job 238 finished: collect at utils.scala:196, took 0.017051 s
17/12/19 16:24:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz88`
WHERE (0 = 1)
17/12/19 16:24:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:01 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `mthzkbbxlj`
17/12/19 16:24:01 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:24:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz89`
WHERE (0 = 1)
17/12/19 16:24:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:24:01 INFO CodeGenerator: Code generated in 8.828981 ms
17/12/19 16:24:01 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:24:01 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 69 is 145 bytes
17/12/19 16:24:01 INFO DAGScheduler: Got job 239 (take at <unknown>:0) with 1 output partitions
17/12/19 16:24:01 INFO DAGScheduler: Final stage: ResultStage 499 (take at <unknown>:0)
17/12/19 16:24:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 498)
17/12/19 16:24:01 INFO DAGScheduler: Missing parents: List()
17/12/19 16:24:01 INFO DAGScheduler: Submitting ResultStage 499 (WorkerRDD[1060] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_335 stored as values in memory (estimated size 124.9 KB, free 1996.9 MB)
17/12/19 16:24:01 INFO MemoryStore: Block broadcast_335_piece0 stored as bytes in memory (estimated size 48.9 KB, free 1996.9 MB)
17/12/19 16:24:01 INFO BlockManagerInfo: Added broadcast_335_piece0 in memory on 127.0.0.1:53618 (size: 48.9 KB, free: 2003.9 MB)
17/12/19 16:24:01 INFO SparkContext: Created broadcast 335 from broadcast at DAGScheduler.scala:996
17/12/19 16:24:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 499 (WorkerRDD[1060] at RDD at rdd.scala:18)
17/12/19 16:24:01 INFO TaskSchedulerImpl: Adding task set 499.0 with 1 tasks
17/12/19 16:24:01 INFO TaskSetManager: Starting task 0.0 in stage 499.0 (TID 370, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:24:01 INFO Executor: Running task 0.0 in stage 499.0 (TID 370)
17/12/19 16:24:01 INFO BlockManager: Found block rdd_1041_0 locally
17/12/19 16:24:02 INFO MemoryStore: Block rdd_1060_0 stored as values in memory (estimated size 608.0 B, free 1996.9 MB)
17/12/19 16:24:02 INFO BlockManagerInfo: Added rdd_1060_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 16:24:02 INFO Executor: Finished task 0.0 in stage 499.0 (TID 370). 2509 bytes result sent to driver
17/12/19 16:24:02 INFO TaskSetManager: Finished task 0.0 in stage 499.0 (TID 370) in 602 ms on localhost (executor driver) (1/1)
17/12/19 16:24:02 INFO TaskSchedulerImpl: Removed TaskSet 499.0, whose tasks have all completed, from pool 
17/12/19 16:24:02 INFO DAGScheduler: ResultStage 499 (take at <unknown>:0) finished in 0.602 s
17/12/19 16:24:02 INFO DAGScheduler: Job 239 finished: take at <unknown>:0, took 0.599535 s
17/12/19 16:24:02 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:24:02 INFO DAGScheduler: Got job 240 (take at <unknown>:0) with 1 output partitions
17/12/19 16:24:02 INFO DAGScheduler: Final stage: ResultStage 501 (take at <unknown>:0)
17/12/19 16:24:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 500)
17/12/19 16:24:02 INFO DAGScheduler: Missing parents: List()
17/12/19 16:24:02 INFO DAGScheduler: Submitting ResultStage 501 (WorkerRDD[1060] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:24:02 INFO MemoryStore: Block broadcast_336 stored as values in memory (estimated size 124.9 KB, free 1996.7 MB)
17/12/19 16:24:02 INFO MemoryStore: Block broadcast_336_piece0 stored as bytes in memory (estimated size 48.9 KB, free 1996.7 MB)
17/12/19 16:24:02 INFO BlockManagerInfo: Added broadcast_336_piece0 in memory on 127.0.0.1:53618 (size: 48.9 KB, free: 2003.9 MB)
17/12/19 16:24:02 INFO SparkContext: Created broadcast 336 from broadcast at DAGScheduler.scala:996
17/12/19 16:24:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 501 (WorkerRDD[1060] at RDD at rdd.scala:18)
17/12/19 16:24:02 INFO TaskSchedulerImpl: Adding task set 501.0 with 1 tasks
17/12/19 16:24:02 INFO TaskSetManager: Starting task 0.0 in stage 501.0 (TID 371, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:24:02 INFO Executor: Running task 0.0 in stage 501.0 (TID 371)
17/12/19 16:24:02 INFO BlockManager: Found block rdd_1041_1 locally
17/12/19 16:24:02 INFO MemoryStore: Block rdd_1060_1 stored as values in memory (estimated size 608.0 B, free 1996.7 MB)
17/12/19 16:24:02 INFO BlockManagerInfo: Added rdd_1060_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 16:24:02 INFO Executor: Finished task 0.0 in stage 501.0 (TID 371). 2675 bytes result sent to driver
17/12/19 16:24:02 INFO TaskSetManager: Finished task 0.0 in stage 501.0 (TID 371) in 608 ms on localhost (executor driver) (1/1)
17/12/19 16:24:02 INFO TaskSchedulerImpl: Removed TaskSet 501.0, whose tasks have all completed, from pool 
17/12/19 16:24:02 INFO DAGScheduler: ResultStage 501 (take at <unknown>:0) finished in 0.608 s
17/12/19 16:24:02 INFO DAGScheduler: Job 240 finished: take at <unknown>:0, took 0.625149 s
17/12/19 16:24:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:02 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e85b5e7494
17/12/19 16:24:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e85b5e7494` AS `zzz90`
WHERE (0 = 1)
17/12/19 16:24:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e85b5e7494`
17/12/19 16:24:02 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:24:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz91`
WHERE (0 = 1)
17/12/19 16:24:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:02 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 16:24:02 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:24:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz92`
WHERE (0 = 1)
17/12/19 16:24:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:24:02 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:24:02 INFO DAGScheduler: Got job 241 (collect at utils.scala:196) with 2 output partitions
17/12/19 16:24:02 INFO DAGScheduler: Final stage: ResultStage 503 (collect at utils.scala:196)
17/12/19 16:24:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 502)
17/12/19 16:24:02 INFO DAGScheduler: Missing parents: List()
17/12/19 16:24:02 INFO DAGScheduler: Submitting ResultStage 503 (MapPartitionsRDD[1067] at collect at utils.scala:196), which has no missing parents
17/12/19 16:24:02 INFO MemoryStore: Block broadcast_337 stored as values in memory (estimated size 132.4 KB, free 1996.6 MB)
17/12/19 16:24:02 INFO MemoryStore: Block broadcast_337_piece0 stored as bytes in memory (estimated size 52.4 KB, free 1996.5 MB)
17/12/19 16:24:02 INFO BlockManagerInfo: Added broadcast_337_piece0 in memory on 127.0.0.1:53618 (size: 52.4 KB, free: 2003.8 MB)
17/12/19 16:24:02 INFO SparkContext: Created broadcast 337 from broadcast at DAGScheduler.scala:996
17/12/19 16:24:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 503 (MapPartitionsRDD[1067] at collect at utils.scala:196)
17/12/19 16:24:02 INFO TaskSchedulerImpl: Adding task set 503.0 with 2 tasks
17/12/19 16:24:02 INFO TaskSetManager: Starting task 0.0 in stage 503.0 (TID 372, localhost, executor driver, partition 0, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:24:02 INFO TaskSetManager: Starting task 1.0 in stage 503.0 (TID 373, localhost, executor driver, partition 1, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:24:02 INFO Executor: Running task 0.0 in stage 503.0 (TID 372)
17/12/19 16:24:02 INFO Executor: Running task 1.0 in stage 503.0 (TID 373)
17/12/19 16:24:02 INFO BlockManager: Found block rdd_1060_1 locally
17/12/19 16:24:02 INFO BlockManager: Found block rdd_1060_0 locally
17/12/19 16:24:02 INFO Executor: Finished task 1.0 in stage 503.0 (TID 373). 1454 bytes result sent to driver
17/12/19 16:24:02 INFO Executor: Finished task 0.0 in stage 503.0 (TID 372). 1446 bytes result sent to driver
17/12/19 16:24:02 INFO TaskSetManager: Finished task 1.0 in stage 503.0 (TID 373) in 0 ms on localhost (executor driver) (1/2)
17/12/19 16:24:02 INFO DAGScheduler: ResultStage 503 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:24:02 INFO DAGScheduler: Job 241 finished: collect at utils.scala:196, took 0.011506 s
17/12/19 16:24:02 INFO TaskSetManager: Finished task 0.0 in stage 503.0 (TID 372) in 0 ms on localhost (executor driver) (2/2)
17/12/19 16:24:02 INFO TaskSchedulerImpl: Removed TaskSet 503.0, whose tasks have all completed, from pool 
17/12/19 16:24:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:24:02 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:24:02 INFO DAGScheduler: Got job 242 (take at <unknown>:0) with 1 output partitions
17/12/19 16:24:02 INFO DAGScheduler: Final stage: ResultStage 505 (take at <unknown>:0)
17/12/19 16:24:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 504)
17/12/19 16:24:02 INFO DAGScheduler: Missing parents: List()
17/12/19 16:24:02 INFO DAGScheduler: Submitting ResultStage 505 (WorkerRDD[1072] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:24:02 INFO MemoryStore: Block broadcast_338 stored as values in memory (estimated size 240.5 KB, free 1996.3 MB)
17/12/19 16:24:02 INFO MemoryStore: Block broadcast_338_piece0 stored as bytes in memory (estimated size 94.7 KB, free 1996.2 MB)
17/12/19 16:24:02 INFO BlockManagerInfo: Added broadcast_338_piece0 in memory on 127.0.0.1:53618 (size: 94.7 KB, free: 2003.7 MB)
17/12/19 16:24:02 INFO SparkContext: Created broadcast 338 from broadcast at DAGScheduler.scala:996
17/12/19 16:24:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 505 (WorkerRDD[1072] at RDD at rdd.scala:18)
17/12/19 16:24:02 INFO TaskSchedulerImpl: Adding task set 505.0 with 1 tasks
17/12/19 16:24:02 INFO TaskSetManager: Starting task 0.0 in stage 505.0 (TID 374, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:24:02 INFO Executor: Running task 0.0 in stage 505.0 (TID 374)
17/12/19 16:24:02 INFO BlockManager: Found block rdd_1060_0 locally
17/12/19 16:24:03 INFO MemoryStore: Block rdd_1072_0 stored as values in memory (estimated size 80.0 B, free 1996.2 MB)
17/12/19 16:24:03 INFO BlockManagerInfo: Added rdd_1072_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.7 MB)
17/12/19 16:24:03 INFO Executor: Finished task 0.0 in stage 505.0 (TID 374). 2400 bytes result sent to driver
17/12/19 16:24:03 INFO TaskSetManager: Finished task 0.0 in stage 505.0 (TID 374) in 634 ms on localhost (executor driver) (1/1)
17/12/19 16:24:03 INFO TaskSchedulerImpl: Removed TaskSet 505.0, whose tasks have all completed, from pool 
17/12/19 16:24:03 INFO DAGScheduler: ResultStage 505 (take at <unknown>:0) finished in 0.634 s
17/12/19 16:24:03 INFO DAGScheduler: Job 242 finished: take at <unknown>:0, took 0.639427 s
17/12/19 16:24:03 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:24:03 INFO DAGScheduler: Got job 243 (take at <unknown>:0) with 1 output partitions
17/12/19 16:24:03 INFO DAGScheduler: Final stage: ResultStage 507 (take at <unknown>:0)
17/12/19 16:24:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 506)
17/12/19 16:24:03 INFO DAGScheduler: Missing parents: List()
17/12/19 16:24:03 INFO DAGScheduler: Submitting ResultStage 507 (WorkerRDD[1072] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:24:03 INFO MemoryStore: Block broadcast_339 stored as values in memory (estimated size 240.5 KB, free 1996.0 MB)
17/12/19 16:24:03 INFO MemoryStore: Block broadcast_339_piece0 stored as bytes in memory (estimated size 94.7 KB, free 1995.9 MB)
17/12/19 16:24:03 INFO BlockManagerInfo: Added broadcast_339_piece0 in memory on 127.0.0.1:53618 (size: 94.7 KB, free: 2003.6 MB)
17/12/19 16:24:03 INFO SparkContext: Created broadcast 339 from broadcast at DAGScheduler.scala:996
17/12/19 16:24:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 507 (WorkerRDD[1072] at RDD at rdd.scala:18)
17/12/19 16:24:03 INFO TaskSchedulerImpl: Adding task set 507.0 with 1 tasks
17/12/19 16:24:03 INFO TaskSetManager: Starting task 0.0 in stage 507.0 (TID 375, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:24:03 INFO Executor: Running task 0.0 in stage 507.0 (TID 375)
17/12/19 16:24:03 INFO BlockManager: Found block rdd_1060_1 locally
17/12/19 16:24:04 INFO MemoryStore: Block rdd_1072_1 stored as values in memory (estimated size 80.0 B, free 1995.9 MB)
17/12/19 16:24:04 INFO BlockManagerInfo: Added rdd_1072_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.6 MB)
17/12/19 16:24:04 INFO Executor: Finished task 0.0 in stage 507.0 (TID 375). 2577 bytes result sent to driver
17/12/19 16:24:04 INFO TaskSetManager: Finished task 0.0 in stage 507.0 (TID 375) in 631 ms on localhost (executor driver) (1/1)
17/12/19 16:24:04 INFO TaskSchedulerImpl: Removed TaskSet 507.0, whose tasks have all completed, from pool 
17/12/19 16:24:04 INFO DAGScheduler: ResultStage 507 (take at <unknown>:0) finished in 0.631 s
17/12/19 16:24:04 INFO DAGScheduler: Job 243 finished: take at <unknown>:0, took 0.634487 s
17/12/19 16:24:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:04 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e86cc57301
17/12/19 16:24:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e86cc57301` AS `zzz93`
WHERE (0 = 1)
17/12/19 16:24:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e86cc57301`
LIMIT 10
17/12/19 16:24:04 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:24:04 INFO DAGScheduler: Got job 244 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:24:04 INFO DAGScheduler: Final stage: ResultStage 509 (collect at utils.scala:196)
17/12/19 16:24:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 508)
17/12/19 16:24:04 INFO DAGScheduler: Missing parents: List()
17/12/19 16:24:04 INFO DAGScheduler: Submitting ResultStage 509 (MapPartitionsRDD[1076] at collect at utils.scala:196), which has no missing parents
17/12/19 16:24:04 INFO MemoryStore: Block broadcast_340 stored as values in memory (estimated size 241.5 KB, free 1995.6 MB)
17/12/19 16:24:04 INFO MemoryStore: Block broadcast_340_piece0 stored as bytes in memory (estimated size 95.4 KB, free 1995.5 MB)
17/12/19 16:24:04 INFO BlockManagerInfo: Added broadcast_340_piece0 in memory on 127.0.0.1:53618 (size: 95.4 KB, free: 2003.6 MB)
17/12/19 16:24:04 INFO SparkContext: Created broadcast 340 from broadcast at DAGScheduler.scala:996
17/12/19 16:24:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 509 (MapPartitionsRDD[1076] at collect at utils.scala:196)
17/12/19 16:24:04 INFO TaskSchedulerImpl: Adding task set 509.0 with 1 tasks
17/12/19 16:24:04 INFO TaskSetManager: Starting task 0.0 in stage 509.0 (TID 376, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:24:04 INFO Executor: Running task 0.0 in stage 509.0 (TID 376)
17/12/19 16:24:04 INFO BlockManager: Found block rdd_1072_0 locally
17/12/19 16:24:04 INFO Executor: Finished task 0.0 in stage 509.0 (TID 376). 1645 bytes result sent to driver
17/12/19 16:24:04 INFO TaskSetManager: Finished task 0.0 in stage 509.0 (TID 376) in 3 ms on localhost (executor driver) (1/1)
17/12/19 16:24:04 INFO TaskSchedulerImpl: Removed TaskSet 509.0, whose tasks have all completed, from pool 
17/12/19 16:24:04 INFO DAGScheduler: ResultStage 509 (collect at utils.scala:196) finished in 0.003 s
17/12/19 16:24:04 INFO DAGScheduler: Job 244 finished: collect at utils.scala:196, took 0.007718 s
17/12/19 16:24:04 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:24:04 INFO DAGScheduler: Got job 245 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:24:04 INFO DAGScheduler: Final stage: ResultStage 511 (collect at utils.scala:196)
17/12/19 16:24:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 510)
17/12/19 16:24:04 INFO DAGScheduler: Missing parents: List()
17/12/19 16:24:04 INFO DAGScheduler: Submitting ResultStage 511 (MapPartitionsRDD[1076] at collect at utils.scala:196), which has no missing parents
17/12/19 16:24:04 INFO MemoryStore: Block broadcast_341 stored as values in memory (estimated size 241.5 KB, free 1995.3 MB)
17/12/19 16:24:04 INFO MemoryStore: Block broadcast_341_piece0 stored as bytes in memory (estimated size 95.4 KB, free 1995.2 MB)
17/12/19 16:24:04 INFO BlockManagerInfo: Added broadcast_341_piece0 in memory on 127.0.0.1:53618 (size: 95.4 KB, free: 2003.5 MB)
17/12/19 16:24:04 INFO SparkContext: Created broadcast 341 from broadcast at DAGScheduler.scala:996
17/12/19 16:24:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 511 (MapPartitionsRDD[1076] at collect at utils.scala:196)
17/12/19 16:24:04 INFO TaskSchedulerImpl: Adding task set 511.0 with 1 tasks
17/12/19 16:24:04 INFO TaskSetManager: Starting task 0.0 in stage 511.0 (TID 377, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:24:04 INFO Executor: Running task 0.0 in stage 511.0 (TID 377)
17/12/19 16:24:04 INFO BlockManager: Found block rdd_1072_1 locally
17/12/19 16:24:04 INFO Executor: Finished task 0.0 in stage 511.0 (TID 377). 1479 bytes result sent to driver
17/12/19 16:24:04 INFO TaskSetManager: Finished task 0.0 in stage 511.0 (TID 377) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:24:04 INFO TaskSchedulerImpl: Removed TaskSet 511.0, whose tasks have all completed, from pool 
17/12/19 16:24:04 INFO DAGScheduler: ResultStage 511 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:24:04 INFO DAGScheduler: Job 245 finished: collect at utils.scala:196, took 0.006880 s
17/12/19 16:24:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:24:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:24:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:24:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:24:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:24:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:24:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:24:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:24:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:24:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:24:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:24:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:24:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:24:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:24:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:24:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:24:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:24:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:24:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:24:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:24:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:24:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:24:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:24:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:24:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:24:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:24:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:24:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:24:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:28:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:35 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:28:35 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:28:35 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:28:35 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:28:35 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:28:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:28:35 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:28:35 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 16:28:35 INFO DAGScheduler: Got job 246 (collect at utils.scala:58) with 1 output partitions
17/12/19 16:28:35 INFO DAGScheduler: Final stage: ResultStage 512 (collect at utils.scala:58)
17/12/19 16:28:35 INFO DAGScheduler: Parents of final stage: List()
17/12/19 16:28:35 INFO DAGScheduler: Missing parents: List()
17/12/19 16:28:35 INFO DAGScheduler: Submitting ResultStage 512 (MapPartitionsRDD[1086] at map at utils.scala:55), which has no missing parents
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_342 stored as values in memory (estimated size 8.7 KB, free 1995.2 MB)
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_342_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1995.2 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Added broadcast_342_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.5 MB)
17/12/19 16:28:35 INFO SparkContext: Created broadcast 342 from broadcast at DAGScheduler.scala:996
17/12/19 16:28:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 512 (MapPartitionsRDD[1086] at map at utils.scala:55)
17/12/19 16:28:35 INFO TaskSchedulerImpl: Adding task set 512.0 with 1 tasks
17/12/19 16:28:35 INFO TaskSetManager: Starting task 0.0 in stage 512.0 (TID 378, localhost, executor driver, partition 0, PROCESS_LOCAL, 8947 bytes)
17/12/19 16:28:35 INFO Executor: Running task 0.0 in stage 512.0 (TID 378)
17/12/19 16:28:35 INFO Executor: Finished task 0.0 in stage 512.0 (TID 378). 1916 bytes result sent to driver
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 16943
17/12/19 16:28:35 INFO DAGScheduler: ResultStage 512 (collect at utils.scala:58) finished in 0.016 s
17/12/19 16:28:35 INFO DAGScheduler: Job 246 finished: collect at utils.scala:58, took 0.012892 s
17/12/19 16:28:35 INFO TaskSetManager: Finished task 0.0 in stage 512.0 (TID 378) in 16 ms on localhost (executor driver) (1/1)
17/12/19 16:28:35 INFO TaskSchedulerImpl: Removed TaskSet 512.0, whose tasks have all completed, from pool 
17/12/19 16:28:35 INFO BlockManagerInfo: Removed broadcast_337_piece0 on 127.0.0.1:53618 in memory (size: 52.4 KB, free: 2003.5 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Removed broadcast_338_piece0 on 127.0.0.1:53618 in memory (size: 94.7 KB, free: 2003.6 MB)
17/12/19 16:28:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:35 INFO BlockManagerInfo: Removed broadcast_339_piece0 on 127.0.0.1:53618 in memory (size: 94.7 KB, free: 2003.7 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Removed broadcast_340_piece0 on 127.0.0.1:53618 in memory (size: 95.4 KB, free: 2003.8 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Removed broadcast_341_piece0 on 127.0.0.1:53618 in memory (size: 95.4 KB, free: 2003.9 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Removed broadcast_328_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2003.9 MB)
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 16993
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 16994
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 17000
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 17001
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 17002
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 17003
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 17004
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 17005
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 17006
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 17007
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 17008
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 17009
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 17010
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 17011
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 17012
17/12/19 16:28:35 INFO ContextCleaner: Cleaned shuffle 70
17/12/19 16:28:35 INFO BlockManagerInfo: Removed broadcast_330_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2003.9 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Removed broadcast_331_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.9 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Removed broadcast_332_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.9 MB)
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 17181
17/12/19 16:28:35 INFO BlockManagerInfo: Removed broadcast_333_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.9 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Removed broadcast_334_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.9 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Removed broadcast_335_piece0 on 127.0.0.1:53618 in memory (size: 48.9 KB, free: 2004.0 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Removed broadcast_336_piece0 on 127.0.0.1:53618 in memory (size: 48.9 KB, free: 2004.0 MB)
17/12/19 16:28:35 INFO ContextCleaner: Cleaned accumulator 16944
17/12/19 16:28:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:35 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:28:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:35 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 16:28:35 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 16:28:35 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 16:28:35 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 16:28:35 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 16:28:35 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_343 stored as values in memory (estimated size 293.7 KB, free 1996.8 MB)
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_343_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1996.8 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Added broadcast_343_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.0 MB)
17/12/19 16:28:35 INFO SparkContext: Created broadcast 343 from sql at <unknown>:0
17/12/19 16:28:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 16:28:35 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 16:28:35 INFO DAGScheduler: Registering RDD 1090 (sql at <unknown>:0)
17/12/19 16:28:35 INFO DAGScheduler: Registering RDD 1095 (sql at <unknown>:0)
17/12/19 16:28:35 INFO DAGScheduler: Got job 247 (sql at <unknown>:0) with 1 output partitions
17/12/19 16:28:35 INFO DAGScheduler: Final stage: ResultStage 515 (sql at <unknown>:0)
17/12/19 16:28:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 514)
17/12/19 16:28:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 514)
17/12/19 16:28:35 INFO DAGScheduler: Submitting ShuffleMapStage 513 (MapPartitionsRDD[1090] at sql at <unknown>:0), which has no missing parents
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_344 stored as values in memory (estimated size 12.1 KB, free 1996.8 MB)
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_344_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1996.8 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Added broadcast_344_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.0 MB)
17/12/19 16:28:35 INFO SparkContext: Created broadcast 344 from broadcast at DAGScheduler.scala:996
17/12/19 16:28:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 513 (MapPartitionsRDD[1090] at sql at <unknown>:0)
17/12/19 16:28:35 INFO TaskSchedulerImpl: Adding task set 513.0 with 1 tasks
17/12/19 16:28:35 INFO TaskSetManager: Starting task 0.0 in stage 513.0 (TID 379, localhost, executor driver, partition 0, PROCESS_LOCAL, 6680 bytes)
17/12/19 16:28:35 INFO Executor: Running task 0.0 in stage 513.0 (TID 379)
17/12/19 16:28:35 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_a9498d0d65e893a4694865d35d776090631c47e5c924c29a3a41a7b96c395bbe.csv, range: 0-458, partition values: [empty row]
17/12/19 16:28:35 INFO Executor: Finished task 0.0 in stage 513.0 (TID 379). 1553 bytes result sent to driver
17/12/19 16:28:35 INFO TaskSetManager: Finished task 0.0 in stage 513.0 (TID 379) in 16 ms on localhost (executor driver) (1/1)
17/12/19 16:28:35 INFO TaskSchedulerImpl: Removed TaskSet 513.0, whose tasks have all completed, from pool 
17/12/19 16:28:35 INFO DAGScheduler: ShuffleMapStage 513 (sql at <unknown>:0) finished in 0.016 s
17/12/19 16:28:35 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:28:35 INFO DAGScheduler: running: Set()
17/12/19 16:28:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 514, ResultStage 515)
17/12/19 16:28:35 INFO DAGScheduler: failed: Set()
17/12/19 16:28:35 INFO DAGScheduler: Submitting ShuffleMapStage 514 (MapPartitionsRDD[1095] at sql at <unknown>:0), which has no missing parents
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_345 stored as values in memory (estimated size 11.9 KB, free 1996.8 MB)
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_345_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1996.8 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Added broadcast_345_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.0 MB)
17/12/19 16:28:35 INFO SparkContext: Created broadcast 345 from broadcast at DAGScheduler.scala:996
17/12/19 16:28:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 514 (MapPartitionsRDD[1095] at sql at <unknown>:0)
17/12/19 16:28:35 INFO TaskSchedulerImpl: Adding task set 514.0 with 2 tasks
17/12/19 16:28:35 INFO TaskSetManager: Starting task 0.0 in stage 514.0 (TID 380, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 16:28:35 INFO TaskSetManager: Starting task 1.0 in stage 514.0 (TID 381, localhost, executor driver, partition 1, ANY, 5946 bytes)
17/12/19 16:28:35 INFO Executor: Running task 0.0 in stage 514.0 (TID 380)
17/12/19 16:28:35 INFO Executor: Running task 1.0 in stage 514.0 (TID 381)
17/12/19 16:28:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:28:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:28:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:28:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:28:35 INFO MemoryStore: Block rdd_1092_0 stored as values in memory (estimated size 544.0 B, free 1996.8 MB)
17/12/19 16:28:35 INFO MemoryStore: Block rdd_1092_1 stored as values in memory (estimated size 544.0 B, free 1996.8 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Added rdd_1092_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.0 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Added rdd_1092_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2004.0 MB)
17/12/19 16:28:35 INFO Executor: Finished task 0.0 in stage 514.0 (TID 380). 3064 bytes result sent to driver
17/12/19 16:28:35 INFO TaskSetManager: Finished task 0.0 in stage 514.0 (TID 380) in 16 ms on localhost (executor driver) (1/2)
17/12/19 16:28:35 INFO Executor: Finished task 1.0 in stage 514.0 (TID 381). 3064 bytes result sent to driver
17/12/19 16:28:35 INFO TaskSetManager: Finished task 1.0 in stage 514.0 (TID 381) in 16 ms on localhost (executor driver) (2/2)
17/12/19 16:28:35 INFO TaskSchedulerImpl: Removed TaskSet 514.0, whose tasks have all completed, from pool 
17/12/19 16:28:35 INFO DAGScheduler: ShuffleMapStage 514 (sql at <unknown>:0) finished in 0.016 s
17/12/19 16:28:35 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:28:35 INFO DAGScheduler: running: Set()
17/12/19 16:28:35 INFO DAGScheduler: waiting: Set(ResultStage 515)
17/12/19 16:28:35 INFO DAGScheduler: failed: Set()
17/12/19 16:28:35 INFO DAGScheduler: Submitting ResultStage 515 (MapPartitionsRDD[1098] at sql at <unknown>:0), which has no missing parents
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_346 stored as values in memory (estimated size 7.0 KB, free 1996.8 MB)
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_346_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1996.8 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Added broadcast_346_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.0 MB)
17/12/19 16:28:35 INFO SparkContext: Created broadcast 346 from broadcast at DAGScheduler.scala:996
17/12/19 16:28:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 515 (MapPartitionsRDD[1098] at sql at <unknown>:0)
17/12/19 16:28:35 INFO TaskSchedulerImpl: Adding task set 515.0 with 1 tasks
17/12/19 16:28:35 INFO TaskSetManager: Starting task 0.0 in stage 515.0 (TID 382, localhost, executor driver, partition 0, ANY, 5957 bytes)
17/12/19 16:28:35 INFO Executor: Running task 0.0 in stage 515.0 (TID 382)
17/12/19 16:28:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:28:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:28:35 INFO Executor: Finished task 0.0 in stage 515.0 (TID 382). 1884 bytes result sent to driver
17/12/19 16:28:35 INFO TaskSetManager: Finished task 0.0 in stage 515.0 (TID 382) in 15 ms on localhost (executor driver) (1/1)
17/12/19 16:28:35 INFO TaskSchedulerImpl: Removed TaskSet 515.0, whose tasks have all completed, from pool 
17/12/19 16:28:35 INFO DAGScheduler: ResultStage 515 (sql at <unknown>:0) finished in 0.015 s
17/12/19 16:28:35 INFO DAGScheduler: Job 247 finished: sql at <unknown>:0, took 0.046269 s
17/12/19 16:28:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:35 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 16:28:35 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:28:35 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 72 is 145 bytes
17/12/19 16:28:35 INFO DAGScheduler: Registering RDD 1102 (collect at utils.scala:196)
17/12/19 16:28:35 INFO DAGScheduler: Got job 248 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:28:35 INFO DAGScheduler: Final stage: ResultStage 518 (collect at utils.scala:196)
17/12/19 16:28:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 517)
17/12/19 16:28:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 517)
17/12/19 16:28:35 INFO DAGScheduler: Submitting ShuffleMapStage 517 (MapPartitionsRDD[1102] at collect at utils.scala:196), which has no missing parents
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_347 stored as values in memory (estimated size 11.9 KB, free 1996.7 MB)
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_347_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1996.7 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Added broadcast_347_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2004.0 MB)
17/12/19 16:28:35 INFO SparkContext: Created broadcast 347 from broadcast at DAGScheduler.scala:996
17/12/19 16:28:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 517 (MapPartitionsRDD[1102] at collect at utils.scala:196)
17/12/19 16:28:35 INFO TaskSchedulerImpl: Adding task set 517.0 with 2 tasks
17/12/19 16:28:35 INFO TaskSetManager: Starting task 0.0 in stage 517.0 (TID 383, localhost, executor driver, partition 0, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:28:35 INFO TaskSetManager: Starting task 1.0 in stage 517.0 (TID 384, localhost, executor driver, partition 1, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:28:35 INFO Executor: Running task 0.0 in stage 517.0 (TID 383)
17/12/19 16:28:35 INFO Executor: Running task 1.0 in stage 517.0 (TID 384)
17/12/19 16:28:35 INFO BlockManager: Found block rdd_1092_0 locally
17/12/19 16:28:35 INFO BlockManager: Found block rdd_1092_1 locally
17/12/19 16:28:35 INFO Executor: Finished task 0.0 in stage 517.0 (TID 383). 1792 bytes result sent to driver
17/12/19 16:28:35 INFO Executor: Finished task 1.0 in stage 517.0 (TID 384). 1871 bytes result sent to driver
17/12/19 16:28:35 INFO TaskSetManager: Finished task 0.0 in stage 517.0 (TID 383) in 15 ms on localhost (executor driver) (1/2)
17/12/19 16:28:35 INFO DAGScheduler: ShuffleMapStage 517 (collect at utils.scala:196) finished in 0.015 s
17/12/19 16:28:35 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:28:35 INFO DAGScheduler: running: Set()
17/12/19 16:28:35 INFO DAGScheduler: waiting: Set(ResultStage 518)
17/12/19 16:28:35 INFO DAGScheduler: failed: Set()
17/12/19 16:28:35 INFO DAGScheduler: Submitting ResultStage 518 (MapPartitionsRDD[1105] at collect at utils.scala:196), which has no missing parents
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_348 stored as values in memory (estimated size 7.0 KB, free 1996.7 MB)
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_348_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1996.7 MB)
17/12/19 16:28:35 INFO TaskSetManager: Finished task 1.0 in stage 517.0 (TID 384) in 15 ms on localhost (executor driver) (2/2)
17/12/19 16:28:35 INFO TaskSchedulerImpl: Removed TaskSet 517.0, whose tasks have all completed, from pool 
17/12/19 16:28:35 INFO BlockManagerInfo: Added broadcast_348_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2004.0 MB)
17/12/19 16:28:35 INFO SparkContext: Created broadcast 348 from broadcast at DAGScheduler.scala:996
17/12/19 16:28:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 518 (MapPartitionsRDD[1105] at collect at utils.scala:196)
17/12/19 16:28:35 INFO TaskSchedulerImpl: Adding task set 518.0 with 1 tasks
17/12/19 16:28:35 INFO TaskSetManager: Starting task 0.0 in stage 518.0 (TID 385, localhost, executor driver, partition 0, ANY, 5949 bytes)
17/12/19 16:28:35 INFO Executor: Running task 0.0 in stage 518.0 (TID 385)
17/12/19 16:28:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:28:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:28:35 INFO Executor: Finished task 0.0 in stage 518.0 (TID 385). 1707 bytes result sent to driver
17/12/19 16:28:35 INFO DAGScheduler: ResultStage 518 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:28:35 INFO DAGScheduler: Job 248 finished: collect at utils.scala:196, took 0.025483 s
17/12/19 16:28:35 INFO TaskSetManager: Finished task 0.0 in stage 518.0 (TID 385) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:28:35 INFO TaskSchedulerImpl: Removed TaskSet 518.0, whose tasks have all completed, from pool 
17/12/19 16:28:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz94`
WHERE (0 = 1)
17/12/19 16:28:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:35 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `fdxhudvkla`
17/12/19 16:28:35 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:28:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz95`
WHERE (0 = 1)
17/12/19 16:28:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:28:35 INFO CodeGenerator: Code generated in 5.042219 ms
17/12/19 16:28:35 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:28:35 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 72 is 145 bytes
17/12/19 16:28:35 INFO DAGScheduler: Got job 249 (take at <unknown>:0) with 1 output partitions
17/12/19 16:28:35 INFO DAGScheduler: Final stage: ResultStage 520 (take at <unknown>:0)
17/12/19 16:28:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 519)
17/12/19 16:28:35 INFO DAGScheduler: Missing parents: List()
17/12/19 16:28:35 INFO DAGScheduler: Submitting ResultStage 520 (WorkerRDD[1111] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_349 stored as values in memory (estimated size 124.7 KB, free 1996.6 MB)
17/12/19 16:28:35 INFO MemoryStore: Block broadcast_349_piece0 stored as bytes in memory (estimated size 48.9 KB, free 1996.6 MB)
17/12/19 16:28:35 INFO BlockManagerInfo: Added broadcast_349_piece0 in memory on 127.0.0.1:53618 (size: 48.9 KB, free: 2003.9 MB)
17/12/19 16:28:35 INFO SparkContext: Created broadcast 349 from broadcast at DAGScheduler.scala:996
17/12/19 16:28:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 520 (WorkerRDD[1111] at RDD at rdd.scala:18)
17/12/19 16:28:35 INFO TaskSchedulerImpl: Adding task set 520.0 with 1 tasks
17/12/19 16:28:35 INFO TaskSetManager: Starting task 0.0 in stage 520.0 (TID 386, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:28:35 INFO Executor: Running task 0.0 in stage 520.0 (TID 386)
17/12/19 16:28:35 INFO BlockManager: Found block rdd_1092_0 locally
17/12/19 16:28:36 INFO MemoryStore: Block rdd_1111_0 stored as values in memory (estimated size 608.0 B, free 1996.6 MB)
17/12/19 16:28:36 INFO BlockManagerInfo: Added rdd_1111_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 16:28:36 INFO Executor: Finished task 0.0 in stage 520.0 (TID 386). 2509 bytes result sent to driver
17/12/19 16:28:36 INFO TaskSetManager: Finished task 0.0 in stage 520.0 (TID 386) in 652 ms on localhost (executor driver) (1/1)
17/12/19 16:28:36 INFO TaskSchedulerImpl: Removed TaskSet 520.0, whose tasks have all completed, from pool 
17/12/19 16:28:36 INFO DAGScheduler: ResultStage 520 (take at <unknown>:0) finished in 0.652 s
17/12/19 16:28:36 INFO DAGScheduler: Job 249 finished: take at <unknown>:0, took 0.657642 s
17/12/19 16:28:36 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:28:36 INFO DAGScheduler: Got job 250 (take at <unknown>:0) with 1 output partitions
17/12/19 16:28:36 INFO DAGScheduler: Final stage: ResultStage 522 (take at <unknown>:0)
17/12/19 16:28:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 521)
17/12/19 16:28:36 INFO DAGScheduler: Missing parents: List()
17/12/19 16:28:36 INFO DAGScheduler: Submitting ResultStage 522 (WorkerRDD[1111] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:28:36 INFO MemoryStore: Block broadcast_350 stored as values in memory (estimated size 124.7 KB, free 1996.4 MB)
17/12/19 16:28:36 INFO MemoryStore: Block broadcast_350_piece0 stored as bytes in memory (estimated size 48.9 KB, free 1996.4 MB)
17/12/19 16:28:36 INFO BlockManagerInfo: Added broadcast_350_piece0 in memory on 127.0.0.1:53618 (size: 48.9 KB, free: 2003.9 MB)
17/12/19 16:28:36 INFO SparkContext: Created broadcast 350 from broadcast at DAGScheduler.scala:996
17/12/19 16:28:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 522 (WorkerRDD[1111] at RDD at rdd.scala:18)
17/12/19 16:28:36 INFO TaskSchedulerImpl: Adding task set 522.0 with 1 tasks
17/12/19 16:28:36 INFO TaskSetManager: Starting task 0.0 in stage 522.0 (TID 387, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:28:36 INFO Executor: Running task 0.0 in stage 522.0 (TID 387)
17/12/19 16:28:36 INFO BlockManager: Found block rdd_1092_1 locally
17/12/19 16:28:36 INFO MemoryStore: Block rdd_1111_1 stored as values in memory (estimated size 608.0 B, free 1996.4 MB)
17/12/19 16:28:36 INFO BlockManagerInfo: Added rdd_1111_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 16:28:36 INFO Executor: Finished task 0.0 in stage 522.0 (TID 387). 2509 bytes result sent to driver
17/12/19 16:28:36 INFO TaskSetManager: Finished task 0.0 in stage 522.0 (TID 387) in 656 ms on localhost (executor driver) (1/1)
17/12/19 16:28:36 INFO TaskSchedulerImpl: Removed TaskSet 522.0, whose tasks have all completed, from pool 
17/12/19 16:28:36 INFO DAGScheduler: ResultStage 522 (take at <unknown>:0) finished in 0.656 s
17/12/19 16:28:36 INFO DAGScheduler: Job 250 finished: take at <unknown>:0, took 0.665228 s
17/12/19 16:28:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:36 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e841f1f64
17/12/19 16:28:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e841f1f64` AS `zzz96`
WHERE (0 = 1)
17/12/19 16:28:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e841f1f64`
17/12/19 16:28:36 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:28:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz97`
WHERE (0 = 1)
17/12/19 16:28:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:36 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 16:28:36 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:28:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz98`
WHERE (0 = 1)
17/12/19 16:28:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:28:36 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:28:36 INFO DAGScheduler: Got job 251 (collect at utils.scala:196) with 2 output partitions
17/12/19 16:28:36 INFO DAGScheduler: Final stage: ResultStage 524 (collect at utils.scala:196)
17/12/19 16:28:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 523)
17/12/19 16:28:36 INFO DAGScheduler: Missing parents: List()
17/12/19 16:28:36 INFO DAGScheduler: Submitting ResultStage 524 (MapPartitionsRDD[1118] at collect at utils.scala:196), which has no missing parents
17/12/19 16:28:36 INFO MemoryStore: Block broadcast_351 stored as values in memory (estimated size 132.2 KB, free 1996.3 MB)
17/12/19 16:28:36 INFO MemoryStore: Block broadcast_351_piece0 stored as bytes in memory (estimated size 52.4 KB, free 1996.2 MB)
17/12/19 16:28:36 INFO BlockManagerInfo: Added broadcast_351_piece0 in memory on 127.0.0.1:53618 (size: 52.4 KB, free: 2003.8 MB)
17/12/19 16:28:36 INFO SparkContext: Created broadcast 351 from broadcast at DAGScheduler.scala:996
17/12/19 16:28:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 524 (MapPartitionsRDD[1118] at collect at utils.scala:196)
17/12/19 16:28:36 INFO TaskSchedulerImpl: Adding task set 524.0 with 2 tasks
17/12/19 16:28:36 INFO TaskSetManager: Starting task 0.0 in stage 524.0 (TID 388, localhost, executor driver, partition 0, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:28:36 INFO TaskSetManager: Starting task 1.0 in stage 524.0 (TID 389, localhost, executor driver, partition 1, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:28:36 INFO Executor: Running task 0.0 in stage 524.0 (TID 388)
17/12/19 16:28:36 INFO Executor: Running task 1.0 in stage 524.0 (TID 389)
17/12/19 16:28:36 INFO BlockManager: Found block rdd_1111_1 locally
17/12/19 16:28:36 INFO BlockManager: Found block rdd_1111_0 locally
17/12/19 16:28:36 INFO Executor: Finished task 0.0 in stage 524.0 (TID 388). 1446 bytes result sent to driver
17/12/19 16:28:36 INFO Executor: Finished task 1.0 in stage 524.0 (TID 389). 1439 bytes result sent to driver
17/12/19 16:28:36 INFO TaskSetManager: Finished task 0.0 in stage 524.0 (TID 388) in 0 ms on localhost (executor driver) (1/2)
17/12/19 16:28:36 INFO TaskSetManager: Finished task 1.0 in stage 524.0 (TID 389) in 0 ms on localhost (executor driver) (2/2)
17/12/19 16:28:36 INFO TaskSchedulerImpl: Removed TaskSet 524.0, whose tasks have all completed, from pool 
17/12/19 16:28:36 INFO DAGScheduler: ResultStage 524 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:28:36 INFO DAGScheduler: Job 251 finished: collect at utils.scala:196, took 0.008513 s
17/12/19 16:28:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:28:37 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:28:37 INFO DAGScheduler: Got job 252 (take at <unknown>:0) with 1 output partitions
17/12/19 16:28:37 INFO DAGScheduler: Final stage: ResultStage 526 (take at <unknown>:0)
17/12/19 16:28:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 525)
17/12/19 16:28:37 INFO DAGScheduler: Missing parents: List()
17/12/19 16:28:37 INFO DAGScheduler: Submitting ResultStage 526 (WorkerRDD[1123] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:28:37 INFO MemoryStore: Block broadcast_352 stored as values in memory (estimated size 240.2 KB, free 1996.0 MB)
17/12/19 16:28:37 INFO MemoryStore: Block broadcast_352_piece0 stored as bytes in memory (estimated size 94.5 KB, free 1995.9 MB)
17/12/19 16:28:37 INFO BlockManagerInfo: Added broadcast_352_piece0 in memory on 127.0.0.1:53618 (size: 94.5 KB, free: 2003.7 MB)
17/12/19 16:28:37 INFO SparkContext: Created broadcast 352 from broadcast at DAGScheduler.scala:996
17/12/19 16:28:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 526 (WorkerRDD[1123] at RDD at rdd.scala:18)
17/12/19 16:28:37 INFO TaskSchedulerImpl: Adding task set 526.0 with 1 tasks
17/12/19 16:28:37 INFO TaskSetManager: Starting task 0.0 in stage 526.0 (TID 390, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:28:37 INFO Executor: Running task 0.0 in stage 526.0 (TID 390)
17/12/19 16:28:37 INFO BlockManager: Found block rdd_1111_0 locally
17/12/19 16:28:37 INFO MemoryStore: Block rdd_1123_0 stored as values in memory (estimated size 80.0 B, free 1995.9 MB)
17/12/19 16:28:37 INFO BlockManagerInfo: Added rdd_1123_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.7 MB)
17/12/19 16:28:37 INFO Executor: Finished task 0.0 in stage 526.0 (TID 390). 2487 bytes result sent to driver
17/12/19 16:28:37 INFO TaskSetManager: Finished task 0.0 in stage 526.0 (TID 390) in 641 ms on localhost (executor driver) (1/1)
17/12/19 16:28:37 INFO TaskSchedulerImpl: Removed TaskSet 526.0, whose tasks have all completed, from pool 
17/12/19 16:28:37 INFO DAGScheduler: ResultStage 526 (take at <unknown>:0) finished in 0.641 s
17/12/19 16:28:37 INFO DAGScheduler: Job 252 finished: take at <unknown>:0, took 0.647069 s
17/12/19 16:28:37 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:28:37 INFO DAGScheduler: Got job 253 (take at <unknown>:0) with 1 output partitions
17/12/19 16:28:37 INFO DAGScheduler: Final stage: ResultStage 528 (take at <unknown>:0)
17/12/19 16:28:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 527)
17/12/19 16:28:37 INFO DAGScheduler: Missing parents: List()
17/12/19 16:28:37 INFO DAGScheduler: Submitting ResultStage 528 (WorkerRDD[1123] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:28:37 INFO MemoryStore: Block broadcast_353 stored as values in memory (estimated size 240.2 KB, free 1995.6 MB)
17/12/19 16:28:37 INFO MemoryStore: Block broadcast_353_piece0 stored as bytes in memory (estimated size 94.5 KB, free 1995.6 MB)
17/12/19 16:28:37 INFO BlockManagerInfo: Added broadcast_353_piece0 in memory on 127.0.0.1:53618 (size: 94.5 KB, free: 2003.6 MB)
17/12/19 16:28:37 INFO SparkContext: Created broadcast 353 from broadcast at DAGScheduler.scala:996
17/12/19 16:28:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 528 (WorkerRDD[1123] at RDD at rdd.scala:18)
17/12/19 16:28:37 INFO TaskSchedulerImpl: Adding task set 528.0 with 1 tasks
17/12/19 16:28:37 INFO TaskSetManager: Starting task 0.0 in stage 528.0 (TID 391, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:28:37 INFO Executor: Running task 0.0 in stage 528.0 (TID 391)
17/12/19 16:28:37 INFO BlockManager: Found block rdd_1111_1 locally
17/12/19 16:28:38 INFO MemoryStore: Block rdd_1123_1 stored as values in memory (estimated size 80.0 B, free 1995.6 MB)
17/12/19 16:28:38 INFO BlockManagerInfo: Added rdd_1123_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.6 MB)
17/12/19 16:28:38 INFO Executor: Finished task 0.0 in stage 528.0 (TID 391). 2400 bytes result sent to driver
17/12/19 16:28:38 INFO TaskSetManager: Finished task 0.0 in stage 528.0 (TID 391) in 653 ms on localhost (executor driver) (1/1)
17/12/19 16:28:38 INFO TaskSchedulerImpl: Removed TaskSet 528.0, whose tasks have all completed, from pool 
17/12/19 16:28:38 INFO DAGScheduler: ResultStage 528 (take at <unknown>:0) finished in 0.653 s
17/12/19 16:28:38 INFO DAGScheduler: Job 253 finished: take at <unknown>:0, took 0.647550 s
17/12/19 16:28:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:38 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e831ed3c7e
17/12/19 16:28:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e831ed3c7e` AS `zzz99`
WHERE (0 = 1)
17/12/19 16:28:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e831ed3c7e`
LIMIT 10
17/12/19 16:28:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:28:38 INFO DAGScheduler: Got job 254 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:28:38 INFO DAGScheduler: Final stage: ResultStage 530 (collect at utils.scala:196)
17/12/19 16:28:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 529)
17/12/19 16:28:38 INFO DAGScheduler: Missing parents: List()
17/12/19 16:28:38 INFO DAGScheduler: Submitting ResultStage 530 (MapPartitionsRDD[1127] at collect at utils.scala:196), which has no missing parents
17/12/19 16:28:38 INFO MemoryStore: Block broadcast_354 stored as values in memory (estimated size 241.2 KB, free 1995.3 MB)
17/12/19 16:28:38 INFO MemoryStore: Block broadcast_354_piece0 stored as bytes in memory (estimated size 95.3 KB, free 1995.2 MB)
17/12/19 16:28:38 INFO BlockManagerInfo: Added broadcast_354_piece0 in memory on 127.0.0.1:53618 (size: 95.3 KB, free: 2003.5 MB)
17/12/19 16:28:38 INFO SparkContext: Created broadcast 354 from broadcast at DAGScheduler.scala:996
17/12/19 16:28:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 530 (MapPartitionsRDD[1127] at collect at utils.scala:196)
17/12/19 16:28:38 INFO TaskSchedulerImpl: Adding task set 530.0 with 1 tasks
17/12/19 16:28:38 INFO TaskSetManager: Starting task 0.0 in stage 530.0 (TID 392, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:28:38 INFO Executor: Running task 0.0 in stage 530.0 (TID 392)
17/12/19 16:28:38 INFO BlockManager: Found block rdd_1123_0 locally
17/12/19 16:28:38 INFO Executor: Finished task 0.0 in stage 530.0 (TID 392). 1479 bytes result sent to driver
17/12/19 16:28:38 INFO TaskSetManager: Finished task 0.0 in stage 530.0 (TID 392) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:28:38 INFO TaskSchedulerImpl: Removed TaskSet 530.0, whose tasks have all completed, from pool 
17/12/19 16:28:38 INFO DAGScheduler: ResultStage 530 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:28:38 INFO DAGScheduler: Job 254 finished: collect at utils.scala:196, took 0.008033 s
17/12/19 16:28:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:28:38 INFO DAGScheduler: Got job 255 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:28:38 INFO DAGScheduler: Final stage: ResultStage 532 (collect at utils.scala:196)
17/12/19 16:28:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 531)
17/12/19 16:28:38 INFO DAGScheduler: Missing parents: List()
17/12/19 16:28:38 INFO DAGScheduler: Submitting ResultStage 532 (MapPartitionsRDD[1127] at collect at utils.scala:196), which has no missing parents
17/12/19 16:28:38 INFO MemoryStore: Block broadcast_355 stored as values in memory (estimated size 241.2 KB, free 1995.0 MB)
17/12/19 16:28:38 INFO MemoryStore: Block broadcast_355_piece0 stored as bytes in memory (estimated size 95.3 KB, free 1994.9 MB)
17/12/19 16:28:38 INFO BlockManagerInfo: Added broadcast_355_piece0 in memory on 127.0.0.1:53618 (size: 95.3 KB, free: 2003.4 MB)
17/12/19 16:28:38 INFO SparkContext: Created broadcast 355 from broadcast at DAGScheduler.scala:996
17/12/19 16:28:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 532 (MapPartitionsRDD[1127] at collect at utils.scala:196)
17/12/19 16:28:38 INFO TaskSchedulerImpl: Adding task set 532.0 with 1 tasks
17/12/19 16:28:38 INFO TaskSetManager: Starting task 0.0 in stage 532.0 (TID 393, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:28:38 INFO Executor: Running task 0.0 in stage 532.0 (TID 393)
17/12/19 16:28:38 INFO BlockManager: Found block rdd_1123_1 locally
17/12/19 16:28:38 INFO Executor: Finished task 0.0 in stage 532.0 (TID 393). 1479 bytes result sent to driver
17/12/19 16:28:38 INFO TaskSetManager: Finished task 0.0 in stage 532.0 (TID 393) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:28:38 INFO TaskSchedulerImpl: Removed TaskSet 532.0, whose tasks have all completed, from pool 
17/12/19 16:28:38 INFO DAGScheduler: ResultStage 532 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:28:38 INFO DAGScheduler: Job 255 finished: collect at utils.scala:196, took 0.007541 s
17/12/19 16:28:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:28:38 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:28:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:28:38 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:28:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:28:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:28:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:28:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:28:38 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:28:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:28:38 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:28:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:28:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:28:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:28:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:28:38 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:28:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:28:38 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:28:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:28:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:28:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:28:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:28:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:28:38 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:28:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:28:38 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:28:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:28:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:28:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:30:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:30:16 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:30:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:30:16 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:30:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:30:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:30:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:30:16 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 16:30:16 INFO DAGScheduler: Got job 256 (collect at utils.scala:58) with 1 output partitions
17/12/19 16:30:16 INFO DAGScheduler: Final stage: ResultStage 533 (collect at utils.scala:58)
17/12/19 16:30:16 INFO DAGScheduler: Parents of final stage: List()
17/12/19 16:30:16 INFO DAGScheduler: Missing parents: List()
17/12/19 16:30:16 INFO DAGScheduler: Submitting ResultStage 533 (MapPartitionsRDD[1137] at map at utils.scala:55), which has no missing parents
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_356 stored as values in memory (estimated size 8.7 KB, free 1994.9 MB)
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_356_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1994.9 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Added broadcast_356_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.4 MB)
17/12/19 16:30:16 INFO SparkContext: Created broadcast 356 from broadcast at DAGScheduler.scala:996
17/12/19 16:30:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 533 (MapPartitionsRDD[1137] at map at utils.scala:55)
17/12/19 16:30:16 INFO TaskSchedulerImpl: Adding task set 533.0 with 1 tasks
17/12/19 16:30:16 INFO TaskSetManager: Starting task 0.0 in stage 533.0 (TID 394, localhost, executor driver, partition 0, PROCESS_LOCAL, 9090 bytes)
17/12/19 16:30:16 INFO Executor: Running task 0.0 in stage 533.0 (TID 394)
17/12/19 16:30:16 INFO Executor: Finished task 0.0 in stage 533.0 (TID 394). 1971 bytes result sent to driver
17/12/19 16:30:16 INFO TaskSetManager: Finished task 0.0 in stage 533.0 (TID 394) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:30:16 INFO TaskSchedulerImpl: Removed TaskSet 533.0, whose tasks have all completed, from pool 
17/12/19 16:30:16 INFO DAGScheduler: ResultStage 533 (collect at utils.scala:58) finished in 0.000 s
17/12/19 16:30:16 INFO DAGScheduler: Job 256 finished: collect at utils.scala:58, took 0.007303 s
17/12/19 16:30:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17682
17/12/19 16:30:16 INFO BlockManagerInfo: Removed broadcast_344_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2003.4 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Removed broadcast_345_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.4 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Removed broadcast_346_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.4 MB)
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17919
17/12/19 16:30:16 INFO BlockManagerInfo: Removed broadcast_347_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.5 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Removed broadcast_348_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.5 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Removed broadcast_349_piece0 on 127.0.0.1:53618 in memory (size: 48.9 KB, free: 2003.5 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Removed broadcast_350_piece0 on 127.0.0.1:53618 in memory (size: 48.9 KB, free: 2003.6 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Removed broadcast_351_piece0 on 127.0.0.1:53618 in memory (size: 52.4 KB, free: 2003.6 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Removed broadcast_352_piece0 on 127.0.0.1:53618 in memory (size: 94.5 KB, free: 2003.7 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Removed broadcast_353_piece0 on 127.0.0.1:53618 in memory (size: 94.5 KB, free: 2003.8 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Removed broadcast_354_piece0 on 127.0.0.1:53618 in memory (size: 95.3 KB, free: 2003.9 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Removed broadcast_355_piece0 on 127.0.0.1:53618 in memory (size: 95.3 KB, free: 2004.0 MB)
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 18419
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 18420
17/12/19 16:30:16 INFO BlockManagerInfo: Removed broadcast_356_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.0 MB)
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17681
17/12/19 16:30:16 INFO BlockManagerInfo: Removed broadcast_342_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2004.0 MB)
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17731
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17732
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17738
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17739
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17740
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17741
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17742
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17743
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17744
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17745
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17746
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17747
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17748
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17749
17/12/19 16:30:16 INFO ContextCleaner: Cleaned accumulator 17750
17/12/19 16:30:16 INFO ContextCleaner: Cleaned shuffle 73
17/12/19 16:30:16 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:30:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:16 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 16:30:16 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 16:30:16 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 16:30:16 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 16:30:16 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 16:30:16 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_357 stored as values in memory (estimated size 293.7 KB, free 1996.5 MB)
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_357_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1996.5 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Added broadcast_357_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2004.0 MB)
17/12/19 16:30:16 INFO SparkContext: Created broadcast 357 from sql at <unknown>:0
17/12/19 16:30:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 16:30:16 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 16:30:16 INFO DAGScheduler: Registering RDD 1141 (sql at <unknown>:0)
17/12/19 16:30:16 INFO DAGScheduler: Registering RDD 1146 (sql at <unknown>:0)
17/12/19 16:30:16 INFO DAGScheduler: Got job 257 (sql at <unknown>:0) with 1 output partitions
17/12/19 16:30:16 INFO DAGScheduler: Final stage: ResultStage 536 (sql at <unknown>:0)
17/12/19 16:30:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 535)
17/12/19 16:30:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 535)
17/12/19 16:30:16 INFO DAGScheduler: Submitting ShuffleMapStage 534 (MapPartitionsRDD[1141] at sql at <unknown>:0), which has no missing parents
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_358 stored as values in memory (estimated size 12.1 KB, free 1996.5 MB)
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_358_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1996.5 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Added broadcast_358_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2004.0 MB)
17/12/19 16:30:16 INFO SparkContext: Created broadcast 358 from broadcast at DAGScheduler.scala:996
17/12/19 16:30:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 534 (MapPartitionsRDD[1141] at sql at <unknown>:0)
17/12/19 16:30:16 INFO TaskSchedulerImpl: Adding task set 534.0 with 1 tasks
17/12/19 16:30:16 INFO TaskSetManager: Starting task 0.0 in stage 534.0 (TID 395, localhost, executor driver, partition 0, PROCESS_LOCAL, 6680 bytes)
17/12/19 16:30:16 INFO Executor: Running task 0.0 in stage 534.0 (TID 395)
17/12/19 16:30:16 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_3baf1748836e2400a3ac9e122684bbd7448bc6e8270a94d4f0cd4de971434110.csv, range: 0-466, partition values: [empty row]
17/12/19 16:30:16 INFO Executor: Finished task 0.0 in stage 534.0 (TID 395). 1632 bytes result sent to driver
17/12/19 16:30:16 INFO TaskSetManager: Finished task 0.0 in stage 534.0 (TID 395) in 31 ms on localhost (executor driver) (1/1)
17/12/19 16:30:16 INFO TaskSchedulerImpl: Removed TaskSet 534.0, whose tasks have all completed, from pool 
17/12/19 16:30:16 INFO DAGScheduler: ShuffleMapStage 534 (sql at <unknown>:0) finished in 0.031 s
17/12/19 16:30:16 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:30:16 INFO DAGScheduler: running: Set()
17/12/19 16:30:16 INFO DAGScheduler: waiting: Set(ShuffleMapStage 535, ResultStage 536)
17/12/19 16:30:16 INFO DAGScheduler: failed: Set()
17/12/19 16:30:16 INFO DAGScheduler: Submitting ShuffleMapStage 535 (MapPartitionsRDD[1146] at sql at <unknown>:0), which has no missing parents
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_359 stored as values in memory (estimated size 11.9 KB, free 1996.5 MB)
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_359_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1996.5 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Added broadcast_359_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2003.9 MB)
17/12/19 16:30:16 INFO SparkContext: Created broadcast 359 from broadcast at DAGScheduler.scala:996
17/12/19 16:30:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 535 (MapPartitionsRDD[1146] at sql at <unknown>:0)
17/12/19 16:30:16 INFO TaskSchedulerImpl: Adding task set 535.0 with 2 tasks
17/12/19 16:30:16 INFO TaskSetManager: Starting task 0.0 in stage 535.0 (TID 396, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 16:30:16 INFO TaskSetManager: Starting task 1.0 in stage 535.0 (TID 397, localhost, executor driver, partition 1, ANY, 5946 bytes)
17/12/19 16:30:16 INFO Executor: Running task 0.0 in stage 535.0 (TID 396)
17/12/19 16:30:16 INFO Executor: Running task 1.0 in stage 535.0 (TID 397)
17/12/19 16:30:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:30:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:30:16 INFO MemoryStore: Block rdd_1143_0 stored as values in memory (estimated size 544.0 B, free 1996.5 MB)
17/12/19 16:30:16 INFO MemoryStore: Block rdd_1143_1 stored as values in memory (estimated size 544.0 B, free 1996.5 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Added rdd_1143_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2003.9 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Added rdd_1143_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2003.9 MB)
17/12/19 16:30:16 INFO Executor: Finished task 0.0 in stage 535.0 (TID 396). 2906 bytes result sent to driver
17/12/19 16:30:16 INFO TaskSetManager: Finished task 0.0 in stage 535.0 (TID 396) in 0 ms on localhost (executor driver) (1/2)
17/12/19 16:30:16 INFO Executor: Finished task 1.0 in stage 535.0 (TID 397). 2906 bytes result sent to driver
17/12/19 16:30:16 INFO TaskSetManager: Finished task 1.0 in stage 535.0 (TID 397) in 0 ms on localhost (executor driver) (2/2)
17/12/19 16:30:16 INFO TaskSchedulerImpl: Removed TaskSet 535.0, whose tasks have all completed, from pool 
17/12/19 16:30:16 INFO DAGScheduler: ShuffleMapStage 535 (sql at <unknown>:0) finished in 0.000 s
17/12/19 16:30:16 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:30:16 INFO DAGScheduler: running: Set()
17/12/19 16:30:16 INFO DAGScheduler: waiting: Set(ResultStage 536)
17/12/19 16:30:16 INFO DAGScheduler: failed: Set()
17/12/19 16:30:16 INFO DAGScheduler: Submitting ResultStage 536 (MapPartitionsRDD[1149] at sql at <unknown>:0), which has no missing parents
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_360 stored as values in memory (estimated size 7.0 KB, free 1996.5 MB)
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_360_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1996.5 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Added broadcast_360_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2003.9 MB)
17/12/19 16:30:16 INFO SparkContext: Created broadcast 360 from broadcast at DAGScheduler.scala:996
17/12/19 16:30:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 536 (MapPartitionsRDD[1149] at sql at <unknown>:0)
17/12/19 16:30:16 INFO TaskSchedulerImpl: Adding task set 536.0 with 1 tasks
17/12/19 16:30:16 INFO TaskSetManager: Starting task 0.0 in stage 536.0 (TID 398, localhost, executor driver, partition 0, ANY, 5957 bytes)
17/12/19 16:30:16 INFO Executor: Running task 0.0 in stage 536.0 (TID 398)
17/12/19 16:30:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:30:16 INFO Executor: Finished task 0.0 in stage 536.0 (TID 398). 1707 bytes result sent to driver
17/12/19 16:30:16 INFO TaskSetManager: Finished task 0.0 in stage 536.0 (TID 398) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:30:16 INFO TaskSchedulerImpl: Removed TaskSet 536.0, whose tasks have all completed, from pool 
17/12/19 16:30:16 INFO DAGScheduler: ResultStage 536 (sql at <unknown>:0) finished in 0.000 s
17/12/19 16:30:16 INFO DAGScheduler: Job 257 finished: sql at <unknown>:0, took 0.040297 s
17/12/19 16:30:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:16 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 16:30:16 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:30:16 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 75 is 145 bytes
17/12/19 16:30:16 INFO DAGScheduler: Registering RDD 1153 (collect at utils.scala:196)
17/12/19 16:30:16 INFO DAGScheduler: Got job 258 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:30:16 INFO DAGScheduler: Final stage: ResultStage 539 (collect at utils.scala:196)
17/12/19 16:30:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 538)
17/12/19 16:30:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 538)
17/12/19 16:30:16 INFO DAGScheduler: Submitting ShuffleMapStage 538 (MapPartitionsRDD[1153] at collect at utils.scala:196), which has no missing parents
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_361 stored as values in memory (estimated size 11.9 KB, free 1996.4 MB)
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_361_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1996.4 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Added broadcast_361_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2003.9 MB)
17/12/19 16:30:16 INFO SparkContext: Created broadcast 361 from broadcast at DAGScheduler.scala:996
17/12/19 16:30:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 538 (MapPartitionsRDD[1153] at collect at utils.scala:196)
17/12/19 16:30:16 INFO TaskSchedulerImpl: Adding task set 538.0 with 2 tasks
17/12/19 16:30:16 INFO TaskSetManager: Starting task 0.0 in stage 538.0 (TID 399, localhost, executor driver, partition 0, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:30:16 INFO TaskSetManager: Starting task 1.0 in stage 538.0 (TID 400, localhost, executor driver, partition 1, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:30:16 INFO Executor: Running task 0.0 in stage 538.0 (TID 399)
17/12/19 16:30:16 INFO Executor: Running task 1.0 in stage 538.0 (TID 400)
17/12/19 16:30:16 INFO BlockManager: Found block rdd_1143_0 locally
17/12/19 16:30:16 INFO BlockManager: Found block rdd_1143_1 locally
17/12/19 16:30:16 INFO Executor: Finished task 1.0 in stage 538.0 (TID 400). 1792 bytes result sent to driver
17/12/19 16:30:16 INFO TaskSetManager: Finished task 1.0 in stage 538.0 (TID 400) in 0 ms on localhost (executor driver) (1/2)
17/12/19 16:30:16 INFO Executor: Finished task 0.0 in stage 538.0 (TID 399). 1792 bytes result sent to driver
17/12/19 16:30:16 INFO TaskSetManager: Finished task 0.0 in stage 538.0 (TID 399) in 16 ms on localhost (executor driver) (2/2)
17/12/19 16:30:16 INFO TaskSchedulerImpl: Removed TaskSet 538.0, whose tasks have all completed, from pool 
17/12/19 16:30:16 INFO DAGScheduler: ShuffleMapStage 538 (collect at utils.scala:196) finished in 0.016 s
17/12/19 16:30:16 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:30:16 INFO DAGScheduler: running: Set()
17/12/19 16:30:16 INFO DAGScheduler: waiting: Set(ResultStage 539)
17/12/19 16:30:16 INFO DAGScheduler: failed: Set()
17/12/19 16:30:16 INFO DAGScheduler: Submitting ResultStage 539 (MapPartitionsRDD[1156] at collect at utils.scala:196), which has no missing parents
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_362 stored as values in memory (estimated size 7.0 KB, free 1996.4 MB)
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_362_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1996.4 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Added broadcast_362_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2003.9 MB)
17/12/19 16:30:16 INFO SparkContext: Created broadcast 362 from broadcast at DAGScheduler.scala:996
17/12/19 16:30:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 539 (MapPartitionsRDD[1156] at collect at utils.scala:196)
17/12/19 16:30:16 INFO TaskSchedulerImpl: Adding task set 539.0 with 1 tasks
17/12/19 16:30:16 INFO TaskSetManager: Starting task 0.0 in stage 539.0 (TID 401, localhost, executor driver, partition 0, ANY, 5949 bytes)
17/12/19 16:30:16 INFO Executor: Running task 0.0 in stage 539.0 (TID 401)
17/12/19 16:30:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:30:16 INFO Executor: Finished task 0.0 in stage 539.0 (TID 401). 1884 bytes result sent to driver
17/12/19 16:30:16 INFO TaskSetManager: Finished task 0.0 in stage 539.0 (TID 401) in 15 ms on localhost (executor driver) (1/1)
17/12/19 16:30:16 INFO TaskSchedulerImpl: Removed TaskSet 539.0, whose tasks have all completed, from pool 
17/12/19 16:30:16 INFO DAGScheduler: ResultStage 539 (collect at utils.scala:196) finished in 0.015 s
17/12/19 16:30:16 INFO DAGScheduler: Job 258 finished: collect at utils.scala:196, took 0.022477 s
17/12/19 16:30:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz100`
WHERE (0 = 1)
17/12/19 16:30:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:16 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `rrqloxzoan`
17/12/19 16:30:16 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:30:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz101`
WHERE (0 = 1)
17/12/19 16:30:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:30:16 INFO CodeGenerator: Code generated in 7.261264 ms
17/12/19 16:30:16 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:30:16 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 75 is 145 bytes
17/12/19 16:30:16 INFO DAGScheduler: Got job 259 (take at <unknown>:0) with 1 output partitions
17/12/19 16:30:16 INFO DAGScheduler: Final stage: ResultStage 541 (take at <unknown>:0)
17/12/19 16:30:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 540)
17/12/19 16:30:16 INFO DAGScheduler: Missing parents: List()
17/12/19 16:30:16 INFO DAGScheduler: Submitting ResultStage 541 (WorkerRDD[1162] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_363 stored as values in memory (estimated size 124.7 KB, free 1996.3 MB)
17/12/19 16:30:16 INFO MemoryStore: Block broadcast_363_piece0 stored as bytes in memory (estimated size 48.9 KB, free 1996.3 MB)
17/12/19 16:30:16 INFO BlockManagerInfo: Added broadcast_363_piece0 in memory on 127.0.0.1:53618 (size: 48.9 KB, free: 2003.9 MB)
17/12/19 16:30:16 INFO SparkContext: Created broadcast 363 from broadcast at DAGScheduler.scala:996
17/12/19 16:30:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 541 (WorkerRDD[1162] at RDD at rdd.scala:18)
17/12/19 16:30:16 INFO TaskSchedulerImpl: Adding task set 541.0 with 1 tasks
17/12/19 16:30:16 INFO TaskSetManager: Starting task 0.0 in stage 541.0 (TID 402, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:30:16 INFO Executor: Running task 0.0 in stage 541.0 (TID 402)
17/12/19 16:30:16 INFO BlockManager: Found block rdd_1143_0 locally
17/12/19 16:30:17 INFO MemoryStore: Block rdd_1162_0 stored as values in memory (estimated size 608.0 B, free 1996.3 MB)
17/12/19 16:30:17 INFO BlockManagerInfo: Added rdd_1162_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 16:30:17 INFO Executor: Finished task 0.0 in stage 541.0 (TID 402). 2509 bytes result sent to driver
17/12/19 16:30:17 INFO TaskSetManager: Finished task 0.0 in stage 541.0 (TID 402) in 734 ms on localhost (executor driver) (1/1)
17/12/19 16:30:17 INFO TaskSchedulerImpl: Removed TaskSet 541.0, whose tasks have all completed, from pool 
17/12/19 16:30:17 INFO DAGScheduler: ResultStage 541 (take at <unknown>:0) finished in 0.734 s
17/12/19 16:30:17 INFO DAGScheduler: Job 259 finished: take at <unknown>:0, took 0.740112 s
17/12/19 16:30:17 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:30:17 INFO DAGScheduler: Got job 260 (take at <unknown>:0) with 1 output partitions
17/12/19 16:30:17 INFO DAGScheduler: Final stage: ResultStage 543 (take at <unknown>:0)
17/12/19 16:30:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 542)
17/12/19 16:30:17 INFO DAGScheduler: Missing parents: List()
17/12/19 16:30:17 INFO DAGScheduler: Submitting ResultStage 543 (WorkerRDD[1162] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:30:17 INFO MemoryStore: Block broadcast_364 stored as values in memory (estimated size 124.7 KB, free 1996.1 MB)
17/12/19 16:30:17 INFO MemoryStore: Block broadcast_364_piece0 stored as bytes in memory (estimated size 48.9 KB, free 1996.1 MB)
17/12/19 16:30:17 INFO BlockManagerInfo: Added broadcast_364_piece0 in memory on 127.0.0.1:53618 (size: 48.9 KB, free: 2003.8 MB)
17/12/19 16:30:17 INFO SparkContext: Created broadcast 364 from broadcast at DAGScheduler.scala:996
17/12/19 16:30:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 543 (WorkerRDD[1162] at RDD at rdd.scala:18)
17/12/19 16:30:17 INFO TaskSchedulerImpl: Adding task set 543.0 with 1 tasks
17/12/19 16:30:17 INFO TaskSetManager: Starting task 0.0 in stage 543.0 (TID 403, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:30:17 INFO Executor: Running task 0.0 in stage 543.0 (TID 403)
17/12/19 16:30:17 INFO BlockManager: Found block rdd_1143_1 locally
17/12/19 16:30:17 INFO MemoryStore: Block rdd_1162_1 stored as values in memory (estimated size 608.0 B, free 1996.1 MB)
17/12/19 16:30:17 INFO BlockManagerInfo: Added rdd_1162_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.8 MB)
17/12/19 16:30:17 INFO Executor: Finished task 0.0 in stage 543.0 (TID 403). 2509 bytes result sent to driver
17/12/19 16:30:17 INFO TaskSetManager: Finished task 0.0 in stage 543.0 (TID 403) in 634 ms on localhost (executor driver) (1/1)
17/12/19 16:30:17 INFO TaskSchedulerImpl: Removed TaskSet 543.0, whose tasks have all completed, from pool 
17/12/19 16:30:17 INFO DAGScheduler: ResultStage 543 (take at <unknown>:0) finished in 0.634 s
17/12/19 16:30:17 INFO DAGScheduler: Job 260 finished: take at <unknown>:0, took 0.639262 s
17/12/19 16:30:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:17 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e8375cf4b
17/12/19 16:30:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8375cf4b` AS `zzz102`
WHERE (0 = 1)
17/12/19 16:30:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8375cf4b`
17/12/19 16:30:17 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:30:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz103`
WHERE (0 = 1)
17/12/19 16:30:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:17 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 16:30:17 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:30:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz104`
WHERE (0 = 1)
17/12/19 16:30:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:30:17 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:30:17 INFO DAGScheduler: Got job 261 (collect at utils.scala:196) with 2 output partitions
17/12/19 16:30:17 INFO DAGScheduler: Final stage: ResultStage 545 (collect at utils.scala:196)
17/12/19 16:30:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 544)
17/12/19 16:30:17 INFO DAGScheduler: Missing parents: List()
17/12/19 16:30:17 INFO DAGScheduler: Submitting ResultStage 545 (MapPartitionsRDD[1169] at collect at utils.scala:196), which has no missing parents
17/12/19 16:30:17 INFO MemoryStore: Block broadcast_365 stored as values in memory (estimated size 132.2 KB, free 1996.0 MB)
17/12/19 16:30:17 INFO MemoryStore: Block broadcast_365_piece0 stored as bytes in memory (estimated size 52.4 KB, free 1995.9 MB)
17/12/19 16:30:17 INFO BlockManagerInfo: Added broadcast_365_piece0 in memory on 127.0.0.1:53618 (size: 52.4 KB, free: 2003.8 MB)
17/12/19 16:30:17 INFO SparkContext: Created broadcast 365 from broadcast at DAGScheduler.scala:996
17/12/19 16:30:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 545 (MapPartitionsRDD[1169] at collect at utils.scala:196)
17/12/19 16:30:17 INFO TaskSchedulerImpl: Adding task set 545.0 with 2 tasks
17/12/19 16:30:17 INFO TaskSetManager: Starting task 0.0 in stage 545.0 (TID 404, localhost, executor driver, partition 0, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:30:17 INFO TaskSetManager: Starting task 1.0 in stage 545.0 (TID 405, localhost, executor driver, partition 1, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:30:17 INFO Executor: Running task 0.0 in stage 545.0 (TID 404)
17/12/19 16:30:17 INFO Executor: Running task 1.0 in stage 545.0 (TID 405)
17/12/19 16:30:17 INFO BlockManager: Found block rdd_1162_1 locally
17/12/19 16:30:17 INFO BlockManager: Found block rdd_1162_0 locally
17/12/19 16:30:17 INFO Executor: Finished task 0.0 in stage 545.0 (TID 404). 1605 bytes result sent to driver
17/12/19 16:30:17 INFO Executor: Finished task 1.0 in stage 545.0 (TID 405). 1605 bytes result sent to driver
17/12/19 16:30:17 INFO TaskSetManager: Finished task 0.0 in stage 545.0 (TID 404) in 6 ms on localhost (executor driver) (1/2)
17/12/19 16:30:17 INFO TaskSetManager: Finished task 1.0 in stage 545.0 (TID 405) in 6 ms on localhost (executor driver) (2/2)
17/12/19 16:30:17 INFO TaskSchedulerImpl: Removed TaskSet 545.0, whose tasks have all completed, from pool 
17/12/19 16:30:17 INFO DAGScheduler: ResultStage 545 (collect at utils.scala:196) finished in 0.006 s
17/12/19 16:30:17 INFO DAGScheduler: Job 261 finished: collect at utils.scala:196, took 0.009040 s
17/12/19 16:30:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:30:17 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:30:17 INFO DAGScheduler: Got job 262 (take at <unknown>:0) with 1 output partitions
17/12/19 16:30:17 INFO DAGScheduler: Final stage: ResultStage 547 (take at <unknown>:0)
17/12/19 16:30:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 546)
17/12/19 16:30:17 INFO DAGScheduler: Missing parents: List()
17/12/19 16:30:17 INFO DAGScheduler: Submitting ResultStage 547 (WorkerRDD[1174] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:30:17 INFO MemoryStore: Block broadcast_366 stored as values in memory (estimated size 240.1 KB, free 1995.7 MB)
17/12/19 16:30:17 INFO MemoryStore: Block broadcast_366_piece0 stored as bytes in memory (estimated size 94.5 KB, free 1995.6 MB)
17/12/19 16:30:17 INFO BlockManagerInfo: Added broadcast_366_piece0 in memory on 127.0.0.1:53618 (size: 94.5 KB, free: 2003.7 MB)
17/12/19 16:30:17 INFO SparkContext: Created broadcast 366 from broadcast at DAGScheduler.scala:996
17/12/19 16:30:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 547 (WorkerRDD[1174] at RDD at rdd.scala:18)
17/12/19 16:30:17 INFO TaskSchedulerImpl: Adding task set 547.0 with 1 tasks
17/12/19 16:30:17 INFO TaskSetManager: Starting task 0.0 in stage 547.0 (TID 406, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:30:17 INFO Executor: Running task 0.0 in stage 547.0 (TID 406)
17/12/19 16:30:17 INFO BlockManager: Found block rdd_1162_0 locally
17/12/19 16:30:18 INFO MemoryStore: Block rdd_1174_0 stored as values in memory (estimated size 80.0 B, free 1995.6 MB)
17/12/19 16:30:18 INFO BlockManagerInfo: Added rdd_1174_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.7 MB)
17/12/19 16:30:18 INFO Executor: Finished task 0.0 in stage 547.0 (TID 406). 2400 bytes result sent to driver
17/12/19 16:30:18 INFO TaskSetManager: Finished task 0.0 in stage 547.0 (TID 406) in 645 ms on localhost (executor driver) (1/1)
17/12/19 16:30:18 INFO TaskSchedulerImpl: Removed TaskSet 547.0, whose tasks have all completed, from pool 
17/12/19 16:30:18 INFO DAGScheduler: ResultStage 547 (take at <unknown>:0) finished in 0.645 s
17/12/19 16:30:18 INFO DAGScheduler: Job 262 finished: take at <unknown>:0, took 0.650683 s
17/12/19 16:30:18 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:30:18 INFO DAGScheduler: Got job 263 (take at <unknown>:0) with 1 output partitions
17/12/19 16:30:18 INFO DAGScheduler: Final stage: ResultStage 549 (take at <unknown>:0)
17/12/19 16:30:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 548)
17/12/19 16:30:18 INFO DAGScheduler: Missing parents: List()
17/12/19 16:30:18 INFO DAGScheduler: Submitting ResultStage 549 (WorkerRDD[1174] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:30:18 INFO MemoryStore: Block broadcast_367 stored as values in memory (estimated size 240.1 KB, free 1995.3 MB)
17/12/19 16:30:18 INFO MemoryStore: Block broadcast_367_piece0 stored as bytes in memory (estimated size 94.5 KB, free 1995.3 MB)
17/12/19 16:30:18 INFO BlockManagerInfo: Added broadcast_367_piece0 in memory on 127.0.0.1:53618 (size: 94.5 KB, free: 2003.6 MB)
17/12/19 16:30:18 INFO SparkContext: Created broadcast 367 from broadcast at DAGScheduler.scala:996
17/12/19 16:30:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 549 (WorkerRDD[1174] at RDD at rdd.scala:18)
17/12/19 16:30:18 INFO TaskSchedulerImpl: Adding task set 549.0 with 1 tasks
17/12/19 16:30:18 INFO TaskSetManager: Starting task 0.0 in stage 549.0 (TID 407, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:30:18 INFO Executor: Running task 0.0 in stage 549.0 (TID 407)
17/12/19 16:30:18 INFO BlockManager: Found block rdd_1162_1 locally
17/12/19 16:30:19 INFO MemoryStore: Block rdd_1174_1 stored as values in memory (estimated size 80.0 B, free 1995.3 MB)
17/12/19 16:30:19 INFO BlockManagerInfo: Added rdd_1174_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.6 MB)
17/12/19 16:30:19 INFO Executor: Finished task 0.0 in stage 549.0 (TID 407). 2479 bytes result sent to driver
17/12/19 16:30:19 INFO TaskSetManager: Finished task 0.0 in stage 549.0 (TID 407) in 622 ms on localhost (executor driver) (1/1)
17/12/19 16:30:19 INFO TaskSchedulerImpl: Removed TaskSet 549.0, whose tasks have all completed, from pool 
17/12/19 16:30:19 INFO DAGScheduler: ResultStage 549 (take at <unknown>:0) finished in 0.622 s
17/12/19 16:30:19 INFO DAGScheduler: Job 263 finished: take at <unknown>:0, took 0.624200 s
17/12/19 16:30:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:19 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e86bb531b
17/12/19 16:30:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e86bb531b` AS `zzz105`
WHERE (0 = 1)
17/12/19 16:30:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e86bb531b`
LIMIT 10
17/12/19 16:30:19 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:30:19 INFO DAGScheduler: Got job 264 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:30:19 INFO DAGScheduler: Final stage: ResultStage 551 (collect at utils.scala:196)
17/12/19 16:30:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 550)
17/12/19 16:30:19 INFO DAGScheduler: Missing parents: List()
17/12/19 16:30:19 INFO DAGScheduler: Submitting ResultStage 551 (MapPartitionsRDD[1178] at collect at utils.scala:196), which has no missing parents
17/12/19 16:30:19 INFO MemoryStore: Block broadcast_368 stored as values in memory (estimated size 241.2 KB, free 1995.0 MB)
17/12/19 16:30:19 INFO MemoryStore: Block broadcast_368_piece0 stored as bytes in memory (estimated size 95.2 KB, free 1994.9 MB)
17/12/19 16:30:19 INFO BlockManagerInfo: Added broadcast_368_piece0 in memory on 127.0.0.1:53618 (size: 95.2 KB, free: 2003.5 MB)
17/12/19 16:30:19 INFO SparkContext: Created broadcast 368 from broadcast at DAGScheduler.scala:996
17/12/19 16:30:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 551 (MapPartitionsRDD[1178] at collect at utils.scala:196)
17/12/19 16:30:19 INFO TaskSchedulerImpl: Adding task set 551.0 with 1 tasks
17/12/19 16:30:19 INFO TaskSetManager: Starting task 0.0 in stage 551.0 (TID 408, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:30:19 INFO Executor: Running task 0.0 in stage 551.0 (TID 408)
17/12/19 16:30:19 INFO BlockManager: Found block rdd_1174_0 locally
17/12/19 16:30:19 INFO Executor: Finished task 0.0 in stage 551.0 (TID 408). 1637 bytes result sent to driver
17/12/19 16:30:19 INFO TaskSetManager: Finished task 0.0 in stage 551.0 (TID 408) in 16 ms on localhost (executor driver) (1/1)
17/12/19 16:30:19 INFO TaskSchedulerImpl: Removed TaskSet 551.0, whose tasks have all completed, from pool 
17/12/19 16:30:19 INFO DAGScheduler: ResultStage 551 (collect at utils.scala:196) finished in 0.017 s
17/12/19 16:30:19 INFO DAGScheduler: Job 264 finished: collect at utils.scala:196, took 0.007254 s
17/12/19 16:30:19 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:30:19 INFO DAGScheduler: Got job 265 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:30:19 INFO DAGScheduler: Final stage: ResultStage 553 (collect at utils.scala:196)
17/12/19 16:30:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 552)
17/12/19 16:30:19 INFO DAGScheduler: Missing parents: List()
17/12/19 16:30:19 INFO DAGScheduler: Submitting ResultStage 553 (MapPartitionsRDD[1178] at collect at utils.scala:196), which has no missing parents
17/12/19 16:30:19 INFO MemoryStore: Block broadcast_369 stored as values in memory (estimated size 241.2 KB, free 1994.7 MB)
17/12/19 16:30:19 INFO MemoryStore: Block broadcast_369_piece0 stored as bytes in memory (estimated size 95.2 KB, free 1994.6 MB)
17/12/19 16:30:19 INFO BlockManagerInfo: Added broadcast_369_piece0 in memory on 127.0.0.1:53618 (size: 95.2 KB, free: 2003.4 MB)
17/12/19 16:30:19 INFO SparkContext: Created broadcast 369 from broadcast at DAGScheduler.scala:996
17/12/19 16:30:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 553 (MapPartitionsRDD[1178] at collect at utils.scala:196)
17/12/19 16:30:19 INFO TaskSchedulerImpl: Adding task set 553.0 with 1 tasks
17/12/19 16:30:19 INFO TaskSetManager: Starting task 0.0 in stage 553.0 (TID 409, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:30:19 INFO Executor: Running task 0.0 in stage 553.0 (TID 409)
17/12/19 16:30:19 INFO BlockManager: Found block rdd_1174_1 locally
17/12/19 16:30:19 INFO Executor: Finished task 0.0 in stage 553.0 (TID 409). 1479 bytes result sent to driver
17/12/19 16:30:19 INFO TaskSetManager: Finished task 0.0 in stage 553.0 (TID 409) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:30:19 INFO TaskSchedulerImpl: Removed TaskSet 553.0, whose tasks have all completed, from pool 
17/12/19 16:30:19 INFO DAGScheduler: ResultStage 553 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:30:19 INFO DAGScheduler: Job 265 finished: collect at utils.scala:196, took 0.006612 s
17/12/19 16:30:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:30:19 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:30:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:30:19 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:30:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:30:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:30:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:30:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:30:19 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:30:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:30:19 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:30:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:30:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:30:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:30:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:30:19 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:30:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:30:19 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:30:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:30:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:30:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:30:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:30:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:30:19 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:30:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:30:19 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:30:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:30:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:30:19 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:31:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:31:59 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:31:59 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:31:59 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:31:59 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:31:59 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:31:59 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:31:59 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:32:00 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 16:32:00 INFO DAGScheduler: Got job 266 (collect at utils.scala:58) with 1 output partitions
17/12/19 16:32:00 INFO DAGScheduler: Final stage: ResultStage 554 (collect at utils.scala:58)
17/12/19 16:32:00 INFO DAGScheduler: Parents of final stage: List()
17/12/19 16:32:00 INFO DAGScheduler: Missing parents: List()
17/12/19 16:32:00 INFO DAGScheduler: Submitting ResultStage 554 (MapPartitionsRDD[1188] at map at utils.scala:55), which has no missing parents
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_370 stored as values in memory (estimated size 8.7 KB, free 1994.6 MB)
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_370_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1994.6 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Added broadcast_370_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.4 MB)
17/12/19 16:32:00 INFO SparkContext: Created broadcast 370 from broadcast at DAGScheduler.scala:996
17/12/19 16:32:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 554 (MapPartitionsRDD[1188] at map at utils.scala:55)
17/12/19 16:32:00 INFO TaskSchedulerImpl: Adding task set 554.0 with 1 tasks
17/12/19 16:32:00 INFO TaskSetManager: Starting task 0.0 in stage 554.0 (TID 410, localhost, executor driver, partition 0, PROCESS_LOCAL, 9232 bytes)
17/12/19 16:32:00 INFO Executor: Running task 0.0 in stage 554.0 (TID 410)
17/12/19 16:32:00 INFO Executor: Finished task 0.0 in stage 554.0 (TID 410). 2112 bytes result sent to driver
17/12/19 16:32:00 INFO TaskSetManager: Finished task 0.0 in stage 554.0 (TID 410) in 16 ms on localhost (executor driver) (1/1)
17/12/19 16:32:00 INFO TaskSchedulerImpl: Removed TaskSet 554.0, whose tasks have all completed, from pool 
17/12/19 16:32:00 INFO DAGScheduler: ResultStage 554 (collect at utils.scala:58) finished in 0.016 s
17/12/19 16:32:00 INFO DAGScheduler: Job 266 finished: collect at utils.scala:58, took 0.005990 s
17/12/19 16:32:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:00 INFO BlockManagerInfo: Removed broadcast_370_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2003.4 MB)
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18469
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18470
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18476
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18477
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18478
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18479
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18480
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18481
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18482
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18483
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18484
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18485
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18486
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18487
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18488
17/12/19 16:32:00 INFO ContextCleaner: Cleaned shuffle 76
17/12/19 16:32:00 INFO BlockManagerInfo: Removed broadcast_358_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2003.4 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Removed broadcast_359_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.4 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Removed broadcast_360_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.4 MB)
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 18657
17/12/19 16:32:00 INFO BlockManagerInfo: Removed broadcast_361_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.4 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Removed broadcast_362_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.4 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Removed broadcast_363_piece0 on 127.0.0.1:53618 in memory (size: 48.9 KB, free: 2003.5 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Removed broadcast_364_piece0 on 127.0.0.1:53618 in memory (size: 48.9 KB, free: 2003.5 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Removed broadcast_365_piece0 on 127.0.0.1:53618 in memory (size: 52.4 KB, free: 2003.6 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Removed broadcast_366_piece0 on 127.0.0.1:53618 in memory (size: 94.5 KB, free: 2003.7 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Removed broadcast_367_piece0 on 127.0.0.1:53618 in memory (size: 94.5 KB, free: 2003.8 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Removed broadcast_368_piece0 on 127.0.0.1:53618 in memory (size: 95.2 KB, free: 2003.9 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Removed broadcast_369_piece0 on 127.0.0.1:53618 in memory (size: 95.2 KB, free: 2004.0 MB)
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 19157
17/12/19 16:32:00 INFO ContextCleaner: Cleaned accumulator 19158
17/12/19 16:32:00 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:32:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:00 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 16:32:00 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 16:32:00 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 16:32:00 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 16:32:00 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 16:32:00 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_371 stored as values in memory (estimated size 293.7 KB, free 1996.2 MB)
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_371_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1996.2 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Added broadcast_371_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2003.9 MB)
17/12/19 16:32:00 INFO SparkContext: Created broadcast 371 from sql at <unknown>:0
17/12/19 16:32:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 16:32:00 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 16:32:00 INFO DAGScheduler: Registering RDD 1192 (sql at <unknown>:0)
17/12/19 16:32:00 INFO DAGScheduler: Registering RDD 1197 (sql at <unknown>:0)
17/12/19 16:32:00 INFO DAGScheduler: Got job 267 (sql at <unknown>:0) with 1 output partitions
17/12/19 16:32:00 INFO DAGScheduler: Final stage: ResultStage 557 (sql at <unknown>:0)
17/12/19 16:32:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 556)
17/12/19 16:32:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 556)
17/12/19 16:32:00 INFO DAGScheduler: Submitting ShuffleMapStage 555 (MapPartitionsRDD[1192] at sql at <unknown>:0), which has no missing parents
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_372 stored as values in memory (estimated size 12.1 KB, free 1996.2 MB)
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_372_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1996.2 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Added broadcast_372_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2003.9 MB)
17/12/19 16:32:00 INFO SparkContext: Created broadcast 372 from broadcast at DAGScheduler.scala:996
17/12/19 16:32:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 555 (MapPartitionsRDD[1192] at sql at <unknown>:0)
17/12/19 16:32:00 INFO TaskSchedulerImpl: Adding task set 555.0 with 1 tasks
17/12/19 16:32:00 INFO TaskSetManager: Starting task 0.0 in stage 555.0 (TID 411, localhost, executor driver, partition 0, PROCESS_LOCAL, 6680 bytes)
17/12/19 16:32:00 INFO Executor: Running task 0.0 in stage 555.0 (TID 411)
17/12/19 16:32:00 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_1b1a21383f3b7a20c4ee4a2f30d7a444f4addcb2d6c83f9768acc3fb1be3a1ee.csv, range: 0-448, partition values: [empty row]
17/12/19 16:32:00 INFO Executor: Finished task 0.0 in stage 555.0 (TID 411). 1553 bytes result sent to driver
17/12/19 16:32:00 INFO TaskSetManager: Finished task 0.0 in stage 555.0 (TID 411) in 16 ms on localhost (executor driver) (1/1)
17/12/19 16:32:00 INFO TaskSchedulerImpl: Removed TaskSet 555.0, whose tasks have all completed, from pool 
17/12/19 16:32:00 INFO DAGScheduler: ShuffleMapStage 555 (sql at <unknown>:0) finished in 0.016 s
17/12/19 16:32:00 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:32:00 INFO DAGScheduler: running: Set()
17/12/19 16:32:00 INFO DAGScheduler: waiting: Set(ShuffleMapStage 556, ResultStage 557)
17/12/19 16:32:00 INFO DAGScheduler: failed: Set()
17/12/19 16:32:00 INFO DAGScheduler: Submitting ShuffleMapStage 556 (MapPartitionsRDD[1197] at sql at <unknown>:0), which has no missing parents
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_373 stored as values in memory (estimated size 11.9 KB, free 1996.2 MB)
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_373_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1996.2 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Added broadcast_373_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2003.9 MB)
17/12/19 16:32:00 INFO SparkContext: Created broadcast 373 from broadcast at DAGScheduler.scala:996
17/12/19 16:32:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 556 (MapPartitionsRDD[1197] at sql at <unknown>:0)
17/12/19 16:32:00 INFO TaskSchedulerImpl: Adding task set 556.0 with 2 tasks
17/12/19 16:32:00 INFO TaskSetManager: Starting task 0.0 in stage 556.0 (TID 412, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 16:32:00 INFO TaskSetManager: Starting task 1.0 in stage 556.0 (TID 413, localhost, executor driver, partition 1, ANY, 5946 bytes)
17/12/19 16:32:00 INFO Executor: Running task 0.0 in stage 556.0 (TID 412)
17/12/19 16:32:00 INFO Executor: Running task 1.0 in stage 556.0 (TID 413)
17/12/19 16:32:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:32:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:32:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:32:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:32:00 INFO MemoryStore: Block rdd_1194_0 stored as values in memory (estimated size 544.0 B, free 1996.2 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Added rdd_1194_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2003.9 MB)
17/12/19 16:32:00 INFO MemoryStore: Block rdd_1194_1 stored as values in memory (estimated size 544.0 B, free 1996.2 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Added rdd_1194_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2003.9 MB)
17/12/19 16:32:00 INFO Executor: Finished task 1.0 in stage 556.0 (TID 413). 3064 bytes result sent to driver
17/12/19 16:32:00 INFO TaskSetManager: Finished task 1.0 in stage 556.0 (TID 413) in 15 ms on localhost (executor driver) (1/2)
17/12/19 16:32:00 INFO Executor: Finished task 0.0 in stage 556.0 (TID 412). 3064 bytes result sent to driver
17/12/19 16:32:00 INFO TaskSetManager: Finished task 0.0 in stage 556.0 (TID 412) in 15 ms on localhost (executor driver) (2/2)
17/12/19 16:32:00 INFO TaskSchedulerImpl: Removed TaskSet 556.0, whose tasks have all completed, from pool 
17/12/19 16:32:00 INFO DAGScheduler: ShuffleMapStage 556 (sql at <unknown>:0) finished in 0.015 s
17/12/19 16:32:00 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:32:00 INFO DAGScheduler: running: Set()
17/12/19 16:32:00 INFO DAGScheduler: waiting: Set(ResultStage 557)
17/12/19 16:32:00 INFO DAGScheduler: failed: Set()
17/12/19 16:32:00 INFO DAGScheduler: Submitting ResultStage 557 (MapPartitionsRDD[1200] at sql at <unknown>:0), which has no missing parents
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_374 stored as values in memory (estimated size 7.0 KB, free 1996.1 MB)
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_374_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1996.1 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Added broadcast_374_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2003.9 MB)
17/12/19 16:32:00 INFO SparkContext: Created broadcast 374 from broadcast at DAGScheduler.scala:996
17/12/19 16:32:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 557 (MapPartitionsRDD[1200] at sql at <unknown>:0)
17/12/19 16:32:00 INFO TaskSchedulerImpl: Adding task set 557.0 with 1 tasks
17/12/19 16:32:00 INFO TaskSetManager: Starting task 0.0 in stage 557.0 (TID 414, localhost, executor driver, partition 0, ANY, 5957 bytes)
17/12/19 16:32:00 INFO Executor: Running task 0.0 in stage 557.0 (TID 414)
17/12/19 16:32:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:32:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:32:00 INFO Executor: Finished task 0.0 in stage 557.0 (TID 414). 1707 bytes result sent to driver
17/12/19 16:32:00 INFO TaskSetManager: Finished task 0.0 in stage 557.0 (TID 414) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:32:00 INFO TaskSchedulerImpl: Removed TaskSet 557.0, whose tasks have all completed, from pool 
17/12/19 16:32:00 INFO DAGScheduler: ResultStage 557 (sql at <unknown>:0) finished in 0.000 s
17/12/19 16:32:00 INFO DAGScheduler: Job 267 finished: sql at <unknown>:0, took 0.043803 s
17/12/19 16:32:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:00 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 16:32:00 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:32:00 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 78 is 145 bytes
17/12/19 16:32:00 INFO DAGScheduler: Registering RDD 1204 (collect at utils.scala:196)
17/12/19 16:32:00 INFO DAGScheduler: Got job 268 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:32:00 INFO DAGScheduler: Final stage: ResultStage 560 (collect at utils.scala:196)
17/12/19 16:32:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 559)
17/12/19 16:32:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 559)
17/12/19 16:32:00 INFO DAGScheduler: Submitting ShuffleMapStage 559 (MapPartitionsRDD[1204] at collect at utils.scala:196), which has no missing parents
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_375 stored as values in memory (estimated size 11.9 KB, free 1996.1 MB)
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_375_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1996.1 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Added broadcast_375_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2003.9 MB)
17/12/19 16:32:00 INFO SparkContext: Created broadcast 375 from broadcast at DAGScheduler.scala:996
17/12/19 16:32:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 559 (MapPartitionsRDD[1204] at collect at utils.scala:196)
17/12/19 16:32:00 INFO TaskSchedulerImpl: Adding task set 559.0 with 2 tasks
17/12/19 16:32:00 INFO TaskSetManager: Starting task 0.0 in stage 559.0 (TID 415, localhost, executor driver, partition 0, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:32:00 INFO TaskSetManager: Starting task 1.0 in stage 559.0 (TID 416, localhost, executor driver, partition 1, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:32:00 INFO Executor: Running task 0.0 in stage 559.0 (TID 415)
17/12/19 16:32:00 INFO Executor: Running task 1.0 in stage 559.0 (TID 416)
17/12/19 16:32:00 INFO BlockManager: Found block rdd_1194_0 locally
17/12/19 16:32:00 INFO BlockManager: Found block rdd_1194_1 locally
17/12/19 16:32:00 INFO Executor: Finished task 0.0 in stage 559.0 (TID 415). 1792 bytes result sent to driver
17/12/19 16:32:00 INFO TaskSetManager: Finished task 0.0 in stage 559.0 (TID 415) in 0 ms on localhost (executor driver) (1/2)
17/12/19 16:32:00 INFO Executor: Finished task 1.0 in stage 559.0 (TID 416). 1792 bytes result sent to driver
17/12/19 16:32:00 INFO TaskSetManager: Finished task 1.0 in stage 559.0 (TID 416) in 0 ms on localhost (executor driver) (2/2)
17/12/19 16:32:00 INFO TaskSchedulerImpl: Removed TaskSet 559.0, whose tasks have all completed, from pool 
17/12/19 16:32:00 INFO DAGScheduler: ShuffleMapStage 559 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:32:00 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:32:00 INFO DAGScheduler: running: Set()
17/12/19 16:32:00 INFO DAGScheduler: waiting: Set(ResultStage 560)
17/12/19 16:32:00 INFO DAGScheduler: failed: Set()
17/12/19 16:32:00 INFO DAGScheduler: Submitting ResultStage 560 (MapPartitionsRDD[1207] at collect at utils.scala:196), which has no missing parents
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_376 stored as values in memory (estimated size 7.0 KB, free 1996.1 MB)
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_376_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1996.1 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Added broadcast_376_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2003.9 MB)
17/12/19 16:32:00 INFO SparkContext: Created broadcast 376 from broadcast at DAGScheduler.scala:996
17/12/19 16:32:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 560 (MapPartitionsRDD[1207] at collect at utils.scala:196)
17/12/19 16:32:00 INFO TaskSchedulerImpl: Adding task set 560.0 with 1 tasks
17/12/19 16:32:00 INFO TaskSetManager: Starting task 0.0 in stage 560.0 (TID 417, localhost, executor driver, partition 0, ANY, 5949 bytes)
17/12/19 16:32:00 INFO Executor: Running task 0.0 in stage 560.0 (TID 417)
17/12/19 16:32:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:32:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:32:00 INFO Executor: Finished task 0.0 in stage 560.0 (TID 417). 1707 bytes result sent to driver
17/12/19 16:32:00 INFO DAGScheduler: ResultStage 560 (collect at utils.scala:196) finished in 0.016 s
17/12/19 16:32:00 INFO DAGScheduler: Job 268 finished: collect at utils.scala:196, took 0.017221 s
17/12/19 16:32:00 INFO TaskSetManager: Finished task 0.0 in stage 560.0 (TID 417) in 16 ms on localhost (executor driver) (1/1)
17/12/19 16:32:00 INFO TaskSchedulerImpl: Removed TaskSet 560.0, whose tasks have all completed, from pool 
17/12/19 16:32:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz106`
WHERE (0 = 1)
17/12/19 16:32:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:00 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `cqjtuyxyse`
17/12/19 16:32:00 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:32:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz107`
WHERE (0 = 1)
17/12/19 16:32:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:32:00 INFO CodeGenerator: Code generated in 7.351884 ms
17/12/19 16:32:00 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:32:00 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 78 is 145 bytes
17/12/19 16:32:00 INFO DAGScheduler: Got job 269 (take at <unknown>:0) with 1 output partitions
17/12/19 16:32:00 INFO DAGScheduler: Final stage: ResultStage 562 (take at <unknown>:0)
17/12/19 16:32:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 561)
17/12/19 16:32:00 INFO DAGScheduler: Missing parents: List()
17/12/19 16:32:00 INFO DAGScheduler: Submitting ResultStage 562 (WorkerRDD[1213] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_377 stored as values in memory (estimated size 125.2 KB, free 1996.0 MB)
17/12/19 16:32:00 INFO MemoryStore: Block broadcast_377_piece0 stored as bytes in memory (estimated size 49.1 KB, free 1995.9 MB)
17/12/19 16:32:00 INFO BlockManagerInfo: Added broadcast_377_piece0 in memory on 127.0.0.1:53618 (size: 49.1 KB, free: 2003.9 MB)
17/12/19 16:32:00 INFO SparkContext: Created broadcast 377 from broadcast at DAGScheduler.scala:996
17/12/19 16:32:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 562 (WorkerRDD[1213] at RDD at rdd.scala:18)
17/12/19 16:32:00 INFO TaskSchedulerImpl: Adding task set 562.0 with 1 tasks
17/12/19 16:32:00 INFO TaskSetManager: Starting task 0.0 in stage 562.0 (TID 418, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:32:00 INFO Executor: Running task 0.0 in stage 562.0 (TID 418)
17/12/19 16:32:00 INFO BlockManager: Found block rdd_1194_0 locally
17/12/19 16:32:01 INFO MemoryStore: Block rdd_1213_0 stored as values in memory (estimated size 608.0 B, free 1995.9 MB)
17/12/19 16:32:01 INFO BlockManagerInfo: Added rdd_1213_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.9 MB)
17/12/19 16:32:01 INFO Executor: Finished task 0.0 in stage 562.0 (TID 418). 2509 bytes result sent to driver
17/12/19 16:32:01 INFO TaskSetManager: Finished task 0.0 in stage 562.0 (TID 418) in 631 ms on localhost (executor driver) (1/1)
17/12/19 16:32:01 INFO TaskSchedulerImpl: Removed TaskSet 562.0, whose tasks have all completed, from pool 
17/12/19 16:32:01 INFO DAGScheduler: ResultStage 562 (take at <unknown>:0) finished in 0.631 s
17/12/19 16:32:01 INFO DAGScheduler: Job 269 finished: take at <unknown>:0, took 0.637810 s
17/12/19 16:32:01 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:32:01 INFO DAGScheduler: Got job 270 (take at <unknown>:0) with 1 output partitions
17/12/19 16:32:01 INFO DAGScheduler: Final stage: ResultStage 564 (take at <unknown>:0)
17/12/19 16:32:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 563)
17/12/19 16:32:01 INFO DAGScheduler: Missing parents: List()
17/12/19 16:32:01 INFO DAGScheduler: Submitting ResultStage 564 (WorkerRDD[1213] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:32:01 INFO MemoryStore: Block broadcast_378 stored as values in memory (estimated size 125.2 KB, free 1995.8 MB)
17/12/19 16:32:01 INFO MemoryStore: Block broadcast_378_piece0 stored as bytes in memory (estimated size 49.1 KB, free 1995.8 MB)
17/12/19 16:32:01 INFO BlockManagerInfo: Added broadcast_378_piece0 in memory on 127.0.0.1:53618 (size: 49.1 KB, free: 2003.8 MB)
17/12/19 16:32:01 INFO SparkContext: Created broadcast 378 from broadcast at DAGScheduler.scala:996
17/12/19 16:32:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 564 (WorkerRDD[1213] at RDD at rdd.scala:18)
17/12/19 16:32:01 INFO TaskSchedulerImpl: Adding task set 564.0 with 1 tasks
17/12/19 16:32:01 INFO TaskSetManager: Starting task 0.0 in stage 564.0 (TID 419, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:32:01 INFO Executor: Running task 0.0 in stage 564.0 (TID 419)
17/12/19 16:32:01 INFO BlockManager: Found block rdd_1194_1 locally
17/12/19 16:32:01 INFO MemoryStore: Block rdd_1213_1 stored as values in memory (estimated size 608.0 B, free 1995.8 MB)
17/12/19 16:32:01 INFO BlockManagerInfo: Added rdd_1213_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.8 MB)
17/12/19 16:32:01 INFO Executor: Finished task 0.0 in stage 564.0 (TID 419). 2588 bytes result sent to driver
17/12/19 16:32:01 INFO TaskSetManager: Finished task 0.0 in stage 564.0 (TID 419) in 693 ms on localhost (executor driver) (1/1)
17/12/19 16:32:01 INFO TaskSchedulerImpl: Removed TaskSet 564.0, whose tasks have all completed, from pool 
17/12/19 16:32:01 INFO DAGScheduler: ResultStage 564 (take at <unknown>:0) finished in 0.693 s
17/12/19 16:32:01 INFO DAGScheduler: Job 270 finished: take at <unknown>:0, took 0.686320 s
17/12/19 16:32:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:01 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e823ee4f34
17/12/19 16:32:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e823ee4f34` AS `zzz108`
WHERE (0 = 1)
17/12/19 16:32:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e823ee4f34`
17/12/19 16:32:01 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:32:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz109`
WHERE (0 = 1)
17/12/19 16:32:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:01 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 16:32:01 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:32:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz110`
WHERE (0 = 1)
17/12/19 16:32:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:32:01 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:32:01 INFO DAGScheduler: Got job 271 (collect at utils.scala:196) with 2 output partitions
17/12/19 16:32:01 INFO DAGScheduler: Final stage: ResultStage 566 (collect at utils.scala:196)
17/12/19 16:32:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 565)
17/12/19 16:32:01 INFO DAGScheduler: Missing parents: List()
17/12/19 16:32:01 INFO DAGScheduler: Submitting ResultStage 566 (MapPartitionsRDD[1220] at collect at utils.scala:196), which has no missing parents
17/12/19 16:32:01 INFO MemoryStore: Block broadcast_379 stored as values in memory (estimated size 132.8 KB, free 1995.6 MB)
17/12/19 16:32:01 INFO MemoryStore: Block broadcast_379_piece0 stored as bytes in memory (estimated size 52.5 KB, free 1995.6 MB)
17/12/19 16:32:01 INFO BlockManagerInfo: Added broadcast_379_piece0 in memory on 127.0.0.1:53618 (size: 52.5 KB, free: 2003.8 MB)
17/12/19 16:32:01 INFO SparkContext: Created broadcast 379 from broadcast at DAGScheduler.scala:996
17/12/19 16:32:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 566 (MapPartitionsRDD[1220] at collect at utils.scala:196)
17/12/19 16:32:01 INFO TaskSchedulerImpl: Adding task set 566.0 with 2 tasks
17/12/19 16:32:01 INFO TaskSetManager: Starting task 0.0 in stage 566.0 (TID 420, localhost, executor driver, partition 0, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:32:01 INFO TaskSetManager: Starting task 1.0 in stage 566.0 (TID 421, localhost, executor driver, partition 1, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:32:01 INFO Executor: Running task 0.0 in stage 566.0 (TID 420)
17/12/19 16:32:01 INFO Executor: Running task 1.0 in stage 566.0 (TID 421)
17/12/19 16:32:01 INFO BlockManager: Found block rdd_1213_0 locally
17/12/19 16:32:01 INFO BlockManager: Found block rdd_1213_1 locally
17/12/19 16:32:01 INFO Executor: Finished task 0.0 in stage 566.0 (TID 420). 1439 bytes result sent to driver
17/12/19 16:32:01 INFO Executor: Finished task 1.0 in stage 566.0 (TID 421). 1450 bytes result sent to driver
17/12/19 16:32:01 INFO TaskSetManager: Finished task 0.0 in stage 566.0 (TID 420) in 0 ms on localhost (executor driver) (1/2)
17/12/19 16:32:01 INFO TaskSetManager: Finished task 1.0 in stage 566.0 (TID 421) in 0 ms on localhost (executor driver) (2/2)
17/12/19 16:32:01 INFO TaskSchedulerImpl: Removed TaskSet 566.0, whose tasks have all completed, from pool 
17/12/19 16:32:01 INFO DAGScheduler: ResultStage 566 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:32:01 INFO DAGScheduler: Job 271 finished: collect at utils.scala:196, took 0.010414 s
17/12/19 16:32:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:32:01 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:32:01 INFO DAGScheduler: Got job 272 (take at <unknown>:0) with 1 output partitions
17/12/19 16:32:01 INFO DAGScheduler: Final stage: ResultStage 568 (take at <unknown>:0)
17/12/19 16:32:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 567)
17/12/19 16:32:01 INFO DAGScheduler: Missing parents: List()
17/12/19 16:32:01 INFO DAGScheduler: Submitting ResultStage 568 (WorkerRDD[1225] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:32:01 INFO MemoryStore: Block broadcast_380 stored as values in memory (estimated size 241.2 KB, free 1995.4 MB)
17/12/19 16:32:01 INFO MemoryStore: Block broadcast_380_piece0 stored as bytes in memory (estimated size 95.0 KB, free 1995.3 MB)
17/12/19 16:32:01 INFO BlockManagerInfo: Added broadcast_380_piece0 in memory on 127.0.0.1:53618 (size: 95.0 KB, free: 2003.7 MB)
17/12/19 16:32:01 INFO SparkContext: Created broadcast 380 from broadcast at DAGScheduler.scala:996
17/12/19 16:32:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 568 (WorkerRDD[1225] at RDD at rdd.scala:18)
17/12/19 16:32:01 INFO TaskSchedulerImpl: Adding task set 568.0 with 1 tasks
17/12/19 16:32:01 INFO TaskSetManager: Starting task 0.0 in stage 568.0 (TID 422, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:32:01 INFO Executor: Running task 0.0 in stage 568.0 (TID 422)
17/12/19 16:32:01 INFO BlockManager: Found block rdd_1213_0 locally
17/12/19 16:32:02 INFO MemoryStore: Block rdd_1225_0 stored as values in memory (estimated size 80.0 B, free 1995.3 MB)
17/12/19 16:32:02 INFO BlockManagerInfo: Added rdd_1225_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.7 MB)
17/12/19 16:32:02 INFO Executor: Finished task 0.0 in stage 568.0 (TID 422). 2400 bytes result sent to driver
17/12/19 16:32:02 INFO TaskSetManager: Finished task 0.0 in stage 568.0 (TID 422) in 649 ms on localhost (executor driver) (1/1)
17/12/19 16:32:02 INFO TaskSchedulerImpl: Removed TaskSet 568.0, whose tasks have all completed, from pool 
17/12/19 16:32:02 INFO DAGScheduler: ResultStage 568 (take at <unknown>:0) finished in 0.649 s
17/12/19 16:32:02 INFO DAGScheduler: Job 272 finished: take at <unknown>:0, took 0.646352 s
17/12/19 16:32:02 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:32:02 INFO DAGScheduler: Got job 273 (take at <unknown>:0) with 1 output partitions
17/12/19 16:32:02 INFO DAGScheduler: Final stage: ResultStage 570 (take at <unknown>:0)
17/12/19 16:32:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 569)
17/12/19 16:32:02 INFO DAGScheduler: Missing parents: List()
17/12/19 16:32:02 INFO DAGScheduler: Submitting ResultStage 570 (WorkerRDD[1225] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:32:02 INFO MemoryStore: Block broadcast_381 stored as values in memory (estimated size 241.2 KB, free 1995.0 MB)
17/12/19 16:32:02 INFO MemoryStore: Block broadcast_381_piece0 stored as bytes in memory (estimated size 95.0 KB, free 1994.9 MB)
17/12/19 16:32:02 INFO BlockManagerInfo: Added broadcast_381_piece0 in memory on 127.0.0.1:53618 (size: 95.0 KB, free: 2003.6 MB)
17/12/19 16:32:02 INFO SparkContext: Created broadcast 381 from broadcast at DAGScheduler.scala:996
17/12/19 16:32:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 570 (WorkerRDD[1225] at RDD at rdd.scala:18)
17/12/19 16:32:02 INFO TaskSchedulerImpl: Adding task set 570.0 with 1 tasks
17/12/19 16:32:02 INFO TaskSetManager: Starting task 0.0 in stage 570.0 (TID 423, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:32:02 INFO Executor: Running task 0.0 in stage 570.0 (TID 423)
17/12/19 16:32:02 INFO BlockManager: Found block rdd_1213_1 locally
17/12/19 16:32:03 INFO MemoryStore: Block rdd_1225_1 stored as values in memory (estimated size 80.0 B, free 1994.9 MB)
17/12/19 16:32:03 INFO BlockManagerInfo: Added rdd_1225_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.6 MB)
17/12/19 16:32:03 INFO Executor: Finished task 0.0 in stage 570.0 (TID 423). 2400 bytes result sent to driver
17/12/19 16:32:03 INFO TaskSetManager: Finished task 0.0 in stage 570.0 (TID 423) in 634 ms on localhost (executor driver) (1/1)
17/12/19 16:32:03 INFO TaskSchedulerImpl: Removed TaskSet 570.0, whose tasks have all completed, from pool 
17/12/19 16:32:03 INFO DAGScheduler: ResultStage 570 (take at <unknown>:0) finished in 0.634 s
17/12/19 16:32:03 INFO DAGScheduler: Job 273 finished: take at <unknown>:0, took 0.646851 s
17/12/19 16:32:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:03 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e8591352bb
17/12/19 16:32:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8591352bb` AS `zzz111`
WHERE (0 = 1)
17/12/19 16:32:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8591352bb`
LIMIT 10
17/12/19 16:32:03 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:32:03 INFO DAGScheduler: Got job 274 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:32:03 INFO DAGScheduler: Final stage: ResultStage 572 (collect at utils.scala:196)
17/12/19 16:32:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 571)
17/12/19 16:32:03 INFO DAGScheduler: Missing parents: List()
17/12/19 16:32:03 INFO DAGScheduler: Submitting ResultStage 572 (MapPartitionsRDD[1229] at collect at utils.scala:196), which has no missing parents
17/12/19 16:32:03 INFO MemoryStore: Block broadcast_382 stored as values in memory (estimated size 242.2 KB, free 1994.7 MB)
17/12/19 16:32:03 INFO MemoryStore: Block broadcast_382_piece0 stored as bytes in memory (estimated size 95.8 KB, free 1994.6 MB)
17/12/19 16:32:03 INFO BlockManagerInfo: Added broadcast_382_piece0 in memory on 127.0.0.1:53618 (size: 95.8 KB, free: 2003.5 MB)
17/12/19 16:32:03 INFO SparkContext: Created broadcast 382 from broadcast at DAGScheduler.scala:996
17/12/19 16:32:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 572 (MapPartitionsRDD[1229] at collect at utils.scala:196)
17/12/19 16:32:03 INFO TaskSchedulerImpl: Adding task set 572.0 with 1 tasks
17/12/19 16:32:03 INFO TaskSetManager: Starting task 0.0 in stage 572.0 (TID 424, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:32:03 INFO Executor: Running task 0.0 in stage 572.0 (TID 424)
17/12/19 16:32:03 INFO BlockManager: Found block rdd_1225_0 locally
17/12/19 16:32:03 INFO Executor: Finished task 0.0 in stage 572.0 (TID 424). 1637 bytes result sent to driver
17/12/19 16:32:03 INFO TaskSetManager: Finished task 0.0 in stage 572.0 (TID 424) in 15 ms on localhost (executor driver) (1/1)
17/12/19 16:32:03 INFO TaskSchedulerImpl: Removed TaskSet 572.0, whose tasks have all completed, from pool 
17/12/19 16:32:03 INFO DAGScheduler: ResultStage 572 (collect at utils.scala:196) finished in 0.015 s
17/12/19 16:32:03 INFO DAGScheduler: Job 274 finished: collect at utils.scala:196, took 0.007045 s
17/12/19 16:32:03 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:32:03 INFO DAGScheduler: Got job 275 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:32:03 INFO DAGScheduler: Final stage: ResultStage 574 (collect at utils.scala:196)
17/12/19 16:32:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 573)
17/12/19 16:32:03 INFO DAGScheduler: Missing parents: List()
17/12/19 16:32:03 INFO DAGScheduler: Submitting ResultStage 574 (MapPartitionsRDD[1229] at collect at utils.scala:196), which has no missing parents
17/12/19 16:32:03 INFO MemoryStore: Block broadcast_383 stored as values in memory (estimated size 242.2 KB, free 1994.4 MB)
17/12/19 16:32:03 INFO MemoryStore: Block broadcast_383_piece0 stored as bytes in memory (estimated size 95.8 KB, free 1994.3 MB)
17/12/19 16:32:03 INFO BlockManagerInfo: Added broadcast_383_piece0 in memory on 127.0.0.1:53618 (size: 95.8 KB, free: 2003.4 MB)
17/12/19 16:32:03 INFO SparkContext: Created broadcast 383 from broadcast at DAGScheduler.scala:996
17/12/19 16:32:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 574 (MapPartitionsRDD[1229] at collect at utils.scala:196)
17/12/19 16:32:03 INFO TaskSchedulerImpl: Adding task set 574.0 with 1 tasks
17/12/19 16:32:03 INFO TaskSetManager: Starting task 0.0 in stage 574.0 (TID 425, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:32:03 INFO Executor: Running task 0.0 in stage 574.0 (TID 425)
17/12/19 16:32:03 INFO BlockManager: Found block rdd_1225_1 locally
17/12/19 16:32:03 INFO Executor: Finished task 0.0 in stage 574.0 (TID 425). 1479 bytes result sent to driver
17/12/19 16:32:03 INFO TaskSetManager: Finished task 0.0 in stage 574.0 (TID 425) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:32:03 INFO TaskSchedulerImpl: Removed TaskSet 574.0, whose tasks have all completed, from pool 
17/12/19 16:32:03 INFO DAGScheduler: ResultStage 574 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:32:03 INFO DAGScheduler: Job 275 finished: collect at utils.scala:196, took 0.007538 s
17/12/19 16:32:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:32:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:32:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:32:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:32:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:32:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:32:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:32:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:32:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:32:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:32:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:32:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:32:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:32:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:32:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:32:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:32:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:32:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:32:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:32:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:32:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:32:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:32:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:32:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:32:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:32:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:32:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:32:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:32:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:39:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:39:13 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:39:13 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:39:13 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:39:13 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:39:13 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:39:13 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:39:13 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 16:39:13 INFO DAGScheduler: Got job 276 (collect at utils.scala:58) with 1 output partitions
17/12/19 16:39:13 INFO DAGScheduler: Final stage: ResultStage 575 (collect at utils.scala:58)
17/12/19 16:39:13 INFO DAGScheduler: Parents of final stage: List()
17/12/19 16:39:13 INFO DAGScheduler: Missing parents: List()
17/12/19 16:39:13 INFO DAGScheduler: Submitting ResultStage 575 (MapPartitionsRDD[1239] at map at utils.scala:55), which has no missing parents
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_384 stored as values in memory (estimated size 8.7 KB, free 1994.3 MB)
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_384_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1994.3 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Added broadcast_384_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.4 MB)
17/12/19 16:39:13 INFO SparkContext: Created broadcast 384 from broadcast at DAGScheduler.scala:996
17/12/19 16:39:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 575 (MapPartitionsRDD[1239] at map at utils.scala:55)
17/12/19 16:39:13 INFO TaskSchedulerImpl: Adding task set 575.0 with 1 tasks
17/12/19 16:39:13 INFO TaskSetManager: Starting task 0.0 in stage 575.0 (TID 426, localhost, executor driver, partition 0, PROCESS_LOCAL, 9376 bytes)
17/12/19 16:39:13 INFO Executor: Running task 0.0 in stage 575.0 (TID 426)
17/12/19 16:39:13 INFO Executor: Finished task 0.0 in stage 575.0 (TID 426). 2081 bytes result sent to driver
17/12/19 16:39:13 INFO TaskSetManager: Finished task 0.0 in stage 575.0 (TID 426) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:39:13 INFO TaskSchedulerImpl: Removed TaskSet 575.0, whose tasks have all completed, from pool 
17/12/19 16:39:13 INFO DAGScheduler: ResultStage 575 (collect at utils.scala:58) finished in 0.000 s
17/12/19 16:39:13 INFO DAGScheduler: Job 276 finished: collect at utils.scala:58, took 0.006354 s
17/12/19 16:39:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:13 INFO BlockManagerInfo: Removed broadcast_384_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2003.4 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Removed broadcast_373_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.4 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Removed broadcast_374_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.4 MB)
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19395
17/12/19 16:39:13 INFO BlockManagerInfo: Removed broadcast_375_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.4 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Removed broadcast_376_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.4 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Removed broadcast_377_piece0 on 127.0.0.1:53618 in memory (size: 49.1 KB, free: 2003.5 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Removed broadcast_378_piece0 on 127.0.0.1:53618 in memory (size: 49.1 KB, free: 2003.5 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Removed broadcast_379_piece0 on 127.0.0.1:53618 in memory (size: 52.5 KB, free: 2003.6 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Removed broadcast_380_piece0 on 127.0.0.1:53618 in memory (size: 95.0 KB, free: 2003.6 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Removed broadcast_381_piece0 on 127.0.0.1:53618 in memory (size: 95.0 KB, free: 2003.7 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Removed broadcast_382_piece0 on 127.0.0.1:53618 in memory (size: 95.8 KB, free: 2003.8 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Removed broadcast_383_piece0 on 127.0.0.1:53618 in memory (size: 95.8 KB, free: 2003.9 MB)
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19895
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19896
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19207
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19208
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19214
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19215
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19216
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19217
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19218
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19219
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19220
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19221
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19222
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19223
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19224
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19225
17/12/19 16:39:13 INFO ContextCleaner: Cleaned accumulator 19226
17/12/19 16:39:13 INFO ContextCleaner: Cleaned shuffle 79
17/12/19 16:39:13 INFO BlockManagerInfo: Removed broadcast_372_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2003.9 MB)
17/12/19 16:39:13 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:39:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:13 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 16:39:13 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 16:39:13 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 16:39:13 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 16:39:13 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 16:39:13 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_385 stored as values in memory (estimated size 293.7 KB, free 1995.9 MB)
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_385_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1995.9 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Added broadcast_385_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2003.9 MB)
17/12/19 16:39:13 INFO SparkContext: Created broadcast 385 from sql at <unknown>:0
17/12/19 16:39:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 16:39:13 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 16:39:13 INFO DAGScheduler: Registering RDD 1243 (sql at <unknown>:0)
17/12/19 16:39:13 INFO DAGScheduler: Registering RDD 1248 (sql at <unknown>:0)
17/12/19 16:39:13 INFO DAGScheduler: Got job 277 (sql at <unknown>:0) with 1 output partitions
17/12/19 16:39:13 INFO DAGScheduler: Final stage: ResultStage 578 (sql at <unknown>:0)
17/12/19 16:39:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 577)
17/12/19 16:39:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 577)
17/12/19 16:39:13 INFO DAGScheduler: Submitting ShuffleMapStage 576 (MapPartitionsRDD[1243] at sql at <unknown>:0), which has no missing parents
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_386 stored as values in memory (estimated size 12.1 KB, free 1995.9 MB)
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_386_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1995.9 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Added broadcast_386_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2003.9 MB)
17/12/19 16:39:13 INFO SparkContext: Created broadcast 386 from broadcast at DAGScheduler.scala:996
17/12/19 16:39:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 576 (MapPartitionsRDD[1243] at sql at <unknown>:0)
17/12/19 16:39:13 INFO TaskSchedulerImpl: Adding task set 576.0 with 1 tasks
17/12/19 16:39:13 INFO TaskSetManager: Starting task 0.0 in stage 576.0 (TID 427, localhost, executor driver, partition 0, PROCESS_LOCAL, 6680 bytes)
17/12/19 16:39:13 INFO Executor: Running task 0.0 in stage 576.0 (TID 427)
17/12/19 16:39:13 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_e8425cf46f6aeb48b83c2c3e4e22f4cf477073ff83f5686d47878c8aa8a4dfc2.csv, range: 0-464, partition values: [empty row]
17/12/19 16:39:13 INFO Executor: Finished task 0.0 in stage 576.0 (TID 427). 1553 bytes result sent to driver
17/12/19 16:39:13 INFO TaskSetManager: Finished task 0.0 in stage 576.0 (TID 427) in 31 ms on localhost (executor driver) (1/1)
17/12/19 16:39:13 INFO TaskSchedulerImpl: Removed TaskSet 576.0, whose tasks have all completed, from pool 
17/12/19 16:39:13 INFO DAGScheduler: ShuffleMapStage 576 (sql at <unknown>:0) finished in 0.031 s
17/12/19 16:39:13 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:39:13 INFO DAGScheduler: running: Set()
17/12/19 16:39:13 INFO DAGScheduler: waiting: Set(ResultStage 578, ShuffleMapStage 577)
17/12/19 16:39:13 INFO DAGScheduler: failed: Set()
17/12/19 16:39:13 INFO DAGScheduler: Submitting ShuffleMapStage 577 (MapPartitionsRDD[1248] at sql at <unknown>:0), which has no missing parents
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_387 stored as values in memory (estimated size 11.9 KB, free 1995.8 MB)
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_387_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1995.8 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Added broadcast_387_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2003.9 MB)
17/12/19 16:39:13 INFO SparkContext: Created broadcast 387 from broadcast at DAGScheduler.scala:996
17/12/19 16:39:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 577 (MapPartitionsRDD[1248] at sql at <unknown>:0)
17/12/19 16:39:13 INFO TaskSchedulerImpl: Adding task set 577.0 with 2 tasks
17/12/19 16:39:13 INFO TaskSetManager: Starting task 0.0 in stage 577.0 (TID 428, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 16:39:13 INFO TaskSetManager: Starting task 1.0 in stage 577.0 (TID 429, localhost, executor driver, partition 1, ANY, 5946 bytes)
17/12/19 16:39:13 INFO Executor: Running task 0.0 in stage 577.0 (TID 428)
17/12/19 16:39:13 INFO Executor: Running task 1.0 in stage 577.0 (TID 429)
17/12/19 16:39:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:39:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:39:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:39:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:39:13 INFO MemoryStore: Block rdd_1245_1 stored as values in memory (estimated size 544.0 B, free 1995.8 MB)
17/12/19 16:39:13 INFO MemoryStore: Block rdd_1245_0 stored as values in memory (estimated size 544.0 B, free 1995.8 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Added rdd_1245_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2003.9 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Added rdd_1245_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2003.9 MB)
17/12/19 16:39:13 INFO Executor: Finished task 0.0 in stage 577.0 (TID 428). 3064 bytes result sent to driver
17/12/19 16:39:13 INFO TaskSetManager: Finished task 0.0 in stage 577.0 (TID 428) in 16 ms on localhost (executor driver) (1/2)
17/12/19 16:39:13 INFO Executor: Finished task 1.0 in stage 577.0 (TID 429). 2985 bytes result sent to driver
17/12/19 16:39:13 INFO TaskSetManager: Finished task 1.0 in stage 577.0 (TID 429) in 16 ms on localhost (executor driver) (2/2)
17/12/19 16:39:13 INFO TaskSchedulerImpl: Removed TaskSet 577.0, whose tasks have all completed, from pool 
17/12/19 16:39:13 INFO DAGScheduler: ShuffleMapStage 577 (sql at <unknown>:0) finished in 0.016 s
17/12/19 16:39:13 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:39:13 INFO DAGScheduler: running: Set()
17/12/19 16:39:13 INFO DAGScheduler: waiting: Set(ResultStage 578)
17/12/19 16:39:13 INFO DAGScheduler: failed: Set()
17/12/19 16:39:13 INFO DAGScheduler: Submitting ResultStage 578 (MapPartitionsRDD[1251] at sql at <unknown>:0), which has no missing parents
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_388 stored as values in memory (estimated size 7.0 KB, free 1995.8 MB)
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_388_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1995.8 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Added broadcast_388_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2003.9 MB)
17/12/19 16:39:13 INFO SparkContext: Created broadcast 388 from broadcast at DAGScheduler.scala:996
17/12/19 16:39:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 578 (MapPartitionsRDD[1251] at sql at <unknown>:0)
17/12/19 16:39:13 INFO TaskSchedulerImpl: Adding task set 578.0 with 1 tasks
17/12/19 16:39:13 INFO TaskSetManager: Starting task 0.0 in stage 578.0 (TID 430, localhost, executor driver, partition 0, ANY, 5957 bytes)
17/12/19 16:39:13 INFO Executor: Running task 0.0 in stage 578.0 (TID 430)
17/12/19 16:39:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:39:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:39:13 INFO Executor: Finished task 0.0 in stage 578.0 (TID 430). 1707 bytes result sent to driver
17/12/19 16:39:13 INFO TaskSetManager: Finished task 0.0 in stage 578.0 (TID 430) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:39:13 INFO TaskSchedulerImpl: Removed TaskSet 578.0, whose tasks have all completed, from pool 
17/12/19 16:39:13 INFO DAGScheduler: ResultStage 578 (sql at <unknown>:0) finished in 0.000 s
17/12/19 16:39:13 INFO DAGScheduler: Job 277 finished: sql at <unknown>:0, took 0.046858 s
17/12/19 16:39:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:13 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 16:39:13 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:39:13 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 81 is 145 bytes
17/12/19 16:39:13 INFO DAGScheduler: Registering RDD 1255 (collect at utils.scala:196)
17/12/19 16:39:13 INFO DAGScheduler: Got job 278 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:39:13 INFO DAGScheduler: Final stage: ResultStage 581 (collect at utils.scala:196)
17/12/19 16:39:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 580)
17/12/19 16:39:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 580)
17/12/19 16:39:13 INFO DAGScheduler: Submitting ShuffleMapStage 580 (MapPartitionsRDD[1255] at collect at utils.scala:196), which has no missing parents
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_389 stored as values in memory (estimated size 11.9 KB, free 1995.8 MB)
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_389_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1995.8 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Added broadcast_389_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2003.9 MB)
17/12/19 16:39:13 INFO SparkContext: Created broadcast 389 from broadcast at DAGScheduler.scala:996
17/12/19 16:39:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 580 (MapPartitionsRDD[1255] at collect at utils.scala:196)
17/12/19 16:39:13 INFO TaskSchedulerImpl: Adding task set 580.0 with 2 tasks
17/12/19 16:39:13 INFO TaskSetManager: Starting task 0.0 in stage 580.0 (TID 431, localhost, executor driver, partition 0, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:39:13 INFO TaskSetManager: Starting task 1.0 in stage 580.0 (TID 432, localhost, executor driver, partition 1, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:39:13 INFO Executor: Running task 1.0 in stage 580.0 (TID 432)
17/12/19 16:39:13 INFO Executor: Running task 0.0 in stage 580.0 (TID 431)
17/12/19 16:39:13 INFO BlockManager: Found block rdd_1245_1 locally
17/12/19 16:39:13 INFO BlockManager: Found block rdd_1245_0 locally
17/12/19 16:39:13 INFO Executor: Finished task 1.0 in stage 580.0 (TID 432). 1950 bytes result sent to driver
17/12/19 16:39:13 INFO TaskSetManager: Finished task 1.0 in stage 580.0 (TID 432) in 21 ms on localhost (executor driver) (1/2)
17/12/19 16:39:13 INFO Executor: Finished task 0.0 in stage 580.0 (TID 431). 1950 bytes result sent to driver
17/12/19 16:39:13 INFO TaskSetManager: Finished task 0.0 in stage 580.0 (TID 431) in 22 ms on localhost (executor driver) (2/2)
17/12/19 16:39:13 INFO TaskSchedulerImpl: Removed TaskSet 580.0, whose tasks have all completed, from pool 
17/12/19 16:39:13 INFO DAGScheduler: ShuffleMapStage 580 (collect at utils.scala:196) finished in 0.022 s
17/12/19 16:39:13 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:39:13 INFO DAGScheduler: running: Set()
17/12/19 16:39:13 INFO DAGScheduler: waiting: Set(ResultStage 581)
17/12/19 16:39:13 INFO DAGScheduler: failed: Set()
17/12/19 16:39:13 INFO DAGScheduler: Submitting ResultStage 581 (MapPartitionsRDD[1258] at collect at utils.scala:196), which has no missing parents
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_390 stored as values in memory (estimated size 7.0 KB, free 1995.8 MB)
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_390_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1995.8 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Added broadcast_390_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2003.9 MB)
17/12/19 16:39:13 INFO SparkContext: Created broadcast 390 from broadcast at DAGScheduler.scala:996
17/12/19 16:39:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 581 (MapPartitionsRDD[1258] at collect at utils.scala:196)
17/12/19 16:39:13 INFO TaskSchedulerImpl: Adding task set 581.0 with 1 tasks
17/12/19 16:39:13 INFO TaskSetManager: Starting task 0.0 in stage 581.0 (TID 433, localhost, executor driver, partition 0, ANY, 5949 bytes)
17/12/19 16:39:13 INFO Executor: Running task 0.0 in stage 581.0 (TID 433)
17/12/19 16:39:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:39:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:39:13 INFO Executor: Finished task 0.0 in stage 581.0 (TID 433). 1873 bytes result sent to driver
17/12/19 16:39:13 INFO TaskSetManager: Finished task 0.0 in stage 581.0 (TID 433) in 2 ms on localhost (executor driver) (1/1)
17/12/19 16:39:13 INFO TaskSchedulerImpl: Removed TaskSet 581.0, whose tasks have all completed, from pool 
17/12/19 16:39:13 INFO DAGScheduler: ResultStage 581 (collect at utils.scala:196) finished in 0.002 s
17/12/19 16:39:13 INFO DAGScheduler: Job 278 finished: collect at utils.scala:196, took 0.018185 s
17/12/19 16:39:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz112`
WHERE (0 = 1)
17/12/19 16:39:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:13 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `ohlqeulvbk`
17/12/19 16:39:13 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:39:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz113`
WHERE (0 = 1)
17/12/19 16:39:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:39:13 INFO CodeGenerator: Code generated in 7.799317 ms
17/12/19 16:39:13 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:39:13 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 81 is 145 bytes
17/12/19 16:39:13 INFO DAGScheduler: Got job 279 (take at <unknown>:0) with 1 output partitions
17/12/19 16:39:13 INFO DAGScheduler: Final stage: ResultStage 583 (take at <unknown>:0)
17/12/19 16:39:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 582)
17/12/19 16:39:13 INFO DAGScheduler: Missing parents: List()
17/12/19 16:39:13 INFO DAGScheduler: Submitting ResultStage 583 (WorkerRDD[1264] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_391 stored as values in memory (estimated size 125.4 KB, free 1995.7 MB)
17/12/19 16:39:13 INFO MemoryStore: Block broadcast_391_piece0 stored as bytes in memory (estimated size 49.2 KB, free 1995.6 MB)
17/12/19 16:39:13 INFO BlockManagerInfo: Added broadcast_391_piece0 in memory on 127.0.0.1:53618 (size: 49.2 KB, free: 2003.8 MB)
17/12/19 16:39:13 INFO SparkContext: Created broadcast 391 from broadcast at DAGScheduler.scala:996
17/12/19 16:39:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 583 (WorkerRDD[1264] at RDD at rdd.scala:18)
17/12/19 16:39:13 INFO TaskSchedulerImpl: Adding task set 583.0 with 1 tasks
17/12/19 16:39:13 INFO TaskSetManager: Starting task 0.0 in stage 583.0 (TID 434, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:39:13 INFO Executor: Running task 0.0 in stage 583.0 (TID 434)
17/12/19 16:39:13 INFO BlockManager: Found block rdd_1245_0 locally
17/12/19 16:39:14 INFO MemoryStore: Block rdd_1264_0 stored as values in memory (estimated size 608.0 B, free 1995.6 MB)
17/12/19 16:39:14 INFO BlockManagerInfo: Added rdd_1264_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.8 MB)
17/12/19 16:39:14 INFO Executor: Finished task 0.0 in stage 583.0 (TID 434). 2509 bytes result sent to driver
17/12/19 16:39:14 INFO TaskSetManager: Finished task 0.0 in stage 583.0 (TID 434) in 606 ms on localhost (executor driver) (1/1)
17/12/19 16:39:14 INFO TaskSchedulerImpl: Removed TaskSet 583.0, whose tasks have all completed, from pool 
17/12/19 16:39:14 INFO DAGScheduler: ResultStage 583 (take at <unknown>:0) finished in 0.606 s
17/12/19 16:39:14 INFO DAGScheduler: Job 279 finished: take at <unknown>:0, took 0.600317 s
17/12/19 16:39:14 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:39:14 INFO DAGScheduler: Got job 280 (take at <unknown>:0) with 1 output partitions
17/12/19 16:39:14 INFO DAGScheduler: Final stage: ResultStage 585 (take at <unknown>:0)
17/12/19 16:39:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 584)
17/12/19 16:39:14 INFO DAGScheduler: Missing parents: List()
17/12/19 16:39:14 INFO DAGScheduler: Submitting ResultStage 585 (WorkerRDD[1264] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:39:14 INFO MemoryStore: Block broadcast_392 stored as values in memory (estimated size 125.4 KB, free 1995.5 MB)
17/12/19 16:39:14 INFO MemoryStore: Block broadcast_392_piece0 stored as bytes in memory (estimated size 49.2 KB, free 1995.5 MB)
17/12/19 16:39:14 INFO BlockManagerInfo: Added broadcast_392_piece0 in memory on 127.0.0.1:53618 (size: 49.2 KB, free: 2003.8 MB)
17/12/19 16:39:14 INFO SparkContext: Created broadcast 392 from broadcast at DAGScheduler.scala:996
17/12/19 16:39:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 585 (WorkerRDD[1264] at RDD at rdd.scala:18)
17/12/19 16:39:14 INFO TaskSchedulerImpl: Adding task set 585.0 with 1 tasks
17/12/19 16:39:14 INFO TaskSetManager: Starting task 0.0 in stage 585.0 (TID 435, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:39:14 INFO Executor: Running task 0.0 in stage 585.0 (TID 435)
17/12/19 16:39:14 INFO BlockManager: Found block rdd_1245_1 locally
17/12/19 16:39:15 INFO MemoryStore: Block rdd_1264_1 stored as values in memory (estimated size 608.0 B, free 1995.5 MB)
17/12/19 16:39:15 INFO BlockManagerInfo: Added rdd_1264_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.8 MB)
17/12/19 16:39:15 INFO Executor: Finished task 0.0 in stage 585.0 (TID 435). 2596 bytes result sent to driver
17/12/19 16:39:15 INFO TaskSetManager: Finished task 0.0 in stage 585.0 (TID 435) in 597 ms on localhost (executor driver) (1/1)
17/12/19 16:39:15 INFO TaskSchedulerImpl: Removed TaskSet 585.0, whose tasks have all completed, from pool 
17/12/19 16:39:15 INFO DAGScheduler: ResultStage 585 (take at <unknown>:0) finished in 0.612 s
17/12/19 16:39:15 INFO DAGScheduler: Job 280 finished: take at <unknown>:0, took 0.616078 s
17/12/19 16:39:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:15 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e840e3bc
17/12/19 16:39:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e840e3bc` AS `zzz114`
WHERE (0 = 1)
17/12/19 16:39:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e840e3bc`
17/12/19 16:39:15 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:39:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz115`
WHERE (0 = 1)
17/12/19 16:39:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:15 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 16:39:15 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:39:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz116`
WHERE (0 = 1)
17/12/19 16:39:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:39:15 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:39:15 INFO DAGScheduler: Got job 281 (collect at utils.scala:196) with 2 output partitions
17/12/19 16:39:15 INFO DAGScheduler: Final stage: ResultStage 587 (collect at utils.scala:196)
17/12/19 16:39:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 586)
17/12/19 16:39:15 INFO DAGScheduler: Missing parents: List()
17/12/19 16:39:15 INFO DAGScheduler: Submitting ResultStage 587 (MapPartitionsRDD[1271] at collect at utils.scala:196), which has no missing parents
17/12/19 16:39:15 INFO MemoryStore: Block broadcast_393 stored as values in memory (estimated size 133.0 KB, free 1995.3 MB)
17/12/19 16:39:15 INFO MemoryStore: Block broadcast_393_piece0 stored as bytes in memory (estimated size 52.8 KB, free 1995.3 MB)
17/12/19 16:39:15 INFO BlockManagerInfo: Added broadcast_393_piece0 in memory on 127.0.0.1:53618 (size: 52.8 KB, free: 2003.7 MB)
17/12/19 16:39:15 INFO SparkContext: Created broadcast 393 from broadcast at DAGScheduler.scala:996
17/12/19 16:39:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 587 (MapPartitionsRDD[1271] at collect at utils.scala:196)
17/12/19 16:39:15 INFO TaskSchedulerImpl: Adding task set 587.0 with 2 tasks
17/12/19 16:39:15 INFO TaskSetManager: Starting task 0.0 in stage 587.0 (TID 436, localhost, executor driver, partition 0, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:39:15 INFO TaskSetManager: Starting task 1.0 in stage 587.0 (TID 437, localhost, executor driver, partition 1, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:39:15 INFO Executor: Running task 1.0 in stage 587.0 (TID 437)
17/12/19 16:39:15 INFO Executor: Running task 0.0 in stage 587.0 (TID 436)
17/12/19 16:39:15 INFO BlockManager: Found block rdd_1264_1 locally
17/12/19 16:39:15 INFO BlockManager: Found block rdd_1264_0 locally
17/12/19 16:39:15 INFO Executor: Finished task 1.0 in stage 587.0 (TID 437). 1448 bytes result sent to driver
17/12/19 16:39:15 INFO TaskSetManager: Finished task 1.0 in stage 587.0 (TID 437) in 0 ms on localhost (executor driver) (1/2)
17/12/19 16:39:15 INFO Executor: Finished task 0.0 in stage 587.0 (TID 436). 1444 bytes result sent to driver
17/12/19 16:39:15 INFO TaskSetManager: Finished task 0.0 in stage 587.0 (TID 436) in 0 ms on localhost (executor driver) (2/2)
17/12/19 16:39:15 INFO TaskSchedulerImpl: Removed TaskSet 587.0, whose tasks have all completed, from pool 
17/12/19 16:39:15 INFO DAGScheduler: ResultStage 587 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:39:15 INFO DAGScheduler: Job 281 finished: collect at utils.scala:196, took 0.007674 s
17/12/19 16:39:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:39:15 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:39:15 INFO DAGScheduler: Got job 282 (take at <unknown>:0) with 1 output partitions
17/12/19 16:39:15 INFO DAGScheduler: Final stage: ResultStage 589 (take at <unknown>:0)
17/12/19 16:39:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 588)
17/12/19 16:39:15 INFO DAGScheduler: Missing parents: List()
17/12/19 16:39:15 INFO DAGScheduler: Submitting ResultStage 589 (WorkerRDD[1276] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:39:15 INFO MemoryStore: Block broadcast_394 stored as values in memory (estimated size 241.6 KB, free 1995.0 MB)
17/12/19 16:39:15 INFO MemoryStore: Block broadcast_394_piece0 stored as bytes in memory (estimated size 95.4 KB, free 1994.9 MB)
17/12/19 16:39:15 INFO BlockManagerInfo: Added broadcast_394_piece0 in memory on 127.0.0.1:53618 (size: 95.4 KB, free: 2003.6 MB)
17/12/19 16:39:15 INFO SparkContext: Created broadcast 394 from broadcast at DAGScheduler.scala:996
17/12/19 16:39:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 589 (WorkerRDD[1276] at RDD at rdd.scala:18)
17/12/19 16:39:15 INFO TaskSchedulerImpl: Adding task set 589.0 with 1 tasks
17/12/19 16:39:15 INFO TaskSetManager: Starting task 0.0 in stage 589.0 (TID 438, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:39:15 INFO Executor: Running task 0.0 in stage 589.0 (TID 438)
17/12/19 16:39:15 INFO BlockManager: Found block rdd_1264_0 locally
17/12/19 16:39:15 INFO MemoryStore: Block rdd_1276_0 stored as values in memory (estimated size 80.0 B, free 1994.9 MB)
17/12/19 16:39:15 INFO BlockManagerInfo: Added rdd_1276_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.6 MB)
17/12/19 16:39:15 INFO Executor: Finished task 0.0 in stage 589.0 (TID 438). 2400 bytes result sent to driver
17/12/19 16:39:15 INFO TaskSetManager: Finished task 0.0 in stage 589.0 (TID 438) in 664 ms on localhost (executor driver) (1/1)
17/12/19 16:39:15 INFO TaskSchedulerImpl: Removed TaskSet 589.0, whose tasks have all completed, from pool 
17/12/19 16:39:15 INFO DAGScheduler: ResultStage 589 (take at <unknown>:0) finished in 0.664 s
17/12/19 16:39:15 INFO DAGScheduler: Job 282 finished: take at <unknown>:0, took 0.670014 s
17/12/19 16:39:15 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:39:15 INFO DAGScheduler: Got job 283 (take at <unknown>:0) with 1 output partitions
17/12/19 16:39:15 INFO DAGScheduler: Final stage: ResultStage 591 (take at <unknown>:0)
17/12/19 16:39:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 590)
17/12/19 16:39:15 INFO DAGScheduler: Missing parents: List()
17/12/19 16:39:15 INFO DAGScheduler: Submitting ResultStage 591 (WorkerRDD[1276] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:39:15 INFO MemoryStore: Block broadcast_395 stored as values in memory (estimated size 241.6 KB, free 1994.7 MB)
17/12/19 16:39:15 INFO MemoryStore: Block broadcast_395_piece0 stored as bytes in memory (estimated size 95.4 KB, free 1994.6 MB)
17/12/19 16:39:15 INFO BlockManagerInfo: Added broadcast_395_piece0 in memory on 127.0.0.1:53618 (size: 95.4 KB, free: 2003.5 MB)
17/12/19 16:39:15 INFO SparkContext: Created broadcast 395 from broadcast at DAGScheduler.scala:996
17/12/19 16:39:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 591 (WorkerRDD[1276] at RDD at rdd.scala:18)
17/12/19 16:39:15 INFO TaskSchedulerImpl: Adding task set 591.0 with 1 tasks
17/12/19 16:39:15 INFO TaskSetManager: Starting task 0.0 in stage 591.0 (TID 439, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:39:15 INFO Executor: Running task 0.0 in stage 591.0 (TID 439)
17/12/19 16:39:15 INFO BlockManager: Found block rdd_1264_1 locally
17/12/19 16:39:16 INFO MemoryStore: Block rdd_1276_1 stored as values in memory (estimated size 80.0 B, free 1994.6 MB)
17/12/19 16:39:16 INFO BlockManagerInfo: Added rdd_1276_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.5 MB)
17/12/19 16:39:16 INFO Executor: Finished task 0.0 in stage 591.0 (TID 439). 2577 bytes result sent to driver
17/12/19 16:39:16 INFO TaskSetManager: Finished task 0.0 in stage 591.0 (TID 439) in 661 ms on localhost (executor driver) (1/1)
17/12/19 16:39:16 INFO TaskSchedulerImpl: Removed TaskSet 591.0, whose tasks have all completed, from pool 
17/12/19 16:39:16 INFO DAGScheduler: ResultStage 591 (take at <unknown>:0) finished in 0.661 s
17/12/19 16:39:16 INFO DAGScheduler: Job 283 finished: take at <unknown>:0, took 0.656582 s
17/12/19 16:39:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:16 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e8692d657d
17/12/19 16:39:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8692d657d` AS `zzz117`
WHERE (0 = 1)
17/12/19 16:39:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8692d657d`
LIMIT 10
17/12/19 16:39:16 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:39:16 INFO DAGScheduler: Got job 284 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:39:16 INFO DAGScheduler: Final stage: ResultStage 593 (collect at utils.scala:196)
17/12/19 16:39:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 592)
17/12/19 16:39:16 INFO DAGScheduler: Missing parents: List()
17/12/19 16:39:16 INFO DAGScheduler: Submitting ResultStage 593 (MapPartitionsRDD[1280] at collect at utils.scala:196), which has no missing parents
17/12/19 16:39:16 INFO MemoryStore: Block broadcast_396 stored as values in memory (estimated size 242.7 KB, free 1994.4 MB)
17/12/19 16:39:16 INFO MemoryStore: Block broadcast_396_piece0 stored as bytes in memory (estimated size 96.1 KB, free 1994.3 MB)
17/12/19 16:39:16 INFO BlockManagerInfo: Added broadcast_396_piece0 in memory on 127.0.0.1:53618 (size: 96.1 KB, free: 2003.5 MB)
17/12/19 16:39:16 INFO SparkContext: Created broadcast 396 from broadcast at DAGScheduler.scala:996
17/12/19 16:39:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 593 (MapPartitionsRDD[1280] at collect at utils.scala:196)
17/12/19 16:39:16 INFO TaskSchedulerImpl: Adding task set 593.0 with 1 tasks
17/12/19 16:39:16 INFO TaskSetManager: Starting task 0.0 in stage 593.0 (TID 440, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:39:16 INFO Executor: Running task 0.0 in stage 593.0 (TID 440)
17/12/19 16:39:16 INFO BlockManager: Found block rdd_1276_0 locally
17/12/19 16:39:16 INFO Executor: Finished task 0.0 in stage 593.0 (TID 440). 1479 bytes result sent to driver
17/12/19 16:39:16 INFO TaskSetManager: Finished task 0.0 in stage 593.0 (TID 440) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:39:16 INFO TaskSchedulerImpl: Removed TaskSet 593.0, whose tasks have all completed, from pool 
17/12/19 16:39:16 INFO DAGScheduler: ResultStage 593 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:39:16 INFO DAGScheduler: Job 284 finished: collect at utils.scala:196, took 0.008531 s
17/12/19 16:39:16 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:39:16 INFO DAGScheduler: Got job 285 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:39:16 INFO DAGScheduler: Final stage: ResultStage 595 (collect at utils.scala:196)
17/12/19 16:39:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 594)
17/12/19 16:39:16 INFO DAGScheduler: Missing parents: List()
17/12/19 16:39:16 INFO DAGScheduler: Submitting ResultStage 595 (MapPartitionsRDD[1280] at collect at utils.scala:196), which has no missing parents
17/12/19 16:39:16 INFO MemoryStore: Block broadcast_397 stored as values in memory (estimated size 242.7 KB, free 1994.0 MB)
17/12/19 16:39:16 INFO MemoryStore: Block broadcast_397_piece0 stored as bytes in memory (estimated size 96.1 KB, free 1994.0 MB)
17/12/19 16:39:16 INFO BlockManagerInfo: Added broadcast_397_piece0 in memory on 127.0.0.1:53618 (size: 96.1 KB, free: 2003.4 MB)
17/12/19 16:39:16 INFO SparkContext: Created broadcast 397 from broadcast at DAGScheduler.scala:996
17/12/19 16:39:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 595 (MapPartitionsRDD[1280] at collect at utils.scala:196)
17/12/19 16:39:16 INFO TaskSchedulerImpl: Adding task set 595.0 with 1 tasks
17/12/19 16:39:16 INFO TaskSetManager: Starting task 0.0 in stage 595.0 (TID 441, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:39:16 INFO Executor: Running task 0.0 in stage 595.0 (TID 441)
17/12/19 16:39:16 INFO BlockManager: Found block rdd_1276_1 locally
17/12/19 16:39:16 INFO Executor: Finished task 0.0 in stage 595.0 (TID 441). 1479 bytes result sent to driver
17/12/19 16:39:16 INFO TaskSetManager: Finished task 0.0 in stage 595.0 (TID 441) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:39:16 INFO TaskSchedulerImpl: Removed TaskSet 595.0, whose tasks have all completed, from pool 
17/12/19 16:39:16 INFO DAGScheduler: ResultStage 595 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:39:16 INFO DAGScheduler: Job 285 finished: collect at utils.scala:196, took 0.008550 s
17/12/19 16:39:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:39:16 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:39:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:39:16 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:39:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:39:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:39:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:39:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:39:16 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:39:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:39:16 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:39:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:39:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:39:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:39:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:39:16 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:39:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:39:16 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:39:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:39:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:39:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:39:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:39:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:39:16 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:39:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:39:16 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:39:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:39:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:39:16 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:43:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:33 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:43:33 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:43:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:43:33 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:43:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:43:33 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:43:33 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:43:33 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 16:43:33 INFO DAGScheduler: Got job 286 (collect at utils.scala:58) with 1 output partitions
17/12/19 16:43:33 INFO DAGScheduler: Final stage: ResultStage 596 (collect at utils.scala:58)
17/12/19 16:43:33 INFO DAGScheduler: Parents of final stage: List()
17/12/19 16:43:33 INFO DAGScheduler: Missing parents: List()
17/12/19 16:43:33 INFO DAGScheduler: Submitting ResultStage 596 (MapPartitionsRDD[1290] at map at utils.scala:55), which has no missing parents
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_398 stored as values in memory (estimated size 8.7 KB, free 1993.9 MB)
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_398_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1993.9 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Added broadcast_398_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.4 MB)
17/12/19 16:43:33 INFO SparkContext: Created broadcast 398 from broadcast at DAGScheduler.scala:996
17/12/19 16:43:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 596 (MapPartitionsRDD[1290] at map at utils.scala:55)
17/12/19 16:43:33 INFO TaskSchedulerImpl: Adding task set 596.0 with 1 tasks
17/12/19 16:43:33 INFO TaskSetManager: Starting task 0.0 in stage 596.0 (TID 442, localhost, executor driver, partition 0, PROCESS_LOCAL, 9518 bytes)
17/12/19 16:43:33 INFO Executor: Running task 0.0 in stage 596.0 (TID 442)
17/12/19 16:43:33 INFO Executor: Finished task 0.0 in stage 596.0 (TID 442). 2138 bytes result sent to driver
17/12/19 16:43:33 INFO TaskSetManager: Finished task 0.0 in stage 596.0 (TID 442) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:43:33 INFO TaskSchedulerImpl: Removed TaskSet 596.0, whose tasks have all completed, from pool 
17/12/19 16:43:33 INFO DAGScheduler: ResultStage 596 (collect at utils.scala:58) finished in 0.000 s
17/12/19 16:43:33 INFO DAGScheduler: Job 286 finished: collect at utils.scala:58, took 0.006294 s
17/12/19 16:43:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:33 INFO BlockManagerInfo: Removed broadcast_398_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2003.4 MB)
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19945
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19946
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19952
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19953
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19954
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19955
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19956
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19957
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19958
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19959
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19960
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19961
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19962
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19963
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 19964
17/12/19 16:43:33 INFO ContextCleaner: Cleaned shuffle 82
17/12/19 16:43:33 INFO BlockManagerInfo: Removed broadcast_386_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2003.4 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Removed broadcast_387_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.4 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Removed broadcast_388_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.4 MB)
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 20133
17/12/19 16:43:33 INFO BlockManagerInfo: Removed broadcast_389_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.4 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Removed broadcast_390_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.4 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Removed broadcast_391_piece0 on 127.0.0.1:53618 in memory (size: 49.2 KB, free: 2003.4 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Removed broadcast_392_piece0 on 127.0.0.1:53618 in memory (size: 49.2 KB, free: 2003.5 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Removed broadcast_393_piece0 on 127.0.0.1:53618 in memory (size: 52.8 KB, free: 2003.5 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Removed broadcast_394_piece0 on 127.0.0.1:53618 in memory (size: 95.4 KB, free: 2003.6 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Removed broadcast_395_piece0 on 127.0.0.1:53618 in memory (size: 95.4 KB, free: 2003.7 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Removed broadcast_396_piece0 on 127.0.0.1:53618 in memory (size: 96.1 KB, free: 2003.8 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Removed broadcast_397_piece0 on 127.0.0.1:53618 in memory (size: 96.1 KB, free: 2003.9 MB)
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 20633
17/12/19 16:43:33 INFO ContextCleaner: Cleaned accumulator 20634
17/12/19 16:43:33 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:43:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:33 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 16:43:33 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 16:43:33 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 16:43:33 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 16:43:33 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 16:43:33 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_399 stored as values in memory (estimated size 293.7 KB, free 1995.6 MB)
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_399_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1995.6 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Added broadcast_399_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2003.9 MB)
17/12/19 16:43:33 INFO SparkContext: Created broadcast 399 from sql at <unknown>:0
17/12/19 16:43:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 16:43:33 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 16:43:33 INFO DAGScheduler: Registering RDD 1294 (sql at <unknown>:0)
17/12/19 16:43:33 INFO DAGScheduler: Registering RDD 1299 (sql at <unknown>:0)
17/12/19 16:43:33 INFO DAGScheduler: Got job 287 (sql at <unknown>:0) with 1 output partitions
17/12/19 16:43:33 INFO DAGScheduler: Final stage: ResultStage 599 (sql at <unknown>:0)
17/12/19 16:43:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 598)
17/12/19 16:43:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 598)
17/12/19 16:43:33 INFO DAGScheduler: Submitting ShuffleMapStage 597 (MapPartitionsRDD[1294] at sql at <unknown>:0), which has no missing parents
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_400 stored as values in memory (estimated size 12.1 KB, free 1995.6 MB)
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_400_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1995.5 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Added broadcast_400_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2003.9 MB)
17/12/19 16:43:33 INFO SparkContext: Created broadcast 400 from broadcast at DAGScheduler.scala:996
17/12/19 16:43:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 597 (MapPartitionsRDD[1294] at sql at <unknown>:0)
17/12/19 16:43:33 INFO TaskSchedulerImpl: Adding task set 597.0 with 1 tasks
17/12/19 16:43:33 INFO TaskSetManager: Starting task 0.0 in stage 597.0 (TID 443, localhost, executor driver, partition 0, PROCESS_LOCAL, 6680 bytes)
17/12/19 16:43:33 INFO Executor: Running task 0.0 in stage 597.0 (TID 443)
17/12/19 16:43:33 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_84f24c390ec852d9eda4c0eb079da2efba74cc3232e1e37044f2397ed2ce9413.csv, range: 0-462, partition values: [empty row]
17/12/19 16:43:33 INFO Executor: Finished task 0.0 in stage 597.0 (TID 443). 1553 bytes result sent to driver
17/12/19 16:43:33 INFO TaskSetManager: Finished task 0.0 in stage 597.0 (TID 443) in 16 ms on localhost (executor driver) (1/1)
17/12/19 16:43:33 INFO TaskSchedulerImpl: Removed TaskSet 597.0, whose tasks have all completed, from pool 
17/12/19 16:43:33 INFO DAGScheduler: ShuffleMapStage 597 (sql at <unknown>:0) finished in 0.016 s
17/12/19 16:43:33 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:43:33 INFO DAGScheduler: running: Set()
17/12/19 16:43:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 598, ResultStage 599)
17/12/19 16:43:33 INFO DAGScheduler: failed: Set()
17/12/19 16:43:33 INFO DAGScheduler: Submitting ShuffleMapStage 598 (MapPartitionsRDD[1299] at sql at <unknown>:0), which has no missing parents
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_401 stored as values in memory (estimated size 11.9 KB, free 1995.5 MB)
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_401_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1995.5 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Added broadcast_401_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2003.9 MB)
17/12/19 16:43:33 INFO SparkContext: Created broadcast 401 from broadcast at DAGScheduler.scala:996
17/12/19 16:43:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 598 (MapPartitionsRDD[1299] at sql at <unknown>:0)
17/12/19 16:43:33 INFO TaskSchedulerImpl: Adding task set 598.0 with 2 tasks
17/12/19 16:43:33 INFO TaskSetManager: Starting task 0.0 in stage 598.0 (TID 444, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 16:43:33 INFO TaskSetManager: Starting task 1.0 in stage 598.0 (TID 445, localhost, executor driver, partition 1, ANY, 5946 bytes)
17/12/19 16:43:33 INFO Executor: Running task 0.0 in stage 598.0 (TID 444)
17/12/19 16:43:33 INFO Executor: Running task 1.0 in stage 598.0 (TID 445)
17/12/19 16:43:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:43:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:43:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:43:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:43:33 INFO MemoryStore: Block rdd_1296_0 stored as values in memory (estimated size 544.0 B, free 1995.5 MB)
17/12/19 16:43:33 INFO MemoryStore: Block rdd_1296_1 stored as values in memory (estimated size 544.0 B, free 1995.5 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Added rdd_1296_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2003.9 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Added rdd_1296_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2003.9 MB)
17/12/19 16:43:33 INFO Executor: Finished task 1.0 in stage 598.0 (TID 445). 2906 bytes result sent to driver
17/12/19 16:43:33 INFO TaskSetManager: Finished task 1.0 in stage 598.0 (TID 445) in 15 ms on localhost (executor driver) (1/2)
17/12/19 16:43:33 INFO Executor: Finished task 0.0 in stage 598.0 (TID 444). 3083 bytes result sent to driver
17/12/19 16:43:33 INFO TaskSetManager: Finished task 0.0 in stage 598.0 (TID 444) in 15 ms on localhost (executor driver) (2/2)
17/12/19 16:43:33 INFO TaskSchedulerImpl: Removed TaskSet 598.0, whose tasks have all completed, from pool 
17/12/19 16:43:33 INFO DAGScheduler: ShuffleMapStage 598 (sql at <unknown>:0) finished in 0.015 s
17/12/19 16:43:33 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:43:33 INFO DAGScheduler: running: Set()
17/12/19 16:43:33 INFO DAGScheduler: waiting: Set(ResultStage 599)
17/12/19 16:43:33 INFO DAGScheduler: failed: Set()
17/12/19 16:43:33 INFO DAGScheduler: Submitting ResultStage 599 (MapPartitionsRDD[1302] at sql at <unknown>:0), which has no missing parents
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_402 stored as values in memory (estimated size 7.0 KB, free 1995.5 MB)
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_402_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1995.5 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Added broadcast_402_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2003.9 MB)
17/12/19 16:43:33 INFO SparkContext: Created broadcast 402 from broadcast at DAGScheduler.scala:996
17/12/19 16:43:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 599 (MapPartitionsRDD[1302] at sql at <unknown>:0)
17/12/19 16:43:33 INFO TaskSchedulerImpl: Adding task set 599.0 with 1 tasks
17/12/19 16:43:33 INFO TaskSetManager: Starting task 0.0 in stage 599.0 (TID 446, localhost, executor driver, partition 0, ANY, 5957 bytes)
17/12/19 16:43:33 INFO Executor: Running task 0.0 in stage 599.0 (TID 446)
17/12/19 16:43:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:43:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:43:33 INFO Executor: Finished task 0.0 in stage 599.0 (TID 446). 1707 bytes result sent to driver
17/12/19 16:43:33 INFO TaskSetManager: Finished task 0.0 in stage 599.0 (TID 446) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:43:33 INFO TaskSchedulerImpl: Removed TaskSet 599.0, whose tasks have all completed, from pool 
17/12/19 16:43:33 INFO DAGScheduler: ResultStage 599 (sql at <unknown>:0) finished in 0.000 s
17/12/19 16:43:33 INFO DAGScheduler: Job 287 finished: sql at <unknown>:0, took 0.041150 s
17/12/19 16:43:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:33 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 16:43:33 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:43:33 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 84 is 145 bytes
17/12/19 16:43:33 INFO DAGScheduler: Registering RDD 1306 (collect at utils.scala:196)
17/12/19 16:43:33 INFO DAGScheduler: Got job 288 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:43:33 INFO DAGScheduler: Final stage: ResultStage 602 (collect at utils.scala:196)
17/12/19 16:43:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 601)
17/12/19 16:43:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 601)
17/12/19 16:43:33 INFO DAGScheduler: Submitting ShuffleMapStage 601 (MapPartitionsRDD[1306] at collect at utils.scala:196), which has no missing parents
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_403 stored as values in memory (estimated size 11.9 KB, free 1995.5 MB)
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_403_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1995.5 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Added broadcast_403_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2003.9 MB)
17/12/19 16:43:33 INFO SparkContext: Created broadcast 403 from broadcast at DAGScheduler.scala:996
17/12/19 16:43:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 601 (MapPartitionsRDD[1306] at collect at utils.scala:196)
17/12/19 16:43:33 INFO TaskSchedulerImpl: Adding task set 601.0 with 2 tasks
17/12/19 16:43:33 INFO TaskSetManager: Starting task 0.0 in stage 601.0 (TID 447, localhost, executor driver, partition 0, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:43:33 INFO TaskSetManager: Starting task 1.0 in stage 601.0 (TID 448, localhost, executor driver, partition 1, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:43:33 INFO Executor: Running task 1.0 in stage 601.0 (TID 448)
17/12/19 16:43:33 INFO Executor: Running task 0.0 in stage 601.0 (TID 447)
17/12/19 16:43:33 INFO BlockManager: Found block rdd_1296_1 locally
17/12/19 16:43:33 INFO BlockManager: Found block rdd_1296_0 locally
17/12/19 16:43:33 INFO Executor: Finished task 0.0 in stage 601.0 (TID 447). 1950 bytes result sent to driver
17/12/19 16:43:33 INFO TaskSetManager: Finished task 0.0 in stage 601.0 (TID 447) in 15 ms on localhost (executor driver) (1/2)
17/12/19 16:43:33 INFO Executor: Finished task 1.0 in stage 601.0 (TID 448). 1871 bytes result sent to driver
17/12/19 16:43:33 INFO TaskSetManager: Finished task 1.0 in stage 601.0 (TID 448) in 15 ms on localhost (executor driver) (2/2)
17/12/19 16:43:33 INFO TaskSchedulerImpl: Removed TaskSet 601.0, whose tasks have all completed, from pool 
17/12/19 16:43:33 INFO DAGScheduler: ShuffleMapStage 601 (collect at utils.scala:196) finished in 0.015 s
17/12/19 16:43:33 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:43:33 INFO DAGScheduler: running: Set()
17/12/19 16:43:33 INFO DAGScheduler: waiting: Set(ResultStage 602)
17/12/19 16:43:33 INFO DAGScheduler: failed: Set()
17/12/19 16:43:33 INFO DAGScheduler: Submitting ResultStage 602 (MapPartitionsRDD[1309] at collect at utils.scala:196), which has no missing parents
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_404 stored as values in memory (estimated size 7.0 KB, free 1995.5 MB)
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_404_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1995.5 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Added broadcast_404_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2003.9 MB)
17/12/19 16:43:33 INFO SparkContext: Created broadcast 404 from broadcast at DAGScheduler.scala:996
17/12/19 16:43:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 602 (MapPartitionsRDD[1309] at collect at utils.scala:196)
17/12/19 16:43:33 INFO TaskSchedulerImpl: Adding task set 602.0 with 1 tasks
17/12/19 16:43:33 INFO TaskSetManager: Starting task 0.0 in stage 602.0 (TID 449, localhost, executor driver, partition 0, ANY, 5949 bytes)
17/12/19 16:43:33 INFO Executor: Running task 0.0 in stage 602.0 (TID 449)
17/12/19 16:43:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:43:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:43:33 INFO Executor: Finished task 0.0 in stage 602.0 (TID 449). 1707 bytes result sent to driver
17/12/19 16:43:33 INFO TaskSetManager: Finished task 0.0 in stage 602.0 (TID 449) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:43:33 INFO TaskSchedulerImpl: Removed TaskSet 602.0, whose tasks have all completed, from pool 
17/12/19 16:43:33 INFO DAGScheduler: ResultStage 602 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:43:33 INFO DAGScheduler: Job 288 finished: collect at utils.scala:196, took 0.017155 s
17/12/19 16:43:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz118`
WHERE (0 = 1)
17/12/19 16:43:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:33 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `claftesrgp`
17/12/19 16:43:33 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:43:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz119`
WHERE (0 = 1)
17/12/19 16:43:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:43:33 INFO CodeGenerator: Code generated in 6.823647 ms
17/12/19 16:43:33 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:43:33 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 84 is 145 bytes
17/12/19 16:43:33 INFO DAGScheduler: Got job 289 (take at <unknown>:0) with 1 output partitions
17/12/19 16:43:33 INFO DAGScheduler: Final stage: ResultStage 604 (take at <unknown>:0)
17/12/19 16:43:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 603)
17/12/19 16:43:33 INFO DAGScheduler: Missing parents: List()
17/12/19 16:43:33 INFO DAGScheduler: Submitting ResultStage 604 (WorkerRDD[1315] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_405 stored as values in memory (estimated size 126.3 KB, free 1995.4 MB)
17/12/19 16:43:33 INFO MemoryStore: Block broadcast_405_piece0 stored as bytes in memory (estimated size 49.4 KB, free 1995.3 MB)
17/12/19 16:43:33 INFO BlockManagerInfo: Added broadcast_405_piece0 in memory on 127.0.0.1:53618 (size: 49.4 KB, free: 2003.8 MB)
17/12/19 16:43:33 INFO SparkContext: Created broadcast 405 from broadcast at DAGScheduler.scala:996
17/12/19 16:43:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 604 (WorkerRDD[1315] at RDD at rdd.scala:18)
17/12/19 16:43:33 INFO TaskSchedulerImpl: Adding task set 604.0 with 1 tasks
17/12/19 16:43:33 INFO TaskSetManager: Starting task 0.0 in stage 604.0 (TID 450, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:43:33 INFO Executor: Running task 0.0 in stage 604.0 (TID 450)
17/12/19 16:43:33 INFO BlockManager: Found block rdd_1296_0 locally
17/12/19 16:43:34 INFO MemoryStore: Block rdd_1315_0 stored as values in memory (estimated size 608.0 B, free 1995.3 MB)
17/12/19 16:43:34 INFO BlockManagerInfo: Added rdd_1315_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.8 MB)
17/12/19 16:43:34 INFO Executor: Finished task 0.0 in stage 604.0 (TID 450). 2509 bytes result sent to driver
17/12/19 16:43:34 INFO TaskSetManager: Finished task 0.0 in stage 604.0 (TID 450) in 704 ms on localhost (executor driver) (1/1)
17/12/19 16:43:34 INFO TaskSchedulerImpl: Removed TaskSet 604.0, whose tasks have all completed, from pool 
17/12/19 16:43:34 INFO DAGScheduler: ResultStage 604 (take at <unknown>:0) finished in 0.704 s
17/12/19 16:43:34 INFO DAGScheduler: Job 289 finished: take at <unknown>:0, took 0.696433 s
17/12/19 16:43:34 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:43:34 INFO DAGScheduler: Got job 290 (take at <unknown>:0) with 1 output partitions
17/12/19 16:43:34 INFO DAGScheduler: Final stage: ResultStage 606 (take at <unknown>:0)
17/12/19 16:43:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 605)
17/12/19 16:43:34 INFO DAGScheduler: Missing parents: List()
17/12/19 16:43:34 INFO DAGScheduler: Submitting ResultStage 606 (WorkerRDD[1315] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:43:34 INFO MemoryStore: Block broadcast_406 stored as values in memory (estimated size 126.3 KB, free 1995.2 MB)
17/12/19 16:43:34 INFO MemoryStore: Block broadcast_406_piece0 stored as bytes in memory (estimated size 49.5 KB, free 1995.1 MB)
17/12/19 16:43:34 INFO BlockManagerInfo: Added broadcast_406_piece0 in memory on 127.0.0.1:53618 (size: 49.5 KB, free: 2003.8 MB)
17/12/19 16:43:34 INFO SparkContext: Created broadcast 406 from broadcast at DAGScheduler.scala:996
17/12/19 16:43:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 606 (WorkerRDD[1315] at RDD at rdd.scala:18)
17/12/19 16:43:34 INFO TaskSchedulerImpl: Adding task set 606.0 with 1 tasks
17/12/19 16:43:34 INFO TaskSetManager: Starting task 0.0 in stage 606.0 (TID 451, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:43:34 INFO Executor: Running task 0.0 in stage 606.0 (TID 451)
17/12/19 16:43:34 INFO BlockManager: Found block rdd_1296_1 locally
17/12/19 16:43:34 INFO MemoryStore: Block rdd_1315_1 stored as values in memory (estimated size 608.0 B, free 1995.1 MB)
17/12/19 16:43:34 INFO BlockManagerInfo: Added rdd_1315_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.8 MB)
17/12/19 16:43:34 INFO Executor: Finished task 0.0 in stage 606.0 (TID 451). 2509 bytes result sent to driver
17/12/19 16:43:34 INFO TaskSetManager: Finished task 0.0 in stage 606.0 (TID 451) in 697 ms on localhost (executor driver) (1/1)
17/12/19 16:43:34 INFO TaskSchedulerImpl: Removed TaskSet 606.0, whose tasks have all completed, from pool 
17/12/19 16:43:34 INFO DAGScheduler: ResultStage 606 (take at <unknown>:0) finished in 0.697 s
17/12/19 16:43:34 INFO DAGScheduler: Job 290 finished: take at <unknown>:0, took 0.696833 s
17/12/19 16:43:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:34 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e876366793
17/12/19 16:43:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e876366793` AS `zzz120`
WHERE (0 = 1)
17/12/19 16:43:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e876366793`
17/12/19 16:43:34 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:43:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz121`
WHERE (0 = 1)
17/12/19 16:43:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:35 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 16:43:35 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:43:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz122`
WHERE (0 = 1)
17/12/19 16:43:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:43:35 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:43:35 INFO DAGScheduler: Got job 291 (collect at utils.scala:196) with 2 output partitions
17/12/19 16:43:35 INFO DAGScheduler: Final stage: ResultStage 608 (collect at utils.scala:196)
17/12/19 16:43:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 607)
17/12/19 16:43:35 INFO DAGScheduler: Missing parents: List()
17/12/19 16:43:35 INFO DAGScheduler: Submitting ResultStage 608 (MapPartitionsRDD[1322] at collect at utils.scala:196), which has no missing parents
17/12/19 16:43:35 INFO MemoryStore: Block broadcast_407 stored as values in memory (estimated size 133.9 KB, free 1995.0 MB)
17/12/19 16:43:35 INFO MemoryStore: Block broadcast_407_piece0 stored as bytes in memory (estimated size 53.0 KB, free 1995.0 MB)
17/12/19 16:43:35 INFO BlockManagerInfo: Added broadcast_407_piece0 in memory on 127.0.0.1:53618 (size: 53.0 KB, free: 2003.7 MB)
17/12/19 16:43:35 INFO SparkContext: Created broadcast 407 from broadcast at DAGScheduler.scala:996
17/12/19 16:43:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 608 (MapPartitionsRDD[1322] at collect at utils.scala:196)
17/12/19 16:43:35 INFO TaskSchedulerImpl: Adding task set 608.0 with 2 tasks
17/12/19 16:43:35 INFO TaskSetManager: Starting task 0.0 in stage 608.0 (TID 452, localhost, executor driver, partition 0, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:43:35 INFO TaskSetManager: Starting task 1.0 in stage 608.0 (TID 453, localhost, executor driver, partition 1, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:43:35 INFO Executor: Running task 1.0 in stage 608.0 (TID 453)
17/12/19 16:43:35 INFO Executor: Running task 0.0 in stage 608.0 (TID 452)
17/12/19 16:43:35 INFO BlockManager: Found block rdd_1315_1 locally
17/12/19 16:43:35 INFO BlockManager: Found block rdd_1315_0 locally
17/12/19 16:43:35 INFO Executor: Finished task 1.0 in stage 608.0 (TID 453). 1526 bytes result sent to driver
17/12/19 16:43:35 INFO Executor: Finished task 0.0 in stage 608.0 (TID 452). 1541 bytes result sent to driver
17/12/19 16:43:35 INFO TaskSetManager: Finished task 1.0 in stage 608.0 (TID 453) in 1 ms on localhost (executor driver) (1/2)
17/12/19 16:43:35 INFO TaskSetManager: Finished task 0.0 in stage 608.0 (TID 452) in 2 ms on localhost (executor driver) (2/2)
17/12/19 16:43:35 INFO TaskSchedulerImpl: Removed TaskSet 608.0, whose tasks have all completed, from pool 
17/12/19 16:43:35 INFO DAGScheduler: ResultStage 608 (collect at utils.scala:196) finished in 0.002 s
17/12/19 16:43:35 INFO DAGScheduler: Job 291 finished: collect at utils.scala:196, took 0.009120 s
17/12/19 16:43:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:43:35 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:43:35 INFO DAGScheduler: Got job 292 (take at <unknown>:0) with 1 output partitions
17/12/19 16:43:35 INFO DAGScheduler: Final stage: ResultStage 610 (take at <unknown>:0)
17/12/19 16:43:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 609)
17/12/19 16:43:35 INFO DAGScheduler: Missing parents: List()
17/12/19 16:43:35 INFO DAGScheduler: Submitting ResultStage 610 (WorkerRDD[1327] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:43:35 INFO MemoryStore: Block broadcast_408 stored as values in memory (estimated size 243.4 KB, free 1994.7 MB)
17/12/19 16:43:35 INFO MemoryStore: Block broadcast_408_piece0 stored as bytes in memory (estimated size 95.8 KB, free 1994.6 MB)
17/12/19 16:43:35 INFO BlockManagerInfo: Added broadcast_408_piece0 in memory on 127.0.0.1:53618 (size: 95.8 KB, free: 2003.6 MB)
17/12/19 16:43:35 INFO SparkContext: Created broadcast 408 from broadcast at DAGScheduler.scala:996
17/12/19 16:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 610 (WorkerRDD[1327] at RDD at rdd.scala:18)
17/12/19 16:43:35 INFO TaskSchedulerImpl: Adding task set 610.0 with 1 tasks
17/12/19 16:43:35 INFO TaskSetManager: Starting task 0.0 in stage 610.0 (TID 454, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:43:35 INFO Executor: Running task 0.0 in stage 610.0 (TID 454)
17/12/19 16:43:35 INFO BlockManager: Found block rdd_1315_0 locally
17/12/19 16:43:35 INFO MemoryStore: Block rdd_1327_0 stored as values in memory (estimated size 80.0 B, free 1994.6 MB)
17/12/19 16:43:35 INFO BlockManagerInfo: Added rdd_1327_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.6 MB)
17/12/19 16:43:35 INFO Executor: Finished task 0.0 in stage 610.0 (TID 454). 2400 bytes result sent to driver
17/12/19 16:43:35 INFO TaskSetManager: Finished task 0.0 in stage 610.0 (TID 454) in 640 ms on localhost (executor driver) (1/1)
17/12/19 16:43:35 INFO TaskSchedulerImpl: Removed TaskSet 610.0, whose tasks have all completed, from pool 
17/12/19 16:43:35 INFO DAGScheduler: ResultStage 610 (take at <unknown>:0) finished in 0.640 s
17/12/19 16:43:35 INFO DAGScheduler: Job 292 finished: take at <unknown>:0, took 0.635863 s
17/12/19 16:43:35 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:43:35 INFO DAGScheduler: Got job 293 (take at <unknown>:0) with 1 output partitions
17/12/19 16:43:35 INFO DAGScheduler: Final stage: ResultStage 612 (take at <unknown>:0)
17/12/19 16:43:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 611)
17/12/19 16:43:35 INFO DAGScheduler: Missing parents: List()
17/12/19 16:43:35 INFO DAGScheduler: Submitting ResultStage 612 (WorkerRDD[1327] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:43:35 INFO MemoryStore: Block broadcast_409 stored as values in memory (estimated size 243.4 KB, free 1994.4 MB)
17/12/19 16:43:35 INFO MemoryStore: Block broadcast_409_piece0 stored as bytes in memory (estimated size 95.8 KB, free 1994.3 MB)
17/12/19 16:43:35 INFO BlockManagerInfo: Added broadcast_409_piece0 in memory on 127.0.0.1:53618 (size: 95.8 KB, free: 2003.5 MB)
17/12/19 16:43:35 INFO SparkContext: Created broadcast 409 from broadcast at DAGScheduler.scala:996
17/12/19 16:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 612 (WorkerRDD[1327] at RDD at rdd.scala:18)
17/12/19 16:43:35 INFO TaskSchedulerImpl: Adding task set 612.0 with 1 tasks
17/12/19 16:43:35 INFO TaskSetManager: Starting task 0.0 in stage 612.0 (TID 455, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:43:35 INFO Executor: Running task 0.0 in stage 612.0 (TID 455)
17/12/19 16:43:35 INFO BlockManager: Found block rdd_1315_1 locally
17/12/19 16:43:36 INFO MemoryStore: Block rdd_1327_1 stored as values in memory (estimated size 80.0 B, free 1994.3 MB)
17/12/19 16:43:36 INFO BlockManagerInfo: Added rdd_1327_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.5 MB)
17/12/19 16:43:36 INFO Executor: Finished task 0.0 in stage 612.0 (TID 455). 2400 bytes result sent to driver
17/12/19 16:43:36 INFO TaskSetManager: Finished task 0.0 in stage 612.0 (TID 455) in 617 ms on localhost (executor driver) (1/1)
17/12/19 16:43:36 INFO TaskSchedulerImpl: Removed TaskSet 612.0, whose tasks have all completed, from pool 
17/12/19 16:43:36 INFO DAGScheduler: ResultStage 612 (take at <unknown>:0) finished in 0.617 s
17/12/19 16:43:36 INFO DAGScheduler: Job 293 finished: take at <unknown>:0, took 0.625686 s
17/12/19 16:43:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:36 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e835fe7a3e
17/12/19 16:43:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e835fe7a3e` AS `zzz123`
WHERE (0 = 1)
17/12/19 16:43:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e835fe7a3e`
LIMIT 10
17/12/19 16:43:36 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:43:36 INFO DAGScheduler: Got job 294 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:43:36 INFO DAGScheduler: Final stage: ResultStage 614 (collect at utils.scala:196)
17/12/19 16:43:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 613)
17/12/19 16:43:36 INFO DAGScheduler: Missing parents: List()
17/12/19 16:43:36 INFO DAGScheduler: Submitting ResultStage 614 (MapPartitionsRDD[1331] at collect at utils.scala:196), which has no missing parents
17/12/19 16:43:36 INFO MemoryStore: Block broadcast_410 stored as values in memory (estimated size 244.5 KB, free 1994.1 MB)
17/12/19 16:43:36 INFO MemoryStore: Block broadcast_410_piece0 stored as bytes in memory (estimated size 96.4 KB, free 1994.0 MB)
17/12/19 16:43:36 INFO BlockManagerInfo: Added broadcast_410_piece0 in memory on 127.0.0.1:53618 (size: 96.4 KB, free: 2003.4 MB)
17/12/19 16:43:36 INFO SparkContext: Created broadcast 410 from broadcast at DAGScheduler.scala:996
17/12/19 16:43:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 614 (MapPartitionsRDD[1331] at collect at utils.scala:196)
17/12/19 16:43:36 INFO TaskSchedulerImpl: Adding task set 614.0 with 1 tasks
17/12/19 16:43:36 INFO TaskSetManager: Starting task 0.0 in stage 614.0 (TID 456, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:43:36 INFO Executor: Running task 0.0 in stage 614.0 (TID 456)
17/12/19 16:43:36 INFO BlockManager: Found block rdd_1327_0 locally
17/12/19 16:43:36 INFO Executor: Finished task 0.0 in stage 614.0 (TID 456). 1479 bytes result sent to driver
17/12/19 16:43:36 INFO TaskSetManager: Finished task 0.0 in stage 614.0 (TID 456) in 16 ms on localhost (executor driver) (1/1)
17/12/19 16:43:36 INFO TaskSchedulerImpl: Removed TaskSet 614.0, whose tasks have all completed, from pool 
17/12/19 16:43:36 INFO DAGScheduler: ResultStage 614 (collect at utils.scala:196) finished in 0.016 s
17/12/19 16:43:36 INFO DAGScheduler: Job 294 finished: collect at utils.scala:196, took 0.006932 s
17/12/19 16:43:36 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:43:36 INFO DAGScheduler: Got job 295 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:43:36 INFO DAGScheduler: Final stage: ResultStage 616 (collect at utils.scala:196)
17/12/19 16:43:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 615)
17/12/19 16:43:36 INFO DAGScheduler: Missing parents: List()
17/12/19 16:43:36 INFO DAGScheduler: Submitting ResultStage 616 (MapPartitionsRDD[1331] at collect at utils.scala:196), which has no missing parents
17/12/19 16:43:36 INFO MemoryStore: Block broadcast_411 stored as values in memory (estimated size 244.5 KB, free 1993.7 MB)
17/12/19 16:43:36 INFO MemoryStore: Block broadcast_411_piece0 stored as bytes in memory (estimated size 96.4 KB, free 1993.6 MB)
17/12/19 16:43:36 INFO BlockManagerInfo: Added broadcast_411_piece0 in memory on 127.0.0.1:53618 (size: 96.4 KB, free: 2003.3 MB)
17/12/19 16:43:36 INFO SparkContext: Created broadcast 411 from broadcast at DAGScheduler.scala:996
17/12/19 16:43:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 616 (MapPartitionsRDD[1331] at collect at utils.scala:196)
17/12/19 16:43:36 INFO TaskSchedulerImpl: Adding task set 616.0 with 1 tasks
17/12/19 16:43:36 INFO TaskSetManager: Starting task 0.0 in stage 616.0 (TID 457, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:43:36 INFO Executor: Running task 0.0 in stage 616.0 (TID 457)
17/12/19 16:43:36 INFO BlockManager: Found block rdd_1327_1 locally
17/12/19 16:43:36 INFO Executor: Finished task 0.0 in stage 616.0 (TID 457). 1479 bytes result sent to driver
17/12/19 16:43:36 INFO TaskSetManager: Finished task 0.0 in stage 616.0 (TID 457) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:43:36 INFO TaskSchedulerImpl: Removed TaskSet 616.0, whose tasks have all completed, from pool 
17/12/19 16:43:36 INFO DAGScheduler: ResultStage 616 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:43:36 INFO DAGScheduler: Job 295 finished: collect at utils.scala:196, took 0.006497 s
17/12/19 16:43:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:43:36 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:43:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:43:36 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:43:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:43:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:43:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:43:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:43:36 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:43:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:43:36 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:43:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:43:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:43:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:43:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:43:36 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:43:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:43:36 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:43:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:43:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:43:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:43:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:43:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:43:36 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:43:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:43:36 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:43:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:43:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:43:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:46:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:46:11 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:46:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:46:11 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:46:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:46:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:46:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20694
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20683
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20684
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20690
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20691
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20692
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20693
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20695
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20696
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20697
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20698
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20699
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20700
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20701
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20702
17/12/19 16:46:11 INFO ContextCleaner: Cleaned shuffle 85
17/12/19 16:46:11 INFO BlockManagerInfo: Removed broadcast_400_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2003.3 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Removed broadcast_401_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.3 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Removed broadcast_402_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.3 MB)
17/12/19 16:46:11 INFO ContextCleaner: Cleaned accumulator 20871
17/12/19 16:46:11 INFO BlockManagerInfo: Removed broadcast_403_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.4 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Removed broadcast_404_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.4 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Removed broadcast_405_piece0 on 127.0.0.1:53618 in memory (size: 49.4 KB, free: 2003.4 MB)
17/12/19 16:46:11 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 16:46:11 INFO BlockManagerInfo: Removed broadcast_406_piece0 on 127.0.0.1:53618 in memory (size: 49.5 KB, free: 2003.5 MB)
17/12/19 16:46:11 INFO DAGScheduler: Got job 296 (collect at utils.scala:58) with 1 output partitions
17/12/19 16:46:11 INFO DAGScheduler: Final stage: ResultStage 617 (collect at utils.scala:58)
17/12/19 16:46:11 INFO DAGScheduler: Parents of final stage: List()
17/12/19 16:46:11 INFO DAGScheduler: Missing parents: List()
17/12/19 16:46:11 INFO DAGScheduler: Submitting ResultStage 617 (MapPartitionsRDD[1341] at map at utils.scala:55), which has no missing parents
17/12/19 16:46:11 INFO BlockManagerInfo: Removed broadcast_407_piece0 on 127.0.0.1:53618 in memory (size: 53.0 KB, free: 2003.5 MB)
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_412 stored as values in memory (estimated size 8.7 KB, free 1994.2 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Removed broadcast_408_piece0 on 127.0.0.1:53618 in memory (size: 95.8 KB, free: 2003.6 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Removed broadcast_409_piece0 on 127.0.0.1:53618 in memory (size: 95.8 KB, free: 2003.7 MB)
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_412_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1994.6 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Added broadcast_412_piece0 in memory on 127.0.0.1:53618 (size: 4.6 KB, free: 2003.7 MB)
17/12/19 16:46:11 INFO SparkContext: Created broadcast 412 from broadcast at DAGScheduler.scala:996
17/12/19 16:46:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 617 (MapPartitionsRDD[1341] at map at utils.scala:55)
17/12/19 16:46:11 INFO TaskSchedulerImpl: Adding task set 617.0 with 1 tasks
17/12/19 16:46:11 INFO BlockManagerInfo: Removed broadcast_410_piece0 on 127.0.0.1:53618 in memory (size: 96.4 KB, free: 2003.8 MB)
17/12/19 16:46:11 INFO TaskSetManager: Starting task 0.0 in stage 617.0 (TID 458, localhost, executor driver, partition 0, PROCESS_LOCAL, 9662 bytes)
17/12/19 16:46:11 INFO BlockManagerInfo: Removed broadcast_411_piece0 on 127.0.0.1:53618 in memory (size: 96.4 KB, free: 2003.9 MB)
17/12/19 16:46:11 INFO Executor: Running task 0.0 in stage 617.0 (TID 458)
17/12/19 16:46:11 INFO Executor: Finished task 0.0 in stage 617.0 (TID 458). 2194 bytes result sent to driver
17/12/19 16:46:11 INFO TaskSetManager: Finished task 0.0 in stage 617.0 (TID 458) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:46:11 INFO DAGScheduler: ResultStage 617 (collect at utils.scala:58) finished in 0.000 s
17/12/19 16:46:11 INFO TaskSchedulerImpl: Removed TaskSet 617.0, whose tasks have all completed, from pool 
17/12/19 16:46:11 INFO DAGScheduler: Job 296 finished: collect at utils.scala:58, took 0.006369 s
17/12/19 16:46:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:11 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:46:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:11 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 16:46:11 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 16:46:11 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 16:46:11 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 16:46:11 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 16:46:11 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_413 stored as values in memory (estimated size 293.7 KB, free 1995.3 MB)
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_413_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1995.2 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Added broadcast_413_piece0 in memory on 127.0.0.1:53618 (size: 24.0 KB, free: 2003.9 MB)
17/12/19 16:46:11 INFO SparkContext: Created broadcast 413 from sql at <unknown>:0
17/12/19 16:46:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 16:46:11 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 16:46:11 INFO DAGScheduler: Registering RDD 1345 (sql at <unknown>:0)
17/12/19 16:46:11 INFO DAGScheduler: Registering RDD 1350 (sql at <unknown>:0)
17/12/19 16:46:11 INFO DAGScheduler: Got job 297 (sql at <unknown>:0) with 1 output partitions
17/12/19 16:46:11 INFO DAGScheduler: Final stage: ResultStage 620 (sql at <unknown>:0)
17/12/19 16:46:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 619)
17/12/19 16:46:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 619)
17/12/19 16:46:11 INFO DAGScheduler: Submitting ShuffleMapStage 618 (MapPartitionsRDD[1345] at sql at <unknown>:0), which has no missing parents
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_414 stored as values in memory (estimated size 12.1 KB, free 1995.2 MB)
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_414_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1995.2 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Added broadcast_414_piece0 in memory on 127.0.0.1:53618 (size: 7.3 KB, free: 2003.8 MB)
17/12/19 16:46:11 INFO SparkContext: Created broadcast 414 from broadcast at DAGScheduler.scala:996
17/12/19 16:46:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 618 (MapPartitionsRDD[1345] at sql at <unknown>:0)
17/12/19 16:46:11 INFO TaskSchedulerImpl: Adding task set 618.0 with 1 tasks
17/12/19 16:46:11 INFO TaskSetManager: Starting task 0.0 in stage 618.0 (TID 459, localhost, executor driver, partition 0, PROCESS_LOCAL, 6680 bytes)
17/12/19 16:46:11 INFO Executor: Running task 0.0 in stage 618.0 (TID 459)
17/12/19 16:46:11 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/Rtmp6bghtt/spark_serialize_3a6216545a996bf4cabe12ec90fa0e12c021010e143a608322651ef94aa0aa23.csv, range: 0-456, partition values: [empty row]
17/12/19 16:46:11 INFO Executor: Finished task 0.0 in stage 618.0 (TID 459). 1553 bytes result sent to driver
17/12/19 16:46:11 INFO TaskSetManager: Finished task 0.0 in stage 618.0 (TID 459) in 31 ms on localhost (executor driver) (1/1)
17/12/19 16:46:11 INFO TaskSchedulerImpl: Removed TaskSet 618.0, whose tasks have all completed, from pool 
17/12/19 16:46:11 INFO DAGScheduler: ShuffleMapStage 618 (sql at <unknown>:0) finished in 0.031 s
17/12/19 16:46:11 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:46:11 INFO DAGScheduler: running: Set()
17/12/19 16:46:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 619, ResultStage 620)
17/12/19 16:46:11 INFO DAGScheduler: failed: Set()
17/12/19 16:46:11 INFO DAGScheduler: Submitting ShuffleMapStage 619 (MapPartitionsRDD[1350] at sql at <unknown>:0), which has no missing parents
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_415 stored as values in memory (estimated size 11.9 KB, free 1995.2 MB)
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_415_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1995.2 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Added broadcast_415_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2003.8 MB)
17/12/19 16:46:11 INFO SparkContext: Created broadcast 415 from broadcast at DAGScheduler.scala:996
17/12/19 16:46:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 619 (MapPartitionsRDD[1350] at sql at <unknown>:0)
17/12/19 16:46:11 INFO TaskSchedulerImpl: Adding task set 619.0 with 2 tasks
17/12/19 16:46:11 INFO TaskSetManager: Starting task 0.0 in stage 619.0 (TID 460, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 16:46:11 INFO TaskSetManager: Starting task 1.0 in stage 619.0 (TID 461, localhost, executor driver, partition 1, ANY, 5946 bytes)
17/12/19 16:46:11 INFO Executor: Running task 0.0 in stage 619.0 (TID 460)
17/12/19 16:46:11 INFO Executor: Running task 1.0 in stage 619.0 (TID 461)
17/12/19 16:46:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:46:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:46:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:46:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:46:11 INFO MemoryStore: Block rdd_1347_1 stored as values in memory (estimated size 544.0 B, free 1995.2 MB)
17/12/19 16:46:11 INFO MemoryStore: Block rdd_1347_0 stored as values in memory (estimated size 544.0 B, free 1995.2 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Added rdd_1347_0 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2003.8 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Added rdd_1347_1 in memory on 127.0.0.1:53618 (size: 544.0 B, free: 2003.8 MB)
17/12/19 16:46:11 INFO Executor: Finished task 1.0 in stage 619.0 (TID 461). 3064 bytes result sent to driver
17/12/19 16:46:11 INFO TaskSetManager: Finished task 1.0 in stage 619.0 (TID 461) in 16 ms on localhost (executor driver) (1/2)
17/12/19 16:46:11 INFO Executor: Finished task 0.0 in stage 619.0 (TID 460). 3064 bytes result sent to driver
17/12/19 16:46:11 INFO TaskSetManager: Finished task 0.0 in stage 619.0 (TID 460) in 16 ms on localhost (executor driver) (2/2)
17/12/19 16:46:11 INFO TaskSchedulerImpl: Removed TaskSet 619.0, whose tasks have all completed, from pool 
17/12/19 16:46:11 INFO DAGScheduler: ShuffleMapStage 619 (sql at <unknown>:0) finished in 0.016 s
17/12/19 16:46:11 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:46:11 INFO DAGScheduler: running: Set()
17/12/19 16:46:11 INFO DAGScheduler: waiting: Set(ResultStage 620)
17/12/19 16:46:11 INFO DAGScheduler: failed: Set()
17/12/19 16:46:11 INFO DAGScheduler: Submitting ResultStage 620 (MapPartitionsRDD[1353] at sql at <unknown>:0), which has no missing parents
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_416 stored as values in memory (estimated size 7.0 KB, free 1995.2 MB)
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_416_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1995.2 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Added broadcast_416_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2003.8 MB)
17/12/19 16:46:11 INFO SparkContext: Created broadcast 416 from broadcast at DAGScheduler.scala:996
17/12/19 16:46:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 620 (MapPartitionsRDD[1353] at sql at <unknown>:0)
17/12/19 16:46:11 INFO TaskSchedulerImpl: Adding task set 620.0 with 1 tasks
17/12/19 16:46:11 INFO TaskSetManager: Starting task 0.0 in stage 620.0 (TID 462, localhost, executor driver, partition 0, ANY, 5957 bytes)
17/12/19 16:46:11 INFO Executor: Running task 0.0 in stage 620.0 (TID 462)
17/12/19 16:46:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:46:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:46:11 INFO Executor: Finished task 0.0 in stage 620.0 (TID 462). 1707 bytes result sent to driver
17/12/19 16:46:11 INFO TaskSetManager: Finished task 0.0 in stage 620.0 (TID 462) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:46:11 INFO TaskSchedulerImpl: Removed TaskSet 620.0, whose tasks have all completed, from pool 
17/12/19 16:46:11 INFO DAGScheduler: ResultStage 620 (sql at <unknown>:0) finished in 0.000 s
17/12/19 16:46:11 INFO DAGScheduler: Job 297 finished: sql at <unknown>:0, took 0.047932 s
17/12/19 16:46:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:11 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 16:46:11 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:46:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 87 is 145 bytes
17/12/19 16:46:11 INFO DAGScheduler: Registering RDD 1357 (collect at utils.scala:196)
17/12/19 16:46:11 INFO DAGScheduler: Got job 298 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:46:11 INFO DAGScheduler: Final stage: ResultStage 623 (collect at utils.scala:196)
17/12/19 16:46:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 622)
17/12/19 16:46:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 622)
17/12/19 16:46:11 INFO DAGScheduler: Submitting ShuffleMapStage 622 (MapPartitionsRDD[1357] at collect at utils.scala:196), which has no missing parents
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_417 stored as values in memory (estimated size 11.9 KB, free 1995.2 MB)
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_417_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1995.2 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Added broadcast_417_piece0 in memory on 127.0.0.1:53618 (size: 6.0 KB, free: 2003.8 MB)
17/12/19 16:46:11 INFO SparkContext: Created broadcast 417 from broadcast at DAGScheduler.scala:996
17/12/19 16:46:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 622 (MapPartitionsRDD[1357] at collect at utils.scala:196)
17/12/19 16:46:11 INFO TaskSchedulerImpl: Adding task set 622.0 with 2 tasks
17/12/19 16:46:11 INFO TaskSetManager: Starting task 0.0 in stage 622.0 (TID 463, localhost, executor driver, partition 0, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:46:11 INFO TaskSetManager: Starting task 1.0 in stage 622.0 (TID 464, localhost, executor driver, partition 1, PROCESS_LOCAL, 5938 bytes)
17/12/19 16:46:11 INFO Executor: Running task 1.0 in stage 622.0 (TID 464)
17/12/19 16:46:11 INFO Executor: Running task 0.0 in stage 622.0 (TID 463)
17/12/19 16:46:11 INFO BlockManager: Found block rdd_1347_0 locally
17/12/19 16:46:11 INFO BlockManager: Found block rdd_1347_1 locally
17/12/19 16:46:11 INFO Executor: Finished task 1.0 in stage 622.0 (TID 464). 1792 bytes result sent to driver
17/12/19 16:46:11 INFO TaskSetManager: Finished task 1.0 in stage 622.0 (TID 464) in 0 ms on localhost (executor driver) (1/2)
17/12/19 16:46:11 INFO Executor: Finished task 0.0 in stage 622.0 (TID 463). 1792 bytes result sent to driver
17/12/19 16:46:11 INFO TaskSetManager: Finished task 0.0 in stage 622.0 (TID 463) in 0 ms on localhost (executor driver) (2/2)
17/12/19 16:46:11 INFO TaskSchedulerImpl: Removed TaskSet 622.0, whose tasks have all completed, from pool 
17/12/19 16:46:11 INFO DAGScheduler: ShuffleMapStage 622 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:46:11 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:46:11 INFO DAGScheduler: running: Set()
17/12/19 16:46:11 INFO DAGScheduler: waiting: Set(ResultStage 623)
17/12/19 16:46:11 INFO DAGScheduler: failed: Set()
17/12/19 16:46:11 INFO DAGScheduler: Submitting ResultStage 623 (MapPartitionsRDD[1360] at collect at utils.scala:196), which has no missing parents
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_418 stored as values in memory (estimated size 7.0 KB, free 1995.2 MB)
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_418_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1995.2 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Added broadcast_418_piece0 in memory on 127.0.0.1:53618 (size: 3.7 KB, free: 2003.8 MB)
17/12/19 16:46:11 INFO SparkContext: Created broadcast 418 from broadcast at DAGScheduler.scala:996
17/12/19 16:46:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 623 (MapPartitionsRDD[1360] at collect at utils.scala:196)
17/12/19 16:46:11 INFO TaskSchedulerImpl: Adding task set 623.0 with 1 tasks
17/12/19 16:46:11 INFO TaskSetManager: Starting task 0.0 in stage 623.0 (TID 465, localhost, executor driver, partition 0, ANY, 5949 bytes)
17/12/19 16:46:11 INFO Executor: Running task 0.0 in stage 623.0 (TID 465)
17/12/19 16:46:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:46:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:46:11 INFO Executor: Finished task 0.0 in stage 623.0 (TID 465). 1707 bytes result sent to driver
17/12/19 16:46:11 INFO TaskSetManager: Finished task 0.0 in stage 623.0 (TID 465) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:46:11 INFO TaskSchedulerImpl: Removed TaskSet 623.0, whose tasks have all completed, from pool 
17/12/19 16:46:11 INFO DAGScheduler: ResultStage 623 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:46:11 INFO DAGScheduler: Job 298 finished: collect at utils.scala:196, took 0.016737 s
17/12/19 16:46:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz124`
WHERE (0 = 1)
17/12/19 16:46:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:11 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.89442719 * RANDN() AS `V1`, `S3` + 0.9486833 * RANDN() AS `V2`, `S3` + 0.9486833 * RANDN() AS `V3`, `S1` + 0.93808315 * RANDN() AS `V4`
FROM `analyis_tbl`) `tqlmnomshg`
17/12/19 16:46:11 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:46:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz125`
WHERE (0 = 1)
17/12/19 16:46:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:46:11 INFO CodeGenerator: Code generated in 7.317146 ms
17/12/19 16:46:11 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:46:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 87 is 145 bytes
17/12/19 16:46:11 INFO DAGScheduler: Got job 299 (take at <unknown>:0) with 1 output partitions
17/12/19 16:46:11 INFO DAGScheduler: Final stage: ResultStage 625 (take at <unknown>:0)
17/12/19 16:46:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 624)
17/12/19 16:46:11 INFO DAGScheduler: Missing parents: List()
17/12/19 16:46:11 INFO DAGScheduler: Submitting ResultStage 625 (WorkerRDD[1366] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_419 stored as values in memory (estimated size 126.6 KB, free 1995.0 MB)
17/12/19 16:46:11 INFO MemoryStore: Block broadcast_419_piece0 stored as bytes in memory (estimated size 49.6 KB, free 1995.0 MB)
17/12/19 16:46:11 INFO BlockManagerInfo: Added broadcast_419_piece0 in memory on 127.0.0.1:53618 (size: 49.6 KB, free: 2003.8 MB)
17/12/19 16:46:11 INFO SparkContext: Created broadcast 419 from broadcast at DAGScheduler.scala:996
17/12/19 16:46:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 625 (WorkerRDD[1366] at RDD at rdd.scala:18)
17/12/19 16:46:11 INFO TaskSchedulerImpl: Adding task set 625.0 with 1 tasks
17/12/19 16:46:11 INFO TaskSetManager: Starting task 0.0 in stage 625.0 (TID 466, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:46:11 INFO Executor: Running task 0.0 in stage 625.0 (TID 466)
17/12/19 16:46:11 INFO BlockManager: Found block rdd_1347_0 locally
17/12/19 16:46:12 INFO MemoryStore: Block rdd_1366_0 stored as values in memory (estimated size 608.0 B, free 1995.0 MB)
17/12/19 16:46:12 INFO BlockManagerInfo: Added rdd_1366_0 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.8 MB)
17/12/19 16:46:12 INFO Executor: Finished task 0.0 in stage 625.0 (TID 466). 2596 bytes result sent to driver
17/12/19 16:46:12 INFO TaskSetManager: Finished task 0.0 in stage 625.0 (TID 466) in 675 ms on localhost (executor driver) (1/1)
17/12/19 16:46:12 INFO TaskSchedulerImpl: Removed TaskSet 625.0, whose tasks have all completed, from pool 
17/12/19 16:46:12 INFO DAGScheduler: ResultStage 625 (take at <unknown>:0) finished in 0.676 s
17/12/19 16:46:12 INFO DAGScheduler: Job 299 finished: take at <unknown>:0, took 0.690875 s
17/12/19 16:46:12 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:46:12 INFO DAGScheduler: Got job 300 (take at <unknown>:0) with 1 output partitions
17/12/19 16:46:12 INFO DAGScheduler: Final stage: ResultStage 627 (take at <unknown>:0)
17/12/19 16:46:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 626)
17/12/19 16:46:12 INFO DAGScheduler: Missing parents: List()
17/12/19 16:46:12 INFO DAGScheduler: Submitting ResultStage 627 (WorkerRDD[1366] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:46:12 INFO MemoryStore: Block broadcast_420 stored as values in memory (estimated size 126.6 KB, free 1994.9 MB)
17/12/19 16:46:12 INFO MemoryStore: Block broadcast_420_piece0 stored as bytes in memory (estimated size 49.6 KB, free 1994.8 MB)
17/12/19 16:46:12 INFO BlockManagerInfo: Added broadcast_420_piece0 in memory on 127.0.0.1:53618 (size: 49.6 KB, free: 2003.7 MB)
17/12/19 16:46:12 INFO SparkContext: Created broadcast 420 from broadcast at DAGScheduler.scala:996
17/12/19 16:46:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 627 (WorkerRDD[1366] at RDD at rdd.scala:18)
17/12/19 16:46:12 INFO TaskSchedulerImpl: Adding task set 627.0 with 1 tasks
17/12/19 16:46:12 INFO TaskSetManager: Starting task 0.0 in stage 627.0 (TID 467, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:46:12 INFO Executor: Running task 0.0 in stage 627.0 (TID 467)
17/12/19 16:46:12 INFO BlockManager: Found block rdd_1347_1 locally
17/12/19 16:46:12 INFO MemoryStore: Block rdd_1366_1 stored as values in memory (estimated size 608.0 B, free 1994.8 MB)
17/12/19 16:46:12 INFO BlockManagerInfo: Added rdd_1366_1 in memory on 127.0.0.1:53618 (size: 608.0 B, free: 2003.7 MB)
17/12/19 16:46:12 INFO Executor: Finished task 0.0 in stage 627.0 (TID 467). 2509 bytes result sent to driver
17/12/19 16:46:12 INFO TaskSetManager: Finished task 0.0 in stage 627.0 (TID 467) in 634 ms on localhost (executor driver) (1/1)
17/12/19 16:46:12 INFO TaskSchedulerImpl: Removed TaskSet 627.0, whose tasks have all completed, from pool 
17/12/19 16:46:12 INFO DAGScheduler: ResultStage 627 (take at <unknown>:0) finished in 0.634 s
17/12/19 16:46:12 INFO DAGScheduler: Job 300 finished: take at <unknown>:0, took 0.642236 s
17/12/19 16:46:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:12 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e84ab66424
17/12/19 16:46:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e84ab66424` AS `zzz126`
WHERE (0 = 1)
17/12/19 16:46:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e84ab66424`
17/12/19 16:46:12 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:46:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz127`
WHERE (0 = 1)
17/12/19 16:46:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:12 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.009) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0138) AS `V3`, (`V4` < 0.0375) AS `V4`
FROM `analyis_tbl`
17/12/19 16:46:12 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:46:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz128`
WHERE (0 = 1)
17/12/19 16:46:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:46:12 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:46:12 INFO DAGScheduler: Got job 301 (collect at utils.scala:196) with 2 output partitions
17/12/19 16:46:12 INFO DAGScheduler: Final stage: ResultStage 629 (collect at utils.scala:196)
17/12/19 16:46:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 628)
17/12/19 16:46:12 INFO DAGScheduler: Missing parents: List()
17/12/19 16:46:12 INFO DAGScheduler: Submitting ResultStage 629 (MapPartitionsRDD[1373] at collect at utils.scala:196), which has no missing parents
17/12/19 16:46:12 INFO MemoryStore: Block broadcast_421 stored as values in memory (estimated size 134.2 KB, free 1994.7 MB)
17/12/19 16:46:12 INFO MemoryStore: Block broadcast_421_piece0 stored as bytes in memory (estimated size 53.2 KB, free 1994.6 MB)
17/12/19 16:46:12 INFO BlockManagerInfo: Added broadcast_421_piece0 in memory on 127.0.0.1:53618 (size: 53.2 KB, free: 2003.7 MB)
17/12/19 16:46:12 INFO SparkContext: Created broadcast 421 from broadcast at DAGScheduler.scala:996
17/12/19 16:46:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 629 (MapPartitionsRDD[1373] at collect at utils.scala:196)
17/12/19 16:46:12 INFO TaskSchedulerImpl: Adding task set 629.0 with 2 tasks
17/12/19 16:46:12 INFO TaskSetManager: Starting task 0.0 in stage 629.0 (TID 468, localhost, executor driver, partition 0, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:46:12 INFO TaskSetManager: Starting task 1.0 in stage 629.0 (TID 469, localhost, executor driver, partition 1, PROCESS_LOCAL, 5949 bytes)
17/12/19 16:46:12 INFO Executor: Running task 1.0 in stage 629.0 (TID 469)
17/12/19 16:46:12 INFO Executor: Running task 0.0 in stage 629.0 (TID 468)
17/12/19 16:46:12 INFO BlockManager: Found block rdd_1366_1 locally
17/12/19 16:46:12 INFO BlockManager: Found block rdd_1366_0 locally
17/12/19 16:46:12 INFO Executor: Finished task 1.0 in stage 629.0 (TID 469). 1439 bytes result sent to driver
17/12/19 16:46:12 INFO Executor: Finished task 0.0 in stage 629.0 (TID 468). 1447 bytes result sent to driver
17/12/19 16:46:12 INFO TaskSetManager: Finished task 1.0 in stage 629.0 (TID 469) in 0 ms on localhost (executor driver) (1/2)
17/12/19 16:46:12 INFO TaskSetManager: Finished task 0.0 in stage 629.0 (TID 468) in 0 ms on localhost (executor driver) (2/2)
17/12/19 16:46:12 INFO DAGScheduler: ResultStage 629 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:46:12 INFO DAGScheduler: Job 301 finished: collect at utils.scala:196, took 0.007981 s
17/12/19 16:46:12 INFO TaskSchedulerImpl: Removed TaskSet 629.0, whose tasks have all completed, from pool 
17/12/19 16:46:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:46:12 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:46:12 INFO DAGScheduler: Got job 302 (take at <unknown>:0) with 1 output partitions
17/12/19 16:46:12 INFO DAGScheduler: Final stage: ResultStage 631 (take at <unknown>:0)
17/12/19 16:46:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 630)
17/12/19 16:46:12 INFO DAGScheduler: Missing parents: List()
17/12/19 16:46:12 INFO DAGScheduler: Submitting ResultStage 631 (WorkerRDD[1378] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:46:12 INFO MemoryStore: Block broadcast_422 stored as values in memory (estimated size 244.0 KB, free 1994.4 MB)
17/12/19 16:46:12 INFO MemoryStore: Block broadcast_422_piece0 stored as bytes in memory (estimated size 96.1 KB, free 1994.3 MB)
17/12/19 16:46:12 INFO BlockManagerInfo: Added broadcast_422_piece0 in memory on 127.0.0.1:53618 (size: 96.1 KB, free: 2003.6 MB)
17/12/19 16:46:12 INFO SparkContext: Created broadcast 422 from broadcast at DAGScheduler.scala:996
17/12/19 16:46:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 631 (WorkerRDD[1378] at RDD at rdd.scala:18)
17/12/19 16:46:12 INFO TaskSchedulerImpl: Adding task set 631.0 with 1 tasks
17/12/19 16:46:12 INFO TaskSetManager: Starting task 0.0 in stage 631.0 (TID 470, localhost, executor driver, partition 0, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:46:12 INFO Executor: Running task 0.0 in stage 631.0 (TID 470)
17/12/19 16:46:12 INFO BlockManager: Found block rdd_1366_0 locally
17/12/19 16:46:13 INFO MemoryStore: Block rdd_1378_0 stored as values in memory (estimated size 80.0 B, free 1994.3 MB)
17/12/19 16:46:13 INFO BlockManagerInfo: Added rdd_1378_0 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.6 MB)
17/12/19 16:46:13 INFO Executor: Finished task 0.0 in stage 631.0 (TID 470). 2400 bytes result sent to driver
17/12/19 16:46:13 INFO TaskSetManager: Finished task 0.0 in stage 631.0 (TID 470) in 637 ms on localhost (executor driver) (1/1)
17/12/19 16:46:13 INFO TaskSchedulerImpl: Removed TaskSet 631.0, whose tasks have all completed, from pool 
17/12/19 16:46:13 INFO DAGScheduler: ResultStage 631 (take at <unknown>:0) finished in 0.637 s
17/12/19 16:46:13 INFO DAGScheduler: Job 302 finished: take at <unknown>:0, took 0.643094 s
17/12/19 16:46:13 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:46:13 INFO DAGScheduler: Got job 303 (take at <unknown>:0) with 1 output partitions
17/12/19 16:46:13 INFO DAGScheduler: Final stage: ResultStage 633 (take at <unknown>:0)
17/12/19 16:46:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 632)
17/12/19 16:46:13 INFO DAGScheduler: Missing parents: List()
17/12/19 16:46:13 INFO DAGScheduler: Submitting ResultStage 633 (WorkerRDD[1378] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:46:13 INFO MemoryStore: Block broadcast_423 stored as values in memory (estimated size 244.0 KB, free 1994.1 MB)
17/12/19 16:46:13 INFO MemoryStore: Block broadcast_423_piece0 stored as bytes in memory (estimated size 96.1 KB, free 1994.0 MB)
17/12/19 16:46:13 INFO BlockManagerInfo: Added broadcast_423_piece0 in memory on 127.0.0.1:53618 (size: 96.1 KB, free: 2003.5 MB)
17/12/19 16:46:13 INFO SparkContext: Created broadcast 423 from broadcast at DAGScheduler.scala:996
17/12/19 16:46:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 633 (WorkerRDD[1378] at RDD at rdd.scala:18)
17/12/19 16:46:13 INFO TaskSchedulerImpl: Adding task set 633.0 with 1 tasks
17/12/19 16:46:13 INFO TaskSetManager: Starting task 0.0 in stage 633.0 (TID 471, localhost, executor driver, partition 1, PROCESS_LOCAL, 5915 bytes)
17/12/19 16:46:13 INFO Executor: Running task 0.0 in stage 633.0 (TID 471)
17/12/19 16:46:13 INFO BlockManager: Found block rdd_1366_1 locally
17/12/19 16:46:14 INFO MemoryStore: Block rdd_1378_1 stored as values in memory (estimated size 80.0 B, free 1994.0 MB)
17/12/19 16:46:14 INFO BlockManagerInfo: Added rdd_1378_1 in memory on 127.0.0.1:53618 (size: 80.0 B, free: 2003.5 MB)
17/12/19 16:46:14 INFO Executor: Finished task 0.0 in stage 633.0 (TID 471). 2400 bytes result sent to driver
17/12/19 16:46:14 INFO TaskSetManager: Finished task 0.0 in stage 633.0 (TID 471) in 628 ms on localhost (executor driver) (1/1)
17/12/19 16:46:14 INFO TaskSchedulerImpl: Removed TaskSet 633.0, whose tasks have all completed, from pool 
17/12/19 16:46:14 INFO DAGScheduler: ResultStage 633 (take at <unknown>:0) finished in 0.628 s
17/12/19 16:46:14 INFO DAGScheduler: Job 303 finished: take at <unknown>:0, took 0.630407 s
17/12/19 16:46:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:14 INFO SparkSqlParser: Parsing command: sparklyr_tmp_29e8df34460
17/12/19 16:46:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8df34460` AS `zzz129`
WHERE (0 = 1)
17/12/19 16:46:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_29e8df34460`
LIMIT 10
17/12/19 16:46:14 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:46:14 INFO DAGScheduler: Got job 304 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:46:14 INFO DAGScheduler: Final stage: ResultStage 635 (collect at utils.scala:196)
17/12/19 16:46:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 634)
17/12/19 16:46:14 INFO DAGScheduler: Missing parents: List()
17/12/19 16:46:14 INFO DAGScheduler: Submitting ResultStage 635 (MapPartitionsRDD[1382] at collect at utils.scala:196), which has no missing parents
17/12/19 16:46:14 INFO MemoryStore: Block broadcast_424 stored as values in memory (estimated size 245.1 KB, free 1993.7 MB)
17/12/19 16:46:14 INFO MemoryStore: Block broadcast_424_piece0 stored as bytes in memory (estimated size 96.8 KB, free 1993.6 MB)
17/12/19 16:46:14 INFO BlockManagerInfo: Added broadcast_424_piece0 in memory on 127.0.0.1:53618 (size: 96.8 KB, free: 2003.4 MB)
17/12/19 16:46:14 INFO SparkContext: Created broadcast 424 from broadcast at DAGScheduler.scala:996
17/12/19 16:46:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 635 (MapPartitionsRDD[1382] at collect at utils.scala:196)
17/12/19 16:46:14 INFO TaskSchedulerImpl: Adding task set 635.0 with 1 tasks
17/12/19 16:46:14 INFO TaskSetManager: Starting task 0.0 in stage 635.0 (TID 472, localhost, executor driver, partition 0, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:46:14 INFO Executor: Running task 0.0 in stage 635.0 (TID 472)
17/12/19 16:46:14 INFO BlockManager: Found block rdd_1378_0 locally
17/12/19 16:46:14 INFO Executor: Finished task 0.0 in stage 635.0 (TID 472). 1479 bytes result sent to driver
17/12/19 16:46:14 INFO TaskSetManager: Finished task 0.0 in stage 635.0 (TID 472) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:46:14 INFO TaskSchedulerImpl: Removed TaskSet 635.0, whose tasks have all completed, from pool 
17/12/19 16:46:14 INFO DAGScheduler: ResultStage 635 (collect at utils.scala:196) finished in 0.000 s
17/12/19 16:46:14 INFO DAGScheduler: Job 304 finished: collect at utils.scala:196, took 0.007626 s
17/12/19 16:46:14 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:46:14 INFO DAGScheduler: Got job 305 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:46:14 INFO DAGScheduler: Final stage: ResultStage 637 (collect at utils.scala:196)
17/12/19 16:46:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 636)
17/12/19 16:46:14 INFO DAGScheduler: Missing parents: List()
17/12/19 16:46:14 INFO DAGScheduler: Submitting ResultStage 637 (MapPartitionsRDD[1382] at collect at utils.scala:196), which has no missing parents
17/12/19 16:46:14 INFO MemoryStore: Block broadcast_425 stored as values in memory (estimated size 245.1 KB, free 1993.4 MB)
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21437
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21371
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21372
17/12/19 16:46:14 INFO MemoryStore: Block broadcast_425_piece0 stored as bytes in memory (estimated size 96.8 KB, free 1993.3 MB)
17/12/19 16:46:14 INFO BlockManagerInfo: Removed broadcast_412_piece0 on 127.0.0.1:53618 in memory (size: 4.6 KB, free: 2003.4 MB)
17/12/19 16:46:14 INFO BlockManagerInfo: Added broadcast_425_piece0 in memory on 127.0.0.1:53618 (size: 96.8 KB, free: 2003.3 MB)
17/12/19 16:46:14 INFO SparkContext: Created broadcast 425 from broadcast at DAGScheduler.scala:996
17/12/19 16:46:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 637 (MapPartitionsRDD[1382] at collect at utils.scala:196)
17/12/19 16:46:14 INFO TaskSchedulerImpl: Adding task set 637.0 with 1 tasks
17/12/19 16:46:14 INFO TaskSetManager: Starting task 0.0 in stage 637.0 (TID 473, localhost, executor driver, partition 1, PROCESS_LOCAL, 5862 bytes)
17/12/19 16:46:14 INFO Executor: Running task 0.0 in stage 637.0 (TID 473)
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21421
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21422
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21428
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21429
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21430
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21431
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21432
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21433
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21434
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21435
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21436
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21438
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21439
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21440
17/12/19 16:46:14 INFO ContextCleaner: Cleaned shuffle 88
17/12/19 16:46:14 INFO BlockManager: Found block rdd_1378_1 locally
17/12/19 16:46:14 INFO BlockManagerInfo: Removed broadcast_414_piece0 on 127.0.0.1:53618 in memory (size: 7.3 KB, free: 2003.3 MB)
17/12/19 16:46:14 INFO Executor: Finished task 0.0 in stage 637.0 (TID 473). 1637 bytes result sent to driver
17/12/19 16:46:14 INFO TaskSetManager: Finished task 0.0 in stage 637.0 (TID 473) in 15 ms on localhost (executor driver) (1/1)
17/12/19 16:46:14 INFO TaskSchedulerImpl: Removed TaskSet 637.0, whose tasks have all completed, from pool 
17/12/19 16:46:14 INFO DAGScheduler: ResultStage 637 (collect at utils.scala:196) finished in 0.015 s
17/12/19 16:46:14 INFO DAGScheduler: Job 305 finished: collect at utils.scala:196, took 0.017922 s
17/12/19 16:46:14 INFO BlockManagerInfo: Removed broadcast_415_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.3 MB)
17/12/19 16:46:14 INFO BlockManagerInfo: Removed broadcast_416_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.3 MB)
17/12/19 16:46:14 INFO ContextCleaner: Cleaned accumulator 21609
17/12/19 16:46:14 INFO BlockManagerInfo: Removed broadcast_417_piece0 on 127.0.0.1:53618 in memory (size: 6.0 KB, free: 2003.3 MB)
17/12/19 16:46:14 INFO BlockManagerInfo: Removed broadcast_418_piece0 on 127.0.0.1:53618 in memory (size: 3.7 KB, free: 2003.3 MB)
17/12/19 16:46:14 INFO BlockManagerInfo: Removed broadcast_419_piece0 on 127.0.0.1:53618 in memory (size: 49.6 KB, free: 2003.4 MB)
17/12/19 16:46:14 INFO BlockManagerInfo: Removed broadcast_420_piece0 on 127.0.0.1:53618 in memory (size: 49.6 KB, free: 2003.4 MB)
17/12/19 16:46:14 INFO BlockManagerInfo: Removed broadcast_421_piece0 on 127.0.0.1:53618 in memory (size: 53.2 KB, free: 2003.5 MB)
17/12/19 16:46:14 INFO BlockManagerInfo: Removed broadcast_422_piece0 on 127.0.0.1:53618 in memory (size: 96.1 KB, free: 2003.6 MB)
17/12/19 16:46:14 INFO BlockManagerInfo: Removed broadcast_423_piece0 on 127.0.0.1:53618 in memory (size: 96.1 KB, free: 2003.7 MB)
17/12/19 16:46:14 INFO BlockManagerInfo: Removed broadcast_424_piece0 on 127.0.0.1:53618 in memory (size: 96.8 KB, free: 2003.8 MB)
17/12/19 16:46:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:46:14 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:46:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:46:14 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:46:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:46:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:46:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:46:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:46:14 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:46:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:46:14 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:46:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:46:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:46:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:46:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:46:14 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:46:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:46:14 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:46:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:46:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:46:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:46:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:46:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:46:14 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:46:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:46:14 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:46:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:46:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:46:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:48:39 INFO BlockManagerInfo: Removed broadcast_425_piece0 on 127.0.0.1:53618 in memory (size: 96.8 KB, free: 2003.9 MB)
17/12/19 16:48:51 INFO SparkContext: Invoking stop() from shutdown hook
17/12/19 16:48:51 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/19 16:48:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/19 16:48:52 INFO MemoryStore: MemoryStore cleared
17/12/19 16:48:52 INFO BlockManager: BlockManager stopped
17/12/19 16:48:52 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/19 16:48:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/19 16:48:52 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-10ef9647-9bcc-4679-ae47-6101db6305d8\userFiles-8b8769fc-4426-4101-9e7c-7bccce33dbc4
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-10ef9647-9bcc-4679-ae47-6101db6305d8\userFiles-8b8769fc-4426-4101-9e7c-7bccce33dbc4
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 16:48:52 INFO SparkContext: Successfully stopped SparkContext
17/12/19 16:48:52 INFO ShutdownHookManager: Shutdown hook called
17/12/19 16:48:52 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-10ef9647-9bcc-4679-ae47-6101db6305d8\userFiles-8b8769fc-4426-4101-9e7c-7bccce33dbc4
17/12/19 16:48:52 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-10ef9647-9bcc-4679-ae47-6101db6305d8\userFiles-8b8769fc-4426-4101-9e7c-7bccce33dbc4
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-10ef9647-9bcc-4679-ae47-6101db6305d8\userFiles-8b8769fc-4426-4101-9e7c-7bccce33dbc4
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 16:48:52 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-10ef9647-9bcc-4679-ae47-6101db6305d8
17/12/19 16:48:52 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-10ef9647-9bcc-4679-ae47-6101db6305d8
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-10ef9647-9bcc-4679-ae47-6101db6305d8
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 16:49:25 INFO SparkContext: Running Spark version 2.1.0
17/12/19 16:49:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/19 16:49:26 INFO SecurityManager: Changing view acls to: conan
17/12/19 16:49:26 INFO SecurityManager: Changing modify acls to: conan
17/12/19 16:49:26 INFO SecurityManager: Changing view acls groups to: 
17/12/19 16:49:26 INFO SecurityManager: Changing modify acls groups to: 
17/12/19 16:49:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(conan); groups with view permissions: Set(); users  with modify permissions: Set(conan); groups with modify permissions: Set()
17/12/19 16:49:26 INFO Utils: Successfully started service 'sparkDriver' on port 56345.
17/12/19 16:49:26 INFO SparkEnv: Registering MapOutputTracker
17/12/19 16:49:26 INFO SparkEnv: Registering BlockManagerMaster
17/12/19 16:49:26 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/19 16:49:26 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/19 16:49:26 INFO DiskBlockManager: Created local directory at C:\Users\conan\AppData\Local\Temp\blockmgr-123f6936-6e6f-422d-a11f-786d3d42b8e5
17/12/19 16:49:26 INFO MemoryStore: MemoryStore started with capacity 2004.6 MB
17/12/19 16:49:26 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/19 16:49:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/19 16:49:26 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/19 16:49:26 INFO SparkContext: Added JAR file:/C:/Users/conan/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:56345/jars/sparklyr-2.1-2.11.jar with timestamp 1513702166843
17/12/19 16:49:26 INFO Executor: Starting executor ID driver on host localhost
17/12/19 16:49:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56366.
17/12/19 16:49:26 INFO NettyBlockTransferService: Server created on 127.0.0.1:56366
17/12/19 16:49:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/19 16:49:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 56366, None)
17/12/19 16:49:26 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:56366 with 2004.6 MB RAM, BlockManagerId(driver, 127.0.0.1, 56366, None)
17/12/19 16:49:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 56366, None)
17/12/19 16:49:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 56366, None)
17/12/19 16:49:27 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/19 16:49:27 INFO SharedState: Warehouse path is 'C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/19 16:49:27 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/19 16:49:28 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/19 16:49:28 INFO ObjectStore: ObjectStore, initialize called
17/12/19 16:49:28 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/19 16:49:28 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/19 16:49:29 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/19 16:49:30 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 16:49:30 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 16:49:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 16:49:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 16:49:31 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/19 16:49:31 INFO ObjectStore: Initialized ObjectStore
17/12/19 16:49:31 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/19 16:49:31 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/19 16:49:31 INFO HiveMetaStore: Added admin role in metastore
17/12/19 16:49:31 INFO HiveMetaStore: Added public role in metastore
17/12/19 16:49:31 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/19 16:49:31 INFO HiveMetaStore: 0: get_all_databases
17/12/19 16:49:31 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/19 16:49:31 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/19 16:49:31 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/19 16:49:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 16:49:32 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/Temp/c46344b8-df5e-4399-834c-2abd66fdf416_resources
17/12/19 16:49:32 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/c46344b8-df5e-4399-834c-2abd66fdf416
17/12/19 16:49:32 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/c46344b8-df5e-4399-834c-2abd66fdf416
17/12/19 16:49:32 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/c46344b8-df5e-4399-834c-2abd66fdf416/_tmp_space.db
17/12/19 16:49:32 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/19 16:49:32 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:49:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:49:32 INFO HiveMetaStore: 0: get_database: global_temp
17/12/19 16:49:32 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/19 16:49:32 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/19 16:49:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:49:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:49:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:49:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:49:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:49:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:49:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:51:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:51:07 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:51:07 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:51:07 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:51:07 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:51:07 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:51:07 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:51:08 INFO CodeGenerator: Code generated in 243.690147 ms
17/12/19 16:51:08 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 16:51:08 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/19 16:51:08 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/19 16:51:08 INFO DAGScheduler: Parents of final stage: List()
17/12/19 16:51:08 INFO DAGScheduler: Missing parents: List()
17/12/19 16:51:08 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/12/19 16:51:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 2004.6 MB)
17/12/19 16:51:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2004.6 MB)
17/12/19 16:51:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:56366 (size: 4.6 KB, free: 2004.6 MB)
17/12/19 16:51:08 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/19 16:51:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/12/19 16:51:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/19 16:51:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/19 16:51:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/19 16:51:08 INFO Executor: Fetching spark://127.0.0.1:56345/jars/sparklyr-2.1-2.11.jar with timestamp 1513702166843
17/12/19 16:51:08 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:56345 after 13 ms (0 ms spent in bootstraps)
17/12/19 16:51:08 INFO Utils: Fetching spark://127.0.0.1:56345/jars/sparklyr-2.1-2.11.jar to C:\Users\conan\AppData\Local\Temp\spark-08aba968-f583-4b4a-bbcc-1a083634f941\userFiles-585ed8af-a537-4b19-9a30-8104ac2f52ea\fetchFileTemp7433815751202125119.tmp
17/12/19 16:51:08 INFO Executor: Adding file:/C:/Users/conan/AppData/Local/Temp/spark-08aba968-f583-4b4a-bbcc-1a083634f941/userFiles-585ed8af-a537-4b19-9a30-8104ac2f52ea/sparklyr-2.1-2.11.jar to class loader
17/12/19 16:51:08 INFO CodeGenerator: Code generated in 13.623507 ms
17/12/19 16:51:08 INFO CodeGenerator: Code generated in 13.939165 ms
17/12/19 16:51:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/12/19 16:51:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 388 ms on localhost (executor driver) (1/1)
17/12/19 16:51:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/19 16:51:08 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.431 s
17/12/19 16:51:08 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.607488 s
17/12/19 16:51:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:09 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:51:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:09 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 16:51:09 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 16:51:09 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 16:51:09 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 16:51:09 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 16:51:09 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 16:51:09 INFO CodeGenerator: Code generated in 6.814207 ms
17/12/19 16:51:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.7 KB, free 2004.3 MB)
17/12/19 16:51:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2004.3 MB)
17/12/19 16:51:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:56366 (size: 24.0 KB, free: 2004.6 MB)
17/12/19 16:51:09 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/19 16:51:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 16:51:09 INFO CodeGenerator: Code generated in 12.619519 ms
17/12/19 16:51:09 INFO CodeGenerator: Code generated in 10.838091 ms
17/12/19 16:51:09 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 16:51:09 INFO DAGScheduler: Registering RDD 10 (sql at <unknown>:0)
17/12/19 16:51:09 INFO DAGScheduler: Registering RDD 15 (sql at <unknown>:0)
17/12/19 16:51:09 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/19 16:51:09 INFO DAGScheduler: Final stage: ResultStage 3 (sql at <unknown>:0)
17/12/19 16:51:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/12/19 16:51:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/12/19 16:51:09 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0), which has no missing parents
17/12/19 16:51:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.1 KB, free 2004.3 MB)
17/12/19 16:51:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2004.3 MB)
17/12/19 16:51:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:56366 (size: 7.3 KB, free: 2004.6 MB)
17/12/19 16:51:09 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/19 16:51:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0)
17/12/19 16:51:09 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/19 16:51:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/19 16:51:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/19 16:51:09 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpwLtPOg/spark_serialize_aa4b999ca89240e71be635f6dc8ce9f2993d827bdc1d32f2b8b59ee91d80ecb0.csv, range: 0-555160, partition values: [empty row]
17/12/19 16:51:09 INFO CodeGenerator: Code generated in 8.953205 ms
17/12/19 16:51:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1632 bytes result sent to driver
17/12/19 16:51:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 262 ms on localhost (executor driver) (1/1)
17/12/19 16:51:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/19 16:51:09 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.277 s
17/12/19 16:51:09 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:51:09 INFO DAGScheduler: running: Set()
17/12/19 16:51:09 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/12/19 16:51:09 INFO DAGScheduler: failed: Set()
17/12/19 16:51:09 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/19 16:51:09 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.9 KB, free 2004.2 MB)
17/12/19 16:51:09 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2004.2 MB)
17/12/19 16:51:09 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:56366 (size: 6.0 KB, free: 2004.6 MB)
17/12/19 16:51:09 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/19 16:51:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/19 16:51:09 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
17/12/19 16:51:09 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5942 bytes)
17/12/19 16:51:09 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5942 bytes)
17/12/19 16:51:09 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/19 16:51:09 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
17/12/19 16:51:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:51:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 16:51:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:51:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:51:09 INFO MemoryStore: Block rdd_12_1 stored as values in memory (estimated size 117.7 KB, free 2004.1 MB)
17/12/19 16:51:09 INFO BlockManagerInfo: Added rdd_12_1 in memory on 127.0.0.1:56366 (size: 117.7 KB, free: 2004.4 MB)
17/12/19 16:51:09 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 117.7 KB, free 2004.0 MB)
17/12/19 16:51:09 INFO BlockManagerInfo: Added rdd_12_0 in memory on 127.0.0.1:56366 (size: 117.7 KB, free: 2004.3 MB)
17/12/19 16:51:09 INFO CodeGenerator: Code generated in 4.37541 ms
17/12/19 16:51:10 INFO CodeGenerator: Code generated in 17.741029 ms
17/12/19 16:51:10 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 3064 bytes result sent to driver
17/12/19 16:51:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 3064 bytes result sent to driver
17/12/19 16:51:10 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 158 ms on localhost (executor driver) (1/2)
17/12/19 16:51:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 161 ms on localhost (executor driver) (2/2)
17/12/19 16:51:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/19 16:51:10 INFO DAGScheduler: ShuffleMapStage 2 (sql at <unknown>:0) finished in 0.161 s
17/12/19 16:51:10 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:51:10 INFO DAGScheduler: running: Set()
17/12/19 16:51:10 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/12/19 16:51:10 INFO DAGScheduler: failed: Set()
17/12/19 16:51:10 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
17/12/19 16:51:10 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 2004.0 MB)
17/12/19 16:51:10 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.0 MB)
17/12/19 16:51:10 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:56366 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 16:51:10 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/19 16:51:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0)
17/12/19 16:51:10 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/19 16:51:10 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/19 16:51:10 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
17/12/19 16:51:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:51:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:51:10 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 1707 bytes result sent to driver
17/12/19 16:51:10 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:51:10 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/19 16:51:10 INFO DAGScheduler: ResultStage 3 (sql at <unknown>:0) finished in 0.000 s
17/12/19 16:51:10 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.502074 s
17/12/19 16:51:10 INFO CodeGenerator: Code generated in 6.249724 ms
17/12/19 16:51:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:10 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 16:51:10 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:51:10 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/19 16:51:10 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:196)
17/12/19 16:51:10 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:51:10 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:196)
17/12/19 16:51:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/12/19 16:51:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/12/19 16:51:10 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
17/12/19 16:51:10 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.9 KB, free 2004.0 MB)
17/12/19 16:51:10 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2004.0 MB)
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 50
17/12/19 16:51:10 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:56366 (size: 6.0 KB, free: 2004.3 MB)
17/12/19 16:51:10 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/19 16:51:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196)
17/12/19 16:51:10 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
17/12/19 16:51:10 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5934 bytes)
17/12/19 16:51:10 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 5934 bytes)
17/12/19 16:51:10 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/19 16:51:10 INFO BlockManager: Found block rdd_12_0 locally
17/12/19 16:51:10 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/12/19 16:51:10 INFO BlockManager: Found block rdd_12_1 locally
17/12/19 16:51:10 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2056 bytes result sent to driver
17/12/19 16:51:10 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 31 ms on localhost (executor driver) (1/2)
17/12/19 16:51:10 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 1871 bytes result sent to driver
17/12/19 16:51:10 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:56366 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/19 16:51:10 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 31 ms on localhost (executor driver) (2/2)
17/12/19 16:51:10 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:196) finished in 0.031 s
17/12/19 16:51:10 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:51:10 INFO DAGScheduler: running: Set()
17/12/19 16:51:10 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/12/19 16:51:10 INFO DAGScheduler: failed: Set()
17/12/19 16:51:10 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196), which has no missing parents
17/12/19 16:51:10 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/19 16:51:10 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 2004.0 MB)
17/12/19 16:51:10 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.0 MB)
17/12/19 16:51:10 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:56366 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 16:51:10 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/12/19 16:51:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196)
17/12/19 16:51:10 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/19 16:51:10 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/19 16:51:10 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
17/12/19 16:51:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:51:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:51:10 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1707 bytes result sent to driver
17/12/19 16:51:10 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:196) finished in 0.016 s
17/12/19 16:51:10 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.084155 s
17/12/19 16:51:10 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 16 ms on localhost (executor driver) (1/1)
17/12/19 16:51:10 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 238
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 51
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 57
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 58
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 59
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 60
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 61
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 62
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 63
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 64
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 65
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 66
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 67
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 68
17/12/19 16:51:10 INFO ContextCleaner: Cleaned accumulator 69
17/12/19 16:51:10 INFO ContextCleaner: Cleaned shuffle 1
17/12/19 16:51:10 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:56366 in memory (size: 7.3 KB, free: 2004.3 MB)
17/12/19 16:51:10 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:56366 in memory (size: 6.0 KB, free: 2004.3 MB)
17/12/19 16:51:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz1`
WHERE (0 = 1)
17/12/19 16:51:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:10 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`, `V11` AS `V11`, `V12` AS `V12`, `V13` AS `V13`, `V14` AS `V14`, `V15` AS `V15`, `V16` AS `V16`, `V17` AS `V17`, `V18` AS `V18`, `V19` AS `V19`, `V20` AS `V20`, `V21` AS `V21`, `V22` AS `V22`, `V23` AS `V23`, `V24` AS `V24`, `V25` AS `V25`, `V26` AS `V26`, `V27` AS `V27`, `V28` AS `V28`, `V29` AS `V29`, `V30` AS `V30`, `V31` AS `V31`, `V32` AS `V32`, `V33` AS `V33`, `V34` AS `V34`, `V35` AS `V35`, `V36` AS `V36`, `V37` AS `V37`, `V38` AS `V38`, `V39` AS `V39`, `V40` AS `V40`, `V41` AS `V41`, `V42` AS `V42`, `V43` AS `V43`, `V44` AS `V44`, `V45` AS `V45`, `V46` AS `V46`, `V47` AS `V47`, `V48` AS `V48`, `V49` AS `V49`, `V50` AS `V50`, `V51` AS `V51`, `V52` AS `V52`, `V53` AS `V53`, `V54` AS `V54`, `V55` AS `V55`, `V56` AS `V56`, `V57` AS `V57`, `V58` AS `V58`, `V59` AS `V59`, `V60` AS `V60`, `V61` AS `V61`, `V62` AS `V62`, `V63` AS `V63`, `V64` AS `V64`, `V65` AS `V65`, `V66` AS `V66`, `V67` AS `V67`, `V68` AS `V68`, `V69` AS `V69`, `V70` AS `V70`, `V71` AS `V71`, `V72` AS `V72`, `V73` AS `V73`, `V74` AS `V74`, `V75` AS `V75`, `V76` AS `V76`, `V77` AS `V77`, `V78` AS `V78`, `V79` AS `V79`, `V80` AS `V80`, `V81` AS `V81`, `V82` AS `V82`, `V83` AS `V83`, `V84` AS `V84`, `V85` AS `V85`, `V86` AS `V86`, `V87` AS `V87`, `V88` AS `V88`, `V89` AS `V89`, `V90` AS `V90`, `V91` AS `V91`, `V92` AS `V92`, `V93` AS `V93`, `V94` AS `V94`, `V95` AS `V95`, `V96` AS `V96`, `V97` AS `V97`, `V98` AS `V98`, `V99` AS `V99`, `V100` AS `V100`
FROM (SELECT `S1`, `S2`, `S3`, `S3` + 0.92195445 * RANDN() AS `V1`, `S1` + 0.9486833 * RANDN() AS `V2`, `S2` + 0.92195445 * RANDN() AS `V3`, `S1` + 0.9486833 * RANDN() AS `V4`, `S3` + 0.92195445 * RANDN() AS `V5`, `S1` + 0.9486833 * RANDN() AS `V6`, `S2` + 0.92195445 * RANDN() AS `V7`, `S3` + 0.92195445 * RANDN() AS `V8`, `S3` + 0.92195445 * RANDN() AS `V9`, `S2` + 0.92195445 * RANDN() AS `V10`, `S3` + 0.92195445 * RANDN() AS `V11`, `S1` + 0.9486833 * RANDN() AS `V12`, `S3` + 0.92195445 * RANDN() AS `V13`, `S1` + 0.9486833 * RANDN() AS `V14`, `S2` + 0.92195445 * RANDN() AS `V15`, `S3` + 0.92195445 * RANDN() AS `V16`, `S1` + 0.9486833 * RANDN() AS `V17`, `S2` + 0.92195445 * RANDN() AS `V18`, `S1` + 0.9486833 * RANDN() AS `V19`, `S1` + 0.9486833 * RANDN() AS `V20`, `S1` + 0.9486833 * RANDN() AS `V21`, `S3` + 0.92195445 * RANDN() AS `V22`, `S1` + 0.9486833 * RANDN() AS `V23`, `S1` + 0.9486833 * RANDN() AS `V24`, `S2` + 0.92195445 * RANDN() AS `V25`, `S1` + 0.9486833 * RANDN() AS `V26`, `S1` + 0.9486833 * RANDN() AS `V27`, `S3` + 0.92195445 * RANDN() AS `V28`, `S2` + 0.92195445 * RANDN() AS `V29`, `S3` + 0.92195445 * RANDN() AS `V30`, `S2` + 0.92195445 * RANDN() AS `V31`, `S2` + 0.92195445 * RANDN() AS `V32`, `S1` + 0.9486833 * RANDN() AS `V33`, `S3` + 0.92195445 * RANDN() AS `V34`, `S1` + 0.9486833 * RANDN() AS `V35`, `S1` + 0.9486833 * RANDN() AS `V36`, `S3` + 0.92195445 * RANDN() AS `V37`, `S1` + 0.9486833 * RANDN() AS `V38`, `S1` + 0.9486833 * RANDN() AS `V39`, `S3` + 0.92195445 * RANDN() AS `V40`, `S1` + 0.9486833 * RANDN() AS `V41`, `S1` + 0.9486833 * RANDN() AS `V42`, `S2` + 0.92195445 * RANDN() AS `V43`, `S2` + 0.92195445 * RANDN() AS `V44`, `S1` + 0.9486833 * RANDN() AS `V45`, `S3` + 0.92195445 * RANDN() AS `V46`, `S3` + 0.92195445 * RANDN() AS `V47`, `S2` + 0.92195445 * RANDN() AS `V48`, `S3` + 0.92195445 * RANDN() AS `V49`, `S3` + 0.92195445 * RANDN() AS `V50`, `S1` + 0.9486833 * RANDN() AS `V51`, `S2` + 0.92195445 * RANDN() AS `V52`, `S2` + 0.92195445 * RANDN() AS `V53`, `S1` + 0.9486833 * RANDN() AS `V54`, `S2` + 0.92195445 * RANDN() AS `V55`, `S3` + 0.92195445 * RANDN() AS `V56`, `S3` + 0.92195445 * RANDN() AS `V57`, `S1` + 0.9486833 * RANDN() AS `V58`, `S1` + 0.9486833 * RANDN() AS `V59`, `S2` + 0.92195445 * RANDN() AS `V60`, `S1` + 0.9486833 * RANDN() AS `V61`, `S2` + 0.92195445 * RANDN() AS `V62`, `S3` + 0.92195445 * RANDN() AS `V63`, `S2` + 0.92195445 * RANDN() AS `V64`, `S2` + 0.92195445 * RANDN() AS `V65`, `S3` + 0.92195445 * RANDN() AS `V66`, `S1` + 0.9486833 * RANDN() AS `V67`, `S1` + 0.9486833 * RANDN() AS `V68`, `S1` + 0.9486833 * RANDN() AS `V69`, `S1` + 0.9486833 * RANDN() AS `V70`, `S2` + 0.92195445 * RANDN() AS `V71`, `S3` + 0.92195445 * RANDN() AS `V72`, `S1` + 0.9486833 * RANDN() AS `V73`, `S2` + 0.92195445 * RANDN() AS `V74`, `S1` + 0.9486833 * RANDN() AS `V75`, `S1` + 0.9486833 * RANDN() AS `V76`, `S2` + 0.92195445 * RANDN() AS `V77`, `S1` + 0.9486833 * RANDN() AS `V78`, `S3` + 0.92195445 * RANDN() AS `V79`, `S1` + 0.9486833 * RANDN() AS `V80`, `S1` + 0.9486833 * RANDN() AS `V81`, `S2` + 0.92195445 * RANDN() AS `V82`, `S2` + 0.92195445 * RANDN() AS `V83`, `S3` + 0.92195445 * RANDN() AS `V84`, `S3` + 0.92195445 * RANDN() AS `V85`, `S3` + 0.92195445 * RANDN() AS `V86`, `S1` + 0.9486833 * RANDN() AS `V87`, `S3` + 0.92195445 * RANDN() AS `V88`, `S3` + 0.92195445 * RANDN() AS `V89`, `S3` + 0.92195445 * RANDN() AS `V90`, `S3` + 0.92195445 * RANDN() AS `V91`, `S2` + 0.92195445 * RANDN() AS `V92`, `S2` + 0.92195445 * RANDN() AS `V93`, `S3` + 0.92195445 * RANDN() AS `V94`, `S1` + 0.9486833 * RANDN() AS `V95`, `S3` + 0.92195445 * RANDN() AS `V96`, `S1` + 0.9486833 * RANDN() AS `V97`, `S2` + 0.92195445 * RANDN() AS `V98`, `S3` + 0.92195445 * RANDN() AS `V99`, `S1` + 0.9486833 * RANDN() AS `V100`
FROM `analyis_tbl`) `xpyxppkvgn`
17/12/19 16:51:11 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:56366 in memory (size: 6.0 KB, free: 2004.3 MB)
17/12/19 16:51:11 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:56366 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/19 16:51:11 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:56366 in memory (size: 4.6 KB, free: 2004.3 MB)
17/12/19 16:51:11 INFO ContextCleaner: Cleaned accumulator 1
17/12/19 16:51:11 INFO ContextCleaner: Cleaned accumulator 0
17/12/19 16:51:11 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:51:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz2`
WHERE (0 = 1)
17/12/19 16:51:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:51:11 INFO CodeGenerator: Code generated in 119.974158 ms
17/12/19 16:51:12 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:51:12 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/19 16:51:12 INFO DAGScheduler: Got job 3 (take at <unknown>:0) with 1 output partitions
17/12/19 16:51:12 INFO DAGScheduler: Final stage: ResultStage 8 (take at <unknown>:0)
17/12/19 16:51:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/12/19 16:51:12 INFO DAGScheduler: Missing parents: List()
17/12/19 16:51:12 INFO DAGScheduler: Submitting ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:51:12 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 467.6 KB, free 2003.6 MB)
17/12/19 16:51:12 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 310.7 KB, free 2003.3 MB)
17/12/19 16:51:12 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:56366 (size: 310.7 KB, free: 2004.0 MB)
17/12/19 16:51:12 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/12/19 16:51:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18)
17/12/19 16:51:12 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/19 16:51:12 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5913 bytes)
17/12/19 16:51:12 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/12/19 16:51:12 INFO BlockManager: Found block rdd_12_0 locally
17/12/19 16:51:12 INFO CodeGenerator: Code generated in 14.916345 ms
17/12/19 16:51:12 INFO CodeGenerator: Code generated in 43.265896 ms
17/12/19 16:51:30 INFO MemoryStore: Block rdd_31_0 stored as values in memory (estimated size 13.5 MB, free 1989.8 MB)
17/12/19 16:51:30 INFO BlockManagerInfo: Added rdd_31_0 in memory on 127.0.0.1:56366 (size: 13.5 MB, free: 1990.5 MB)
17/12/19 16:51:30 WARN Executor: 1 block locks were not released by TID = 8:
[rdd_31_0]
17/12/19 16:51:30 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 16777 bytes result sent to driver
17/12/19 16:51:30 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 17997 ms on localhost (executor driver) (1/1)
17/12/19 16:51:30 INFO DAGScheduler: ResultStage 8 (take at <unknown>:0) finished in 17.997 s
17/12/19 16:51:30 INFO DAGScheduler: Job 3 finished: take at <unknown>:0, took 18.008006 s
17/12/19 16:51:30 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/19 16:51:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_225076c7764c
17/12/19 16:51:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_225076c7764c` AS `zzz3`
WHERE (0 = 1)
17/12/19 16:51:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_225076c7764c`
17/12/19 16:51:30 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:51:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz4`
WHERE (0 = 1)
17/12/19 16:51:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:30 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.0138) AS `V1`, (`V2` < 0.0138) AS `V2`, (`V3` < 0.0028) AS `V3`, (`V4` < 0.026) AS `V4`, (`V5` < 0.0375) AS `V5`, (`V6` < 0.0055) AS `V6`, (`V7` < 0.0045) AS `V7`, (`V8` < 0.0035) AS `V8`, (`V9` < 0.1) AS `V9`, (`V10` < 0.0138) AS `V10`, (`V11` < 0.0035) AS `V11`, (`V12` < 0.009) AS `V12`, (`V13` < 0.0028) AS `V13`, (`V14` < 0.0023) AS `V14`, (`V15` < 0.0185) AS `V15`, (`V16` < 0.026) AS `V16`, (`V17` < 0.054) AS `V17`, (`V18` < 0.0045) AS `V18`, (`V19` < 0.0028) AS `V19`, (`V20` < 0.0185) AS `V20`, (`V21` < 0.0018) AS `V21`, (`V22` < 0.0035) AS `V22`, (`V23` < 0.0185) AS `V23`, (`V24` < 0.1) AS `V24`, (`V25` < 0.0018) AS `V25`, (`V26` < 0.0023) AS `V26`, (`V27` < 0.0138) AS `V27`, (`V28` < 0.009) AS `V28`, (`V29` < 0.0185) AS `V29`, (`V30` < 0.1) AS `V30`, (`V31` < 0.0185) AS `V31`, (`V32` < 0.0185) AS `V32`, (`V33` < 0.0055) AS `V33`, (`V34` < 0.0138) AS `V34`, (`V35` < 0.0055) AS `V35`, (`V36` < 0.0028) AS `V36`, (`V37` < 0.3) AS `V37`, (`V38` < 0.026) AS `V38`, (`V39` < 0.009) AS `V39`, (`V40` < 0.0013) AS `V40`, (`V41` < 0.0185) AS `V41`, (`V42` < 0.1) AS `V42`, (`V43` < 0.0055) AS `V43`, (`V44` < 0.0138) AS `V44`, (`V45` < 0.0055) AS `V45`, (`V46` < 0.009) AS `V46`, (`V47` < 0.026) AS `V47`, (`V48` < 0.026) AS `V48`, (`V49` < 0.075) AS `V49`, (`V50` < 0.0013) AS `V50`, (`V51` < 0.0045) AS `V51`, (`V52` < 0.0023) AS `V52`, (`V53` < 0.075) AS `V53`, (`V54` < 0.0138) AS `V54`, (`V55` < 0.0023) AS `V55`, (`V56` < 0.075) AS `V56`, (`V57` < 0.0375) AS `V57`, (`V58` < 0.054) AS `V58`, (`V59` < 0.0375) AS `V59`, (`V60` < 0.15) AS `V60`, (`V61` < 0.0138) AS `V61`, (`V62` < 0.0055) AS `V62`, (`V63` < 0.0185) AS `V63`, (`V64` < 0.0138) AS `V64`, (`V65` < 0.0138) AS `V65`, (`V66` < 0.0045) AS `V66`, (`V67` < 0.075) AS `V67`, (`V68` < 0.0045) AS `V68`, (`V69` < 0.0375) AS `V69`, (`V70` < 0.009) AS `V70`, (`V71` < 0.009) AS `V71`, (`V72` < 0.15) AS `V72`, (`V73` < 0.054) AS `V73`, (`V74` < 0.0045) AS `V74`, (`V75` < 0.075) AS `V75`, (`V76` < 0.0375) AS `V76`, (`V77` < 0.1) AS `V77`, (`V78` < 0.075) AS `V78`, (`V79` < 0.054) AS `V79`, (`V80` < 0.054) AS `V80`, (`V81` < 0.026) AS `V81`, (`V82` < 0.1) AS `V82`, (`V83` < 0.0018) AS `V83`, (`V84` < 0.026) AS `V84`, (`V85` < 0.0035) AS `V85`, (`V86` < 0.054) AS `V86`, (`V87` < 4e-04) AS `V87`, (`V88` < 0.0023) AS `V88`, (`V89` < 0.0185) AS `V89`, (`V90` < 0.0138) AS `V90`, (`V91` < 0.0028) AS `V91`, (`V92` < 0.0055) AS `V92`, (`V93` < 0.0055) AS `V93`, (`V94` < 0.0375) AS `V94`, (`V95` < 0.1) AS `V95`, (`V96` < 0.1) AS `V96`, (`V97` < 0.0055) AS `V97`, (`V98` < 0.0055) AS `V98`, (`V99` < 0.0185) AS `V99`, (`V100` < 0.15) AS `V100`
FROM `analyis_tbl`
17/12/19 16:51:30 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:51:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz5`
WHERE (0 = 1)
17/12/19 16:51:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:51:31 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/12/19 16:51:31 INFO CodeGenerator: Code generated in 77.557065 ms
17/12/19 16:51:31 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:51:31 INFO DAGScheduler: Got job 4 (collect at utils.scala:196) with 2 output partitions
17/12/19 16:51:31 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:196)
17/12/19 16:51:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
17/12/19 16:51:31 INFO DAGScheduler: Missing parents: List()
17/12/19 16:51:31 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196), which has no missing parents
17/12/19 16:51:31 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 561.7 KB, free 1989.2 MB)
17/12/19 16:51:31 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 330.3 KB, free 1988.9 MB)
17/12/19 16:51:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:56366 (size: 330.3 KB, free: 1990.2 MB)
17/12/19 16:51:31 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/12/19 16:51:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196)
17/12/19 16:51:31 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks
17/12/19 16:51:31 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5945 bytes)
17/12/19 16:51:31 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 5945 bytes)
17/12/19 16:51:31 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
17/12/19 16:51:31 INFO Executor: Running task 1.0 in stage 10.0 (TID 10)
17/12/19 16:51:31 INFO BlockManager: Found block rdd_31_0 locally
17/12/19 16:51:31 INFO BlockManager: Found block rdd_12_1 locally
17/12/19 16:51:31 INFO CodeGenerator: Code generated in 58.585121 ms
17/12/19 16:51:31 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:56366 in memory (size: 310.7 KB, free: 1990.5 MB)
17/12/19 16:51:31 INFO CodeGenerator: Code generated in 210.479615 ms
17/12/19 16:51:32 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 209302 bytes result sent to driver
17/12/19 16:51:32 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 872 ms on localhost (executor driver) (1/2)
17/12/19 16:51:49 INFO MemoryStore: Block rdd_31_1 stored as values in memory (estimated size 13.5 MB, free 1976.1 MB)
17/12/19 16:51:49 INFO BlockManagerInfo: Added rdd_31_1 in memory on 127.0.0.1:56366 (size: 13.5 MB, free: 1977.0 MB)
17/12/19 16:51:49 INFO Executor: Finished task 1.0 in stage 10.0 (TID 10). 215335 bytes result sent to driver
17/12/19 16:51:49 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:196) finished in 18.376 s
17/12/19 16:51:49 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 10) in 18376 ms on localhost (executor driver) (2/2)
17/12/19 16:51:49 INFO DAGScheduler: Job 4 finished: collect at utils.scala:196, took 18.382400 s
17/12/19 16:51:49 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/19 16:51:49 INFO CodeGenerator: Code generated in 24.874294 ms
17/12/19 16:51:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:51:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:51:49 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:51:49 INFO DAGScheduler: Got job 5 (take at <unknown>:0) with 1 output partitions
17/12/19 16:51:49 INFO DAGScheduler: Final stage: ResultStage 12 (take at <unknown>:0)
17/12/19 16:51:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/12/19 16:51:49 INFO DAGScheduler: Missing parents: List()
17/12/19 16:51:49 INFO DAGScheduler: Submitting ResultStage 12 (WorkerRDD[43] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:51:49 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 1021.3 KB, free 1975.1 MB)
17/12/19 16:51:49 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 677.2 KB, free 1974.5 MB)
17/12/19 16:51:49 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:56366 (size: 677.2 KB, free: 1976.3 MB)
17/12/19 16:51:49 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/12/19 16:51:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (WorkerRDD[43] at RDD at rdd.scala:18)
17/12/19 16:51:49 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/12/19 16:51:49 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5913 bytes)
17/12/19 16:51:49 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
17/12/19 16:51:50 INFO BlockManager: Found block rdd_31_0 locally
17/12/19 16:51:57 INFO MemoryStore: Block rdd_43_0 stored as values in memory (estimated size 80.0 B, free 1974.5 MB)
17/12/19 16:51:57 INFO BlockManagerInfo: Added rdd_43_0 in memory on 127.0.0.1:56366 (size: 80.0 B, free: 1976.3 MB)
17/12/19 16:51:57 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 2656 bytes result sent to driver
17/12/19 16:51:57 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 7223 ms on localhost (executor driver) (1/1)
17/12/19 16:51:57 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/12/19 16:51:57 INFO DAGScheduler: ResultStage 12 (take at <unknown>:0) finished in 7.223 s
17/12/19 16:51:57 INFO DAGScheduler: Job 5 finished: take at <unknown>:0, took 7.232006 s
17/12/19 16:51:57 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:51:57 INFO DAGScheduler: Got job 6 (take at <unknown>:0) with 1 output partitions
17/12/19 16:51:57 INFO DAGScheduler: Final stage: ResultStage 14 (take at <unknown>:0)
17/12/19 16:51:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/12/19 16:51:57 INFO DAGScheduler: Missing parents: List()
17/12/19 16:51:57 INFO DAGScheduler: Submitting ResultStage 14 (WorkerRDD[43] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:51:57 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 1021.3 KB, free 1973.5 MB)
17/12/19 16:51:57 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 677.2 KB, free 1972.8 MB)
17/12/19 16:51:57 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:56366 (size: 677.2 KB, free: 1975.7 MB)
17/12/19 16:51:57 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/12/19 16:51:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (WorkerRDD[43] at RDD at rdd.scala:18)
17/12/19 16:51:57 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/12/19 16:51:57 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 5913 bytes)
17/12/19 16:51:57 INFO Executor: Running task 0.0 in stage 14.0 (TID 12)
17/12/19 16:51:57 INFO BlockManager: Found block rdd_31_1 locally
17/12/19 16:52:04 INFO MemoryStore: Block rdd_43_1 stored as values in memory (estimated size 80.0 B, free 1972.8 MB)
17/12/19 16:52:04 INFO BlockManagerInfo: Added rdd_43_1 in memory on 127.0.0.1:56366 (size: 80.0 B, free: 1975.7 MB)
17/12/19 16:52:04 INFO Executor: Finished task 0.0 in stage 14.0 (TID 12). 2479 bytes result sent to driver
17/12/19 16:52:04 INFO DAGScheduler: ResultStage 14 (take at <unknown>:0) finished in 7.066 s
17/12/19 16:52:04 INFO DAGScheduler: Job 6 finished: take at <unknown>:0, took 7.076352 s
17/12/19 16:52:04 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 12) in 7066 ms on localhost (executor driver) (1/1)
17/12/19 16:52:04 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/12/19 16:52:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:52:04 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2250523a1e8f
17/12/19 16:52:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:52:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2250523a1e8f` AS `zzz6`
WHERE (0 = 1)
17/12/19 16:52:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:52:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2250523a1e8f`
LIMIT 10
17/12/19 16:52:04 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:52:04 INFO DAGScheduler: Got job 7 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:52:04 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:196)
17/12/19 16:52:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
17/12/19 16:52:04 INFO DAGScheduler: Missing parents: List()
17/12/19 16:52:04 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/12/19 16:52:04 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 1022.3 KB, free 1971.8 MB)
17/12/19 16:52:04 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 678.0 KB, free 1971.2 MB)
17/12/19 16:52:04 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:56366 (size: 678.0 KB, free: 1975.0 MB)
17/12/19 16:52:04 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/12/19 16:52:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/12/19 16:52:04 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/12/19 16:52:04 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5860 bytes)
17/12/19 16:52:04 INFO Executor: Running task 0.0 in stage 16.0 (TID 13)
17/12/19 16:52:04 INFO BlockManager: Found block rdd_43_0 locally
17/12/19 16:52:04 INFO CodeGenerator: Code generated in 4.546833 ms
17/12/19 16:52:04 INFO CodeGenerator: Code generated in 8.25166 ms
17/12/19 16:52:04 INFO Executor: Finished task 0.0 in stage 16.0 (TID 13). 1814 bytes result sent to driver
17/12/19 16:52:04 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:196) finished in 0.031 s
17/12/19 16:52:04 INFO DAGScheduler: Job 7 finished: collect at utils.scala:196, took 0.037772 s
17/12/19 16:52:04 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:52:04 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:52:04 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:196)
17/12/19 16:52:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
17/12/19 16:52:04 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 13) in 31 ms on localhost (executor driver) (1/1)
17/12/19 16:52:04 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/12/19 16:52:04 INFO DAGScheduler: Missing parents: List()
17/12/19 16:52:04 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/12/19 16:52:04 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1022.3 KB, free 1970.2 MB)
17/12/19 16:52:04 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 678.0 KB, free 1969.5 MB)
17/12/19 16:52:04 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:56366 (size: 678.0 KB, free: 1974.3 MB)
17/12/19 16:52:04 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/12/19 16:52:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/12/19 16:52:04 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/12/19 16:52:04 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 14, localhost, executor driver, partition 1, PROCESS_LOCAL, 5860 bytes)
17/12/19 16:52:04 INFO Executor: Running task 0.0 in stage 18.0 (TID 14)
17/12/19 16:52:04 INFO BlockManager: Found block rdd_43_1 locally
17/12/19 16:52:04 INFO Executor: Finished task 0.0 in stage 18.0 (TID 14). 1637 bytes result sent to driver
17/12/19 16:52:04 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 14) in 16 ms on localhost (executor driver) (1/1)
17/12/19 16:52:04 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/12/19 16:52:04 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:196) finished in 0.016 s
17/12/19 16:52:04 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.023265 s
17/12/19 16:52:04 INFO CodeGenerator: Code generated in 4.05862 ms
17/12/19 16:52:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:52:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:52:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:52:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:52:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:52:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:52:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:52:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:52:04 INFO CodeGenerator: Code generated in 5.47757 ms
17/12/19 16:52:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:52:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:52:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:52:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:52:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:52:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:52:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:52:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:52:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:52:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:52:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:52:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:52:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:52:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:52:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:52:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:52:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:52:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:52:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:52:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:52:04 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:52:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:52:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:52:04 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:53:17 INFO SparkContext: Invoking stop() from shutdown hook
17/12/19 16:53:17 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/19 16:53:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/19 16:53:18 INFO MemoryStore: MemoryStore cleared
17/12/19 16:53:18 INFO BlockManager: BlockManager stopped
17/12/19 16:53:18 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/19 16:53:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/19 16:53:18 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-08aba968-f583-4b4a-bbcc-1a083634f941\userFiles-585ed8af-a537-4b19-9a30-8104ac2f52ea
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-08aba968-f583-4b4a-bbcc-1a083634f941\userFiles-585ed8af-a537-4b19-9a30-8104ac2f52ea
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 16:53:18 INFO SparkContext: Successfully stopped SparkContext
17/12/19 16:53:18 INFO ShutdownHookManager: Shutdown hook called
17/12/19 16:53:18 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-08aba968-f583-4b4a-bbcc-1a083634f941
17/12/19 16:53:18 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-08aba968-f583-4b4a-bbcc-1a083634f941
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-08aba968-f583-4b4a-bbcc-1a083634f941
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 16:53:18 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-08aba968-f583-4b4a-bbcc-1a083634f941\userFiles-585ed8af-a537-4b19-9a30-8104ac2f52ea
17/12/19 16:53:18 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-08aba968-f583-4b4a-bbcc-1a083634f941\userFiles-585ed8af-a537-4b19-9a30-8104ac2f52ea
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-08aba968-f583-4b4a-bbcc-1a083634f941\userFiles-585ed8af-a537-4b19-9a30-8104ac2f52ea
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 16:53:30 INFO SparkContext: Running Spark version 2.1.0
17/12/19 16:53:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/19 16:53:30 INFO SecurityManager: Changing view acls to: conan
17/12/19 16:53:30 INFO SecurityManager: Changing modify acls to: conan
17/12/19 16:53:30 INFO SecurityManager: Changing view acls groups to: 
17/12/19 16:53:30 INFO SecurityManager: Changing modify acls groups to: 
17/12/19 16:53:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(conan); groups with view permissions: Set(); users  with modify permissions: Set(conan); groups with modify permissions: Set()
17/12/19 16:53:30 INFO Utils: Successfully started service 'sparkDriver' on port 56520.
17/12/19 16:53:30 INFO SparkEnv: Registering MapOutputTracker
17/12/19 16:53:30 INFO SparkEnv: Registering BlockManagerMaster
17/12/19 16:53:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/19 16:53:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/19 16:53:30 INFO DiskBlockManager: Created local directory at C:\Users\conan\AppData\Local\Temp\blockmgr-7fc2bd5e-081b-46a0-8a9b-7c7742b479c7
17/12/19 16:53:30 INFO MemoryStore: MemoryStore started with capacity 2004.6 MB
17/12/19 16:53:30 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/19 16:53:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/19 16:53:31 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/19 16:53:31 INFO SparkContext: Added JAR file:/C:/Users/conan/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:56520/jars/sparklyr-2.1-2.11.jar with timestamp 1513702411179
17/12/19 16:53:31 INFO Executor: Starting executor ID driver on host localhost
17/12/19 16:53:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56541.
17/12/19 16:53:31 INFO NettyBlockTransferService: Server created on 127.0.0.1:56541
17/12/19 16:53:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/19 16:53:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 56541, None)
17/12/19 16:53:31 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:56541 with 2004.6 MB RAM, BlockManagerId(driver, 127.0.0.1, 56541, None)
17/12/19 16:53:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 56541, None)
17/12/19 16:53:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 56541, None)
17/12/19 16:53:31 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/19 16:53:31 INFO SharedState: Warehouse path is 'C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/19 16:53:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/19 16:53:32 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/19 16:53:32 INFO ObjectStore: ObjectStore, initialize called
17/12/19 16:53:32 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/19 16:53:32 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/19 16:53:34 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/19 16:53:34 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 16:53:34 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 16:53:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 16:53:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 16:53:35 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/19 16:53:35 INFO ObjectStore: Initialized ObjectStore
17/12/19 16:53:35 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/19 16:53:35 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/19 16:53:36 INFO HiveMetaStore: Added admin role in metastore
17/12/19 16:53:36 INFO HiveMetaStore: Added public role in metastore
17/12/19 16:53:36 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/19 16:53:36 INFO HiveMetaStore: 0: get_all_databases
17/12/19 16:53:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/19 16:53:36 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/19 16:53:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/19 16:53:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 16:53:36 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/Temp/2a5aa037-6319-4be1-a599-e511ef5b55f4_resources
17/12/19 16:53:36 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/2a5aa037-6319-4be1-a599-e511ef5b55f4
17/12/19 16:53:36 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/2a5aa037-6319-4be1-a599-e511ef5b55f4
17/12/19 16:53:36 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/2a5aa037-6319-4be1-a599-e511ef5b55f4/_tmp_space.db
17/12/19 16:53:36 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/19 16:53:36 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:53:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:53:36 INFO HiveMetaStore: 0: get_database: global_temp
17/12/19 16:53:36 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/19 16:53:36 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/19 16:53:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:53:38 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:53:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:53:38 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:53:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:53:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:53:38 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:54:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:54:08 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 16:54:08 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:54:08 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:54:08 INFO HiveMetaStore: 0: get_database: default
17/12/19 16:54:08 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 16:54:08 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 16:54:08 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 16:54:08 INFO CodeGenerator: Code generated in 261.322811 ms
17/12/19 16:54:08 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 16:54:08 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/19 16:54:08 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/19 16:54:08 INFO DAGScheduler: Parents of final stage: List()
17/12/19 16:54:08 INFO DAGScheduler: Missing parents: List()
17/12/19 16:54:08 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/12/19 16:54:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 2004.6 MB)
17/12/19 16:54:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2004.6 MB)
17/12/19 16:54:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:56541 (size: 4.6 KB, free: 2004.6 MB)
17/12/19 16:54:08 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/19 16:54:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/12/19 16:54:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/19 16:54:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/19 16:54:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/19 16:54:08 INFO Executor: Fetching spark://127.0.0.1:56520/jars/sparklyr-2.1-2.11.jar with timestamp 1513702411179
17/12/19 16:54:08 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:56520 after 18 ms (0 ms spent in bootstraps)
17/12/19 16:54:08 INFO Utils: Fetching spark://127.0.0.1:56520/jars/sparklyr-2.1-2.11.jar to C:\Users\conan\AppData\Local\Temp\spark-b83755d1-1ba2-4197-9bfd-78f6ce883f38\userFiles-d10ae8db-d26e-4786-992e-b95282b58dfb\fetchFileTemp1550943272668624950.tmp
17/12/19 16:54:09 INFO Executor: Adding file:/C:/Users/conan/AppData/Local/Temp/spark-b83755d1-1ba2-4197-9bfd-78f6ce883f38/userFiles-d10ae8db-d26e-4786-992e-b95282b58dfb/sparklyr-2.1-2.11.jar to class loader
17/12/19 16:54:09 INFO CodeGenerator: Code generated in 13.00956 ms
17/12/19 16:54:09 INFO CodeGenerator: Code generated in 12.223058 ms
17/12/19 16:54:09 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/12/19 16:54:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 316 ms on localhost (executor driver) (1/1)
17/12/19 16:54:09 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.343 s
17/12/19 16:54:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/19 16:54:09 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.546274 s
17/12/19 16:54:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:54:10 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:54:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:54:10 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 16:54:10 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 16:54:10 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 16:54:10 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 16:54:10 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 16:54:10 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 16:54:10 INFO CodeGenerator: Code generated in 8.699093 ms
17/12/19 16:54:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.7 KB, free 2004.3 MB)
17/12/19 16:54:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2004.3 MB)
17/12/19 16:54:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:56541 (size: 24.0 KB, free: 2004.6 MB)
17/12/19 16:54:10 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/19 16:54:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 16:54:10 INFO CodeGenerator: Code generated in 9.907731 ms
17/12/19 16:54:10 INFO CodeGenerator: Code generated in 11.136757 ms
17/12/19 16:54:10 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 16:54:10 INFO DAGScheduler: Registering RDD 10 (sql at <unknown>:0)
17/12/19 16:54:10 INFO DAGScheduler: Registering RDD 15 (sql at <unknown>:0)
17/12/19 16:54:10 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/19 16:54:10 INFO DAGScheduler: Final stage: ResultStage 3 (sql at <unknown>:0)
17/12/19 16:54:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/12/19 16:54:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/12/19 16:54:10 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0), which has no missing parents
17/12/19 16:54:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.1 KB, free 2004.3 MB)
17/12/19 16:54:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2004.3 MB)
17/12/19 16:54:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:56541 (size: 7.3 KB, free: 2004.6 MB)
17/12/19 16:54:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/19 16:54:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0)
17/12/19 16:54:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
17/12/19 16:54:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/19 16:54:10 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 6676 bytes)
17/12/19 16:54:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/19 16:54:10 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/12/19 16:54:10 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpwLtPOg/spark_serialize_0761a63bd511fa651bf5d303672c3d40807d82a0eb9f75ba8436984c1bc3c5b4.csv, range: 0-4194304, partition values: [empty row]
17/12/19 16:54:10 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpwLtPOg/spark_serialize_0761a63bd511fa651bf5d303672c3d40807d82a0eb9f75ba8436984c1bc3c5b4.csv, range: 4194304-5549682, partition values: [empty row]
17/12/19 16:54:10 INFO CodeGenerator: Code generated in 6.891234 ms
17/12/19 16:54:11 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1809 bytes result sent to driver
17/12/19 16:54:11 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 368 ms on localhost (executor driver) (1/2)
17/12/19 16:54:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1719 bytes result sent to driver
17/12/19 16:54:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 430 ms on localhost (executor driver) (2/2)
17/12/19 16:54:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/19 16:54:11 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.430 s
17/12/19 16:54:11 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:54:11 INFO DAGScheduler: running: Set()
17/12/19 16:54:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/12/19 16:54:11 INFO DAGScheduler: failed: Set()
17/12/19 16:54:11 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/19 16:54:11 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.9 KB, free 2004.2 MB)
17/12/19 16:54:11 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2004.2 MB)
17/12/19 16:54:11 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:56541 (size: 6.0 KB, free: 2004.6 MB)
17/12/19 16:54:11 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/19 16:54:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/19 16:54:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
17/12/19 16:54:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, ANY, 5942 bytes)
17/12/19 16:54:11 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 4, localhost, executor driver, partition 1, ANY, 5942 bytes)
17/12/19 16:54:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 3)
17/12/19 16:54:11 INFO Executor: Running task 1.0 in stage 2.0 (TID 4)
17/12/19 16:54:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:54:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:54:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:54:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:54:11 INFO MemoryStore: Block rdd_12_1 stored as values in memory (estimated size 1174.3 KB, free 2003.1 MB)
17/12/19 16:54:11 INFO BlockManagerInfo: Added rdd_12_1 in memory on 127.0.0.1:56541 (size: 1174.3 KB, free: 2003.4 MB)
17/12/19 16:54:11 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 1174.3 KB, free 2001.9 MB)
17/12/19 16:54:11 INFO BlockManagerInfo: Added rdd_12_0 in memory on 127.0.0.1:56541 (size: 1174.3 KB, free: 2002.3 MB)
17/12/19 16:54:11 INFO CodeGenerator: Code generated in 4.557405 ms
17/12/19 16:54:11 INFO CodeGenerator: Code generated in 18.201679 ms
17/12/19 16:54:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 4). 3064 bytes result sent to driver
17/12/19 16:54:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 3). 3064 bytes result sent to driver
17/12/19 16:54:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 4) in 200 ms on localhost (executor driver) (1/2)
17/12/19 16:54:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 200 ms on localhost (executor driver) (2/2)
17/12/19 16:54:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/19 16:54:11 INFO DAGScheduler: ShuffleMapStage 2 (sql at <unknown>:0) finished in 0.215 s
17/12/19 16:54:11 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:54:11 INFO DAGScheduler: running: Set()
17/12/19 16:54:11 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/12/19 16:54:11 INFO DAGScheduler: failed: Set()
17/12/19 16:54:11 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
17/12/19 16:54:11 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 2001.9 MB)
17/12/19 16:54:11 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.9 MB)
17/12/19 16:54:11 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:56541 (size: 3.7 KB, free: 2002.3 MB)
17/12/19 16:54:11 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/19 16:54:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0)
17/12/19 16:54:11 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/19 16:54:11 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 5, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/19 16:54:11 INFO Executor: Running task 0.0 in stage 3.0 (TID 5)
17/12/19 16:54:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:54:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:54:11 INFO Executor: Finished task 0.0 in stage 3.0 (TID 5). 1707 bytes result sent to driver
17/12/19 16:54:11 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 5) in 0 ms on localhost (executor driver) (1/1)
17/12/19 16:54:11 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/19 16:54:11 INFO DAGScheduler: ResultStage 3 (sql at <unknown>:0) finished in 0.000 s
17/12/19 16:54:11 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.705996 s
17/12/19 16:54:11 INFO CodeGenerator: Code generated in 6.127388 ms
17/12/19 16:54:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:54:11 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 16:54:11 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:54:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 156 bytes
17/12/19 16:54:11 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:196)
17/12/19 16:54:11 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/12/19 16:54:11 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:196)
17/12/19 16:54:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/12/19 16:54:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/12/19 16:54:11 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
17/12/19 16:54:11 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.9 KB, free 2001.9 MB)
17/12/19 16:54:11 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2001.9 MB)
17/12/19 16:54:11 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:56541 (size: 6.0 KB, free: 2002.3 MB)
17/12/19 16:54:11 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/19 16:54:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196)
17/12/19 16:54:11 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
17/12/19 16:54:11 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5934 bytes)
17/12/19 16:54:11 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 5934 bytes)
17/12/19 16:54:11 INFO Executor: Running task 0.0 in stage 5.0 (TID 6)
17/12/19 16:54:11 INFO Executor: Running task 1.0 in stage 5.0 (TID 7)
17/12/19 16:54:11 INFO BlockManager: Found block rdd_12_0 locally
17/12/19 16:54:11 INFO BlockManager: Found block rdd_12_1 locally
17/12/19 16:54:11 INFO Executor: Finished task 0.0 in stage 5.0 (TID 6). 2127 bytes result sent to driver
17/12/19 16:54:11 INFO Executor: Finished task 1.0 in stage 5.0 (TID 7). 1958 bytes result sent to driver
17/12/19 16:54:11 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 32 ms on localhost (executor driver) (1/2)
17/12/19 16:54:11 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 7) in 32 ms on localhost (executor driver) (2/2)
17/12/19 16:54:11 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:196) finished in 0.032 s
17/12/19 16:54:11 INFO DAGScheduler: looking for newly runnable stages
17/12/19 16:54:11 INFO DAGScheduler: running: Set()
17/12/19 16:54:11 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/12/19 16:54:11 INFO DAGScheduler: failed: Set()
17/12/19 16:54:11 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196), which has no missing parents
17/12/19 16:54:11 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/19 16:54:11 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 2001.9 MB)
17/12/19 16:54:11 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2001.9 MB)
17/12/19 16:54:11 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:56541 (size: 3.7 KB, free: 2002.3 MB)
17/12/19 16:54:11 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/12/19 16:54:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196)
17/12/19 16:54:11 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/19 16:54:11 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/19 16:54:11 INFO Executor: Running task 0.0 in stage 6.0 (TID 8)
17/12/19 16:54:11 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 16:54:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 16:54:11 INFO Executor: Finished task 0.0 in stage 6.0 (TID 8). 1865 bytes result sent to driver
17/12/19 16:54:11 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:196) finished in 0.016 s
17/12/19 16:54:11 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.054804 s
17/12/19 16:54:11 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 16 ms on localhost (executor driver) (1/1)
17/12/19 16:54:11 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/19 16:54:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:54:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz7`
WHERE (0 = 1)
17/12/19 16:54:11 INFO ContextCleaner: Cleaned accumulator 57
17/12/19 16:54:11 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:56541 in memory (size: 3.7 KB, free: 2002.3 MB)
17/12/19 16:54:11 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:56541 in memory (size: 7.3 KB, free: 2002.3 MB)
17/12/19 16:54:11 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:56541 in memory (size: 6.0 KB, free: 2002.3 MB)
17/12/19 16:54:11 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:56541 in memory (size: 3.7 KB, free: 2002.3 MB)
17/12/19 16:54:11 INFO ContextCleaner: Cleaned accumulator 262
17/12/19 16:54:11 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:56541 in memory (size: 6.0 KB, free: 2002.3 MB)
17/12/19 16:54:11 INFO ContextCleaner: Cleaned accumulator 58
17/12/19 16:54:11 INFO ContextCleaner: Cleaned accumulator 59
17/12/19 16:54:11 INFO ContextCleaner: Cleaned accumulator 60
17/12/19 16:54:11 INFO ContextCleaner: Cleaned accumulator 61
17/12/19 16:54:11 INFO ContextCleaner: Cleaned accumulator 62
17/12/19 16:54:11 INFO ContextCleaner: Cleaned accumulator 63
17/12/19 16:54:11 INFO ContextCleaner: Cleaned accumulator 64
17/12/19 16:54:11 INFO ContextCleaner: Cleaned accumulator 65
17/12/19 16:54:11 INFO ContextCleaner: Cleaned accumulator 66
17/12/19 16:54:11 INFO ContextCleaner: Cleaned accumulator 67
17/12/19 16:54:11 INFO ContextCleaner: Cleaned accumulator 68
17/12/19 16:54:11 INFO ContextCleaner: Cleaned accumulator 69
17/12/19 16:54:11 INFO ContextCleaner: Cleaned shuffle 1
17/12/19 16:54:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:54:12 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`, `V11` AS `V11`, `V12` AS `V12`, `V13` AS `V13`, `V14` AS `V14`, `V15` AS `V15`, `V16` AS `V16`, `V17` AS `V17`, `V18` AS `V18`, `V19` AS `V19`, `V20` AS `V20`, `V21` AS `V21`, `V22` AS `V22`, `V23` AS `V23`, `V24` AS `V24`, `V25` AS `V25`, `V26` AS `V26`, `V27` AS `V27`, `V28` AS `V28`, `V29` AS `V29`, `V30` AS `V30`, `V31` AS `V31`, `V32` AS `V32`, `V33` AS `V33`, `V34` AS `V34`, `V35` AS `V35`, `V36` AS `V36`, `V37` AS `V37`, `V38` AS `V38`, `V39` AS `V39`, `V40` AS `V40`, `V41` AS `V41`, `V42` AS `V42`, `V43` AS `V43`, `V44` AS `V44`, `V45` AS `V45`, `V46` AS `V46`, `V47` AS `V47`, `V48` AS `V48`, `V49` AS `V49`, `V50` AS `V50`, `V51` AS `V51`, `V52` AS `V52`, `V53` AS `V53`, `V54` AS `V54`, `V55` AS `V55`, `V56` AS `V56`, `V57` AS `V57`, `V58` AS `V58`, `V59` AS `V59`, `V60` AS `V60`, `V61` AS `V61`, `V62` AS `V62`, `V63` AS `V63`, `V64` AS `V64`, `V65` AS `V65`, `V66` AS `V66`, `V67` AS `V67`, `V68` AS `V68`, `V69` AS `V69`, `V70` AS `V70`, `V71` AS `V71`, `V72` AS `V72`, `V73` AS `V73`, `V74` AS `V74`, `V75` AS `V75`, `V76` AS `V76`, `V77` AS `V77`, `V78` AS `V78`, `V79` AS `V79`, `V80` AS `V80`, `V81` AS `V81`, `V82` AS `V82`, `V83` AS `V83`, `V84` AS `V84`, `V85` AS `V85`, `V86` AS `V86`, `V87` AS `V87`, `V88` AS `V88`, `V89` AS `V89`, `V90` AS `V90`, `V91` AS `V91`, `V92` AS `V92`, `V93` AS `V93`, `V94` AS `V94`, `V95` AS `V95`, `V96` AS `V96`, `V97` AS `V97`, `V98` AS `V98`, `V99` AS `V99`, `V100` AS `V100`
FROM (SELECT `S1`, `S2`, `S3`, `S1` + 0.91104336 * RANDN() AS `V1`, `S1` + 0.91104336 * RANDN() AS `V2`, `S3` + 0.89442719 * RANDN() AS `V3`, `S1` + 0.91104336 * RANDN() AS `V4`, `S3` + 0.89442719 * RANDN() AS `V5`, `S1` + 0.91104336 * RANDN() AS `V6`, `S3` + 0.89442719 * RANDN() AS `V7`, `S2` + 0.91651514 * RANDN() AS `V8`, `S1` + 0.91104336 * RANDN() AS `V9`, `S1` + 0.91104336 * RANDN() AS `V10`, `S3` + 0.89442719 * RANDN() AS `V11`, `S2` + 0.91651514 * RANDN() AS `V12`, `S3` + 0.89442719 * RANDN() AS `V13`, `S1` + 0.91104336 * RANDN() AS `V14`, `S1` + 0.91104336 * RANDN() AS `V15`, `S3` + 0.89442719 * RANDN() AS `V16`, `S1` + 0.91104336 * RANDN() AS `V17`, `S1` + 0.91104336 * RANDN() AS `V18`, `S2` + 0.91651514 * RANDN() AS `V19`, `S1` + 0.91104336 * RANDN() AS `V20`, `S2` + 0.91651514 * RANDN() AS `V21`, `S3` + 0.89442719 * RANDN() AS `V22`, `S3` + 0.89442719 * RANDN() AS `V23`, `S1` + 0.91104336 * RANDN() AS `V24`, `S3` + 0.89442719 * RANDN() AS `V25`, `S3` + 0.89442719 * RANDN() AS `V26`, `S3` + 0.89442719 * RANDN() AS `V27`, `S2` + 0.91651514 * RANDN() AS `V28`, `S3` + 0.89442719 * RANDN() AS `V29`, `S3` + 0.89442719 * RANDN() AS `V30`, `S3` + 0.89442719 * RANDN() AS `V31`, `S2` + 0.91651514 * RANDN() AS `V32`, `S1` + 0.91104336 * RANDN() AS `V33`, `S3` + 0.89442719 * RANDN() AS `V34`, `S1` + 0.91104336 * RANDN() AS `V35`, `S1` + 0.91104336 * RANDN() AS `V36`, `S3` + 0.89442719 * RANDN() AS `V37`, `S3` + 0.89442719 * RANDN() AS `V38`, `S2` + 0.91651514 * RANDN() AS `V39`, `S3` + 0.89442719 * RANDN() AS `V40`, `S2` + 0.91651514 * RANDN() AS `V41`, `S2` + 0.91651514 * RANDN() AS `V42`, `S2` + 0.91651514 * RANDN() AS `V43`, `S2` + 0.91651514 * RANDN() AS `V44`, `S2` + 0.91651514 * RANDN() AS `V45`, `S3` + 0.89442719 * RANDN() AS `V46`, `S3` + 0.89442719 * RANDN() AS `V47`, `S2` + 0.91651514 * RANDN() AS `V48`, `S3` + 0.89442719 * RANDN() AS `V49`, `S2` + 0.91651514 * RANDN() AS `V50`, `S1` + 0.91104336 * RANDN() AS `V51`, `S2` + 0.91651514 * RANDN() AS `V52`, `S1` + 0.91104336 * RANDN() AS `V53`, `S1` + 0.91104336 * RANDN() AS `V54`, `S1` + 0.91104336 * RANDN() AS `V55`, `S3` + 0.89442719 * RANDN() AS `V56`, `S2` + 0.91651514 * RANDN() AS `V57`, `S1` + 0.91104336 * RANDN() AS `V58`, `S3` + 0.89442719 * RANDN() AS `V59`, `S3` + 0.89442719 * RANDN() AS `V60`, `S2` + 0.91651514 * RANDN() AS `V61`, `S2` + 0.91651514 * RANDN() AS `V62`, `S2` + 0.91651514 * RANDN() AS `V63`, `S3` + 0.89442719 * RANDN() AS `V64`, `S3` + 0.89442719 * RANDN() AS `V65`, `S1` + 0.91104336 * RANDN() AS `V66`, `S1` + 0.91104336 * RANDN() AS `V67`, `S1` + 0.91104336 * RANDN() AS `V68`, `S2` + 0.91651514 * RANDN() AS `V69`, `S2` + 0.91651514 * RANDN() AS `V70`, `S1` + 0.91104336 * RANDN() AS `V71`, `S1` + 0.91104336 * RANDN() AS `V72`, `S1` + 0.91104336 * RANDN() AS `V73`, `S2` + 0.91651514 * RANDN() AS `V74`, `S2` + 0.91651514 * RANDN() AS `V75`, `S1` + 0.91104336 * RANDN() AS `V76`, `S3` + 0.89442719 * RANDN() AS `V77`, `S1` + 0.91104336 * RANDN() AS `V78`, `S1` + 0.91104336 * RANDN() AS `V79`, `S2` + 0.91651514 * RANDN() AS `V80`, `S2` + 0.91651514 * RANDN() AS `V81`, `S1` + 0.91104336 * RANDN() AS `V82`, `S3` + 0.89442719 * RANDN() AS `V83`, `S1` + 0.91104336 * RANDN() AS `V84`, `S3` + 0.89442719 * RANDN() AS `V85`, `S3` + 0.89442719 * RANDN() AS `V86`, `S3` + 0.89442719 * RANDN() AS `V87`, `S3` + 0.89442719 * RANDN() AS `V88`, `S1` + 0.91104336 * RANDN() AS `V89`, `S2` + 0.91651514 * RANDN() AS `V90`, `S3` + 0.89442719 * RANDN() AS `V91`, `S2` + 0.91651514 * RANDN() AS `V92`, `S1` + 0.91104336 * RANDN() AS `V93`, `S3` + 0.89442719 * RANDN() AS `V94`, `S2` + 0.91651514 * RANDN() AS `V95`, `S3` + 0.89442719 * RANDN() AS `V96`, `S3` + 0.89442719 * RANDN() AS `V97`, `S3` + 0.89442719 * RANDN() AS `V98`, `S3` + 0.89442719 * RANDN() AS `V99`, `S3` + 0.89442719 * RANDN() AS `V100`
FROM `analyis_tbl`) `fozuppwmry`
17/12/19 16:54:12 INFO ContextCleaner: Cleaned accumulator 51
17/12/19 16:54:12 INFO ContextCleaner: Cleaned accumulator 50
17/12/19 16:54:12 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:56541 in memory (size: 4.6 KB, free: 2002.3 MB)
17/12/19 16:54:12 INFO ContextCleaner: Cleaned accumulator 1
17/12/19 16:54:12 INFO ContextCleaner: Cleaned accumulator 0
17/12/19 16:54:12 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:54:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:54:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz8`
WHERE (0 = 1)
17/12/19 16:54:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:54:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:54:13 INFO CodeGenerator: Code generated in 122.097297 ms
17/12/19 16:54:13 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:54:13 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 156 bytes
17/12/19 16:54:13 INFO DAGScheduler: Got job 3 (take at <unknown>:0) with 1 output partitions
17/12/19 16:54:13 INFO DAGScheduler: Final stage: ResultStage 8 (take at <unknown>:0)
17/12/19 16:54:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/12/19 16:54:13 INFO DAGScheduler: Missing parents: List()
17/12/19 16:54:13 INFO DAGScheduler: Submitting ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:54:13 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 2.5 MB, free 1999.5 MB)
17/12/19 16:54:13 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 MB, free 1997.1 MB)
17/12/19 16:54:13 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:56541 (size: 2.4 MB, free: 1999.9 MB)
17/12/19 16:54:13 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/12/19 16:54:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18)
17/12/19 16:54:13 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/19 16:54:13 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5913 bytes)
17/12/19 16:54:13 INFO Executor: Running task 0.0 in stage 8.0 (TID 9)
17/12/19 16:54:13 INFO BlockManager: Found block rdd_12_0 locally
17/12/19 16:54:13 INFO CodeGenerator: Code generated in 16.604133 ms
17/12/19 16:54:13 INFO CodeGenerator: Code generated in 42.314769 ms
17/12/19 16:57:02 INFO MemoryStore: Block rdd_31_0 stored as values in memory (estimated size 135.2 MB, free 1861.9 MB)
17/12/19 16:57:02 INFO BlockManagerInfo: Added rdd_31_0 in memory on 127.0.0.1:56541 (size: 135.2 MB, free: 1864.7 MB)
17/12/19 16:57:02 WARN Executor: 1 block locks were not released by TID = 9:
[rdd_31_0]
17/12/19 16:57:02 INFO Executor: Finished task 0.0 in stage 8.0 (TID 9). 16777 bytes result sent to driver
17/12/19 16:57:02 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 9) in 169380 ms on localhost (executor driver) (1/1)
17/12/19 16:57:02 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/19 16:57:02 INFO DAGScheduler: ResultStage 8 (take at <unknown>:0) finished in 169.380 s
17/12/19 16:57:02 INFO DAGScheduler: Job 3 finished: take at <unknown>:0, took 169.402289 s
17/12/19 16:57:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:57:02 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2250550b5246
17/12/19 16:57:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:57:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2250550b5246` AS `zzz9`
WHERE (0 = 1)
17/12/19 16:57:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:57:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2250550b5246`
17/12/19 16:57:02 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:57:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:57:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz10`
WHERE (0 = 1)
17/12/19 16:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:57:03 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.0375) AS `V1`, (`V2` < 0.0185) AS `V2`, (`V3` < 0.026) AS `V3`, (`V4` < 0.0138) AS `V4`, (`V5` < 0.1) AS `V5`, (`V6` < 0.0185) AS `V6`, (`V7` < 0.009) AS `V7`, (`V8` < 0.026) AS `V8`, (`V9` < 0.026) AS `V9`, (`V10` < 4e-04) AS `V10`, (`V11` < 0.054) AS `V11`, (`V12` < 0.054) AS `V12`, (`V13` < 0.0055) AS `V13`, (`V14` < 0.075) AS `V14`, (`V15` < 0.0185) AS `V15`, (`V16` < 0.0028) AS `V16`, (`V17` < 0.0023) AS `V17`, (`V18` < 0.0045) AS `V18`, (`V19` < 0.026) AS `V19`, (`V20` < 0.0013) AS `V20`, (`V21` < 0.054) AS `V21`, (`V22` < 0.0028) AS `V22`, (`V23` < 0.009) AS `V23`, (`V24` < 0.009) AS `V24`, (`V25` < 0.0055) AS `V25`, (`V26` < 0.0055) AS `V26`, (`V27` < 0.0185) AS `V27`, (`V28` < 0.0045) AS `V28`, (`V29` < 0.0375) AS `V29`, (`V30` < 3e-04) AS `V30`, (`V31` < 0.009) AS `V31`, (`V32` < 0.009) AS `V32`, (`V33` < 0.0138) AS `V33`, (`V34` < 0.0138) AS `V34`, (`V35` < 8e-04) AS `V35`, (`V36` < 0.3) AS `V36`, (`V37` < 0.0018) AS `V37`, (`V38` < 0.026) AS `V38`, (`V39` < 0.0028) AS `V39`, (`V40` < 0.054) AS `V40`, (`V41` < 0.0035) AS `V41`, (`V42` < 0.3) AS `V42`, (`V43` < 0.0028) AS `V43`, (`V44` < 0.009) AS `V44`, (`V45` < 0.0045) AS `V45`, (`V46` < 0.075) AS `V46`, (`V47` < 0.009) AS `V47`, (`V48` < 0.054) AS `V48`, (`V49` < 0.0138) AS `V49`, (`V50` < 0.0055) AS `V50`, (`V51` < 0.1) AS `V51`, (`V52` < 0.0035) AS `V52`, (`V53` < 0.0023) AS `V53`, (`V54` < 0.3) AS `V54`, (`V55` < 0.1) AS `V55`, (`V56` < 0.0035) AS `V56`, (`V57` < 0.0138) AS `V57`, (`V58` < 0.0045) AS `V58`, (`V59` < 0.0055) AS `V59`, (`V60` < 4e-04) AS `V60`, (`V61` < 0.0035) AS `V61`, (`V62` < 0.0045) AS `V62`, (`V63` < 0.054) AS `V63`, (`V64` < 0.1) AS `V64`, (`V65` < 0.0375) AS `V65`, (`V66` < 0.0028) AS `V66`, (`V67` < 0.1) AS `V67`, (`V68` < 0.0185) AS `V68`, (`V69` < 0.0375) AS `V69`, (`V70` < 0.0028) AS `V70`, (`V71` < 0.0055) AS `V71`, (`V72` < 0.0138) AS `V72`, (`V73` < 0.0138) AS `V73`, (`V74` < 0.0055) AS `V74`, (`V75` < 0.0023) AS `V75`, (`V76` < 0.0045) AS `V76`, (`V77` < 0.0138) AS `V77`, (`V78` < 4e-04) AS `V78`, (`V79` < 0.3) AS `V79`, (`V80` < 0.0023) AS `V80`, (`V81` < 0.009) AS `V81`, (`V82` < 0.026) AS `V82`, (`V83` < 3e-04) AS `V83`, (`V84` < 0.0055) AS `V84`, (`V85` < 0.026) AS `V85`, (`V86` < 0.054) AS `V86`, (`V87` < 0.009) AS `V87`, (`V88` < 0.009) AS `V88`, (`V89` < 0.15) AS `V89`, (`V90` < 0.0185) AS `V90`, (`V91` < 0.075) AS `V91`, (`V92` < 0.1) AS `V92`, (`V93` < 0.0055) AS `V93`, (`V94` < 0.3) AS `V94`, (`V95` < 0.0138) AS `V95`, (`V96` < 0.009) AS `V96`, (`V97` < 0.15) AS `V97`, (`V98` < 0.009) AS `V98`, (`V99` < 0.026) AS `V99`, (`V100` < 0.0375) AS `V100`
FROM `analyis_tbl`
17/12/19 16:57:03 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 16:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:57:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz11`
WHERE (0 = 1)
17/12/19 16:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:57:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:57:03 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/12/19 16:57:03 INFO CodeGenerator: Code generated in 77.924829 ms
17/12/19 16:57:03 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 16:57:03 INFO DAGScheduler: Got job 4 (collect at utils.scala:196) with 2 output partitions
17/12/19 16:57:03 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:196)
17/12/19 16:57:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
17/12/19 16:57:03 INFO DAGScheduler: Missing parents: List()
17/12/19 16:57:03 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196), which has no missing parents
17/12/19 16:57:03 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 2.6 MB, free 1859.3 MB)
17/12/19 16:57:03 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.4 MB, free 1856.9 MB)
17/12/19 16:57:03 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:56541 (size: 2.4 MB, free: 1862.3 MB)
17/12/19 16:57:03 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/12/19 16:57:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196)
17/12/19 16:57:03 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks
17/12/19 16:57:03 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5945 bytes)
17/12/19 16:57:03 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 11, localhost, executor driver, partition 1, PROCESS_LOCAL, 5945 bytes)
17/12/19 16:57:03 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
17/12/19 16:57:03 INFO BlockManager: Found block rdd_31_0 locally
17/12/19 16:57:03 INFO Executor: Running task 1.0 in stage 10.0 (TID 11)
17/12/19 16:57:03 INFO BlockManager: Found block rdd_12_1 locally
17/12/19 16:57:03 INFO CodeGenerator: Code generated in 50.741249 ms
17/12/19 16:57:03 INFO CodeGenerator: Code generated in 247.689486 ms
17/12/19 16:57:05 INFO MemoryStore: Block taskresult_10 stored as bytes in memory (estimated size 2.1 MB, free 1854.8 MB)
17/12/19 16:57:05 INFO BlockManagerInfo: Added taskresult_10 in memory on 127.0.0.1:56541 (size: 2.1 MB, free: 1860.2 MB)
17/12/19 16:57:05 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2165427 bytes result sent via BlockManager)
17/12/19 16:57:05 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:56541 after 1 ms (0 ms spent in bootstraps)
17/12/19 16:57:05 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 1805 ms on localhost (executor driver) (1/2)
17/12/19 16:57:05 INFO BlockManagerInfo: Removed taskresult_10 on 127.0.0.1:56541 in memory (size: 2.1 MB, free: 1862.3 MB)
17/12/19 16:57:07 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:56541 in memory (size: 2.4 MB, free: 1864.7 MB)
17/12/19 16:59:55 INFO MemoryStore: Block rdd_31_1 stored as values in memory (estimated size 135.2 MB, free 1726.5 MB)
17/12/19 16:59:55 INFO BlockManagerInfo: Added rdd_31_1 in memory on 127.0.0.1:56541 (size: 135.2 MB, free: 1729.4 MB)
17/12/19 16:59:56 INFO MemoryStore: Block taskresult_11 stored as bytes in memory (estimated size 2.1 MB, free 1724.5 MB)
17/12/19 16:59:56 INFO BlockManagerInfo: Added taskresult_11 in memory on 127.0.0.1:56541 (size: 2.1 MB, free: 1727.4 MB)
17/12/19 16:59:56 INFO Executor: Finished task 1.0 in stage 10.0 (TID 11). 2172583 bytes result sent via BlockManager)
17/12/19 16:59:56 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 11) in 172986 ms on localhost (executor driver) (2/2)
17/12/19 16:59:56 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/19 16:59:56 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:196) finished in 172.986 s
17/12/19 16:59:56 INFO DAGScheduler: Job 4 finished: collect at utils.scala:196, took 173.116236 s
17/12/19 16:59:56 INFO BlockManagerInfo: Removed taskresult_11 on 127.0.0.1:56541 in memory (size: 2.1 MB, free: 1729.4 MB)
17/12/19 16:59:56 INFO CodeGenerator: Code generated in 27.284772 ms
17/12/19 16:59:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 16:59:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 16:59:58 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 16:59:58 INFO DAGScheduler: Got job 5 (take at <unknown>:0) with 1 output partitions
17/12/19 16:59:58 INFO DAGScheduler: Final stage: ResultStage 12 (take at <unknown>:0)
17/12/19 16:59:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/12/19 16:59:58 INFO DAGScheduler: Missing parents: List()
17/12/19 16:59:58 INFO DAGScheduler: Submitting ResultStage 12 (WorkerRDD[43] at RDD at rdd.scala:18), which has no missing parents
17/12/19 16:59:58 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 5.8 MB, free 1720.7 MB)
17/12/19 16:59:58 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.0 MB, free 1716.7 MB)
17/12/19 16:59:58 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:56541 (size: 4.0 MB, free: 1725.4 MB)
17/12/19 16:59:58 INFO MemoryStore: Block broadcast_9_piece1 stored as bytes in memory (estimated size 1334.1 KB, free 1715.4 MB)
17/12/19 16:59:58 INFO BlockManagerInfo: Added broadcast_9_piece1 in memory on 127.0.0.1:56541 (size: 1334.1 KB, free: 1724.1 MB)
17/12/19 16:59:58 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/12/19 16:59:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (WorkerRDD[43] at RDD at rdd.scala:18)
17/12/19 16:59:58 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/12/19 16:59:58 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 5917 bytes)
17/12/19 16:59:58 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
17/12/19 16:59:58 INFO BlockManager: Found block rdd_31_0 locally
17/12/19 17:01:05 INFO MemoryStore: Block rdd_43_0 stored as values in memory (estimated size 80.0 B, free 1715.4 MB)
17/12/19 17:01:05 INFO BlockManagerInfo: Added rdd_43_0 in memory on 127.0.0.1:56541 (size: 80.0 B, free: 1724.1 MB)
17/12/19 17:01:05 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2656 bytes result sent to driver
17/12/19 17:01:05 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 66999 ms on localhost (executor driver) (1/1)
17/12/19 17:01:05 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/12/19 17:01:05 INFO DAGScheduler: ResultStage 12 (take at <unknown>:0) finished in 66.999 s
17/12/19 17:01:05 INFO DAGScheduler: Job 5 finished: take at <unknown>:0, took 67.021655 s
17/12/19 17:01:05 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 17:01:05 INFO DAGScheduler: Got job 6 (take at <unknown>:0) with 1 output partitions
17/12/19 17:01:05 INFO DAGScheduler: Final stage: ResultStage 14 (take at <unknown>:0)
17/12/19 17:01:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/12/19 17:01:05 INFO DAGScheduler: Missing parents: List()
17/12/19 17:01:05 INFO DAGScheduler: Submitting ResultStage 14 (WorkerRDD[43] at RDD at rdd.scala:18), which has no missing parents
17/12/19 17:01:05 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.8 MB, free 1709.6 MB)
17/12/19 17:01:05 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.0 MB, free 1705.6 MB)
17/12/19 17:01:05 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:56541 (size: 4.0 MB, free: 1720.1 MB)
17/12/19 17:01:05 INFO MemoryStore: Block broadcast_10_piece1 stored as bytes in memory (estimated size 1334.1 KB, free 1704.3 MB)
17/12/19 17:01:05 INFO BlockManagerInfo: Added broadcast_10_piece1 in memory on 127.0.0.1:56541 (size: 1334.1 KB, free: 1718.8 MB)
17/12/19 17:01:05 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/12/19 17:01:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (WorkerRDD[43] at RDD at rdd.scala:18)
17/12/19 17:01:05 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/12/19 17:01:05 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 5917 bytes)
17/12/19 17:01:05 INFO Executor: Running task 0.0 in stage 14.0 (TID 13)
17/12/19 17:01:05 INFO BlockManager: Found block rdd_31_1 locally
17/12/19 17:01:05 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:56541 in memory (size: 4.0 MB, free: 1722.8 MB)
17/12/19 17:01:05 INFO BlockManagerInfo: Removed broadcast_9_piece1 on 127.0.0.1:56541 in memory (size: 1334.1 KB, free: 1724.1 MB)
17/12/19 17:02:12 INFO MemoryStore: Block rdd_43_1 stored as values in memory (estimated size 80.0 B, free 1715.4 MB)
17/12/19 17:02:12 INFO BlockManagerInfo: Added rdd_43_1 in memory on 127.0.0.1:56541 (size: 80.0 B, free: 1724.1 MB)
17/12/19 17:02:12 INFO Executor: Finished task 0.0 in stage 14.0 (TID 13). 2729 bytes result sent to driver
17/12/19 17:02:12 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 13) in 67034 ms on localhost (executor driver) (1/1)
17/12/19 17:02:12 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/12/19 17:02:12 INFO DAGScheduler: ResultStage 14 (take at <unknown>:0) finished in 67.034 s
17/12/19 17:02:12 INFO DAGScheduler: Job 6 finished: take at <unknown>:0, took 67.051818 s
17/12/19 17:02:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:02:12 INFO SparkSqlParser: Parsing command: sparklyr_tmp_22503d7b55b5
17/12/19 17:02:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:02:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22503d7b55b5` AS `zzz12`
WHERE (0 = 1)
17/12/19 17:02:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:02:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22503d7b55b5`
LIMIT 10
17/12/19 17:02:12 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:02:12 INFO DAGScheduler: Got job 7 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:02:12 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:196)
17/12/19 17:02:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
17/12/19 17:02:12 INFO DAGScheduler: Missing parents: List()
17/12/19 17:02:12 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/12/19 17:02:12 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 5.8 MB, free 1709.6 MB)
17/12/19 17:02:12 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.0 MB, free 1705.6 MB)
17/12/19 17:02:12 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:56541 (size: 4.0 MB, free: 1720.1 MB)
17/12/19 17:02:12 INFO MemoryStore: Block broadcast_11_piece1 stored as bytes in memory (estimated size 1335.1 KB, free 1704.3 MB)
17/12/19 17:02:12 INFO BlockManagerInfo: Added broadcast_11_piece1 in memory on 127.0.0.1:56541 (size: 1335.1 KB, free: 1718.8 MB)
17/12/19 17:02:12 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/12/19 17:02:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/12/19 17:02:12 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/12/19 17:02:12 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5864 bytes)
17/12/19 17:02:12 INFO Executor: Running task 0.0 in stage 16.0 (TID 14)
17/12/19 17:02:12 INFO BlockManager: Found block rdd_43_0 locally
17/12/19 17:02:12 INFO CodeGenerator: Code generated in 6.212721 ms
17/12/19 17:02:12 INFO CodeGenerator: Code generated in 9.437265 ms
17/12/19 17:02:12 INFO Executor: Finished task 0.0 in stage 16.0 (TID 14). 1637 bytes result sent to driver
17/12/19 17:02:12 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:196) finished in 0.031 s
17/12/19 17:02:12 INFO DAGScheduler: Job 7 finished: collect at utils.scala:196, took 0.063529 s
17/12/19 17:02:12 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:02:12 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:02:12 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:196)
17/12/19 17:02:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
17/12/19 17:02:12 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 14) in 31 ms on localhost (executor driver) (1/1)
17/12/19 17:02:12 INFO DAGScheduler: Missing parents: List()
17/12/19 17:02:12 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/12/19 17:02:12 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 5.8 MB, free 1698.5 MB)
17/12/19 17:02:12 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/12/19 17:02:12 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.0 MB, free 1694.5 MB)
17/12/19 17:02:12 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:56541 (size: 4.0 MB, free: 1714.8 MB)
17/12/19 17:02:12 INFO MemoryStore: Block broadcast_12_piece1 stored as bytes in memory (estimated size 1335.1 KB, free 1693.2 MB)
17/12/19 17:02:12 INFO BlockManagerInfo: Added broadcast_12_piece1 in memory on 127.0.0.1:56541 (size: 1335.1 KB, free: 1713.5 MB)
17/12/19 17:02:12 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/12/19 17:02:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/12/19 17:02:12 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/12/19 17:02:12 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 15, localhost, executor driver, partition 1, PROCESS_LOCAL, 5864 bytes)
17/12/19 17:02:12 INFO Executor: Running task 0.0 in stage 18.0 (TID 15)
17/12/19 17:02:12 INFO BlockManager: Found block rdd_43_1 locally
17/12/19 17:02:12 INFO Executor: Finished task 0.0 in stage 18.0 (TID 15). 1656 bytes result sent to driver
17/12/19 17:02:12 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:196) finished in 0.016 s
17/12/19 17:02:12 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.039890 s
17/12/19 17:02:12 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 15) in 16 ms on localhost (executor driver) (1/1)
17/12/19 17:02:12 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/12/19 17:02:12 INFO CodeGenerator: Code generated in 4.8236 ms
17/12/19 17:02:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:02:12 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:02:12 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:02:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:02:12 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:02:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:02:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:02:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:02:12 INFO CodeGenerator: Code generated in 5.357122 ms
17/12/19 17:02:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:02:12 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:02:12 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:02:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:02:12 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:02:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:02:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:02:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:02:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:02:12 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:02:12 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:02:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:02:12 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:02:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:02:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:02:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:02:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:02:12 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:02:12 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:02:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:02:12 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:02:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:02:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:02:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:12:56 INFO SparkContext: Invoking stop() from shutdown hook
17/12/19 17:12:56 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/19 17:12:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/19 17:12:56 INFO MemoryStore: MemoryStore cleared
17/12/19 17:12:56 INFO BlockManager: BlockManager stopped
17/12/19 17:12:56 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/19 17:12:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/19 17:12:56 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-b83755d1-1ba2-4197-9bfd-78f6ce883f38\userFiles-d10ae8db-d26e-4786-992e-b95282b58dfb
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-b83755d1-1ba2-4197-9bfd-78f6ce883f38\userFiles-d10ae8db-d26e-4786-992e-b95282b58dfb
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 17:12:56 INFO SparkContext: Successfully stopped SparkContext
17/12/19 17:12:56 INFO ShutdownHookManager: Shutdown hook called
17/12/19 17:12:56 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-b83755d1-1ba2-4197-9bfd-78f6ce883f38
17/12/19 17:12:56 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-b83755d1-1ba2-4197-9bfd-78f6ce883f38
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-b83755d1-1ba2-4197-9bfd-78f6ce883f38
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 17:12:56 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-b83755d1-1ba2-4197-9bfd-78f6ce883f38\userFiles-d10ae8db-d26e-4786-992e-b95282b58dfb
17/12/19 17:12:56 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-b83755d1-1ba2-4197-9bfd-78f6ce883f38\userFiles-d10ae8db-d26e-4786-992e-b95282b58dfb
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-b83755d1-1ba2-4197-9bfd-78f6ce883f38\userFiles-d10ae8db-d26e-4786-992e-b95282b58dfb
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 17:13:06 INFO SparkContext: Running Spark version 2.1.0
17/12/19 17:13:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/19 17:13:06 INFO SecurityManager: Changing view acls to: conan
17/12/19 17:13:06 INFO SecurityManager: Changing modify acls to: conan
17/12/19 17:13:06 INFO SecurityManager: Changing view acls groups to: 
17/12/19 17:13:06 INFO SecurityManager: Changing modify acls groups to: 
17/12/19 17:13:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(conan); groups with view permissions: Set(); users  with modify permissions: Set(conan); groups with modify permissions: Set()
17/12/19 17:13:06 INFO Utils: Successfully started service 'sparkDriver' on port 56730.
17/12/19 17:13:06 INFO SparkEnv: Registering MapOutputTracker
17/12/19 17:13:06 INFO SparkEnv: Registering BlockManagerMaster
17/12/19 17:13:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/19 17:13:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/19 17:13:06 INFO DiskBlockManager: Created local directory at C:\Users\conan\AppData\Local\Temp\blockmgr-ab478b07-407b-4a7c-a393-4ce6d71389cf
17/12/19 17:13:06 INFO MemoryStore: MemoryStore started with capacity 2004.6 MB
17/12/19 17:13:06 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/19 17:13:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/19 17:13:07 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/19 17:13:07 INFO SparkContext: Added JAR file:/C:/Users/conan/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:56730/jars/sparklyr-2.1-2.11.jar with timestamp 1513703587026
17/12/19 17:13:07 INFO Executor: Starting executor ID driver on host localhost
17/12/19 17:13:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56751.
17/12/19 17:13:07 INFO NettyBlockTransferService: Server created on 127.0.0.1:56751
17/12/19 17:13:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/19 17:13:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 56751, None)
17/12/19 17:13:07 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:56751 with 2004.6 MB RAM, BlockManagerId(driver, 127.0.0.1, 56751, None)
17/12/19 17:13:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 56751, None)
17/12/19 17:13:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 56751, None)
17/12/19 17:13:07 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/19 17:13:07 INFO SharedState: Warehouse path is 'C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/19 17:13:07 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/19 17:13:08 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/19 17:13:08 INFO ObjectStore: ObjectStore, initialize called
17/12/19 17:13:08 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/19 17:13:08 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/19 17:13:09 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/19 17:13:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 17:13:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 17:13:11 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 17:13:11 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 17:13:11 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/19 17:13:11 INFO ObjectStore: Initialized ObjectStore
17/12/19 17:13:11 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/19 17:13:11 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/19 17:13:11 INFO HiveMetaStore: Added admin role in metastore
17/12/19 17:13:11 INFO HiveMetaStore: Added public role in metastore
17/12/19 17:13:11 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/19 17:13:11 INFO HiveMetaStore: 0: get_all_databases
17/12/19 17:13:11 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/19 17:13:12 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/19 17:13:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/19 17:13:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 17:13:12 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/Temp/e0860a21-712e-4f70-8137-b60996ff2e7b_resources
17/12/19 17:13:12 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/e0860a21-712e-4f70-8137-b60996ff2e7b
17/12/19 17:13:12 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/e0860a21-712e-4f70-8137-b60996ff2e7b
17/12/19 17:13:12 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/e0860a21-712e-4f70-8137-b60996ff2e7b/_tmp_space.db
17/12/19 17:13:12 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/19 17:13:12 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:13:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:13:12 INFO HiveMetaStore: 0: get_database: global_temp
17/12/19 17:13:12 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/19 17:13:12 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/19 17:13:12 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:13:14 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:13:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:13:14 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:13:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:13:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:13:14 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:18:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:35 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:18:35 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:18:35 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:18:35 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:18:35 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:18:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:18:35 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:18:36 INFO CodeGenerator: Code generated in 249.055952 ms
17/12/19 17:18:36 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 17:18:36 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/19 17:18:36 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/19 17:18:36 INFO DAGScheduler: Parents of final stage: List()
17/12/19 17:18:36 INFO DAGScheduler: Missing parents: List()
17/12/19 17:18:36 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/12/19 17:18:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 2004.6 MB)
17/12/19 17:18:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2004.6 MB)
17/12/19 17:18:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:56751 (size: 4.6 KB, free: 2004.6 MB)
17/12/19 17:18:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/19 17:18:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/12/19 17:18:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/19 17:18:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/19 17:18:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/19 17:18:36 INFO Executor: Fetching spark://127.0.0.1:56730/jars/sparklyr-2.1-2.11.jar with timestamp 1513703587026
17/12/19 17:18:36 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:56730 after 16 ms (0 ms spent in bootstraps)
17/12/19 17:18:36 INFO Utils: Fetching spark://127.0.0.1:56730/jars/sparklyr-2.1-2.11.jar to C:\Users\conan\AppData\Local\Temp\spark-b0a511e3-5f4e-4cc8-8d22-d13cd327c07e\userFiles-269948d3-a9e3-4c2d-8e48-29bebf0fdf63\fetchFileTemp4259050872466225985.tmp
17/12/19 17:18:36 INFO Executor: Adding file:/C:/Users/conan/AppData/Local/Temp/spark-b0a511e3-5f4e-4cc8-8d22-d13cd327c07e/userFiles-269948d3-a9e3-4c2d-8e48-29bebf0fdf63/sparklyr-2.1-2.11.jar to class loader
17/12/19 17:18:36 INFO CodeGenerator: Code generated in 14.666008 ms
17/12/19 17:18:36 INFO CodeGenerator: Code generated in 13.595189 ms
17/12/19 17:18:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/12/19 17:18:37 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.391 s
17/12/19 17:18:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 365 ms on localhost (executor driver) (1/1)
17/12/19 17:18:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/19 17:18:37 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.607016 s
17/12/19 17:18:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:37 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:18:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:37 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 17:18:37 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 17:18:37 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 17:18:37 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 17:18:37 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 17:18:37 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 17:18:37 INFO CodeGenerator: Code generated in 8.013028 ms
17/12/19 17:18:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.7 KB, free 2004.3 MB)
17/12/19 17:18:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2004.3 MB)
17/12/19 17:18:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:56751 (size: 24.0 KB, free: 2004.6 MB)
17/12/19 17:18:37 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/19 17:18:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 17:18:37 INFO CodeGenerator: Code generated in 12.716557 ms
17/12/19 17:18:37 INFO CodeGenerator: Code generated in 8.998893 ms
17/12/19 17:18:37 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 17:18:37 INFO DAGScheduler: Registering RDD 10 (sql at <unknown>:0)
17/12/19 17:18:37 INFO DAGScheduler: Registering RDD 15 (sql at <unknown>:0)
17/12/19 17:18:37 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/19 17:18:37 INFO DAGScheduler: Final stage: ResultStage 3 (sql at <unknown>:0)
17/12/19 17:18:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/12/19 17:18:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/12/19 17:18:37 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0), which has no missing parents
17/12/19 17:18:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.1 KB, free 2004.3 MB)
17/12/19 17:18:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2004.3 MB)
17/12/19 17:18:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:56751 (size: 7.3 KB, free: 2004.6 MB)
17/12/19 17:18:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/19 17:18:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0)
17/12/19 17:18:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/19 17:18:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/19 17:18:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/19 17:18:37 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpwLtPOg/spark_serialize_fe82ac6e69bf513b144f2e46c02bb1195e47181d5c9b5d12c69053d8e71f0ef8.csv, range: 0-567, partition values: [empty row]
17/12/19 17:18:37 INFO CodeGenerator: Code generated in 6.908225 ms
17/12/19 17:18:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1719 bytes result sent to driver
17/12/19 17:18:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 216 ms on localhost (executor driver) (1/1)
17/12/19 17:18:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/19 17:18:37 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.219 s
17/12/19 17:18:37 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:18:37 INFO DAGScheduler: running: Set()
17/12/19 17:18:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/12/19 17:18:37 INFO DAGScheduler: failed: Set()
17/12/19 17:18:37 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/19 17:18:37 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.9 KB, free 2004.2 MB)
17/12/19 17:18:37 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2004.2 MB)
17/12/19 17:18:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:56751 (size: 6.0 KB, free: 2004.6 MB)
17/12/19 17:18:37 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/19 17:18:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/19 17:18:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
17/12/19 17:18:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5942 bytes)
17/12/19 17:18:38 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5942 bytes)
17/12/19 17:18:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/19 17:18:38 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
17/12/19 17:18:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 17:18:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 17:18:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:18:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:18:38 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 568.0 B, free 2004.2 MB)
17/12/19 17:18:38 INFO BlockManagerInfo: Added rdd_12_0 in memory on 127.0.0.1:56751 (size: 568.0 B, free: 2004.6 MB)
17/12/19 17:18:38 INFO MemoryStore: Block rdd_12_1 stored as values in memory (estimated size 568.0 B, free 2004.2 MB)
17/12/19 17:18:38 INFO BlockManagerInfo: Added rdd_12_1 in memory on 127.0.0.1:56751 (size: 568.0 B, free: 2004.6 MB)
17/12/19 17:18:38 INFO CodeGenerator: Code generated in 4.237217 ms
17/12/19 17:18:38 INFO CodeGenerator: Code generated in 17.385726 ms
17/12/19 17:18:38 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 3064 bytes result sent to driver
17/12/19 17:18:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 3064 bytes result sent to driver
17/12/19 17:18:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 125 ms on localhost (executor driver) (1/2)
17/12/19 17:18:38 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 109 ms on localhost (executor driver) (2/2)
17/12/19 17:18:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/19 17:18:38 INFO DAGScheduler: ShuffleMapStage 2 (sql at <unknown>:0) finished in 0.125 s
17/12/19 17:18:38 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:18:38 INFO DAGScheduler: running: Set()
17/12/19 17:18:38 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/12/19 17:18:38 INFO DAGScheduler: failed: Set()
17/12/19 17:18:38 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
17/12/19 17:18:38 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 2004.2 MB)
17/12/19 17:18:38 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.2 MB)
17/12/19 17:18:38 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:56751 (size: 3.7 KB, free: 2004.6 MB)
17/12/19 17:18:38 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/19 17:18:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0)
17/12/19 17:18:38 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/19 17:18:38 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/19 17:18:38 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
17/12/19 17:18:38 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 17:18:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:18:38 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 1865 bytes result sent to driver
17/12/19 17:18:38 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 16 ms on localhost (executor driver) (1/1)
17/12/19 17:18:38 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/19 17:18:38 INFO DAGScheduler: ResultStage 3 (sql at <unknown>:0) finished in 0.016 s
17/12/19 17:18:38 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.414144 s
17/12/19 17:18:38 INFO CodeGenerator: Code generated in 5.338998 ms
17/12/19 17:18:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:38 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 50
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 51
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 57
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 58
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 59
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 60
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 61
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 62
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 63
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 64
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 65
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 66
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 67
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 68
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 69
17/12/19 17:18:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:18:38 INFO ContextCleaner: Cleaned shuffle 1
17/12/19 17:18:38 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/19 17:18:38 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:196)
17/12/19 17:18:38 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:18:38 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:196)
17/12/19 17:18:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/12/19 17:18:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/12/19 17:18:38 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
17/12/19 17:18:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.9 KB, free 2004.2 MB)
17/12/19 17:18:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2004.2 MB)
17/12/19 17:18:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:56751 (size: 6.0 KB, free: 2004.5 MB)
17/12/19 17:18:38 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/19 17:18:38 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196)
17/12/19 17:18:38 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
17/12/19 17:18:38 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5934 bytes)
17/12/19 17:18:38 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 5934 bytes)
17/12/19 17:18:38 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/19 17:18:38 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/12/19 17:18:38 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:56751 in memory (size: 7.3 KB, free: 2004.6 MB)
17/12/19 17:18:38 INFO BlockManager: Found block rdd_12_0 locally
17/12/19 17:18:38 INFO BlockManager: Found block rdd_12_1 locally
17/12/19 17:18:38 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:56751 in memory (size: 6.0 KB, free: 2004.6 MB)
17/12/19 17:18:38 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:56751 in memory (size: 3.7 KB, free: 2004.6 MB)
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 238
17/12/19 17:18:38 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 1958 bytes result sent to driver
17/12/19 17:18:38 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1958 bytes result sent to driver
17/12/19 17:18:38 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 31 ms on localhost (executor driver) (1/2)
17/12/19 17:18:38 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 31 ms on localhost (executor driver) (2/2)
17/12/19 17:18:38 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:196) finished in 0.031 s
17/12/19 17:18:38 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:18:38 INFO DAGScheduler: running: Set()
17/12/19 17:18:38 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/12/19 17:18:38 INFO DAGScheduler: failed: Set()
17/12/19 17:18:38 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196), which has no missing parents
17/12/19 17:18:38 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 2004.3 MB)
17/12/19 17:18:38 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/19 17:18:38 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.2 MB)
17/12/19 17:18:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:56751 (size: 3.7 KB, free: 2004.6 MB)
17/12/19 17:18:38 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/12/19 17:18:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196)
17/12/19 17:18:38 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/19 17:18:38 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/19 17:18:38 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
17/12/19 17:18:38 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 17:18:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:18:38 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1707 bytes result sent to driver
17/12/19 17:18:38 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:196) finished in 0.016 s
17/12/19 17:18:38 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.073805 s
17/12/19 17:18:38 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 16 ms on localhost (executor driver) (1/1)
17/12/19 17:18:38 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/19 17:18:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz13`
WHERE (0 = 1)
17/12/19 17:18:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:38 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`
FROM (SELECT `S1`, `S2`, `S3`, `S3` + 0.91651514 * RANDN() AS `V1`, `S2` + 0.93273791 * RANDN() AS `V2`, `S2` + 0.93273791 * RANDN() AS `V3`, `S2` + 0.93273791 * RANDN() AS `V4`, `S1` + 0.92195445 * RANDN() AS `V5`, `S2` + 0.93273791 * RANDN() AS `V6`, `S3` + 0.91651514 * RANDN() AS `V7`, `S2` + 0.93273791 * RANDN() AS `V8`, `S3` + 0.91651514 * RANDN() AS `V9`, `S3` + 0.91651514 * RANDN() AS `V10`
FROM `analyis_tbl`) `lbjkfbbiqk`
17/12/19 17:18:38 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:18:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz14`
WHERE (0 = 1)
17/12/19 17:18:38 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:56751 in memory (size: 3.7 KB, free: 2004.6 MB)
17/12/19 17:18:38 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:56751 in memory (size: 6.0 KB, free: 2004.6 MB)
17/12/19 17:18:38 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:56751 in memory (size: 4.6 KB, free: 2004.6 MB)
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 1
17/12/19 17:18:38 INFO ContextCleaner: Cleaned accumulator 0
17/12/19 17:18:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 17:18:38 INFO CodeGenerator: Code generated in 20.982187 ms
17/12/19 17:18:38 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 17:18:38 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/19 17:18:38 INFO DAGScheduler: Got job 3 (take at <unknown>:0) with 1 output partitions
17/12/19 17:18:38 INFO DAGScheduler: Final stage: ResultStage 8 (take at <unknown>:0)
17/12/19 17:18:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/12/19 17:18:38 INFO DAGScheduler: Missing parents: List()
17/12/19 17:18:38 INFO DAGScheduler: Submitting ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18), which has no missing parents
17/12/19 17:18:38 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 133.2 KB, free 2004.2 MB)
17/12/19 17:18:38 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 52.9 KB, free 2004.1 MB)
17/12/19 17:18:38 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:56751 (size: 52.9 KB, free: 2004.5 MB)
17/12/19 17:18:38 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/12/19 17:18:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18)
17/12/19 17:18:38 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/19 17:18:38 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5913 bytes)
17/12/19 17:18:38 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/12/19 17:18:38 INFO BlockManager: Found block rdd_12_0 locally
17/12/19 17:18:39 INFO CodeGenerator: Code generated in 17.0527 ms
17/12/19 17:18:39 INFO CodeGenerator: Code generated in 13.092251 ms
17/12/19 17:18:39 INFO MemoryStore: Block rdd_31_0 stored as values in memory (estimated size 1600.0 B, free 2004.1 MB)
17/12/19 17:18:39 INFO BlockManagerInfo: Added rdd_31_0 in memory on 127.0.0.1:56751 (size: 1600.0 B, free: 2004.5 MB)
17/12/19 17:18:39 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 3082 bytes result sent to driver
17/12/19 17:18:39 INFO DAGScheduler: ResultStage 8 (take at <unknown>:0) finished in 0.750 s
17/12/19 17:18:39 INFO DAGScheduler: Job 3 finished: take at <unknown>:0, took 0.771930 s
17/12/19 17:18:39 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 750 ms on localhost (executor driver) (1/1)
17/12/19 17:18:39 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/19 17:18:39 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 17:18:39 INFO DAGScheduler: Got job 4 (take at <unknown>:0) with 1 output partitions
17/12/19 17:18:39 INFO DAGScheduler: Final stage: ResultStage 10 (take at <unknown>:0)
17/12/19 17:18:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
17/12/19 17:18:39 INFO DAGScheduler: Missing parents: List()
17/12/19 17:18:39 INFO DAGScheduler: Submitting ResultStage 10 (WorkerRDD[31] at RDD at rdd.scala:18), which has no missing parents
17/12/19 17:18:39 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 133.2 KB, free 2004.0 MB)
17/12/19 17:18:39 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 52.9 KB, free 2003.9 MB)
17/12/19 17:18:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:56751 (size: 52.9 KB, free: 2004.5 MB)
17/12/19 17:18:39 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/12/19 17:18:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (WorkerRDD[31] at RDD at rdd.scala:18)
17/12/19 17:18:39 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/12/19 17:18:39 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 5913 bytes)
17/12/19 17:18:39 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
17/12/19 17:18:39 INFO BlockManager: Found block rdd_12_1 locally
17/12/19 17:18:40 INFO MemoryStore: Block rdd_31_1 stored as values in memory (estimated size 1600.0 B, free 2003.9 MB)
17/12/19 17:18:40 INFO BlockManagerInfo: Added rdd_31_1 in memory on 127.0.0.1:56751 (size: 1600.0 B, free: 2004.5 MB)
17/12/19 17:18:40 WARN Executor: 1 block locks were not released by TID = 9:
[rdd_31_1]
17/12/19 17:18:40 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 3082 bytes result sent to driver
17/12/19 17:18:40 INFO DAGScheduler: ResultStage 10 (take at <unknown>:0) finished in 0.678 s
17/12/19 17:18:40 INFO DAGScheduler: Job 4 finished: take at <unknown>:0, took 0.692012 s
17/12/19 17:18:40 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 678 ms on localhost (executor driver) (1/1)
17/12/19 17:18:40 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/19 17:18:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:40 INFO SparkSqlParser: Parsing command: sparklyr_tmp_225029433dff
17/12/19 17:18:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_225029433dff` AS `zzz15`
WHERE (0 = 1)
17/12/19 17:18:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_225029433dff`
17/12/19 17:18:40 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:18:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz16`
WHERE (0 = 1)
17/12/19 17:18:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:40 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.054) AS `V1`, (`V2` < 0.0055) AS `V2`, (`V3` < 0.0045) AS `V3`, (`V4` < 0.009) AS `V4`, (`V5` < 0.054) AS `V5`, (`V6` < 0.15) AS `V6`, (`V7` < 0.1) AS `V7`, (`V8` < 0.0035) AS `V8`, (`V9` < 3e-04) AS `V9`, (`V10` < 0.0055) AS `V10`
FROM `analyis_tbl`
17/12/19 17:18:40 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:18:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz17`
WHERE (0 = 1)
17/12/19 17:18:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 17:18:40 INFO CodeGenerator: Code generated in 19.931756 ms
17/12/19 17:18:40 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:18:40 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 2 output partitions
17/12/19 17:18:40 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:196)
17/12/19 17:18:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/12/19 17:18:40 INFO DAGScheduler: Missing parents: List()
17/12/19 17:18:40 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[38] at collect at utils.scala:196), which has no missing parents
17/12/19 17:18:40 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 146.0 KB, free 2003.8 MB)
17/12/19 17:18:40 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 57.3 KB, free 2003.7 MB)
17/12/19 17:18:40 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:56751 (size: 57.3 KB, free: 2004.4 MB)
17/12/19 17:18:40 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/12/19 17:18:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[38] at collect at utils.scala:196)
17/12/19 17:18:40 INFO TaskSchedulerImpl: Adding task set 12.0 with 2 tasks
17/12/19 17:18:40 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5945 bytes)
17/12/19 17:18:40 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 11, localhost, executor driver, partition 1, PROCESS_LOCAL, 5945 bytes)
17/12/19 17:18:40 INFO Executor: Running task 1.0 in stage 12.0 (TID 11)
17/12/19 17:18:40 INFO Executor: Running task 0.0 in stage 12.0 (TID 10)
17/12/19 17:18:40 INFO BlockManager: Found block rdd_31_1 locally
17/12/19 17:18:40 INFO BlockManager: Found block rdd_31_0 locally
17/12/19 17:18:40 INFO CodeGenerator: Code generated in 26.091238 ms
17/12/19 17:18:40 INFO CodeGenerator: Code generated in 66.70236 ms
17/12/19 17:18:40 INFO Executor: Finished task 0.0 in stage 12.0 (TID 10). 1710 bytes result sent to driver
17/12/19 17:18:40 INFO Executor: Finished task 1.0 in stage 12.0 (TID 11). 1618 bytes result sent to driver
17/12/19 17:18:40 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 10) in 129 ms on localhost (executor driver) (1/2)
17/12/19 17:18:40 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 11) in 129 ms on localhost (executor driver) (2/2)
17/12/19 17:18:40 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:196) finished in 0.129 s
17/12/19 17:18:40 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/12/19 17:18:40 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.158069 s
17/12/19 17:18:40 INFO CodeGenerator: Code generated in 8.60583 ms
17/12/19 17:18:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 17:18:41 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 17:18:41 INFO DAGScheduler: Got job 6 (take at <unknown>:0) with 1 output partitions
17/12/19 17:18:41 INFO DAGScheduler: Final stage: ResultStage 14 (take at <unknown>:0)
17/12/19 17:18:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/12/19 17:18:41 INFO DAGScheduler: Missing parents: List()
17/12/19 17:18:41 INFO DAGScheduler: Submitting ResultStage 14 (WorkerRDD[43] at RDD at rdd.scala:18), which has no missing parents
17/12/19 17:18:41 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 258.3 KB, free 2003.5 MB)
17/12/19 17:18:41 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 100.9 KB, free 2003.4 MB)
17/12/19 17:18:41 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:56751 (size: 100.9 KB, free: 2004.3 MB)
17/12/19 17:18:41 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/12/19 17:18:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (WorkerRDD[43] at RDD at rdd.scala:18)
17/12/19 17:18:41 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/12/19 17:18:41 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 5913 bytes)
17/12/19 17:18:41 INFO Executor: Running task 0.0 in stage 14.0 (TID 12)
17/12/19 17:18:41 INFO BlockManager: Found block rdd_31_0 locally
17/12/19 17:18:41 INFO MemoryStore: Block rdd_43_0 stored as values in memory (estimated size 80.0 B, free 2003.4 MB)
17/12/19 17:18:41 INFO BlockManagerInfo: Added rdd_43_0 in memory on 127.0.0.1:56751 (size: 80.0 B, free: 2004.3 MB)
17/12/19 17:18:41 INFO Executor: Finished task 0.0 in stage 14.0 (TID 12). 2479 bytes result sent to driver
17/12/19 17:18:41 INFO DAGScheduler: ResultStage 14 (take at <unknown>:0) finished in 0.767 s
17/12/19 17:18:41 INFO DAGScheduler: Job 6 finished: take at <unknown>:0, took 0.777398 s
17/12/19 17:18:41 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 12) in 767 ms on localhost (executor driver) (1/1)
17/12/19 17:18:41 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/12/19 17:18:41 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 17:18:41 INFO DAGScheduler: Got job 7 (take at <unknown>:0) with 1 output partitions
17/12/19 17:18:41 INFO DAGScheduler: Final stage: ResultStage 16 (take at <unknown>:0)
17/12/19 17:18:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
17/12/19 17:18:41 INFO DAGScheduler: Missing parents: List()
17/12/19 17:18:41 INFO DAGScheduler: Submitting ResultStage 16 (WorkerRDD[43] at RDD at rdd.scala:18), which has no missing parents
17/12/19 17:18:41 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 258.3 KB, free 2003.1 MB)
17/12/19 17:18:41 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 100.9 KB, free 2003.0 MB)
17/12/19 17:18:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:56751 (size: 100.9 KB, free: 2004.2 MB)
17/12/19 17:18:41 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/12/19 17:18:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (WorkerRDD[43] at RDD at rdd.scala:18)
17/12/19 17:18:41 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/12/19 17:18:41 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 5913 bytes)
17/12/19 17:18:41 INFO Executor: Running task 0.0 in stage 16.0 (TID 13)
17/12/19 17:18:41 INFO BlockManager: Found block rdd_31_1 locally
17/12/19 17:18:42 INFO MemoryStore: Block rdd_43_1 stored as values in memory (estimated size 80.0 B, free 2003.0 MB)
17/12/19 17:18:42 INFO BlockManagerInfo: Added rdd_43_1 in memory on 127.0.0.1:56751 (size: 80.0 B, free: 2004.2 MB)
17/12/19 17:18:42 INFO Executor: Finished task 0.0 in stage 16.0 (TID 13). 2577 bytes result sent to driver
17/12/19 17:18:42 INFO DAGScheduler: ResultStage 16 (take at <unknown>:0) finished in 0.691 s
17/12/19 17:18:42 INFO DAGScheduler: Job 7 finished: take at <unknown>:0, took 0.697574 s
17/12/19 17:18:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:42 INFO SparkSqlParser: Parsing command: sparklyr_tmp_22501bffb5f
17/12/19 17:18:42 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 13) in 691 ms on localhost (executor driver) (1/1)
17/12/19 17:18:42 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/12/19 17:18:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22501bffb5f` AS `zzz18`
WHERE (0 = 1)
17/12/19 17:18:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22501bffb5f`
LIMIT 10
17/12/19 17:18:42 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:18:42 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:18:42 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:196)
17/12/19 17:18:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
17/12/19 17:18:42 INFO DAGScheduler: Missing parents: List()
17/12/19 17:18:42 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/12/19 17:18:42 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 259.3 KB, free 2002.8 MB)
17/12/19 17:18:42 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 101.7 KB, free 2002.7 MB)
17/12/19 17:18:42 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:56751 (size: 101.7 KB, free: 2004.1 MB)
17/12/19 17:18:42 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/12/19 17:18:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/12/19 17:18:42 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/12/19 17:18:42 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5860 bytes)
17/12/19 17:18:42 INFO Executor: Running task 0.0 in stage 18.0 (TID 14)
17/12/19 17:18:42 INFO BlockManager: Found block rdd_43_0 locally
17/12/19 17:18:42 INFO CodeGenerator: Code generated in 4.630278 ms
17/12/19 17:18:42 INFO CodeGenerator: Code generated in 9.574704 ms
17/12/19 17:18:42 INFO Executor: Finished task 0.0 in stage 18.0 (TID 14). 1637 bytes result sent to driver
17/12/19 17:18:42 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:196) finished in 0.015 s
17/12/19 17:18:42 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.033288 s
17/12/19 17:18:42 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:18:42 INFO DAGScheduler: Got job 9 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:18:42 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:196)
17/12/19 17:18:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
17/12/19 17:18:42 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 14) in 15 ms on localhost (executor driver) (1/1)
17/12/19 17:18:42 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/12/19 17:18:42 INFO DAGScheduler: Missing parents: List()
17/12/19 17:18:42 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/12/19 17:18:42 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 259.3 KB, free 2002.4 MB)
17/12/19 17:18:42 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 101.7 KB, free 2002.3 MB)
17/12/19 17:18:42 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:56751 (size: 101.7 KB, free: 2004.0 MB)
17/12/19 17:18:42 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/12/19 17:18:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/12/19 17:18:42 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
17/12/19 17:18:42 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 15, localhost, executor driver, partition 1, PROCESS_LOCAL, 5860 bytes)
17/12/19 17:18:42 INFO Executor: Running task 0.0 in stage 20.0 (TID 15)
17/12/19 17:18:42 INFO BlockManager: Found block rdd_43_1 locally
17/12/19 17:18:42 INFO Executor: Finished task 0.0 in stage 20.0 (TID 15). 1735 bytes result sent to driver
17/12/19 17:18:42 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 15) in 47 ms on localhost (executor driver) (1/1)
17/12/19 17:18:42 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/12/19 17:18:42 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:196) finished in 0.047 s
17/12/19 17:18:42 INFO DAGScheduler: Job 9 finished: collect at utils.scala:196, took 0.054275 s
17/12/19 17:18:42 INFO CodeGenerator: Code generated in 6.072261 ms
17/12/19 17:18:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:18:42 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:18:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:18:42 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:18:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:18:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:18:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:18:42 INFO CodeGenerator: Code generated in 7.559553 ms
17/12/19 17:18:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:18:42 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:18:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:18:42 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:18:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:18:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:18:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:18:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:18:42 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:18:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:18:42 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:18:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:18:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:18:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:18:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:18:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:18:42 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:18:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:18:42 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:18:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:18:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:18:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:19:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:17 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:19:17 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:19:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:19:17 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:19:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:19:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:19:17 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:19:17 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 17:19:17 INFO DAGScheduler: Got job 10 (collect at utils.scala:58) with 1 output partitions
17/12/19 17:19:17 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:58)
17/12/19 17:19:17 INFO DAGScheduler: Parents of final stage: List()
17/12/19 17:19:17 INFO DAGScheduler: Missing parents: List()
17/12/19 17:19:17 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[57] at map at utils.scala:55), which has no missing parents
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 8.7 KB, free 2002.3 MB)
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2002.3 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:56751 (size: 4.6 KB, free: 2004.0 MB)
17/12/19 17:19:17 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[57] at map at utils.scala:55)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
17/12/19 17:19:17 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 6504 bytes)
17/12/19 17:19:17 INFO Executor: Running task 0.0 in stage 21.0 (TID 16)
17/12/19 17:19:17 INFO Executor: Finished task 0.0 in stage 21.0 (TID 16). 965 bytes result sent to driver
17/12/19 17:19:17 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 16) in 0 ms on localhost (executor driver) (1/1)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/12/19 17:19:17 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:58) finished in 0.000 s
17/12/19 17:19:17 INFO DAGScheduler: Job 10 finished: collect at utils.scala:58, took 0.011684 s
17/12/19 17:19:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:17 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:19:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:17 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 17:19:17 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 17:19:17 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 17:19:17 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 17:19:17 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 17:19:17 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 293.7 KB, free 2002.0 MB)
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2002.0 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:56751 (size: 24.0 KB, free: 2004.0 MB)
17/12/19 17:19:17 INFO SparkContext: Created broadcast 15 from sql at <unknown>:0
17/12/19 17:19:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 17:19:17 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 17:19:17 INFO DAGScheduler: Registering RDD 61 (sql at <unknown>:0)
17/12/19 17:19:17 INFO DAGScheduler: Registering RDD 66 (sql at <unknown>:0)
17/12/19 17:19:17 INFO DAGScheduler: Got job 11 (sql at <unknown>:0) with 1 output partitions
17/12/19 17:19:17 INFO DAGScheduler: Final stage: ResultStage 24 (sql at <unknown>:0)
17/12/19 17:19:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
17/12/19 17:19:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
17/12/19 17:19:17 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[61] at sql at <unknown>:0), which has no missing parents
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 12.1 KB, free 2002.0 MB)
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2002.0 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:56751 (size: 7.3 KB, free: 2004.0 MB)
17/12/19 17:19:17 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[61] at sql at <unknown>:0)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/12/19 17:19:17 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6677 bytes)
17/12/19 17:19:17 INFO Executor: Running task 0.0 in stage 22.0 (TID 17)
17/12/19 17:19:17 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpwLtPOg/spark_serialize_5b2e4c9736e1fa732dd5f414f9f9a6d325d8e8f4e4d64efec813d4a076fcd83d.csv, range: 0-575, partition values: [empty row]
17/12/19 17:19:17 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:56751 in memory (size: 52.9 KB, free: 2004.0 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:56751 in memory (size: 101.7 KB, free: 2004.1 MB)
17/12/19 17:19:17 INFO ContextCleaner: Cleaned accumulator 738
17/12/19 17:19:17 INFO ContextCleaner: Cleaned accumulator 739
17/12/19 17:19:17 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:56751 in memory (size: 4.6 KB, free: 2004.1 MB)
17/12/19 17:19:17 INFO ContextCleaner: Cleaned accumulator 788
17/12/19 17:19:17 INFO ContextCleaner: Cleaned accumulator 789
17/12/19 17:19:17 INFO ContextCleaner: Cleaned accumulator 795
17/12/19 17:19:17 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:56751 in memory (size: 52.9 KB, free: 2004.2 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:56751 in memory (size: 57.3 KB, free: 2004.2 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:56751 in memory (size: 100.9 KB, free: 2004.3 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:56751 in memory (size: 100.9 KB, free: 2004.4 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:56751 in memory (size: 101.7 KB, free: 2004.5 MB)
17/12/19 17:19:17 INFO Executor: Finished task 0.0 in stage 22.0 (TID 17). 1626 bytes result sent to driver
17/12/19 17:19:17 INFO DAGScheduler: ShuffleMapStage 22 (sql at <unknown>:0) finished in 0.078 s
17/12/19 17:19:17 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:19:17 INFO DAGScheduler: running: Set()
17/12/19 17:19:17 INFO DAGScheduler: waiting: Set(ResultStage 24, ShuffleMapStage 23)
17/12/19 17:19:17 INFO DAGScheduler: failed: Set()
17/12/19 17:19:17 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 17) in 78 ms on localhost (executor driver) (1/1)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/12/19 17:19:17 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[66] at sql at <unknown>:0), which has no missing parents
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 11.9 KB, free 2003.9 MB)
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2003.9 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:56751 (size: 6.0 KB, free: 2004.5 MB)
17/12/19 17:19:17 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[66] at sql at <unknown>:0)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Adding task set 23.0 with 2 tasks
17/12/19 17:19:17 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 18, localhost, executor driver, partition 0, ANY, 5943 bytes)
17/12/19 17:19:17 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 19, localhost, executor driver, partition 1, ANY, 5943 bytes)
17/12/19 17:19:17 INFO Executor: Running task 0.0 in stage 23.0 (TID 18)
17/12/19 17:19:17 INFO Executor: Running task 1.0 in stage 23.0 (TID 19)
17/12/19 17:19:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 17:19:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:19:17 INFO MemoryStore: Block rdd_63_1 stored as values in memory (estimated size 568.0 B, free 2003.9 MB)
17/12/19 17:19:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 17:19:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:19:17 INFO MemoryStore: Block rdd_63_0 stored as values in memory (estimated size 568.0 B, free 2003.9 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Added rdd_63_1 in memory on 127.0.0.1:56751 (size: 568.0 B, free: 2004.5 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Added rdd_63_0 in memory on 127.0.0.1:56751 (size: 568.0 B, free: 2004.5 MB)
17/12/19 17:19:17 INFO Executor: Finished task 0.0 in stage 23.0 (TID 18). 3064 bytes result sent to driver
17/12/19 17:19:17 INFO Executor: Finished task 1.0 in stage 23.0 (TID 19). 2985 bytes result sent to driver
17/12/19 17:19:17 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 18) in 16 ms on localhost (executor driver) (1/2)
17/12/19 17:19:17 INFO DAGScheduler: ShuffleMapStage 23 (sql at <unknown>:0) finished in 0.016 s
17/12/19 17:19:17 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:19:17 INFO DAGScheduler: running: Set()
17/12/19 17:19:17 INFO DAGScheduler: waiting: Set(ResultStage 24)
17/12/19 17:19:17 INFO DAGScheduler: failed: Set()
17/12/19 17:19:17 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[69] at sql at <unknown>:0), which has no missing parents
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 7.0 KB, free 2003.9 MB)
17/12/19 17:19:17 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 19) in 16 ms on localhost (executor driver) (2/2)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.9 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:56751 (size: 3.7 KB, free: 2004.5 MB)
17/12/19 17:19:17 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[69] at sql at <unknown>:0)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
17/12/19 17:19:17 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 20, localhost, executor driver, partition 0, ANY, 5954 bytes)
17/12/19 17:19:17 INFO Executor: Running task 0.0 in stage 24.0 (TID 20)
17/12/19 17:19:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 17:19:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:19:17 INFO Executor: Finished task 0.0 in stage 24.0 (TID 20). 1707 bytes result sent to driver
17/12/19 17:19:17 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 20) in 0 ms on localhost (executor driver) (1/1)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
17/12/19 17:19:17 INFO DAGScheduler: ResultStage 24 (sql at <unknown>:0) finished in 0.000 s
17/12/19 17:19:17 INFO DAGScheduler: Job 11 finished: sql at <unknown>:0, took 0.133049 s
17/12/19 17:19:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:17 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 17:19:17 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:19:17 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 145 bytes
17/12/19 17:19:17 INFO DAGScheduler: Registering RDD 73 (collect at utils.scala:196)
17/12/19 17:19:17 INFO DAGScheduler: Got job 12 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:19:17 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:196)
17/12/19 17:19:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
17/12/19 17:19:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
17/12/19 17:19:17 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[73] at collect at utils.scala:196), which has no missing parents
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 11.9 KB, free 2003.9 MB)
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2003.9 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:56751 (size: 6.0 KB, free: 2004.5 MB)
17/12/19 17:19:17 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[73] at collect at utils.scala:196)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Adding task set 26.0 with 2 tasks
17/12/19 17:19:17 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/19 17:19:17 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 22, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/19 17:19:17 INFO Executor: Running task 1.0 in stage 26.0 (TID 22)
17/12/19 17:19:17 INFO Executor: Running task 0.0 in stage 26.0 (TID 21)
17/12/19 17:19:17 INFO BlockManager: Found block rdd_63_0 locally
17/12/19 17:19:17 INFO BlockManager: Found block rdd_63_1 locally
17/12/19 17:19:17 INFO Executor: Finished task 0.0 in stage 26.0 (TID 21). 1879 bytes result sent to driver
17/12/19 17:19:17 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 21) in 3 ms on localhost (executor driver) (1/2)
17/12/19 17:19:17 INFO Executor: Finished task 1.0 in stage 26.0 (TID 22). 2037 bytes result sent to driver
17/12/19 17:19:17 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 22) in 19 ms on localhost (executor driver) (2/2)
17/12/19 17:19:17 INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:196) finished in 0.020 s
17/12/19 17:19:17 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:19:17 INFO DAGScheduler: running: Set()
17/12/19 17:19:17 INFO DAGScheduler: waiting: Set(ResultStage 27)
17/12/19 17:19:17 INFO DAGScheduler: failed: Set()
17/12/19 17:19:17 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[76] at collect at utils.scala:196), which has no missing parents
17/12/19 17:19:17 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.0 KB, free 2003.9 MB)
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.9 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:56751 (size: 3.7 KB, free: 2004.5 MB)
17/12/19 17:19:17 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[76] at collect at utils.scala:196)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
17/12/19 17:19:17 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 23, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/19 17:19:17 INFO Executor: Running task 0.0 in stage 27.0 (TID 23)
17/12/19 17:19:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 17:19:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:19:17 INFO Executor: Finished task 0.0 in stage 27.0 (TID 23). 1707 bytes result sent to driver
17/12/19 17:19:17 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 23) in 0 ms on localhost (executor driver) (1/1)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
17/12/19 17:19:17 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:196) finished in 0.000 s
17/12/19 17:19:17 INFO DAGScheduler: Job 12 finished: collect at utils.scala:196, took 0.039165 s
17/12/19 17:19:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz19`
WHERE (0 = 1)
17/12/19 17:19:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 17:19:17 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:19:17 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 145 bytes
17/12/19 17:19:17 INFO DAGScheduler: Got job 13 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:19:17 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:196)
17/12/19 17:19:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
17/12/19 17:19:17 INFO DAGScheduler: Missing parents: List()
17/12/19 17:19:17 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[78] at collect at utils.scala:196), which has no missing parents
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 8.3 KB, free 2003.9 MB)
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.4 KB, free 2003.9 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:56751 (size: 4.4 KB, free: 2004.5 MB)
17/12/19 17:19:17 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[78] at collect at utils.scala:196)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
17/12/19 17:19:17 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:19:17 INFO Executor: Running task 0.0 in stage 29.0 (TID 24)
17/12/19 17:19:17 INFO BlockManager: Found block rdd_63_0 locally
17/12/19 17:19:17 INFO Executor: Finished task 0.0 in stage 29.0 (TID 24). 1298 bytes result sent to driver
17/12/19 17:19:17 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 24) in 16 ms on localhost (executor driver) (1/1)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
17/12/19 17:19:17 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:196) finished in 0.016 s
17/12/19 17:19:17 INFO DAGScheduler: Job 13 finished: collect at utils.scala:196, took 0.016590 s
17/12/19 17:19:17 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:19:17 INFO DAGScheduler: Got job 14 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:19:17 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:196)
17/12/19 17:19:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
17/12/19 17:19:17 INFO DAGScheduler: Missing parents: List()
17/12/19 17:19:17 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[78] at collect at utils.scala:196), which has no missing parents
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 8.3 KB, free 2003.9 MB)
17/12/19 17:19:17 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.4 KB, free 2003.9 MB)
17/12/19 17:19:17 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:56751 (size: 4.4 KB, free: 2004.5 MB)
17/12/19 17:19:17 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[78] at collect at utils.scala:196)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
17/12/19 17:19:17 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 25, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:19:17 INFO Executor: Running task 0.0 in stage 31.0 (TID 25)
17/12/19 17:19:17 INFO BlockManager: Found block rdd_63_1 locally
17/12/19 17:19:17 INFO Executor: Finished task 0.0 in stage 31.0 (TID 25). 1298 bytes result sent to driver
17/12/19 17:19:17 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 25) in 16 ms on localhost (executor driver) (1/1)
17/12/19 17:19:17 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
17/12/19 17:19:17 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:196) finished in 0.016 s
17/12/19 17:19:17 INFO DAGScheduler: Job 14 finished: collect at utils.scala:196, took 0.011930 s
17/12/19 17:19:17 INFO CodeGenerator: Code generated in 6.27842 ms
17/12/19 17:19:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:17 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`
FROM (SELECT `S1`, `S2`, `S3`, `S3` + 0.91651514 * RANDN() AS `V1`, `S2` + 0.93273791 * RANDN() AS `V2`, `S2` + 0.93273791 * RANDN() AS `V3`, `S2` + 0.93273791 * RANDN() AS `V4`, `S1` + 0.92195445 * RANDN() AS `V5`, `S2` + 0.93273791 * RANDN() AS `V6`, `S3` + 0.91651514 * RANDN() AS `V7`, `S2` + 0.93273791 * RANDN() AS `V8`, `S3` + 0.91651514 * RANDN() AS `V9`, `S3` + 0.91651514 * RANDN() AS `V10`
FROM `analyis_tbl`) `dicqwckadq`
17/12/19 17:19:17 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:19:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz20`
WHERE (0 = 1)
17/12/19 17:19:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 17:19:18 INFO CodeGenerator: Code generated in 12.113937 ms
17/12/19 17:19:18 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:19:18 INFO DAGScheduler: Got job 15 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:19:18 INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:196)
17/12/19 17:19:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
17/12/19 17:19:18 INFO DAGScheduler: Missing parents: List()
17/12/19 17:19:18 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[82] at collect at utils.scala:196), which has no missing parents
17/12/19 17:19:18 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 17.3 KB, free 2003.9 MB)
17/12/19 17:19:18 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2003.9 MB)
17/12/19 17:19:18 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:56751 (size: 7.0 KB, free: 2004.5 MB)
17/12/19 17:19:18 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[82] at collect at utils.scala:196)
17/12/19 17:19:18 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
17/12/19 17:19:18 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:19:18 INFO Executor: Running task 0.0 in stage 33.0 (TID 26)
17/12/19 17:19:18 INFO BlockManager: Found block rdd_63_0 locally
17/12/19 17:19:18 INFO Executor: Finished task 0.0 in stage 33.0 (TID 26). 1840 bytes result sent to driver
17/12/19 17:19:18 INFO DAGScheduler: ResultStage 33 (collect at utils.scala:196) finished in 0.009 s
17/12/19 17:19:18 INFO DAGScheduler: Job 15 finished: collect at utils.scala:196, took 0.018859 s
17/12/19 17:19:18 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 26) in 8 ms on localhost (executor driver) (1/1)
17/12/19 17:19:18 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
17/12/19 17:19:18 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:19:18 INFO DAGScheduler: Got job 16 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:19:18 INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:196)
17/12/19 17:19:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
17/12/19 17:19:18 INFO DAGScheduler: Missing parents: List()
17/12/19 17:19:18 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[82] at collect at utils.scala:196), which has no missing parents
17/12/19 17:19:18 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 17.3 KB, free 2003.8 MB)
17/12/19 17:19:18 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2003.8 MB)
17/12/19 17:19:18 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:56751 (size: 7.0 KB, free: 2004.5 MB)
17/12/19 17:19:18 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[82] at collect at utils.scala:196)
17/12/19 17:19:18 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
17/12/19 17:19:18 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 27, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:19:18 INFO Executor: Running task 0.0 in stage 35.0 (TID 27)
17/12/19 17:19:18 INFO BlockManager: Found block rdd_63_1 locally
17/12/19 17:19:18 INFO Executor: Finished task 0.0 in stage 35.0 (TID 27). 1842 bytes result sent to driver
17/12/19 17:19:18 INFO DAGScheduler: ResultStage 35 (collect at utils.scala:196) finished in 0.006 s
17/12/19 17:19:18 INFO DAGScheduler: Job 16 finished: collect at utils.scala:196, took 0.011514 s
17/12/19 17:19:18 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 27) in 6 ms on localhost (executor driver) (1/1)
17/12/19 17:19:18 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
17/12/19 17:19:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 17:19:18 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 17:19:18 INFO DAGScheduler: Got job 17 (take at <unknown>:0) with 1 output partitions
17/12/19 17:19:18 INFO DAGScheduler: Final stage: ResultStage 37 (take at <unknown>:0)
17/12/19 17:19:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
17/12/19 17:19:18 INFO DAGScheduler: Missing parents: List()
17/12/19 17:19:18 INFO DAGScheduler: Submitting ResultStage 37 (WorkerRDD[87] at RDD at rdd.scala:18), which has no missing parents
17/12/19 17:19:18 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 130.2 KB, free 2003.7 MB)
17/12/19 17:19:18 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 51.1 KB, free 2003.7 MB)
17/12/19 17:19:18 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:56751 (size: 51.1 KB, free: 2004.4 MB)
17/12/19 17:19:18 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (WorkerRDD[87] at RDD at rdd.scala:18)
17/12/19 17:19:18 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
17/12/19 17:19:18 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 17:19:18 INFO Executor: Running task 0.0 in stage 37.0 (TID 28)
17/12/19 17:19:18 INFO BlockManager: Found block rdd_63_0 locally
17/12/19 17:19:18 INFO MemoryStore: Block rdd_87_0 stored as values in memory (estimated size 1600.0 B, free 2003.6 MB)
17/12/19 17:19:18 INFO BlockManagerInfo: Added rdd_87_0 in memory on 127.0.0.1:56751 (size: 1600.0 B, free: 2004.4 MB)
17/12/19 17:19:18 INFO Executor: Finished task 0.0 in stage 37.0 (TID 28). 3169 bytes result sent to driver
17/12/19 17:19:18 INFO DAGScheduler: ResultStage 37 (take at <unknown>:0) finished in 0.655 s
17/12/19 17:19:18 INFO DAGScheduler: Job 17 finished: take at <unknown>:0, took 0.665514 s
17/12/19 17:19:18 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 28) in 655 ms on localhost (executor driver) (1/1)
17/12/19 17:19:18 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
17/12/19 17:19:18 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 17:19:18 INFO DAGScheduler: Got job 18 (take at <unknown>:0) with 1 output partitions
17/12/19 17:19:18 INFO DAGScheduler: Final stage: ResultStage 39 (take at <unknown>:0)
17/12/19 17:19:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
17/12/19 17:19:18 INFO DAGScheduler: Missing parents: List()
17/12/19 17:19:18 INFO DAGScheduler: Submitting ResultStage 39 (WorkerRDD[87] at RDD at rdd.scala:18), which has no missing parents
17/12/19 17:19:18 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 130.2 KB, free 2003.5 MB)
17/12/19 17:19:18 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 51.1 KB, free 2003.5 MB)
17/12/19 17:19:18 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:56751 (size: 51.1 KB, free: 2004.4 MB)
17/12/19 17:19:18 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (WorkerRDD[87] at RDD at rdd.scala:18)
17/12/19 17:19:18 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
17/12/19 17:19:18 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 17:19:18 INFO Executor: Running task 0.0 in stage 39.0 (TID 29)
17/12/19 17:19:18 INFO BlockManager: Found block rdd_63_1 locally
17/12/19 17:19:19 INFO MemoryStore: Block rdd_87_1 stored as values in memory (estimated size 1600.0 B, free 2003.5 MB)
17/12/19 17:19:19 INFO BlockManagerInfo: Added rdd_87_1 in memory on 127.0.0.1:56751 (size: 1600.0 B, free: 2004.4 MB)
17/12/19 17:19:19 WARN Executor: 1 block locks were not released by TID = 29:
[rdd_87_1]
17/12/19 17:19:19 INFO Executor: Finished task 0.0 in stage 39.0 (TID 29). 3003 bytes result sent to driver
17/12/19 17:19:19 INFO DAGScheduler: ResultStage 39 (take at <unknown>:0) finished in 0.706 s
17/12/19 17:19:19 INFO DAGScheduler: Job 18 finished: take at <unknown>:0, took 0.720563 s
17/12/19 17:19:19 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 29) in 706 ms on localhost (executor driver) (1/1)
17/12/19 17:19:19 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
17/12/19 17:19:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:19 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2250389e1d30
17/12/19 17:19:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2250389e1d30` AS `zzz21`
WHERE (0 = 1)
17/12/19 17:19:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2250389e1d30`
17/12/19 17:19:19 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:19:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz22`
WHERE (0 = 1)
17/12/19 17:19:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 17:19:19 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:19:19 INFO DAGScheduler: Got job 19 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:19:19 INFO DAGScheduler: Final stage: ResultStage 41 (collect at utils.scala:196)
17/12/19 17:19:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
17/12/19 17:19:19 INFO DAGScheduler: Missing parents: List()
17/12/19 17:19:19 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[92] at collect at utils.scala:196), which has no missing parents
17/12/19 17:19:19 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 136.3 KB, free 2003.3 MB)
17/12/19 17:19:19 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 53.5 KB, free 2003.3 MB)
17/12/19 17:19:19 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:56751 (size: 53.5 KB, free: 2004.3 MB)
17/12/19 17:19:19 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[92] at collect at utils.scala:196)
17/12/19 17:19:19 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
17/12/19 17:19:19 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:19:19 INFO Executor: Running task 0.0 in stage 41.0 (TID 30)
17/12/19 17:19:19 INFO BlockManager: Found block rdd_87_0 locally
17/12/19 17:19:19 INFO Executor: Finished task 0.0 in stage 41.0 (TID 30). 1736 bytes result sent to driver
17/12/19 17:19:19 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 30) in 16 ms on localhost (executor driver) (1/1)
17/12/19 17:19:19 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
17/12/19 17:19:19 INFO DAGScheduler: ResultStage 41 (collect at utils.scala:196) finished in 0.016 s
17/12/19 17:19:19 INFO DAGScheduler: Job 19 finished: collect at utils.scala:196, took 0.017961 s
17/12/19 17:19:19 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:19:19 INFO DAGScheduler: Got job 20 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:19:19 INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:196)
17/12/19 17:19:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
17/12/19 17:19:19 INFO DAGScheduler: Missing parents: List()
17/12/19 17:19:19 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[92] at collect at utils.scala:196), which has no missing parents
17/12/19 17:19:19 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 136.3 KB, free 2003.2 MB)
17/12/19 17:19:19 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 53.5 KB, free 2003.1 MB)
17/12/19 17:19:19 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:56751 (size: 53.5 KB, free: 2004.3 MB)
17/12/19 17:19:19 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[92] at collect at utils.scala:196)
17/12/19 17:19:19 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
17/12/19 17:19:19 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:19:19 INFO Executor: Running task 0.0 in stage 43.0 (TID 31)
17/12/19 17:19:19 INFO BlockManager: Found block rdd_87_1 locally
17/12/19 17:19:19 INFO Executor: Finished task 0.0 in stage 43.0 (TID 31). 1980 bytes result sent to driver
17/12/19 17:19:19 INFO DAGScheduler: ResultStage 43 (collect at utils.scala:196) finished in 0.011 s
17/12/19 17:19:19 INFO DAGScheduler: Job 20 finished: collect at utils.scala:196, took 0.017475 s
17/12/19 17:19:19 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 31) in 10 ms on localhost (executor driver) (1/1)
17/12/19 17:19:19 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
17/12/19 17:19:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:19 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.054) AS `V1`, (`V2` < 0.0055) AS `V2`, (`V3` < 0.0045) AS `V3`, (`V4` < 0.009) AS `V4`, (`V5` < 0.054) AS `V5`, (`V6` < 0.15) AS `V6`, (`V7` < 0.1) AS `V7`, (`V8` < 0.0035) AS `V8`, (`V9` < 3e-04) AS `V9`, (`V10` < 0.0055) AS `V10`
FROM `analyis_tbl`
17/12/19 17:19:19 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:19:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz23`
WHERE (0 = 1)
17/12/19 17:19:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 17:19:19 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:19:19 INFO DAGScheduler: Got job 21 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:19:19 INFO DAGScheduler: Final stage: ResultStage 45 (collect at utils.scala:196)
17/12/19 17:19:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
17/12/19 17:19:19 INFO DAGScheduler: Missing parents: List()
17/12/19 17:19:19 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[96] at collect at utils.scala:196), which has no missing parents
17/12/19 17:19:19 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 142.9 KB, free 2003.0 MB)
17/12/19 17:19:19 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 55.4 KB, free 2002.9 MB)
17/12/19 17:19:19 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:56751 (size: 55.4 KB, free: 2004.2 MB)
17/12/19 17:19:19 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[96] at collect at utils.scala:196)
17/12/19 17:19:19 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
17/12/19 17:19:19 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:19:19 INFO Executor: Running task 0.0 in stage 45.0 (TID 32)
17/12/19 17:19:19 INFO BlockManager: Found block rdd_87_0 locally
17/12/19 17:19:19 INFO Executor: Finished task 0.0 in stage 45.0 (TID 32). 1705 bytes result sent to driver
17/12/19 17:19:19 INFO DAGScheduler: ResultStage 45 (collect at utils.scala:196) finished in 0.013 s
17/12/19 17:19:19 INFO DAGScheduler: Job 21 finished: collect at utils.scala:196, took 0.019783 s
17/12/19 17:19:19 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:19:19 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 32) in 11 ms on localhost (executor driver) (1/1)
17/12/19 17:19:19 INFO DAGScheduler: Got job 22 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:19:19 INFO DAGScheduler: Final stage: ResultStage 47 (collect at utils.scala:196)
17/12/19 17:19:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
17/12/19 17:19:19 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
17/12/19 17:19:19 INFO DAGScheduler: Missing parents: List()
17/12/19 17:19:19 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[96] at collect at utils.scala:196), which has no missing parents
17/12/19 17:19:19 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 142.9 KB, free 2002.8 MB)
17/12/19 17:19:19 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 55.4 KB, free 2002.7 MB)
17/12/19 17:19:19 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:56751 (size: 55.4 KB, free: 2004.2 MB)
17/12/19 17:19:19 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[96] at collect at utils.scala:196)
17/12/19 17:19:19 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
17/12/19 17:19:19 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 33, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:19:19 INFO Executor: Running task 0.0 in stage 47.0 (TID 33)
17/12/19 17:19:20 INFO BlockManager: Found block rdd_87_1 locally
17/12/19 17:19:20 INFO Executor: Finished task 0.0 in stage 47.0 (TID 33). 1622 bytes result sent to driver
17/12/19 17:19:20 INFO DAGScheduler: ResultStage 47 (collect at utils.scala:196) finished in 0.017 s
17/12/19 17:19:20 INFO DAGScheduler: Job 22 finished: collect at utils.scala:196, took 0.028005 s
17/12/19 17:19:20 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 33) in 17 ms on localhost (executor driver) (1/1)
17/12/19 17:19:20 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
17/12/19 17:19:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 17:19:20 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:19:20 INFO DAGScheduler: Got job 23 (collect at utils.scala:196) with 2 output partitions
17/12/19 17:19:20 INFO DAGScheduler: Final stage: ResultStage 49 (collect at utils.scala:196)
17/12/19 17:19:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)
17/12/19 17:19:20 INFO DAGScheduler: Missing parents: List()
17/12/19 17:19:20 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[99] at collect at utils.scala:196), which has no missing parents
17/12/19 17:19:20 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 143.0 KB, free 2002.6 MB)
17/12/19 17:19:20 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 55.5 KB, free 2002.5 MB)
17/12/19 17:19:20 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:56751 (size: 55.5 KB, free: 2004.1 MB)
17/12/19 17:19:20 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
17/12/19 17:19:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 49 (MapPartitionsRDD[99] at collect at utils.scala:196)
17/12/19 17:19:20 INFO TaskSchedulerImpl: Adding task set 49.0 with 2 tasks
17/12/19 17:19:20 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/19 17:19:20 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/19 17:19:20 INFO Executor: Running task 1.0 in stage 49.0 (TID 35)
17/12/19 17:19:20 INFO Executor: Running task 0.0 in stage 49.0 (TID 34)
17/12/19 17:19:20 INFO BlockManager: Found block rdd_87_1 locally
17/12/19 17:19:20 INFO BlockManager: Found block rdd_87_0 locally
17/12/19 17:19:20 INFO Executor: Finished task 1.0 in stage 49.0 (TID 35). 1480 bytes result sent to driver
17/12/19 17:19:20 INFO Executor: Finished task 0.0 in stage 49.0 (TID 34). 1631 bytes result sent to driver
17/12/19 17:19:20 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 35) in 16 ms on localhost (executor driver) (1/2)
17/12/19 17:19:20 INFO DAGScheduler: ResultStage 49 (collect at utils.scala:196) finished in 0.016 s
17/12/19 17:19:20 INFO DAGScheduler: Job 23 finished: collect at utils.scala:196, took 0.026772 s
17/12/19 17:19:20 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 34) in 16 ms on localhost (executor driver) (2/2)
17/12/19 17:19:20 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
17/12/19 17:19:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:19:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:19:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:19:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:19:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:19:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:19:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:19:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:19:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:19:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:19:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:19:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:19:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:19:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:19:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:19:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:19:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:19:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:19:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:19:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:19:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:19:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:19:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:19:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:19:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:19:20 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:19:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:19:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:19:20 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:43:07 INFO ContextCleaner: Cleaned accumulator 976
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:56751 in memory (size: 6.0 KB, free: 2004.1 MB)
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:56751 in memory (size: 3.7 KB, free: 2004.1 MB)
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:56751 in memory (size: 4.4 KB, free: 2004.1 MB)
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:56751 in memory (size: 4.4 KB, free: 2004.1 MB)
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:56751 in memory (size: 7.0 KB, free: 2004.2 MB)
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:56751 in memory (size: 7.0 KB, free: 2004.2 MB)
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:56751 in memory (size: 51.1 KB, free: 2004.2 MB)
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:56751 in memory (size: 51.1 KB, free: 2004.3 MB)
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:56751 in memory (size: 53.5 KB, free: 2004.3 MB)
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:56751 in memory (size: 53.5 KB, free: 2004.4 MB)
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:56751 in memory (size: 55.4 KB, free: 2004.4 MB)
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:56751 in memory (size: 55.4 KB, free: 2004.5 MB)
17/12/19 17:43:07 INFO ContextCleaner: Cleaned accumulator 796
17/12/19 17:43:07 INFO ContextCleaner: Cleaned accumulator 797
17/12/19 17:43:07 INFO ContextCleaner: Cleaned accumulator 798
17/12/19 17:43:07 INFO ContextCleaner: Cleaned accumulator 799
17/12/19 17:43:07 INFO ContextCleaner: Cleaned accumulator 800
17/12/19 17:43:07 INFO ContextCleaner: Cleaned accumulator 801
17/12/19 17:43:07 INFO ContextCleaner: Cleaned accumulator 802
17/12/19 17:43:07 INFO ContextCleaner: Cleaned accumulator 803
17/12/19 17:43:07 INFO ContextCleaner: Cleaned accumulator 804
17/12/19 17:43:07 INFO ContextCleaner: Cleaned accumulator 805
17/12/19 17:43:07 INFO ContextCleaner: Cleaned accumulator 806
17/12/19 17:43:07 INFO ContextCleaner: Cleaned accumulator 807
17/12/19 17:43:07 INFO ContextCleaner: Cleaned shuffle 4
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:56751 in memory (size: 7.3 KB, free: 2004.5 MB)
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:56751 in memory (size: 6.0 KB, free: 2004.5 MB)
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:56751 in memory (size: 3.7 KB, free: 2004.5 MB)
17/12/19 17:43:07 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:56751 in memory (size: 55.5 KB, free: 2004.5 MB)
17/12/19 17:51:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:51:55 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:51:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:51:55 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:51:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:51:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:51:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:51:55 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 17:51:55 INFO DAGScheduler: Got job 24 (collect at utils.scala:58) with 1 output partitions
17/12/19 17:51:55 INFO DAGScheduler: Final stage: ResultStage 50 (collect at utils.scala:58)
17/12/19 17:51:55 INFO DAGScheduler: Parents of final stage: List()
17/12/19 17:51:55 INFO DAGScheduler: Missing parents: List()
17/12/19 17:51:55 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[109] at map at utils.scala:55), which has no missing parents
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 8.7 KB, free 2004.0 MB)
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2004.0 MB)
17/12/19 17:51:55 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:56751 (size: 4.6 KB, free: 2004.5 MB)
17/12/19 17:51:55 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[109] at map at utils.scala:55)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
17/12/19 17:51:55 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 6576 bytes)
17/12/19 17:51:55 INFO Executor: Running task 0.0 in stage 50.0 (TID 36)
17/12/19 17:51:55 INFO Executor: Finished task 0.0 in stage 50.0 (TID 36). 1080 bytes result sent to driver
17/12/19 17:51:55 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 36) in 3 ms on localhost (executor driver) (1/1)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
17/12/19 17:51:55 INFO DAGScheduler: ResultStage 50 (collect at utils.scala:58) finished in 0.003 s
17/12/19 17:51:55 INFO DAGScheduler: Job 24 finished: collect at utils.scala:58, took 0.010948 s
17/12/19 17:51:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:55 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:51:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:55 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 17:51:55 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 17:51:55 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 17:51:55 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 17:51:55 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 17:51:55 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 293.7 KB, free 2003.7 MB)
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2003.6 MB)
17/12/19 17:51:55 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:56751 (size: 24.0 KB, free: 2004.5 MB)
17/12/19 17:51:55 INFO SparkContext: Created broadcast 33 from sql at <unknown>:0
17/12/19 17:51:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 17:51:55 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 17:51:55 INFO DAGScheduler: Registering RDD 113 (sql at <unknown>:0)
17/12/19 17:51:55 INFO DAGScheduler: Registering RDD 118 (sql at <unknown>:0)
17/12/19 17:51:55 INFO DAGScheduler: Got job 25 (sql at <unknown>:0) with 1 output partitions
17/12/19 17:51:55 INFO DAGScheduler: Final stage: ResultStage 53 (sql at <unknown>:0)
17/12/19 17:51:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
17/12/19 17:51:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 52)
17/12/19 17:51:55 INFO DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[113] at sql at <unknown>:0), which has no missing parents
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 12.1 KB, free 2003.6 MB)
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2003.6 MB)
17/12/19 17:51:55 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:56751 (size: 7.3 KB, free: 2004.5 MB)
17/12/19 17:51:55 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[113] at sql at <unknown>:0)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
17/12/19 17:51:55 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/19 17:51:55 INFO Executor: Running task 0.0 in stage 51.0 (TID 37)
17/12/19 17:51:55 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpwLtPOg/spark_serialize_6e3736f9f9eb7033d4d7cc2b168cff1f35194e54a13f206a9bc37269dac996a6.csv, range: 0-577, partition values: [empty row]
17/12/19 17:51:55 INFO Executor: Finished task 0.0 in stage 51.0 (TID 37). 1719 bytes result sent to driver
17/12/19 17:51:55 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 37) in 28 ms on localhost (executor driver) (1/1)
17/12/19 17:51:55 INFO DAGScheduler: ShuffleMapStage 51 (sql at <unknown>:0) finished in 0.029 s
17/12/19 17:51:55 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:51:55 INFO DAGScheduler: running: Set()
17/12/19 17:51:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 52, ResultStage 53)
17/12/19 17:51:55 INFO DAGScheduler: failed: Set()
17/12/19 17:51:55 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
17/12/19 17:51:55 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[118] at sql at <unknown>:0), which has no missing parents
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 11.9 KB, free 2003.6 MB)
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2003.6 MB)
17/12/19 17:51:55 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:56751 (size: 6.0 KB, free: 2004.5 MB)
17/12/19 17:51:55 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[118] at sql at <unknown>:0)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Adding task set 52.0 with 2 tasks
17/12/19 17:51:55 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 38, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/19 17:51:55 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 39, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/19 17:51:55 INFO Executor: Running task 0.0 in stage 52.0 (TID 38)
17/12/19 17:51:55 INFO Executor: Running task 1.0 in stage 52.0 (TID 39)
17/12/19 17:51:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 17:51:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:51:55 INFO MemoryStore: Block rdd_115_0 stored as values in memory (estimated size 568.0 B, free 2003.6 MB)
17/12/19 17:51:55 INFO BlockManagerInfo: Added rdd_115_0 in memory on 127.0.0.1:56751 (size: 568.0 B, free: 2004.5 MB)
17/12/19 17:51:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 17:51:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:51:55 INFO MemoryStore: Block rdd_115_1 stored as values in memory (estimated size 568.0 B, free 2003.6 MB)
17/12/19 17:51:55 INFO BlockManagerInfo: Added rdd_115_1 in memory on 127.0.0.1:56751 (size: 568.0 B, free: 2004.5 MB)
17/12/19 17:51:55 INFO Executor: Finished task 0.0 in stage 52.0 (TID 38). 3064 bytes result sent to driver
17/12/19 17:51:55 INFO Executor: Finished task 1.0 in stage 52.0 (TID 39). 2993 bytes result sent to driver
17/12/19 17:51:55 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 38) in 16 ms on localhost (executor driver) (1/2)
17/12/19 17:51:55 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 39) in 31 ms on localhost (executor driver) (2/2)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
17/12/19 17:51:55 INFO DAGScheduler: ShuffleMapStage 52 (sql at <unknown>:0) finished in 0.031 s
17/12/19 17:51:55 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:51:55 INFO DAGScheduler: running: Set()
17/12/19 17:51:55 INFO DAGScheduler: waiting: Set(ResultStage 53)
17/12/19 17:51:55 INFO DAGScheduler: failed: Set()
17/12/19 17:51:55 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[121] at sql at <unknown>:0), which has no missing parents
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 7.0 KB, free 2003.6 MB)
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.6 MB)
17/12/19 17:51:55 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:56751 (size: 3.7 KB, free: 2004.5 MB)
17/12/19 17:51:55 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[121] at sql at <unknown>:0)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
17/12/19 17:51:55 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 40, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/19 17:51:55 INFO Executor: Running task 0.0 in stage 53.0 (TID 40)
17/12/19 17:51:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 17:51:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:51:55 INFO Executor: Finished task 0.0 in stage 53.0 (TID 40). 1707 bytes result sent to driver
17/12/19 17:51:55 INFO DAGScheduler: ResultStage 53 (sql at <unknown>:0) finished in 0.000 s
17/12/19 17:51:55 INFO DAGScheduler: Job 25 finished: sql at <unknown>:0, took 0.074675 s
17/12/19 17:51:55 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 40) in 0 ms on localhost (executor driver) (1/1)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
17/12/19 17:51:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:55 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 17:51:55 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:51:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 145 bytes
17/12/19 17:51:55 INFO DAGScheduler: Registering RDD 125 (collect at utils.scala:196)
17/12/19 17:51:55 INFO DAGScheduler: Got job 26 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:51:55 INFO DAGScheduler: Final stage: ResultStage 56 (collect at utils.scala:196)
17/12/19 17:51:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)
17/12/19 17:51:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 55)
17/12/19 17:51:55 INFO DAGScheduler: Submitting ShuffleMapStage 55 (MapPartitionsRDD[125] at collect at utils.scala:196), which has no missing parents
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 11.9 KB, free 2003.6 MB)
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2003.6 MB)
17/12/19 17:51:55 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:56751 (size: 6.0 KB, free: 2004.5 MB)
17/12/19 17:51:55 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[125] at collect at utils.scala:196)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Adding task set 55.0 with 2 tasks
17/12/19 17:51:55 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/19 17:51:55 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 42, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/19 17:51:55 INFO Executor: Running task 1.0 in stage 55.0 (TID 42)
17/12/19 17:51:55 INFO Executor: Running task 0.0 in stage 55.0 (TID 41)
17/12/19 17:51:55 INFO BlockManager: Found block rdd_115_1 locally
17/12/19 17:51:55 INFO BlockManager: Found block rdd_115_0 locally
17/12/19 17:51:55 INFO Executor: Finished task 1.0 in stage 55.0 (TID 42). 1969 bytes result sent to driver
17/12/19 17:51:55 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 42) in 16 ms on localhost (executor driver) (1/2)
17/12/19 17:51:55 INFO Executor: Finished task 0.0 in stage 55.0 (TID 41). 1969 bytes result sent to driver
17/12/19 17:51:55 INFO DAGScheduler: ShuffleMapStage 55 (collect at utils.scala:196) finished in 0.016 s
17/12/19 17:51:55 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:51:55 INFO DAGScheduler: running: Set()
17/12/19 17:51:55 INFO DAGScheduler: waiting: Set(ResultStage 56)
17/12/19 17:51:55 INFO DAGScheduler: failed: Set()
17/12/19 17:51:55 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[128] at collect at utils.scala:196), which has no missing parents
17/12/19 17:51:55 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 41) in 16 ms on localhost (executor driver) (2/2)
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 7.0 KB, free 2003.6 MB)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.6 MB)
17/12/19 17:51:55 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:56751 (size: 3.7 KB, free: 2004.5 MB)
17/12/19 17:51:55 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[128] at collect at utils.scala:196)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
17/12/19 17:51:55 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 43, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/19 17:51:55 INFO Executor: Running task 0.0 in stage 56.0 (TID 43)
17/12/19 17:51:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 17:51:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:51:55 INFO Executor: Finished task 0.0 in stage 56.0 (TID 43). 1707 bytes result sent to driver
17/12/19 17:51:55 INFO DAGScheduler: ResultStage 56 (collect at utils.scala:196) finished in 0.000 s
17/12/19 17:51:55 INFO DAGScheduler: Job 26 finished: collect at utils.scala:196, took 0.030404 s
17/12/19 17:51:55 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 43) in 0 ms on localhost (executor driver) (1/1)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
17/12/19 17:51:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz24`
WHERE (0 = 1)
17/12/19 17:51:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 17:51:55 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:51:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 145 bytes
17/12/19 17:51:55 INFO DAGScheduler: Got job 27 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:51:55 INFO DAGScheduler: Final stage: ResultStage 58 (collect at utils.scala:196)
17/12/19 17:51:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)
17/12/19 17:51:55 INFO DAGScheduler: Missing parents: List()
17/12/19 17:51:55 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[130] at collect at utils.scala:196), which has no missing parents
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 8.3 KB, free 2003.6 MB)
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 4.4 KB, free 2003.6 MB)
17/12/19 17:51:55 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:56751 (size: 4.4 KB, free: 2004.5 MB)
17/12/19 17:51:55 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[130] at collect at utils.scala:196)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
17/12/19 17:51:55 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:51:55 INFO Executor: Running task 0.0 in stage 58.0 (TID 44)
17/12/19 17:51:55 INFO BlockManager: Found block rdd_115_0 locally
17/12/19 17:51:55 INFO Executor: Finished task 0.0 in stage 58.0 (TID 44). 1554 bytes result sent to driver
17/12/19 17:51:55 INFO DAGScheduler: ResultStage 58 (collect at utils.scala:196) finished in 0.008 s
17/12/19 17:51:55 INFO DAGScheduler: Job 27 finished: collect at utils.scala:196, took 0.012856 s
17/12/19 17:51:55 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 44) in 4 ms on localhost (executor driver) (1/1)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
17/12/19 17:51:55 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:51:55 INFO DAGScheduler: Got job 28 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:51:55 INFO DAGScheduler: Final stage: ResultStage 60 (collect at utils.scala:196)
17/12/19 17:51:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
17/12/19 17:51:55 INFO DAGScheduler: Missing parents: List()
17/12/19 17:51:55 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[130] at collect at utils.scala:196), which has no missing parents
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 8.3 KB, free 2003.6 MB)
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 4.4 KB, free 2003.5 MB)
17/12/19 17:51:55 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:56751 (size: 4.4 KB, free: 2004.5 MB)
17/12/19 17:51:55 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[130] at collect at utils.scala:196)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
17/12/19 17:51:55 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 45, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:51:55 INFO Executor: Running task 0.0 in stage 60.0 (TID 45)
17/12/19 17:51:55 INFO BlockManager: Found block rdd_115_1 locally
17/12/19 17:51:55 INFO Executor: Finished task 0.0 in stage 60.0 (TID 45). 1377 bytes result sent to driver
17/12/19 17:51:55 INFO DAGScheduler: ResultStage 60 (collect at utils.scala:196) finished in 0.012 s
17/12/19 17:51:55 INFO DAGScheduler: Job 28 finished: collect at utils.scala:196, took 0.012526 s
17/12/19 17:51:55 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 45) in 12 ms on localhost (executor driver) (1/1)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
17/12/19 17:51:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:55 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`
FROM (SELECT `S1`, `S2`, `S3`, `S3` + 0.91651514 * RANDN() AS `V1`, `S2` + 0.93273791 * RANDN() AS `V2`, `S2` + 0.93273791 * RANDN() AS `V3`, `S2` + 0.93273791 * RANDN() AS `V4`, `S1` + 0.92195445 * RANDN() AS `V5`, `S2` + 0.93273791 * RANDN() AS `V6`, `S3` + 0.91651514 * RANDN() AS `V7`, `S2` + 0.93273791 * RANDN() AS `V8`, `S3` + 0.91651514 * RANDN() AS `V9`, `S3` + 0.91651514 * RANDN() AS `V10`
FROM `analyis_tbl`) `qtgxiutnwq`
17/12/19 17:51:55 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:51:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz25`
WHERE (0 = 1)
17/12/19 17:51:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 17:51:55 INFO CodeGenerator: Code generated in 13.834198 ms
17/12/19 17:51:55 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:51:55 INFO DAGScheduler: Got job 29 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:51:55 INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:196)
17/12/19 17:51:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
17/12/19 17:51:55 INFO DAGScheduler: Missing parents: List()
17/12/19 17:51:55 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[134] at collect at utils.scala:196), which has no missing parents
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 17.3 KB, free 2003.5 MB)
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2003.5 MB)
17/12/19 17:51:55 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:56751 (size: 7.0 KB, free: 2004.5 MB)
17/12/19 17:51:55 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[134] at collect at utils.scala:196)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
17/12/19 17:51:55 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:51:55 INFO Executor: Running task 0.0 in stage 62.0 (TID 46)
17/12/19 17:51:55 INFO BlockManager: Found block rdd_115_0 locally
17/12/19 17:51:55 INFO Executor: Finished task 0.0 in stage 62.0 (TID 46). 1675 bytes result sent to driver
17/12/19 17:51:55 INFO DAGScheduler: ResultStage 62 (collect at utils.scala:196) finished in 0.000 s
17/12/19 17:51:55 INFO DAGScheduler: Job 29 finished: collect at utils.scala:196, took 0.011132 s
17/12/19 17:51:55 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 46) in 0 ms on localhost (executor driver) (1/1)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
17/12/19 17:51:55 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:51:55 INFO DAGScheduler: Got job 30 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:51:55 INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:196)
17/12/19 17:51:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
17/12/19 17:51:55 INFO DAGScheduler: Missing parents: List()
17/12/19 17:51:55 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[134] at collect at utils.scala:196), which has no missing parents
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 17.3 KB, free 2003.5 MB)
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 7.0 KB, free 2003.5 MB)
17/12/19 17:51:55 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:56751 (size: 7.0 KB, free: 2004.5 MB)
17/12/19 17:51:55 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[134] at collect at utils.scala:196)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
17/12/19 17:51:55 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 47, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:51:55 INFO Executor: Running task 0.0 in stage 64.0 (TID 47)
17/12/19 17:51:55 INFO BlockManager: Found block rdd_115_1 locally
17/12/19 17:51:55 INFO Executor: Finished task 0.0 in stage 64.0 (TID 47). 1677 bytes result sent to driver
17/12/19 17:51:55 INFO DAGScheduler: ResultStage 64 (collect at utils.scala:196) finished in 0.000 s
17/12/19 17:51:55 INFO DAGScheduler: Job 30 finished: collect at utils.scala:196, took 0.011202 s
17/12/19 17:51:55 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 47) in 0 ms on localhost (executor driver) (1/1)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
17/12/19 17:51:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 17:51:55 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 17:51:55 INFO DAGScheduler: Got job 31 (take at <unknown>:0) with 1 output partitions
17/12/19 17:51:55 INFO DAGScheduler: Final stage: ResultStage 66 (take at <unknown>:0)
17/12/19 17:51:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
17/12/19 17:51:55 INFO DAGScheduler: Missing parents: List()
17/12/19 17:51:55 INFO DAGScheduler: Submitting ResultStage 66 (WorkerRDD[139] at RDD at rdd.scala:18), which has no missing parents
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 132.4 KB, free 2003.4 MB)
17/12/19 17:51:55 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 52.8 KB, free 2003.3 MB)
17/12/19 17:51:55 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:56751 (size: 52.8 KB, free: 2004.4 MB)
17/12/19 17:51:55 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (WorkerRDD[139] at RDD at rdd.scala:18)
17/12/19 17:51:55 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
17/12/19 17:51:55 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 17:51:55 INFO Executor: Running task 0.0 in stage 66.0 (TID 48)
17/12/19 17:51:55 INFO BlockManager: Found block rdd_115_0 locally
17/12/19 17:51:56 INFO MemoryStore: Block rdd_139_0 stored as values in memory (estimated size 1600.0 B, free 2003.3 MB)
17/12/19 17:51:56 INFO BlockManagerInfo: Added rdd_139_0 in memory on 127.0.0.1:56751 (size: 1600.0 B, free: 2004.4 MB)
17/12/19 17:51:56 INFO Executor: Finished task 0.0 in stage 66.0 (TID 48). 3090 bytes result sent to driver
17/12/19 17:51:56 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 48) in 628 ms on localhost (executor driver) (1/1)
17/12/19 17:51:56 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
17/12/19 17:51:56 INFO DAGScheduler: ResultStage 66 (take at <unknown>:0) finished in 0.628 s
17/12/19 17:51:56 INFO DAGScheduler: Job 31 finished: take at <unknown>:0, took 0.637197 s
17/12/19 17:51:56 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 17:51:56 INFO DAGScheduler: Got job 32 (take at <unknown>:0) with 1 output partitions
17/12/19 17:51:56 INFO DAGScheduler: Final stage: ResultStage 68 (take at <unknown>:0)
17/12/19 17:51:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
17/12/19 17:51:56 INFO DAGScheduler: Missing parents: List()
17/12/19 17:51:56 INFO DAGScheduler: Submitting ResultStage 68 (WorkerRDD[139] at RDD at rdd.scala:18), which has no missing parents
17/12/19 17:51:56 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 132.4 KB, free 2003.2 MB)
17/12/19 17:51:56 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 52.8 KB, free 2003.1 MB)
17/12/19 17:51:56 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:56751 (size: 52.8 KB, free: 2004.4 MB)
17/12/19 17:51:56 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (WorkerRDD[139] at RDD at rdd.scala:18)
17/12/19 17:51:56 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
17/12/19 17:51:56 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 49, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 17:51:56 INFO Executor: Running task 0.0 in stage 68.0 (TID 49)
17/12/19 17:51:56 INFO BlockManager: Found block rdd_115_1 locally
17/12/19 17:51:57 INFO MemoryStore: Block rdd_139_1 stored as values in memory (estimated size 1600.0 B, free 2003.1 MB)
17/12/19 17:51:57 INFO BlockManagerInfo: Added rdd_139_1 in memory on 127.0.0.1:56751 (size: 1600.0 B, free: 2004.4 MB)
17/12/19 17:51:57 WARN Executor: 1 block locks were not released by TID = 49:
[rdd_139_1]
17/12/19 17:51:57 INFO Executor: Finished task 0.0 in stage 68.0 (TID 49). 3003 bytes result sent to driver
17/12/19 17:51:57 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 49) in 628 ms on localhost (executor driver) (1/1)
17/12/19 17:51:57 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
17/12/19 17:51:57 INFO DAGScheduler: ResultStage 68 (take at <unknown>:0) finished in 0.628 s
17/12/19 17:51:57 INFO DAGScheduler: Job 32 finished: take at <unknown>:0, took 0.642397 s
17/12/19 17:51:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2250684670b
17/12/19 17:51:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2250684670b` AS `zzz26`
WHERE (0 = 1)
17/12/19 17:51:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2250684670b`
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:51:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz27`
WHERE (0 = 1)
17/12/19 17:51:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 17:51:57 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:51:57 INFO DAGScheduler: Got job 33 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:51:57 INFO DAGScheduler: Final stage: ResultStage 70 (collect at utils.scala:196)
17/12/19 17:51:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 69)
17/12/19 17:51:57 INFO DAGScheduler: Missing parents: List()
17/12/19 17:51:57 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[144] at collect at utils.scala:196), which has no missing parents
17/12/19 17:51:57 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 138.4 KB, free 2003.0 MB)
17/12/19 17:51:57 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 55.1 KB, free 2002.9 MB)
17/12/19 17:51:57 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:56751 (size: 55.1 KB, free: 2004.3 MB)
17/12/19 17:51:57 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[144] at collect at utils.scala:196)
17/12/19 17:51:57 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
17/12/19 17:51:57 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:51:57 INFO Executor: Running task 0.0 in stage 70.0 (TID 50)
17/12/19 17:51:57 INFO BlockManager: Found block rdd_139_0 locally
17/12/19 17:51:57 INFO Executor: Finished task 0.0 in stage 70.0 (TID 50). 1735 bytes result sent to driver
17/12/19 17:51:57 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 50) in 1 ms on localhost (executor driver) (1/1)
17/12/19 17:51:57 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
17/12/19 17:51:57 INFO DAGScheduler: ResultStage 70 (collect at utils.scala:196) finished in 0.002 s
17/12/19 17:51:57 INFO DAGScheduler: Job 33 finished: collect at utils.scala:196, took 0.012396 s
17/12/19 17:51:57 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:51:57 INFO DAGScheduler: Got job 34 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:51:57 INFO DAGScheduler: Final stage: ResultStage 72 (collect at utils.scala:196)
17/12/19 17:51:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
17/12/19 17:51:57 INFO DAGScheduler: Missing parents: List()
17/12/19 17:51:57 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[144] at collect at utils.scala:196), which has no missing parents
17/12/19 17:51:57 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 138.4 KB, free 2002.8 MB)
17/12/19 17:51:57 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 55.1 KB, free 2002.8 MB)
17/12/19 17:51:57 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:56751 (size: 55.1 KB, free: 2004.3 MB)
17/12/19 17:51:57 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[144] at collect at utils.scala:196)
17/12/19 17:51:57 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
17/12/19 17:51:57 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 51, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:51:57 INFO Executor: Running task 0.0 in stage 72.0 (TID 51)
17/12/19 17:51:57 INFO BlockManager: Found block rdd_139_1 locally
17/12/19 17:51:57 INFO Executor: Finished task 0.0 in stage 72.0 (TID 51). 1913 bytes result sent to driver
17/12/19 17:51:57 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 51) in 15 ms on localhost (executor driver) (1/1)
17/12/19 17:51:57 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
17/12/19 17:51:57 INFO DAGScheduler: ResultStage 72 (collect at utils.scala:196) finished in 0.015 s
17/12/19 17:51:57 INFO DAGScheduler: Job 34 finished: collect at utils.scala:196, took 0.010652 s
17/12/19 17:51:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.054) AS `V1`, (`V2` < 0.0055) AS `V2`, (`V3` < 0.0045) AS `V3`, (`V4` < 0.009) AS `V4`, (`V5` < 0.054) AS `V5`, (`V6` < 0.15) AS `V6`, (`V7` < 0.1) AS `V7`, (`V8` < 0.0035) AS `V8`, (`V9` < 3e-04) AS `V9`, (`V10` < 0.0055) AS `V10`
FROM `analyis_tbl`
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:51:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz28`
WHERE (0 = 1)
17/12/19 17:51:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
LIMIT 10
17/12/19 17:51:57 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:51:57 INFO DAGScheduler: Got job 35 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:51:57 INFO DAGScheduler: Final stage: ResultStage 74 (collect at utils.scala:196)
17/12/19 17:51:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
17/12/19 17:51:57 INFO DAGScheduler: Missing parents: List()
17/12/19 17:51:57 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[148] at collect at utils.scala:196), which has no missing parents
17/12/19 17:51:57 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 145.1 KB, free 2002.6 MB)
17/12/19 17:51:57 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 57.1 KB, free 2002.6 MB)
17/12/19 17:51:57 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:56751 (size: 57.1 KB, free: 2004.2 MB)
17/12/19 17:51:57 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[148] at collect at utils.scala:196)
17/12/19 17:51:57 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks
17/12/19 17:51:57 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:51:57 INFO Executor: Running task 0.0 in stage 74.0 (TID 52)
17/12/19 17:51:57 INFO BlockManager: Found block rdd_139_0 locally
17/12/19 17:51:57 INFO Executor: Finished task 0.0 in stage 74.0 (TID 52). 1431 bytes result sent to driver
17/12/19 17:51:57 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 52) in 0 ms on localhost (executor driver) (1/1)
17/12/19 17:51:57 INFO DAGScheduler: ResultStage 74 (collect at utils.scala:196) finished in 0.000 s
17/12/19 17:51:57 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
17/12/19 17:51:57 INFO DAGScheduler: Job 35 finished: collect at utils.scala:196, took 0.015774 s
17/12/19 17:51:57 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:51:57 INFO DAGScheduler: Got job 36 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:51:57 INFO DAGScheduler: Final stage: ResultStage 76 (collect at utils.scala:196)
17/12/19 17:51:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
17/12/19 17:51:57 INFO DAGScheduler: Missing parents: List()
17/12/19 17:51:57 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[148] at collect at utils.scala:196), which has no missing parents
17/12/19 17:51:57 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 145.1 KB, free 2002.4 MB)
17/12/19 17:51:57 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 57.1 KB, free 2002.4 MB)
17/12/19 17:51:57 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:56751 (size: 57.1 KB, free: 2004.1 MB)
17/12/19 17:51:57 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[148] at collect at utils.scala:196)
17/12/19 17:51:57 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
17/12/19 17:51:57 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 53, localhost, executor driver, partition 1, PROCESS_LOCAL, 5861 bytes)
17/12/19 17:51:57 INFO Executor: Running task 0.0 in stage 76.0 (TID 53)
17/12/19 17:51:57 INFO BlockManager: Found block rdd_139_1 locally
17/12/19 17:51:57 INFO Executor: Finished task 0.0 in stage 76.0 (TID 53). 1444 bytes result sent to driver
17/12/19 17:51:57 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 53) in 15 ms on localhost (executor driver) (1/1)
17/12/19 17:51:57 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
17/12/19 17:51:57 INFO DAGScheduler: ResultStage 76 (collect at utils.scala:196) finished in 0.015 s
17/12/19 17:51:57 INFO DAGScheduler: Job 36 finished: collect at utils.scala:196, took 0.013736 s
17/12/19 17:51:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 17:51:57 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:51:57 INFO DAGScheduler: Got job 37 (collect at utils.scala:196) with 2 output partitions
17/12/19 17:51:57 INFO DAGScheduler: Final stage: ResultStage 78 (collect at utils.scala:196)
17/12/19 17:51:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
17/12/19 17:51:57 INFO DAGScheduler: Missing parents: List()
17/12/19 17:51:57 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[151] at collect at utils.scala:196), which has no missing parents
17/12/19 17:51:57 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 145.2 KB, free 2002.2 MB)
17/12/19 17:51:57 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 57.1 KB, free 2002.2 MB)
17/12/19 17:51:57 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:56751 (size: 57.1 KB, free: 2004.1 MB)
17/12/19 17:51:57 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:996
17/12/19 17:51:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 78 (MapPartitionsRDD[151] at collect at utils.scala:196)
17/12/19 17:51:57 INFO TaskSchedulerImpl: Adding task set 78.0 with 2 tasks
17/12/19 17:51:57 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/19 17:51:57 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 55, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/19 17:51:57 INFO Executor: Running task 0.0 in stage 78.0 (TID 54)
17/12/19 17:51:57 INFO Executor: Running task 1.0 in stage 78.0 (TID 55)
17/12/19 17:51:57 INFO BlockManager: Found block rdd_139_0 locally
17/12/19 17:51:57 INFO BlockManager: Found block rdd_139_1 locally
17/12/19 17:51:57 INFO Executor: Finished task 0.0 in stage 78.0 (TID 54). 1455 bytes result sent to driver
17/12/19 17:51:57 INFO Executor: Finished task 1.0 in stage 78.0 (TID 55). 1468 bytes result sent to driver
17/12/19 17:51:57 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 54) in 0 ms on localhost (executor driver) (1/2)
17/12/19 17:51:57 INFO DAGScheduler: ResultStage 78 (collect at utils.scala:196) finished in 0.016 s
17/12/19 17:51:57 INFO DAGScheduler: Job 37 finished: collect at utils.scala:196, took 0.020380 s
17/12/19 17:51:57 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 55) in 0 ms on localhost (executor driver) (2/2)
17/12/19 17:51:57 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
17/12/19 17:51:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:51:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:51:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:51:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:51:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:51:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:51:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:51:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:51:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:51:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:51:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:51:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:51:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:51:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:51:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:51:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:51:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:51:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:51:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:51:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:51:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:51:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:51:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:51:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:51:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:51:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:51:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:51:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:51:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:52:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:52:55 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:52:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:52:55 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:52:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:52:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:52:55 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:52:55 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 17:52:55 INFO DAGScheduler: Got job 38 (collect at utils.scala:58) with 1 output partitions
17/12/19 17:52:55 INFO DAGScheduler: Final stage: ResultStage 79 (collect at utils.scala:58)
17/12/19 17:52:55 INFO DAGScheduler: Parents of final stage: List()
17/12/19 17:52:55 INFO DAGScheduler: Missing parents: List()
17/12/19 17:52:55 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[161] at map at utils.scala:55), which has no missing parents
17/12/19 17:52:55 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 8.7 KB, free 2002.2 MB)
17/12/19 17:52:55 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2002.2 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:56751 (size: 4.6 KB, free: 2004.1 MB)
17/12/19 17:52:55 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:996
17/12/19 17:52:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[161] at map at utils.scala:55)
17/12/19 17:52:55 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
17/12/19 17:52:55 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 6647 bytes)
17/12/19 17:52:55 INFO Executor: Running task 0.0 in stage 79.0 (TID 56)
17/12/19 17:52:55 INFO Executor: Finished task 0.0 in stage 79.0 (TID 56). 1197 bytes result sent to driver
17/12/19 17:52:55 INFO DAGScheduler: ResultStage 79 (collect at utils.scala:58) finished in 0.016 s
17/12/19 17:52:55 INFO DAGScheduler: Job 38 finished: collect at utils.scala:58, took 0.009281 s
17/12/19 17:52:55 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 56) in 16 ms on localhost (executor driver) (1/1)
17/12/19 17:52:55 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
17/12/19 17:52:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:55 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:52:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:55 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 17:52:55 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 17:52:55 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 17:52:55 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 17:52:55 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 17:52:55 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 17:52:55 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 293.7 KB, free 2001.9 MB)
17/12/19 17:52:55 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2001.8 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:56751 (size: 24.0 KB, free: 2004.1 MB)
17/12/19 17:52:55 INFO SparkContext: Created broadcast 51 from sql at <unknown>:0
17/12/19 17:52:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 17:52:55 INFO ContextCleaner: Cleaned shuffle 7
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:56751 in memory (size: 57.1 KB, free: 2004.1 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:56751 in memory (size: 57.1 KB, free: 2004.2 MB)
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 2604
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 2605
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:56751 in memory (size: 4.6 KB, free: 2004.2 MB)
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 2654
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 2655
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:56751 in memory (size: 7.0 KB, free: 2004.2 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:56751 in memory (size: 52.8 KB, free: 2004.2 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:56751 in memory (size: 52.8 KB, free: 2004.3 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:56751 in memory (size: 55.1 KB, free: 2004.3 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:56751 in memory (size: 55.1 KB, free: 2004.4 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:56751 in memory (size: 57.1 KB, free: 2004.4 MB)
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1671
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1672
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:56751 in memory (size: 4.6 KB, free: 2004.5 MB)
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1721
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1722
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1728
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1729
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1730
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1731
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1732
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1733
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1734
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1735
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1736
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1737
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1738
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1739
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1740
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:56751 in memory (size: 7.3 KB, free: 2004.5 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:56751 in memory (size: 6.0 KB, free: 2004.5 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:56751 in memory (size: 3.7 KB, free: 2004.5 MB)
17/12/19 17:52:55 INFO ContextCleaner: Cleaned accumulator 1909
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:56751 in memory (size: 6.0 KB, free: 2004.5 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:56751 in memory (size: 3.7 KB, free: 2004.5 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:56751 in memory (size: 4.4 KB, free: 2004.5 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:56751 in memory (size: 4.4 KB, free: 2004.5 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:56751 in memory (size: 7.0 KB, free: 2004.5 MB)
17/12/19 17:52:55 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 17:52:55 INFO DAGScheduler: Registering RDD 165 (sql at <unknown>:0)
17/12/19 17:52:55 INFO DAGScheduler: Registering RDD 170 (sql at <unknown>:0)
17/12/19 17:52:55 INFO DAGScheduler: Got job 39 (sql at <unknown>:0) with 1 output partitions
17/12/19 17:52:55 INFO DAGScheduler: Final stage: ResultStage 82 (sql at <unknown>:0)
17/12/19 17:52:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)
17/12/19 17:52:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 81)
17/12/19 17:52:55 INFO DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[165] at sql at <unknown>:0), which has no missing parents
17/12/19 17:52:55 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 12.1 KB, free 2003.3 MB)
17/12/19 17:52:55 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2003.3 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:56751 (size: 7.3 KB, free: 2004.5 MB)
17/12/19 17:52:55 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:996
17/12/19 17:52:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[165] at sql at <unknown>:0)
17/12/19 17:52:55 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
17/12/19 17:52:55 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/19 17:52:55 INFO Executor: Running task 0.0 in stage 80.0 (TID 57)
17/12/19 17:52:55 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpwLtPOg/spark_serialize_bfca1a2fc164b932ad9bfe2b1f6d433edb0bd8296da348a63a394a558e879c87.csv, range: 0-581, partition values: [empty row]
17/12/19 17:52:55 INFO Executor: Finished task 0.0 in stage 80.0 (TID 57). 1730 bytes result sent to driver
17/12/19 17:52:55 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 57) in 31 ms on localhost (executor driver) (1/1)
17/12/19 17:52:55 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
17/12/19 17:52:55 INFO DAGScheduler: ShuffleMapStage 80 (sql at <unknown>:0) finished in 0.031 s
17/12/19 17:52:55 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:52:55 INFO DAGScheduler: running: Set()
17/12/19 17:52:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 81, ResultStage 82)
17/12/19 17:52:55 INFO DAGScheduler: failed: Set()
17/12/19 17:52:55 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[170] at sql at <unknown>:0), which has no missing parents
17/12/19 17:52:55 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 11.9 KB, free 2003.3 MB)
17/12/19 17:52:55 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2003.3 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:56751 (size: 6.0 KB, free: 2004.5 MB)
17/12/19 17:52:55 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:996
17/12/19 17:52:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[170] at sql at <unknown>:0)
17/12/19 17:52:55 INFO TaskSchedulerImpl: Adding task set 81.0 with 2 tasks
17/12/19 17:52:55 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 58, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/19 17:52:55 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 59, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/19 17:52:55 INFO Executor: Running task 0.0 in stage 81.0 (TID 58)
17/12/19 17:52:55 INFO Executor: Running task 1.0 in stage 81.0 (TID 59)
17/12/19 17:52:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 17:52:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 17:52:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:52:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:52:55 INFO MemoryStore: Block rdd_167_0 stored as values in memory (estimated size 568.0 B, free 2003.3 MB)
17/12/19 17:52:55 INFO MemoryStore: Block rdd_167_1 stored as values in memory (estimated size 568.0 B, free 2003.3 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Added rdd_167_0 in memory on 127.0.0.1:56751 (size: 568.0 B, free: 2004.5 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Added rdd_167_1 in memory on 127.0.0.1:56751 (size: 568.0 B, free: 2004.5 MB)
17/12/19 17:52:55 INFO Executor: Finished task 0.0 in stage 81.0 (TID 58). 3064 bytes result sent to driver
17/12/19 17:52:55 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 58) in 16 ms on localhost (executor driver) (1/2)
17/12/19 17:52:55 INFO Executor: Finished task 1.0 in stage 81.0 (TID 59). 3064 bytes result sent to driver
17/12/19 17:52:55 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 59) in 16 ms on localhost (executor driver) (2/2)
17/12/19 17:52:55 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
17/12/19 17:52:55 INFO DAGScheduler: ShuffleMapStage 81 (sql at <unknown>:0) finished in 0.016 s
17/12/19 17:52:55 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:52:55 INFO DAGScheduler: running: Set()
17/12/19 17:52:55 INFO DAGScheduler: waiting: Set(ResultStage 82)
17/12/19 17:52:55 INFO DAGScheduler: failed: Set()
17/12/19 17:52:55 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[173] at sql at <unknown>:0), which has no missing parents
17/12/19 17:52:55 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 7.0 KB, free 2003.3 MB)
17/12/19 17:52:55 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.3 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:56751 (size: 3.7 KB, free: 2004.5 MB)
17/12/19 17:52:55 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:996
17/12/19 17:52:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[173] at sql at <unknown>:0)
17/12/19 17:52:55 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
17/12/19 17:52:55 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 60, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/19 17:52:55 INFO Executor: Running task 0.0 in stage 82.0 (TID 60)
17/12/19 17:52:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 17:52:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:52:55 INFO Executor: Finished task 0.0 in stage 82.0 (TID 60). 1707 bytes result sent to driver
17/12/19 17:52:55 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 60) in 0 ms on localhost (executor driver) (1/1)
17/12/19 17:52:55 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
17/12/19 17:52:55 INFO DAGScheduler: ResultStage 82 (sql at <unknown>:0) finished in 0.000 s
17/12/19 17:52:55 INFO DAGScheduler: Job 39 finished: sql at <unknown>:0, took 0.051049 s
17/12/19 17:52:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:55 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 17:52:55 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:52:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 145 bytes
17/12/19 17:52:55 INFO DAGScheduler: Registering RDD 177 (collect at utils.scala:196)
17/12/19 17:52:55 INFO DAGScheduler: Got job 40 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:52:55 INFO DAGScheduler: Final stage: ResultStage 85 (collect at utils.scala:196)
17/12/19 17:52:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)
17/12/19 17:52:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 84)
17/12/19 17:52:55 INFO DAGScheduler: Submitting ShuffleMapStage 84 (MapPartitionsRDD[177] at collect at utils.scala:196), which has no missing parents
17/12/19 17:52:55 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 11.9 KB, free 2003.3 MB)
17/12/19 17:52:55 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2003.3 MB)
17/12/19 17:52:55 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:56751 (size: 6.0 KB, free: 2004.5 MB)
17/12/19 17:52:55 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:996
17/12/19 17:52:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[177] at collect at utils.scala:196)
17/12/19 17:52:55 INFO TaskSchedulerImpl: Adding task set 84.0 with 2 tasks
17/12/19 17:52:55 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/19 17:52:55 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 62, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/19 17:52:55 INFO Executor: Running task 1.0 in stage 84.0 (TID 62)
17/12/19 17:52:55 INFO Executor: Running task 0.0 in stage 84.0 (TID 61)
17/12/19 17:52:55 INFO BlockManager: Found block rdd_167_0 locally
17/12/19 17:52:55 INFO BlockManager: Found block rdd_167_1 locally
17/12/19 17:52:56 INFO Executor: Finished task 0.0 in stage 84.0 (TID 61). 1950 bytes result sent to driver
17/12/19 17:52:56 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 61) in 20 ms on localhost (executor driver) (1/2)
17/12/19 17:52:56 INFO Executor: Finished task 1.0 in stage 84.0 (TID 62). 1950 bytes result sent to driver
17/12/19 17:52:56 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 62) in 21 ms on localhost (executor driver) (2/2)
17/12/19 17:52:56 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
17/12/19 17:52:56 INFO DAGScheduler: ShuffleMapStage 84 (collect at utils.scala:196) finished in 0.021 s
17/12/19 17:52:56 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:52:56 INFO DAGScheduler: running: Set()
17/12/19 17:52:56 INFO DAGScheduler: waiting: Set(ResultStage 85)
17/12/19 17:52:56 INFO DAGScheduler: failed: Set()
17/12/19 17:52:56 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[180] at collect at utils.scala:196), which has no missing parents
17/12/19 17:52:56 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 7.0 KB, free 2003.3 MB)
17/12/19 17:52:56 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2003.3 MB)
17/12/19 17:52:56 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:56751 (size: 3.7 KB, free: 2004.5 MB)
17/12/19 17:52:56 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:996
17/12/19 17:52:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[180] at collect at utils.scala:196)
17/12/19 17:52:56 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks
17/12/19 17:52:56 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 63, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/19 17:52:56 INFO Executor: Running task 0.0 in stage 85.0 (TID 63)
17/12/19 17:52:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 17:52:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:52:56 INFO Executor: Finished task 0.0 in stage 85.0 (TID 63). 1873 bytes result sent to driver
17/12/19 17:52:56 INFO DAGScheduler: ResultStage 85 (collect at utils.scala:196) finished in 0.005 s
17/12/19 17:52:56 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 63) in 3 ms on localhost (executor driver) (1/1)
17/12/19 17:52:56 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
17/12/19 17:52:56 INFO DAGScheduler: Job 40 finished: collect at utils.scala:196, took 0.021040 s
17/12/19 17:52:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz29`
WHERE (0 = 1)
17/12/19 17:52:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:56 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`
FROM (SELECT `S1`, `S2`, `S3`, `S3` + 0.91651514 * RANDN() AS `V1`, `S2` + 0.93273791 * RANDN() AS `V2`, `S2` + 0.93273791 * RANDN() AS `V3`, `S2` + 0.93273791 * RANDN() AS `V4`, `S1` + 0.92195445 * RANDN() AS `V5`, `S2` + 0.93273791 * RANDN() AS `V6`, `S3` + 0.91651514 * RANDN() AS `V7`, `S2` + 0.93273791 * RANDN() AS `V8`, `S3` + 0.91651514 * RANDN() AS `V9`, `S3` + 0.91651514 * RANDN() AS `V10`
FROM `analyis_tbl`) `pwpoubbqfj`
17/12/19 17:52:56 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:52:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz30`
WHERE (0 = 1)
17/12/19 17:52:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 17:52:56 INFO CodeGenerator: Code generated in 12.010858 ms
17/12/19 17:52:56 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 17:52:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 145 bytes
17/12/19 17:52:56 INFO DAGScheduler: Got job 41 (take at <unknown>:0) with 1 output partitions
17/12/19 17:52:56 INFO DAGScheduler: Final stage: ResultStage 87 (take at <unknown>:0)
17/12/19 17:52:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 86)
17/12/19 17:52:56 INFO DAGScheduler: Missing parents: List()
17/12/19 17:52:56 INFO DAGScheduler: Submitting ResultStage 87 (WorkerRDD[186] at RDD at rdd.scala:18), which has no missing parents
17/12/19 17:52:56 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 131.1 KB, free 2003.1 MB)
17/12/19 17:52:56 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 51.7 KB, free 2003.1 MB)
17/12/19 17:52:56 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:56751 (size: 51.7 KB, free: 2004.4 MB)
17/12/19 17:52:56 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:996
17/12/19 17:52:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (WorkerRDD[186] at RDD at rdd.scala:18)
17/12/19 17:52:56 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks
17/12/19 17:52:56 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 17:52:56 INFO Executor: Running task 0.0 in stage 87.0 (TID 64)
17/12/19 17:52:56 INFO BlockManager: Found block rdd_167_0 locally
17/12/19 17:52:56 INFO MemoryStore: Block rdd_186_0 stored as values in memory (estimated size 1600.0 B, free 2003.1 MB)
17/12/19 17:52:56 INFO BlockManagerInfo: Added rdd_186_0 in memory on 127.0.0.1:56751 (size: 1600.0 B, free: 2004.4 MB)
17/12/19 17:52:56 INFO Executor: Finished task 0.0 in stage 87.0 (TID 64). 3003 bytes result sent to driver
17/12/19 17:52:56 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 64) in 638 ms on localhost (executor driver) (1/1)
17/12/19 17:52:56 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
17/12/19 17:52:56 INFO DAGScheduler: ResultStage 87 (take at <unknown>:0) finished in 0.638 s
17/12/19 17:52:56 INFO DAGScheduler: Job 41 finished: take at <unknown>:0, took 0.651999 s
17/12/19 17:52:56 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 17:52:56 INFO DAGScheduler: Got job 42 (take at <unknown>:0) with 1 output partitions
17/12/19 17:52:56 INFO DAGScheduler: Final stage: ResultStage 89 (take at <unknown>:0)
17/12/19 17:52:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)
17/12/19 17:52:56 INFO DAGScheduler: Missing parents: List()
17/12/19 17:52:56 INFO DAGScheduler: Submitting ResultStage 89 (WorkerRDD[186] at RDD at rdd.scala:18), which has no missing parents
17/12/19 17:52:56 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 131.1 KB, free 2003.0 MB)
17/12/19 17:52:56 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 51.7 KB, free 2002.9 MB)
17/12/19 17:52:56 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:56751 (size: 51.7 KB, free: 2004.4 MB)
17/12/19 17:52:56 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:996
17/12/19 17:52:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (WorkerRDD[186] at RDD at rdd.scala:18)
17/12/19 17:52:56 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks
17/12/19 17:52:56 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 17:52:56 INFO Executor: Running task 0.0 in stage 89.0 (TID 65)
17/12/19 17:52:56 INFO BlockManager: Found block rdd_167_1 locally
17/12/19 17:52:57 INFO MemoryStore: Block rdd_186_1 stored as values in memory (estimated size 1600.0 B, free 2002.9 MB)
17/12/19 17:52:57 INFO BlockManagerInfo: Added rdd_186_1 in memory on 127.0.0.1:56751 (size: 1600.0 B, free: 2004.4 MB)
17/12/19 17:52:57 WARN Executor: 1 block locks were not released by TID = 65:
[rdd_186_1]
17/12/19 17:52:57 INFO Executor: Finished task 0.0 in stage 89.0 (TID 65). 3003 bytes result sent to driver
17/12/19 17:52:57 INFO DAGScheduler: ResultStage 89 (take at <unknown>:0) finished in 0.649 s
17/12/19 17:52:57 INFO DAGScheduler: Job 42 finished: take at <unknown>:0, took 0.645705 s
17/12/19 17:52:57 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 65) in 649 ms on localhost (executor driver) (1/1)
17/12/19 17:52:57 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
17/12/19 17:52:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:57 INFO SparkSqlParser: Parsing command: sparklyr_tmp_225019b94e0f
17/12/19 17:52:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_225019b94e0f` AS `zzz31`
WHERE (0 = 1)
17/12/19 17:52:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_225019b94e0f`
17/12/19 17:52:57 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:52:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz32`
WHERE (0 = 1)
17/12/19 17:52:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:57 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.054) AS `V1`, (`V2` < 0.0055) AS `V2`, (`V3` < 0.0045) AS `V3`, (`V4` < 0.009) AS `V4`, (`V5` < 0.054) AS `V5`, (`V6` < 0.15) AS `V6`, (`V7` < 0.1) AS `V7`, (`V8` < 0.0035) AS `V8`, (`V9` < 3e-04) AS `V9`, (`V10` < 0.0055) AS `V10`
FROM `analyis_tbl`
17/12/19 17:52:57 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:52:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz33`
WHERE (0 = 1)
17/12/19 17:52:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 17:52:57 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:52:57 INFO DAGScheduler: Got job 43 (collect at utils.scala:196) with 2 output partitions
17/12/19 17:52:57 INFO DAGScheduler: Final stage: ResultStage 91 (collect at utils.scala:196)
17/12/19 17:52:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)
17/12/19 17:52:57 INFO DAGScheduler: Missing parents: List()
17/12/19 17:52:57 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[193] at collect at utils.scala:196), which has no missing parents
17/12/19 17:52:57 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 143.9 KB, free 2002.8 MB)
17/12/19 17:52:57 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 56.0 KB, free 2002.7 MB)
17/12/19 17:52:57 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:56751 (size: 56.0 KB, free: 2004.3 MB)
17/12/19 17:52:57 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:996
17/12/19 17:52:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 91 (MapPartitionsRDD[193] at collect at utils.scala:196)
17/12/19 17:52:57 INFO TaskSchedulerImpl: Adding task set 91.0 with 2 tasks
17/12/19 17:52:57 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/19 17:52:57 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 67, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/19 17:52:57 INFO Executor: Running task 0.0 in stage 91.0 (TID 66)
17/12/19 17:52:57 INFO Executor: Running task 1.0 in stage 91.0 (TID 67)
17/12/19 17:52:57 INFO BlockManager: Found block rdd_186_0 locally
17/12/19 17:52:57 INFO BlockManager: Found block rdd_186_1 locally
17/12/19 17:52:57 INFO Executor: Finished task 0.0 in stage 91.0 (TID 66). 1466 bytes result sent to driver
17/12/19 17:52:57 INFO Executor: Finished task 1.0 in stage 91.0 (TID 67). 1456 bytes result sent to driver
17/12/19 17:52:57 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 66) in 0 ms on localhost (executor driver) (1/2)
17/12/19 17:52:57 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 67) in 0 ms on localhost (executor driver) (2/2)
17/12/19 17:52:57 INFO DAGScheduler: ResultStage 91 (collect at utils.scala:196) finished in 0.000 s
17/12/19 17:52:57 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
17/12/19 17:52:57 INFO DAGScheduler: Job 43 finished: collect at utils.scala:196, took 0.016401 s
17/12/19 17:52:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:52:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:52:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:52:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:52:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:52:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:52:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:52:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:52:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:52:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:52:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:52:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:52:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:52:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:52:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:52:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:52:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:52:57 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:52:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:52:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:52:57 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:52:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:52:58 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:52:58 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:52:58 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:52:58 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:52:58 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:52:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:52:58 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:57:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:57:01 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:57:01 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:57:01 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:57:01 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:57:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:57:01 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:57:01 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 17:57:01 INFO DAGScheduler: Got job 44 (collect at utils.scala:58) with 1 output partitions
17/12/19 17:57:01 INFO DAGScheduler: Final stage: ResultStage 92 (collect at utils.scala:58)
17/12/19 17:57:01 INFO DAGScheduler: Parents of final stage: List()
17/12/19 17:57:01 INFO DAGScheduler: Missing parents: List()
17/12/19 17:57:01 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[203] at map at utils.scala:55), which has no missing parents
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 8.7 KB, free 2002.7 MB)
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2002.7 MB)
17/12/19 17:57:01 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:56751 (size: 4.6 KB, free: 2004.3 MB)
17/12/19 17:57:01 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:996
17/12/19 17:57:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[203] at map at utils.scala:55)
17/12/19 17:57:01 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
17/12/19 17:57:01 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 6719 bytes)
17/12/19 17:57:01 INFO Executor: Running task 0.0 in stage 92.0 (TID 68)
17/12/19 17:57:01 INFO Executor: Finished task 0.0 in stage 92.0 (TID 68). 1048 bytes result sent to driver
17/12/19 17:57:01 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 68) in 0 ms on localhost (executor driver) (1/1)
17/12/19 17:57:01 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
17/12/19 17:57:01 INFO DAGScheduler: ResultStage 92 (collect at utils.scala:58) finished in 0.000 s
17/12/19 17:57:01 INFO DAGScheduler: Job 44 finished: collect at utils.scala:58, took 0.007444 s
17/12/19 17:57:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:01 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:57:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:01 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 17:57:01 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 17:57:01 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 17:57:01 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 17:57:01 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 17:57:01 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 293.7 KB, free 2002.4 MB)
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2002.4 MB)
17/12/19 17:57:01 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:56751 (size: 24.0 KB, free: 2004.3 MB)
17/12/19 17:57:01 INFO SparkContext: Created broadcast 61 from sql at <unknown>:0
17/12/19 17:57:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 17:57:01 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 17:57:01 INFO DAGScheduler: Registering RDD 207 (sql at <unknown>:0)
17/12/19 17:57:01 INFO DAGScheduler: Registering RDD 212 (sql at <unknown>:0)
17/12/19 17:57:01 INFO DAGScheduler: Got job 45 (sql at <unknown>:0) with 1 output partitions
17/12/19 17:57:01 INFO DAGScheduler: Final stage: ResultStage 95 (sql at <unknown>:0)
17/12/19 17:57:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 94)
17/12/19 17:57:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 94)
17/12/19 17:57:01 INFO DAGScheduler: Submitting ShuffleMapStage 93 (MapPartitionsRDD[207] at sql at <unknown>:0), which has no missing parents
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 12.1 KB, free 2002.4 MB)
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2002.4 MB)
17/12/19 17:57:01 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:56751 (size: 7.3 KB, free: 2004.3 MB)
17/12/19 17:57:01 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:996
17/12/19 17:57:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 93 (MapPartitionsRDD[207] at sql at <unknown>:0)
17/12/19 17:57:01 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks
17/12/19 17:57:01 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/12/19 17:57:01 INFO Executor: Running task 0.0 in stage 93.0 (TID 69)
17/12/19 17:57:01 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpwLtPOg/spark_serialize_bfee02325681221ca18e3dbb33f3db2815a1a5d8ddc7e26818d08b9f191c4b7a.csv, range: 0-585, partition values: [empty row]
17/12/19 17:57:01 INFO Executor: Finished task 0.0 in stage 93.0 (TID 69). 1632 bytes result sent to driver
17/12/19 17:57:01 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 69) in 32 ms on localhost (executor driver) (1/1)
17/12/19 17:57:01 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
17/12/19 17:57:01 INFO DAGScheduler: ShuffleMapStage 93 (sql at <unknown>:0) finished in 0.032 s
17/12/19 17:57:01 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:57:01 INFO DAGScheduler: running: Set()
17/12/19 17:57:01 INFO DAGScheduler: waiting: Set(ShuffleMapStage 94, ResultStage 95)
17/12/19 17:57:01 INFO DAGScheduler: failed: Set()
17/12/19 17:57:01 INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[212] at sql at <unknown>:0), which has no missing parents
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 11.9 KB, free 2002.4 MB)
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2002.4 MB)
17/12/19 17:57:01 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:56751 (size: 6.0 KB, free: 2004.3 MB)
17/12/19 17:57:01 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:996
17/12/19 17:57:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[212] at sql at <unknown>:0)
17/12/19 17:57:01 INFO TaskSchedulerImpl: Adding task set 94.0 with 2 tasks
17/12/19 17:57:01 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 70, localhost, executor driver, partition 0, ANY, 5944 bytes)
17/12/19 17:57:01 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 71, localhost, executor driver, partition 1, ANY, 5944 bytes)
17/12/19 17:57:01 INFO Executor: Running task 0.0 in stage 94.0 (TID 70)
17/12/19 17:57:01 INFO Executor: Running task 1.0 in stage 94.0 (TID 71)
17/12/19 17:57:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 17:57:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 17:57:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:57:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:57:01 INFO MemoryStore: Block rdd_209_0 stored as values in memory (estimated size 568.0 B, free 2002.4 MB)
17/12/19 17:57:01 INFO MemoryStore: Block rdd_209_1 stored as values in memory (estimated size 568.0 B, free 2002.4 MB)
17/12/19 17:57:01 INFO BlockManagerInfo: Added rdd_209_0 in memory on 127.0.0.1:56751 (size: 568.0 B, free: 2004.3 MB)
17/12/19 17:57:01 INFO BlockManagerInfo: Added rdd_209_1 in memory on 127.0.0.1:56751 (size: 568.0 B, free: 2004.3 MB)
17/12/19 17:57:01 INFO Executor: Finished task 1.0 in stage 94.0 (TID 71). 2985 bytes result sent to driver
17/12/19 17:57:01 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 71) in 15 ms on localhost (executor driver) (1/2)
17/12/19 17:57:01 INFO Executor: Finished task 0.0 in stage 94.0 (TID 70). 3064 bytes result sent to driver
17/12/19 17:57:01 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 70) in 15 ms on localhost (executor driver) (2/2)
17/12/19 17:57:01 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
17/12/19 17:57:01 INFO DAGScheduler: ShuffleMapStage 94 (sql at <unknown>:0) finished in 0.015 s
17/12/19 17:57:01 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:57:01 INFO DAGScheduler: running: Set()
17/12/19 17:57:01 INFO DAGScheduler: waiting: Set(ResultStage 95)
17/12/19 17:57:01 INFO DAGScheduler: failed: Set()
17/12/19 17:57:01 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[215] at sql at <unknown>:0), which has no missing parents
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 7.0 KB, free 2002.3 MB)
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.3 MB)
17/12/19 17:57:01 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:56751 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 17:57:01 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:996
17/12/19 17:57:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[215] at sql at <unknown>:0)
17/12/19 17:57:01 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks
17/12/19 17:57:01 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 72, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/12/19 17:57:01 INFO Executor: Running task 0.0 in stage 95.0 (TID 72)
17/12/19 17:57:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 17:57:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:57:01 INFO Executor: Finished task 0.0 in stage 95.0 (TID 72). 1707 bytes result sent to driver
17/12/19 17:57:01 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 72) in 0 ms on localhost (executor driver) (1/1)
17/12/19 17:57:01 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
17/12/19 17:57:01 INFO DAGScheduler: ResultStage 95 (sql at <unknown>:0) finished in 0.000 s
17/12/19 17:57:01 INFO DAGScheduler: Job 45 finished: sql at <unknown>:0, took 0.051756 s
17/12/19 17:57:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:01 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 17:57:01 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:57:01 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 145 bytes
17/12/19 17:57:01 INFO DAGScheduler: Registering RDD 219 (collect at utils.scala:196)
17/12/19 17:57:01 INFO DAGScheduler: Got job 46 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:57:01 INFO DAGScheduler: Final stage: ResultStage 98 (collect at utils.scala:196)
17/12/19 17:57:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)
17/12/19 17:57:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 97)
17/12/19 17:57:01 INFO DAGScheduler: Submitting ShuffleMapStage 97 (MapPartitionsRDD[219] at collect at utils.scala:196), which has no missing parents
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 11.9 KB, free 2002.3 MB)
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2002.3 MB)
17/12/19 17:57:01 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:56751 (size: 6.0 KB, free: 2004.3 MB)
17/12/19 17:57:01 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:996
17/12/19 17:57:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 97 (MapPartitionsRDD[219] at collect at utils.scala:196)
17/12/19 17:57:01 INFO TaskSchedulerImpl: Adding task set 97.0 with 2 tasks
17/12/19 17:57:01 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 5936 bytes)
17/12/19 17:57:01 INFO TaskSetManager: Starting task 1.0 in stage 97.0 (TID 74, localhost, executor driver, partition 1, PROCESS_LOCAL, 5936 bytes)
17/12/19 17:57:01 INFO Executor: Running task 1.0 in stage 97.0 (TID 74)
17/12/19 17:57:01 INFO Executor: Running task 0.0 in stage 97.0 (TID 73)
17/12/19 17:57:01 INFO BlockManager: Found block rdd_209_1 locally
17/12/19 17:57:01 INFO BlockManager: Found block rdd_209_0 locally
17/12/19 17:57:01 INFO Executor: Finished task 0.0 in stage 97.0 (TID 73). 1950 bytes result sent to driver
17/12/19 17:57:01 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 73) in 16 ms on localhost (executor driver) (1/2)
17/12/19 17:57:01 INFO Executor: Finished task 1.0 in stage 97.0 (TID 74). 1950 bytes result sent to driver
17/12/19 17:57:01 INFO TaskSetManager: Finished task 1.0 in stage 97.0 (TID 74) in 16 ms on localhost (executor driver) (2/2)
17/12/19 17:57:01 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
17/12/19 17:57:01 INFO DAGScheduler: ShuffleMapStage 97 (collect at utils.scala:196) finished in 0.016 s
17/12/19 17:57:01 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:57:01 INFO DAGScheduler: running: Set()
17/12/19 17:57:01 INFO DAGScheduler: waiting: Set(ResultStage 98)
17/12/19 17:57:01 INFO DAGScheduler: failed: Set()
17/12/19 17:57:01 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[222] at collect at utils.scala:196), which has no missing parents
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 7.0 KB, free 2002.3 MB)
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2002.3 MB)
17/12/19 17:57:01 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:56751 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 17:57:01 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:996
17/12/19 17:57:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[222] at collect at utils.scala:196)
17/12/19 17:57:01 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks
17/12/19 17:57:01 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 75, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/12/19 17:57:01 INFO Executor: Running task 0.0 in stage 98.0 (TID 75)
17/12/19 17:57:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 17:57:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:57:01 INFO Executor: Finished task 0.0 in stage 98.0 (TID 75). 1707 bytes result sent to driver
17/12/19 17:57:01 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 75) in 0 ms on localhost (executor driver) (1/1)
17/12/19 17:57:01 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
17/12/19 17:57:01 INFO DAGScheduler: ResultStage 98 (collect at utils.scala:196) finished in 0.000 s
17/12/19 17:57:01 INFO DAGScheduler: Job 46 finished: collect at utils.scala:196, took 0.029516 s
17/12/19 17:57:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz34`
WHERE (0 = 1)
17/12/19 17:57:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:01 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`
FROM (SELECT `S1`, `S2`, `S3`, `S3` + 0.91651514 * RANDN() AS `V1`, `S2` + 0.93273791 * RANDN() AS `V2`, `S2` + 0.93273791 * RANDN() AS `V3`, `S2` + 0.93273791 * RANDN() AS `V4`, `S1` + 0.92195445 * RANDN() AS `V5`, `S2` + 0.93273791 * RANDN() AS `V6`, `S3` + 0.91651514 * RANDN() AS `V7`, `S2` + 0.93273791 * RANDN() AS `V8`, `S3` + 0.91651514 * RANDN() AS `V9`, `S3` + 0.91651514 * RANDN() AS `V10`
FROM `analyis_tbl`) `qhnncdnlbn`
17/12/19 17:57:01 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:57:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz35`
WHERE (0 = 1)
17/12/19 17:57:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 17:57:01 INFO CodeGenerator: Code generated in 12.158492 ms
17/12/19 17:57:01 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 17:57:01 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 145 bytes
17/12/19 17:57:01 INFO DAGScheduler: Got job 47 (take at <unknown>:0) with 1 output partitions
17/12/19 17:57:01 INFO DAGScheduler: Final stage: ResultStage 100 (take at <unknown>:0)
17/12/19 17:57:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 99)
17/12/19 17:57:01 INFO DAGScheduler: Missing parents: List()
17/12/19 17:57:01 INFO DAGScheduler: Submitting ResultStage 100 (WorkerRDD[228] at RDD at rdd.scala:18), which has no missing parents
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 131.3 KB, free 2002.2 MB)
17/12/19 17:57:01 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 51.9 KB, free 2002.1 MB)
17/12/19 17:57:01 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:56751 (size: 51.9 KB, free: 2004.2 MB)
17/12/19 17:57:01 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:996
17/12/19 17:57:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (WorkerRDD[228] at RDD at rdd.scala:18)
17/12/19 17:57:01 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
17/12/19 17:57:01 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 17:57:01 INFO Executor: Running task 0.0 in stage 100.0 (TID 76)
17/12/19 17:57:01 INFO BlockManager: Found block rdd_209_0 locally
17/12/19 17:57:02 INFO MemoryStore: Block rdd_228_0 stored as values in memory (estimated size 1600.0 B, free 2002.1 MB)
17/12/19 17:57:02 INFO BlockManagerInfo: Added rdd_228_0 in memory on 127.0.0.1:56751 (size: 1600.0 B, free: 2004.2 MB)
17/12/19 17:57:02 INFO Executor: Finished task 0.0 in stage 100.0 (TID 76). 3003 bytes result sent to driver
17/12/19 17:57:02 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 76) in 703 ms on localhost (executor driver) (1/1)
17/12/19 17:57:02 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
17/12/19 17:57:02 INFO DAGScheduler: ResultStage 100 (take at <unknown>:0) finished in 0.704 s
17/12/19 17:57:02 INFO DAGScheduler: Job 47 finished: take at <unknown>:0, took 0.709722 s
17/12/19 17:57:02 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 17:57:02 INFO DAGScheduler: Got job 48 (take at <unknown>:0) with 1 output partitions
17/12/19 17:57:02 INFO DAGScheduler: Final stage: ResultStage 102 (take at <unknown>:0)
17/12/19 17:57:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 101)
17/12/19 17:57:02 INFO DAGScheduler: Missing parents: List()
17/12/19 17:57:02 INFO DAGScheduler: Submitting ResultStage 102 (WorkerRDD[228] at RDD at rdd.scala:18), which has no missing parents
17/12/19 17:57:02 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 131.3 KB, free 2002.0 MB)
17/12/19 17:57:02 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 51.9 KB, free 2002.0 MB)
17/12/19 17:57:02 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:56751 (size: 51.9 KB, free: 2004.1 MB)
17/12/19 17:57:02 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:996
17/12/19 17:57:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (WorkerRDD[228] at RDD at rdd.scala:18)
17/12/19 17:57:02 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
17/12/19 17:57:02 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 77, localhost, executor driver, partition 1, PROCESS_LOCAL, 5914 bytes)
17/12/19 17:57:02 INFO Executor: Running task 0.0 in stage 102.0 (TID 77)
17/12/19 17:57:02 INFO BlockManager: Found block rdd_209_1 locally
17/12/19 17:57:03 INFO MemoryStore: Block rdd_228_1 stored as values in memory (estimated size 1600.0 B, free 2002.0 MB)
17/12/19 17:57:03 INFO BlockManagerInfo: Added rdd_228_1 in memory on 127.0.0.1:56751 (size: 1600.0 B, free: 2004.1 MB)
17/12/19 17:57:03 WARN Executor: 1 block locks were not released by TID = 77:
[rdd_228_1]
17/12/19 17:57:03 INFO Executor: Finished task 0.0 in stage 102.0 (TID 77). 3003 bytes result sent to driver
17/12/19 17:57:03 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 77) in 630 ms on localhost (executor driver) (1/1)
17/12/19 17:57:03 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
17/12/19 17:57:03 INFO DAGScheduler: ResultStage 102 (take at <unknown>:0) finished in 0.630 s
17/12/19 17:57:03 INFO DAGScheduler: Job 48 finished: take at <unknown>:0, took 0.636062 s
17/12/19 17:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:03 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2250692534b
17/12/19 17:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2250692534b` AS `zzz36`
WHERE (0 = 1)
17/12/19 17:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2250692534b`
17/12/19 17:57:03 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz37`
WHERE (0 = 1)
17/12/19 17:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:03 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.054) AS `V1`, (`V2` < 0.0055) AS `V2`, (`V3` < 0.0045) AS `V3`, (`V4` < 0.009) AS `V4`, (`V5` < 0.054) AS `V5`, (`V6` < 0.15) AS `V6`, (`V7` < 0.1) AS `V7`, (`V8` < 0.0035) AS `V8`, (`V9` < 3e-04) AS `V9`, (`V10` < 0.0055) AS `V10`
FROM `analyis_tbl`
17/12/19 17:57:03 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz38`
WHERE (0 = 1)
17/12/19 17:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 17:57:03 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:57:03 INFO DAGScheduler: Got job 49 (collect at utils.scala:196) with 2 output partitions
17/12/19 17:57:03 INFO DAGScheduler: Final stage: ResultStage 104 (collect at utils.scala:196)
17/12/19 17:57:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 103)
17/12/19 17:57:03 INFO DAGScheduler: Missing parents: List()
17/12/19 17:57:03 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[235] at collect at utils.scala:196), which has no missing parents
17/12/19 17:57:03 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 144.1 KB, free 2001.8 MB)
17/12/19 17:57:03 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 56.3 KB, free 2001.8 MB)
17/12/19 17:57:03 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:56751 (size: 56.3 KB, free: 2004.1 MB)
17/12/19 17:57:03 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:996
17/12/19 17:57:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 104 (MapPartitionsRDD[235] at collect at utils.scala:196)
17/12/19 17:57:03 INFO TaskSchedulerImpl: Adding task set 104.0 with 2 tasks
17/12/19 17:57:03 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/19 17:57:03 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 79, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/19 17:57:03 INFO Executor: Running task 0.0 in stage 104.0 (TID 78)
17/12/19 17:57:03 INFO Executor: Running task 1.0 in stage 104.0 (TID 79)
17/12/19 17:57:03 INFO BlockManager: Found block rdd_228_1 locally
17/12/19 17:57:03 INFO BlockManager: Found block rdd_228_0 locally
17/12/19 17:57:03 INFO Executor: Finished task 1.0 in stage 104.0 (TID 79). 1460 bytes result sent to driver
17/12/19 17:57:03 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 79) in 0 ms on localhost (executor driver) (1/2)
17/12/19 17:57:03 INFO Executor: Finished task 0.0 in stage 104.0 (TID 78). 1440 bytes result sent to driver
17/12/19 17:57:03 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 78) in 0 ms on localhost (executor driver) (2/2)
17/12/19 17:57:03 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
17/12/19 17:57:03 INFO DAGScheduler: ResultStage 104 (collect at utils.scala:196) finished in 0.000 s
17/12/19 17:57:03 INFO DAGScheduler: Job 49 finished: collect at utils.scala:196, took 0.014008 s
17/12/19 17:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:57:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:57:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:57:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:57:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:57:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:57:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:57:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:57:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:57:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:57:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:57:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:57:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:57:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:57:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:57:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:57:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:57:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:57:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:57:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:57:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:57:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:57:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:57:03 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:57:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:57:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:57:03 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:58:25 INFO SparkContext: Invoking stop() from shutdown hook
17/12/19 17:58:25 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/19 17:58:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/19 17:58:25 INFO MemoryStore: MemoryStore cleared
17/12/19 17:58:25 INFO BlockManager: BlockManager stopped
17/12/19 17:58:25 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/19 17:58:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/19 17:58:25 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-b0a511e3-5f4e-4cc8-8d22-d13cd327c07e\userFiles-269948d3-a9e3-4c2d-8e48-29bebf0fdf63
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-b0a511e3-5f4e-4cc8-8d22-d13cd327c07e\userFiles-269948d3-a9e3-4c2d-8e48-29bebf0fdf63
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 17:58:25 INFO SparkContext: Successfully stopped SparkContext
17/12/19 17:58:25 INFO ShutdownHookManager: Shutdown hook called
17/12/19 17:58:25 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-b0a511e3-5f4e-4cc8-8d22-d13cd327c07e
17/12/19 17:58:25 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-b0a511e3-5f4e-4cc8-8d22-d13cd327c07e
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-b0a511e3-5f4e-4cc8-8d22-d13cd327c07e
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 17:58:25 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-b0a511e3-5f4e-4cc8-8d22-d13cd327c07e\userFiles-269948d3-a9e3-4c2d-8e48-29bebf0fdf63
17/12/19 17:58:25 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-b0a511e3-5f4e-4cc8-8d22-d13cd327c07e\userFiles-269948d3-a9e3-4c2d-8e48-29bebf0fdf63
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-b0a511e3-5f4e-4cc8-8d22-d13cd327c07e\userFiles-269948d3-a9e3-4c2d-8e48-29bebf0fdf63
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 17:58:33 INFO SparkContext: Running Spark version 2.1.0
17/12/19 17:58:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/19 17:58:33 INFO SecurityManager: Changing view acls to: conan
17/12/19 17:58:33 INFO SecurityManager: Changing modify acls to: conan
17/12/19 17:58:33 INFO SecurityManager: Changing view acls groups to: 
17/12/19 17:58:33 INFO SecurityManager: Changing modify acls groups to: 
17/12/19 17:58:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(conan); groups with view permissions: Set(); users  with modify permissions: Set(conan); groups with modify permissions: Set()
17/12/19 17:58:33 INFO Utils: Successfully started service 'sparkDriver' on port 57183.
17/12/19 17:58:33 INFO SparkEnv: Registering MapOutputTracker
17/12/19 17:58:34 INFO SparkEnv: Registering BlockManagerMaster
17/12/19 17:58:34 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/19 17:58:34 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/19 17:58:34 INFO DiskBlockManager: Created local directory at C:\Users\conan\AppData\Local\Temp\blockmgr-baece9d9-8b3e-4509-a8e9-04ee7e921054
17/12/19 17:58:34 INFO MemoryStore: MemoryStore started with capacity 2004.6 MB
17/12/19 17:58:34 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/19 17:58:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/19 17:58:34 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/19 17:58:34 INFO SparkContext: Added JAR file:/C:/Users/conan/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:57183/jars/sparklyr-2.1-2.11.jar with timestamp 1513706314344
17/12/19 17:58:34 INFO Executor: Starting executor ID driver on host localhost
17/12/19 17:58:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57204.
17/12/19 17:58:34 INFO NettyBlockTransferService: Server created on 127.0.0.1:57204
17/12/19 17:58:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/19 17:58:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 57204, None)
17/12/19 17:58:34 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:57204 with 2004.6 MB RAM, BlockManagerId(driver, 127.0.0.1, 57204, None)
17/12/19 17:58:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 57204, None)
17/12/19 17:58:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 57204, None)
17/12/19 17:58:34 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/19 17:58:35 INFO SharedState: Warehouse path is 'C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/19 17:58:35 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/19 17:58:35 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/19 17:58:35 INFO ObjectStore: ObjectStore, initialize called
17/12/19 17:58:35 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/19 17:58:35 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/19 17:58:37 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/19 17:58:38 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 17:58:38 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 17:58:38 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 17:58:38 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 17:58:38 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/19 17:58:38 INFO ObjectStore: Initialized ObjectStore
17/12/19 17:58:38 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/19 17:58:39 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/19 17:58:39 INFO HiveMetaStore: Added admin role in metastore
17/12/19 17:58:39 INFO HiveMetaStore: Added public role in metastore
17/12/19 17:58:39 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/19 17:58:39 INFO HiveMetaStore: 0: get_all_databases
17/12/19 17:58:39 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/19 17:58:39 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/19 17:58:39 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/19 17:58:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 17:58:39 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/Temp/cf2b71b9-13ca-4e60-8e1a-c6ed19b94225_resources
17/12/19 17:58:39 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/cf2b71b9-13ca-4e60-8e1a-c6ed19b94225
17/12/19 17:58:39 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/cf2b71b9-13ca-4e60-8e1a-c6ed19b94225
17/12/19 17:58:39 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/cf2b71b9-13ca-4e60-8e1a-c6ed19b94225/_tmp_space.db
17/12/19 17:58:39 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/19 17:58:39 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:58:39 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:58:39 INFO HiveMetaStore: 0: get_database: global_temp
17/12/19 17:58:39 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/19 17:58:39 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/19 17:58:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:58:41 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:58:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:58:41 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:58:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:58:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:58:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:58:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:58:42 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:58:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:58:42 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:58:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:58:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:58:42 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:58:43 INFO CodeGenerator: Code generated in 251.578195 ms
17/12/19 17:58:43 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 17:58:43 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/19 17:58:43 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/19 17:58:43 INFO DAGScheduler: Parents of final stage: List()
17/12/19 17:58:43 INFO DAGScheduler: Missing parents: List()
17/12/19 17:58:43 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/12/19 17:58:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 2004.6 MB)
17/12/19 17:58:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2004.6 MB)
17/12/19 17:58:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:57204 (size: 4.6 KB, free: 2004.6 MB)
17/12/19 17:58:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/19 17:58:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/12/19 17:58:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/19 17:58:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/19 17:58:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/19 17:58:43 INFO Executor: Fetching spark://127.0.0.1:57183/jars/sparklyr-2.1-2.11.jar with timestamp 1513706314344
17/12/19 17:58:43 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:57183 after 15 ms (0 ms spent in bootstraps)
17/12/19 17:58:43 INFO Utils: Fetching spark://127.0.0.1:57183/jars/sparklyr-2.1-2.11.jar to C:\Users\conan\AppData\Local\Temp\spark-a5009d24-b320-4b18-a57a-7e66bdc934a6\userFiles-5d1f862d-feff-42f8-b19b-3ad6078423fc\fetchFileTemp6296372374716156955.tmp
17/12/19 17:58:43 INFO Executor: Adding file:/C:/Users/conan/AppData/Local/Temp/spark-a5009d24-b320-4b18-a57a-7e66bdc934a6/userFiles-5d1f862d-feff-42f8-b19b-3ad6078423fc/sparklyr-2.1-2.11.jar to class loader
17/12/19 17:58:43 INFO CodeGenerator: Code generated in 14.386221 ms
17/12/19 17:58:44 INFO CodeGenerator: Code generated in 12.309902 ms
17/12/19 17:58:44 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/12/19 17:58:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 323 ms on localhost (executor driver) (1/1)
17/12/19 17:58:44 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.334 s
17/12/19 17:58:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/19 17:58:44 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.537735 s
17/12/19 17:58:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:44 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:58:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:44 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 17:58:44 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 17:58:44 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 17:58:44 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 17:58:44 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 17:58:44 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 17:58:44 INFO CodeGenerator: Code generated in 7.235588 ms
17/12/19 17:58:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.7 KB, free 2004.3 MB)
17/12/19 17:58:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2004.3 MB)
17/12/19 17:58:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:57204 (size: 24.0 KB, free: 2004.6 MB)
17/12/19 17:58:44 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/19 17:58:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 17:58:44 INFO CodeGenerator: Code generated in 13.371661 ms
17/12/19 17:58:44 INFO CodeGenerator: Code generated in 11.563424 ms
17/12/19 17:58:44 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 17:58:44 INFO DAGScheduler: Registering RDD 10 (sql at <unknown>:0)
17/12/19 17:58:44 INFO DAGScheduler: Registering RDD 15 (sql at <unknown>:0)
17/12/19 17:58:44 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/19 17:58:44 INFO DAGScheduler: Final stage: ResultStage 3 (sql at <unknown>:0)
17/12/19 17:58:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/12/19 17:58:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/12/19 17:58:44 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0), which has no missing parents
17/12/19 17:58:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.1 KB, free 2004.3 MB)
17/12/19 17:58:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2004.3 MB)
17/12/19 17:58:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:57204 (size: 7.3 KB, free: 2004.6 MB)
17/12/19 17:58:44 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/19 17:58:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0)
17/12/19 17:58:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/19 17:58:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/19 17:58:44 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/19 17:58:44 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpwLtPOg/spark_serialize_8ec1e5d3aeb9c95d73e1b8c3c3e41923602e48a3c49222c40e29f0e645f0db12.csv, range: 0-568690, partition values: [empty row]
17/12/19 17:58:44 INFO CodeGenerator: Code generated in 8.293949 ms
17/12/19 17:58:45 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1632 bytes result sent to driver
17/12/19 17:58:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 285 ms on localhost (executor driver) (1/1)
17/12/19 17:58:45 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/19 17:58:45 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.301 s
17/12/19 17:58:45 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:58:45 INFO DAGScheduler: running: Set()
17/12/19 17:58:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/12/19 17:58:45 INFO DAGScheduler: failed: Set()
17/12/19 17:58:45 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/19 17:58:45 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.9 KB, free 2004.3 MB)
17/12/19 17:58:45 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:57204 in memory (size: 4.6 KB, free: 2004.6 MB)
17/12/19 17:58:45 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2004.3 MB)
17/12/19 17:58:45 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:57204 (size: 6.0 KB, free: 2004.6 MB)
17/12/19 17:58:45 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/19 17:58:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/19 17:58:45 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 50
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 51
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 57
17/12/19 17:58:45 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5942 bytes)
17/12/19 17:58:45 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5942 bytes)
17/12/19 17:58:45 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/19 17:58:45 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
17/12/19 17:58:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 17:58:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 17:58:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:58:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:58:45 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 117.7 KB, free 2004.1 MB)
17/12/19 17:58:45 INFO MemoryStore: Block rdd_12_1 stored as values in memory (estimated size 117.7 KB, free 2004.0 MB)
17/12/19 17:58:45 INFO BlockManagerInfo: Added rdd_12_0 in memory on 127.0.0.1:57204 (size: 117.7 KB, free: 2004.4 MB)
17/12/19 17:58:45 INFO BlockManagerInfo: Added rdd_12_1 in memory on 127.0.0.1:57204 (size: 117.7 KB, free: 2004.3 MB)
17/12/19 17:58:45 INFO CodeGenerator: Code generated in 5.00144 ms
17/12/19 17:58:45 INFO CodeGenerator: Code generated in 20.051827 ms
17/12/19 17:58:45 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 3064 bytes result sent to driver
17/12/19 17:58:45 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 3241 bytes result sent to driver
17/12/19 17:58:45 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 157 ms on localhost (executor driver) (1/2)
17/12/19 17:58:45 INFO DAGScheduler: ShuffleMapStage 2 (sql at <unknown>:0) finished in 0.188 s
17/12/19 17:58:45 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:58:45 INFO DAGScheduler: running: Set()
17/12/19 17:58:45 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/12/19 17:58:45 INFO DAGScheduler: failed: Set()
17/12/19 17:58:45 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
17/12/19 17:58:45 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 188 ms on localhost (executor driver) (2/2)
17/12/19 17:58:45 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/19 17:58:45 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 2004.0 MB)
17/12/19 17:58:45 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.0 MB)
17/12/19 17:58:45 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:57204 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 17:58:45 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/19 17:58:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0)
17/12/19 17:58:45 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/19 17:58:45 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/19 17:58:45 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
17/12/19 17:58:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 17:58:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:58:45 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 1707 bytes result sent to driver
17/12/19 17:58:45 INFO DAGScheduler: ResultStage 3 (sql at <unknown>:0) finished in 0.015 s
17/12/19 17:58:45 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.554984 s
17/12/19 17:58:45 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 15 ms on localhost (executor driver) (1/1)
17/12/19 17:58:45 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/19 17:58:45 INFO CodeGenerator: Code generated in 7.251069 ms
17/12/19 17:58:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:45 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 17:58:45 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:58:45 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/19 17:58:45 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:196)
17/12/19 17:58:45 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/12/19 17:58:45 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:196)
17/12/19 17:58:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/12/19 17:58:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/12/19 17:58:45 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
17/12/19 17:58:45 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.9 KB, free 2004.0 MB)
17/12/19 17:58:45 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2004.0 MB)
17/12/19 17:58:45 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:57204 (size: 6.0 KB, free: 2004.3 MB)
17/12/19 17:58:45 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/19 17:58:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196)
17/12/19 17:58:45 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
17/12/19 17:58:45 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5934 bytes)
17/12/19 17:58:45 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 5934 bytes)
17/12/19 17:58:45 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/19 17:58:45 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/12/19 17:58:45 INFO BlockManager: Found block rdd_12_0 locally
17/12/19 17:58:45 INFO BlockManager: Found block rdd_12_1 locally
17/12/19 17:58:45 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1879 bytes result sent to driver
17/12/19 17:58:45 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 15 ms on localhost (executor driver) (1/2)
17/12/19 17:58:45 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 1969 bytes result sent to driver
17/12/19 17:58:45 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 31 ms on localhost (executor driver) (2/2)
17/12/19 17:58:45 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:196) finished in 0.031 s
17/12/19 17:58:45 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/19 17:58:45 INFO DAGScheduler: looking for newly runnable stages
17/12/19 17:58:45 INFO DAGScheduler: running: Set()
17/12/19 17:58:45 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/12/19 17:58:45 INFO DAGScheduler: failed: Set()
17/12/19 17:58:45 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196), which has no missing parents
17/12/19 17:58:45 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 2004.0 MB)
17/12/19 17:58:45 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.0 MB)
17/12/19 17:58:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:57204 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 17:58:45 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/12/19 17:58:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196)
17/12/19 17:58:45 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/19 17:58:45 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/19 17:58:45 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
17/12/19 17:58:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 17:58:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 17:58:45 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1707 bytes result sent to driver
17/12/19 17:58:45 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 0 ms on localhost (executor driver) (1/1)
17/12/19 17:58:45 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/19 17:58:45 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:196) finished in 0.000 s
17/12/19 17:58:45 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.048039 s
17/12/19 17:58:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz39`
WHERE (0 = 1)
17/12/19 17:58:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:45 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`
FROM (SELECT `S1`, `S2`, `S3`, `S3` + 0.91104336 * RANDN() AS `V1`, `S3` + 0.91104336 * RANDN() AS `V2`, `S1` + 0.9486833 * RANDN() AS `V3`, `S3` + 0.91104336 * RANDN() AS `V4`, `S2` + 0.93273791 * RANDN() AS `V5`, `S2` + 0.93273791 * RANDN() AS `V6`, `S3` + 0.91104336 * RANDN() AS `V7`, `S1` + 0.9486833 * RANDN() AS `V8`, `S1` + 0.9486833 * RANDN() AS `V9`, `S2` + 0.93273791 * RANDN() AS `V10`
FROM `analyis_tbl`) `tooevtgfva`
17/12/19 17:58:45 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:57204 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 58
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 59
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 60
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 61
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 62
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 63
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 64
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 65
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 66
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 67
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 68
17/12/19 17:58:45 INFO ContextCleaner: Cleaned accumulator 69
17/12/19 17:58:45 INFO ContextCleaner: Cleaned shuffle 1
17/12/19 17:58:46 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:57204 in memory (size: 7.3 KB, free: 2004.3 MB)
17/12/19 17:58:46 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:58:46 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:57204 in memory (size: 6.0 KB, free: 2004.3 MB)
17/12/19 17:58:46 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:57204 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/19 17:58:46 INFO ContextCleaner: Cleaned accumulator 238
17/12/19 17:58:46 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:57204 in memory (size: 6.0 KB, free: 2004.3 MB)
17/12/19 17:58:46 INFO ContextCleaner: Cleaned accumulator 1
17/12/19 17:58:46 INFO ContextCleaner: Cleaned accumulator 0
17/12/19 17:58:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz40`
WHERE (0 = 1)
17/12/19 17:58:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 17:58:46 INFO CodeGenerator: Code generated in 19.381242 ms
17/12/19 17:58:46 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 17:58:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/19 17:58:46 INFO DAGScheduler: Got job 3 (take at <unknown>:0) with 1 output partitions
17/12/19 17:58:46 INFO DAGScheduler: Final stage: ResultStage 8 (take at <unknown>:0)
17/12/19 17:58:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/12/19 17:58:46 INFO DAGScheduler: Missing parents: List()
17/12/19 17:58:46 INFO DAGScheduler: Submitting ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18), which has no missing parents
17/12/19 17:58:46 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 365.4 KB, free 2003.7 MB)
17/12/19 17:58:46 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 286.3 KB, free 2003.4 MB)
17/12/19 17:58:46 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:57204 (size: 286.3 KB, free: 2004.1 MB)
17/12/19 17:58:46 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/12/19 17:58:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18)
17/12/19 17:58:46 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/19 17:58:46 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5913 bytes)
17/12/19 17:58:46 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/12/19 17:58:46 INFO BlockManager: Found block rdd_12_0 locally
17/12/19 17:58:46 INFO CodeGenerator: Code generated in 20.916865 ms
17/12/19 17:58:46 INFO CodeGenerator: Code generated in 12.821902 ms
17/12/19 17:58:49 INFO MemoryStore: Block rdd_31_0 stored as values in memory (estimated size 1543.0 KB, free 2001.9 MB)
17/12/19 17:58:49 INFO BlockManagerInfo: Added rdd_31_0 in memory on 127.0.0.1:57204 (size: 1543.0 KB, free: 2002.6 MB)
17/12/19 17:58:49 WARN Executor: 1 block locks were not released by TID = 8:
[rdd_31_0]
17/12/19 17:58:49 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 4129 bytes result sent to driver
17/12/19 17:58:49 INFO DAGScheduler: ResultStage 8 (take at <unknown>:0) finished in 3.332 s
17/12/19 17:58:49 INFO DAGScheduler: Job 3 finished: take at <unknown>:0, took 3.330154 s
17/12/19 17:58:49 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 3332 ms on localhost (executor driver) (1/1)
17/12/19 17:58:49 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/19 17:58:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:49 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2250117d14d1
17/12/19 17:58:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2250117d14d1` AS `zzz41`
WHERE (0 = 1)
17/12/19 17:58:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2250117d14d1`
17/12/19 17:58:49 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:58:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz42`
WHERE (0 = 1)
17/12/19 17:58:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:49 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.0055) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0055) AS `V3`, (`V4` < 0.0028) AS `V4`, (`V5` < 0.0055) AS `V5`, (`V6` < 0.009) AS `V6`, (`V7` < 0.0185) AS `V7`, (`V8` < 0.009) AS `V8`, (`V9` < 0.075) AS `V9`, (`V10` < 0.0045) AS `V10`
FROM `analyis_tbl`
17/12/19 17:58:49 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 17:58:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz43`
WHERE (0 = 1)
17/12/19 17:58:49 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 17:58:49 INFO CodeGenerator: Code generated in 18.595496 ms
17/12/19 17:58:49 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 17:58:49 INFO DAGScheduler: Got job 4 (collect at utils.scala:196) with 2 output partitions
17/12/19 17:58:49 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:196)
17/12/19 17:58:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
17/12/19 17:58:49 INFO DAGScheduler: Missing parents: List()
17/12/19 17:58:49 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196), which has no missing parents
17/12/19 17:58:49 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 378.2 KB, free 2001.5 MB)
17/12/19 17:58:49 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 290.7 KB, free 2001.3 MB)
17/12/19 17:58:49 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:57204 (size: 290.7 KB, free: 2002.3 MB)
17/12/19 17:58:49 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/12/19 17:58:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196)
17/12/19 17:58:49 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks
17/12/19 17:58:49 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5945 bytes)
17/12/19 17:58:49 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 5945 bytes)
17/12/19 17:58:49 INFO Executor: Running task 1.0 in stage 10.0 (TID 10)
17/12/19 17:58:49 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
17/12/19 17:58:49 INFO BlockManager: Found block rdd_12_1 locally
17/12/19 17:58:49 INFO BlockManager: Found block rdd_31_0 locally
17/12/19 17:58:49 INFO CodeGenerator: Code generated in 10.877359 ms
17/12/19 17:58:49 INFO CodeGenerator: Code generated in 63.290159 ms
17/12/19 17:58:50 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 13503 bytes result sent to driver
17/12/19 17:58:50 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 165 ms on localhost (executor driver) (1/2)
17/12/19 17:58:53 INFO MemoryStore: Block rdd_31_1 stored as values in memory (estimated size 1543.0 KB, free 1999.8 MB)
17/12/19 17:58:53 INFO BlockManagerInfo: Added rdd_31_1 in memory on 127.0.0.1:57204 (size: 1543.0 KB, free: 2000.8 MB)
17/12/19 17:58:53 INFO Executor: Finished task 1.0 in stage 10.0 (TID 10). 14588 bytes result sent to driver
17/12/19 17:58:53 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 10) in 3189 ms on localhost (executor driver) (2/2)
17/12/19 17:58:53 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/19 17:58:53 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:196) finished in 3.205 s
17/12/19 17:58:53 INFO DAGScheduler: Job 4 finished: collect at utils.scala:196, took 3.203725 s
17/12/19 17:58:53 INFO CodeGenerator: Code generated in 9.091777 ms
17/12/19 17:58:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:53 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:58:53 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:58:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:58:53 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:58:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:58:53 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:58:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:58:53 INFO CodeGenerator: Code generated in 6.97619 ms
17/12/19 17:58:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:53 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:58:53 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:58:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:58:53 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:58:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:58:53 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:58:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:58:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:53 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:58:53 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:58:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:58:53 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:58:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:58:53 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:58:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 17:58:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 17:58:53 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 17:58:53 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:58:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:58:53 INFO HiveMetaStore: 0: get_database: default
17/12/19 17:58:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 17:58:53 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 17:58:53 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 18:01:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:27 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 18:01:27 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:01:27 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:01:27 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:01:27 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:01:27 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 18:01:27 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 18:01:27 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 18:01:27 INFO DAGScheduler: Got job 5 (collect at utils.scala:58) with 1 output partitions
17/12/19 18:01:27 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:58)
17/12/19 18:01:27 INFO DAGScheduler: Parents of final stage: List()
17/12/19 18:01:27 INFO DAGScheduler: Missing parents: List()
17/12/19 18:01:27 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[48] at map at utils.scala:55), which has no missing parents
17/12/19 18:01:27 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 8.7 KB, free 1999.7 MB)
17/12/19 18:01:27 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1999.7 MB)
17/12/19 18:01:27 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:57204 (size: 4.6 KB, free: 2000.8 MB)
17/12/19 18:01:27 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/12/19 18:01:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[48] at map at utils.scala:55)
17/12/19 18:01:27 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/12/19 18:01:27 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6432 bytes)
17/12/19 18:01:27 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
17/12/19 18:01:27 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1096 bytes result sent to driver
17/12/19 18:01:27 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:58) finished in 0.028 s
17/12/19 18:01:27 INFO DAGScheduler: Job 5 finished: collect at utils.scala:58, took 0.024152 s
17/12/19 18:01:27 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 28 ms on localhost (executor driver) (1/1)
17/12/19 18:01:27 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/12/19 18:01:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:27 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 18:01:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:27 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 18:01:27 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 18:01:27 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 18:01:27 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 18:01:27 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 18:01:27 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 18:01:27 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 293.7 KB, free 1999.5 MB)
17/12/19 18:01:27 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:57204 in memory (size: 286.3 KB, free: 2001.0 MB)
17/12/19 18:01:27 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:57204 in memory (size: 290.7 KB, free: 2001.3 MB)
17/12/19 18:01:27 INFO ContextCleaner: Cleaned accumulator 495
17/12/19 18:01:27 INFO ContextCleaner: Cleaned accumulator 496
17/12/19 18:01:27 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:57204 in memory (size: 4.6 KB, free: 2001.3 MB)
17/12/19 18:01:27 INFO ContextCleaner: Cleaned accumulator 545
17/12/19 18:01:27 INFO ContextCleaner: Cleaned accumulator 546
17/12/19 18:01:27 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2000.7 MB)
17/12/19 18:01:27 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:57204 (size: 24.0 KB, free: 2001.3 MB)
17/12/19 18:01:27 INFO SparkContext: Created broadcast 10 from sql at <unknown>:0
17/12/19 18:01:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 18:01:27 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 18:01:27 INFO DAGScheduler: Registering RDD 52 (sql at <unknown>:0)
17/12/19 18:01:27 INFO DAGScheduler: Registering RDD 57 (sql at <unknown>:0)
17/12/19 18:01:27 INFO DAGScheduler: Got job 6 (sql at <unknown>:0) with 1 output partitions
17/12/19 18:01:27 INFO DAGScheduler: Final stage: ResultStage 14 (sql at <unknown>:0)
17/12/19 18:01:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/12/19 18:01:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/12/19 18:01:27 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[52] at sql at <unknown>:0), which has no missing parents
17/12/19 18:01:27 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 12.1 KB, free 2000.7 MB)
17/12/19 18:01:27 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2000.7 MB)
17/12/19 18:01:27 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:57204 (size: 7.3 KB, free: 2001.3 MB)
17/12/19 18:01:27 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/12/19 18:01:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[52] at sql at <unknown>:0)
17/12/19 18:01:27 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/12/19 18:01:27 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6677 bytes)
17/12/19 18:01:27 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
17/12/19 18:01:27 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpwLtPOg/spark_serialize_30d31e0e791b75c70e3204c7dcda7624b2e348805bff37ec6d2ad2a10e6fd8a4.csv, range: 0-568102, partition values: [empty row]
17/12/19 18:01:28 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1632 bytes result sent to driver
17/12/19 18:01:28 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 93 ms on localhost (executor driver) (1/1)
17/12/19 18:01:28 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/12/19 18:01:28 INFO DAGScheduler: ShuffleMapStage 12 (sql at <unknown>:0) finished in 0.093 s
17/12/19 18:01:28 INFO DAGScheduler: looking for newly runnable stages
17/12/19 18:01:28 INFO DAGScheduler: running: Set()
17/12/19 18:01:28 INFO DAGScheduler: waiting: Set(ShuffleMapStage 13, ResultStage 14)
17/12/19 18:01:28 INFO DAGScheduler: failed: Set()
17/12/19 18:01:28 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[57] at sql at <unknown>:0), which has no missing parents
17/12/19 18:01:28 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 11.9 KB, free 2000.7 MB)
17/12/19 18:01:28 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2000.7 MB)
17/12/19 18:01:28 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:57204 (size: 6.0 KB, free: 2001.3 MB)
17/12/19 18:01:28 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/12/19 18:01:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[57] at sql at <unknown>:0)
17/12/19 18:01:28 INFO TaskSchedulerImpl: Adding task set 13.0 with 2 tasks
17/12/19 18:01:28 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, ANY, 5943 bytes)
17/12/19 18:01:28 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 14, localhost, executor driver, partition 1, ANY, 5943 bytes)
17/12/19 18:01:28 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
17/12/19 18:01:28 INFO Executor: Running task 1.0 in stage 13.0 (TID 14)
17/12/19 18:01:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 18:01:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 18:01:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 18:01:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 18:01:28 INFO MemoryStore: Block rdd_54_0 stored as values in memory (estimated size 117.7 KB, free 2000.6 MB)
17/12/19 18:01:28 INFO BlockManagerInfo: Added rdd_54_0 in memory on 127.0.0.1:57204 (size: 117.7 KB, free: 2001.2 MB)
17/12/19 18:01:28 INFO MemoryStore: Block rdd_54_1 stored as values in memory (estimated size 117.7 KB, free 2000.5 MB)
17/12/19 18:01:28 INFO BlockManagerInfo: Added rdd_54_1 in memory on 127.0.0.1:57204 (size: 117.7 KB, free: 2001.1 MB)
17/12/19 18:01:28 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2985 bytes result sent to driver
17/12/19 18:01:28 INFO Executor: Finished task 1.0 in stage 13.0 (TID 14). 3064 bytes result sent to driver
17/12/19 18:01:28 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 47 ms on localhost (executor driver) (1/2)
17/12/19 18:01:28 INFO DAGScheduler: ShuffleMapStage 13 (sql at <unknown>:0) finished in 0.047 s
17/12/19 18:01:28 INFO DAGScheduler: looking for newly runnable stages
17/12/19 18:01:28 INFO DAGScheduler: running: Set()
17/12/19 18:01:28 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/12/19 18:01:28 INFO DAGScheduler: failed: Set()
17/12/19 18:01:28 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[60] at sql at <unknown>:0), which has no missing parents
17/12/19 18:01:28 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.0 KB, free 2000.5 MB)
17/12/19 18:01:28 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 14) in 47 ms on localhost (executor driver) (2/2)
17/12/19 18:01:28 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/12/19 18:01:28 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2000.5 MB)
17/12/19 18:01:28 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:57204 (size: 3.7 KB, free: 2001.1 MB)
17/12/19 18:01:28 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/12/19 18:01:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[60] at sql at <unknown>:0)
17/12/19 18:01:28 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/12/19 18:01:28 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, ANY, 5954 bytes)
17/12/19 18:01:28 INFO Executor: Running task 0.0 in stage 14.0 (TID 15)
17/12/19 18:01:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 18:01:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 18:01:28 INFO Executor: Finished task 0.0 in stage 14.0 (TID 15). 1707 bytes result sent to driver
17/12/19 18:01:28 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 15) in 16 ms on localhost (executor driver) (1/1)
17/12/19 18:01:28 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/12/19 18:01:28 INFO DAGScheduler: ResultStage 14 (sql at <unknown>:0) finished in 0.016 s
17/12/19 18:01:28 INFO DAGScheduler: Job 6 finished: sql at <unknown>:0, took 0.157927 s
17/12/19 18:01:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:28 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 18:01:28 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 18:01:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 145 bytes
17/12/19 18:01:28 INFO DAGScheduler: Registering RDD 64 (collect at utils.scala:196)
17/12/19 18:01:28 INFO DAGScheduler: Got job 7 (collect at utils.scala:196) with 1 output partitions
17/12/19 18:01:28 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:196)
17/12/19 18:01:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
17/12/19 18:01:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
17/12/19 18:01:28 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[64] at collect at utils.scala:196), which has no missing parents
17/12/19 18:01:28 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 11.9 KB, free 2000.4 MB)
17/12/19 18:01:28 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2000.4 MB)
17/12/19 18:01:28 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:57204 (size: 6.0 KB, free: 2001.1 MB)
17/12/19 18:01:28 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/12/19 18:01:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[64] at collect at utils.scala:196)
17/12/19 18:01:28 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks
17/12/19 18:01:28 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5935 bytes)
17/12/19 18:01:28 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 17, localhost, executor driver, partition 1, PROCESS_LOCAL, 5935 bytes)
17/12/19 18:01:28 INFO Executor: Running task 1.0 in stage 16.0 (TID 17)
17/12/19 18:01:28 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
17/12/19 18:01:28 INFO BlockManager: Found block rdd_54_1 locally
17/12/19 18:01:28 INFO BlockManager: Found block rdd_54_0 locally
17/12/19 18:01:28 INFO Executor: Finished task 1.0 in stage 16.0 (TID 17). 1871 bytes result sent to driver
17/12/19 18:01:28 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1950 bytes result sent to driver
17/12/19 18:01:28 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 17) in 15 ms on localhost (executor driver) (1/2)
17/12/19 18:01:28 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 15 ms on localhost (executor driver) (2/2)
17/12/19 18:01:28 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/12/19 18:01:28 INFO DAGScheduler: ShuffleMapStage 16 (collect at utils.scala:196) finished in 0.015 s
17/12/19 18:01:28 INFO DAGScheduler: looking for newly runnable stages
17/12/19 18:01:28 INFO DAGScheduler: running: Set()
17/12/19 18:01:28 INFO DAGScheduler: waiting: Set(ResultStage 17)
17/12/19 18:01:28 INFO DAGScheduler: failed: Set()
17/12/19 18:01:28 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[67] at collect at utils.scala:196), which has no missing parents
17/12/19 18:01:28 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 2000.4 MB)
17/12/19 18:01:28 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2000.4 MB)
17/12/19 18:01:28 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:57204 (size: 3.7 KB, free: 2001.1 MB)
17/12/19 18:01:28 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/12/19 18:01:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[67] at collect at utils.scala:196)
17/12/19 18:01:28 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/12/19 18:01:28 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 18:01:28 INFO Executor: Running task 0.0 in stage 17.0 (TID 18)
17/12/19 18:01:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 18:01:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 18:01:28 INFO Executor: Finished task 0.0 in stage 17.0 (TID 18). 1865 bytes result sent to driver
17/12/19 18:01:28 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:196) finished in 0.020 s
17/12/19 18:01:28 INFO DAGScheduler: Job 7 finished: collect at utils.scala:196, took 0.038474 s
17/12/19 18:01:28 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 19 ms on localhost (executor driver) (1/1)
17/12/19 18:01:28 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/12/19 18:01:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz44`
WHERE (0 = 1)
17/12/19 18:01:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:28 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`
FROM (SELECT `S1`, `S2`, `S3`, `S2` + 0.92736185 * RANDN() AS `V1`, `S3` + 0.93273791 * RANDN() AS `V2`, `S3` + 0.93273791 * RANDN() AS `V3`, `S2` + 0.92736185 * RANDN() AS `V4`, `S2` + 0.92736185 * RANDN() AS `V5`, `S3` + 0.93273791 * RANDN() AS `V6`, `S2` + 0.92736185 * RANDN() AS `V7`, `S1` + 0.9 * RANDN() AS `V8`, `S2` + 0.92736185 * RANDN() AS `V9`, `S3` + 0.93273791 * RANDN() AS `V10`
FROM `analyis_tbl`) `qwqotyjimu`
17/12/19 18:01:28 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 18:01:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz45`
WHERE (0 = 1)
17/12/19 18:01:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 18:01:28 INFO CodeGenerator: Code generated in 12.85513 ms
17/12/19 18:01:28 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 18:01:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 145 bytes
17/12/19 18:01:28 INFO DAGScheduler: Got job 8 (take at <unknown>:0) with 1 output partitions
17/12/19 18:01:28 INFO DAGScheduler: Final stage: ResultStage 19 (take at <unknown>:0)
17/12/19 18:01:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
17/12/19 18:01:28 INFO DAGScheduler: Missing parents: List()
17/12/19 18:01:28 INFO DAGScheduler: Submitting ResultStage 19 (WorkerRDD[73] at RDD at rdd.scala:18), which has no missing parents
17/12/19 18:01:28 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 365.4 KB, free 2000.1 MB)
17/12/19 18:01:28 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 286.4 KB, free 1999.8 MB)
17/12/19 18:01:28 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:57204 (size: 286.4 KB, free: 2000.8 MB)
17/12/19 18:01:28 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/12/19 18:01:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (WorkerRDD[73] at RDD at rdd.scala:18)
17/12/19 18:01:28 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/12/19 18:01:28 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 18:01:28 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
17/12/19 18:01:28 INFO BlockManager: Found block rdd_54_0 locally
17/12/19 18:01:31 INFO MemoryStore: Block rdd_73_0 stored as values in memory (estimated size 1543.0 KB, free 1998.3 MB)
17/12/19 18:01:31 INFO BlockManagerInfo: Added rdd_73_0 in memory on 127.0.0.1:57204 (size: 1543.0 KB, free: 1999.3 MB)
17/12/19 18:01:31 WARN Executor: 1 block locks were not released by TID = 19:
[rdd_73_0]
17/12/19 18:01:31 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 3952 bytes result sent to driver
17/12/19 18:01:31 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 3009 ms on localhost (executor driver) (1/1)
17/12/19 18:01:31 INFO DAGScheduler: ResultStage 19 (take at <unknown>:0) finished in 3.009 s
17/12/19 18:01:31 INFO DAGScheduler: Job 8 finished: take at <unknown>:0, took 3.033272 s
17/12/19 18:01:31 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/12/19 18:01:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:31 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2250a71862
17/12/19 18:01:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2250a71862` AS `zzz46`
WHERE (0 = 1)
17/12/19 18:01:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2250a71862`
17/12/19 18:01:31 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 18:01:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz47`
WHERE (0 = 1)
17/12/19 18:01:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:31 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.3) AS `V1`, (`V2` < 0.0375) AS `V2`, (`V3` < 0.0045) AS `V3`, (`V4` < 0.0023) AS `V4`, (`V5` < 0.0138) AS `V5`, (`V6` < 0.15) AS `V6`, (`V7` < 0.009) AS `V7`, (`V8` < 0.054) AS `V8`, (`V9` < 0.0028) AS `V9`, (`V10` < 0.0138) AS `V10`
FROM `analyis_tbl`
17/12/19 18:01:31 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 18:01:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz48`
WHERE (0 = 1)
17/12/19 18:01:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 18:01:31 INFO CodeGenerator: Code generated in 14.567838 ms
17/12/19 18:01:31 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 18:01:31 INFO DAGScheduler: Got job 9 (collect at utils.scala:196) with 2 output partitions
17/12/19 18:01:31 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:196)
17/12/19 18:01:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
17/12/19 18:01:31 INFO DAGScheduler: Missing parents: List()
17/12/19 18:01:31 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[80] at collect at utils.scala:196), which has no missing parents
17/12/19 18:01:31 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 378.2 KB, free 1997.9 MB)
17/12/19 18:01:31 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 290.9 KB, free 1997.6 MB)
17/12/19 18:01:31 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:57204 (size: 290.9 KB, free: 1999.0 MB)
17/12/19 18:01:31 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/12/19 18:01:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[80] at collect at utils.scala:196)
17/12/19 18:01:31 INFO TaskSchedulerImpl: Adding task set 21.0 with 2 tasks
17/12/19 18:01:31 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/19 18:01:31 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/19 18:01:31 INFO Executor: Running task 0.0 in stage 21.0 (TID 20)
17/12/19 18:01:31 INFO Executor: Running task 1.0 in stage 21.0 (TID 21)
17/12/19 18:01:31 INFO BlockManager: Found block rdd_73_0 locally
17/12/19 18:01:31 INFO BlockManager: Found block rdd_54_1 locally
17/12/19 18:01:31 INFO Executor: Finished task 0.0 in stage 21.0 (TID 20). 30672 bytes result sent to driver
17/12/19 18:01:31 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 20) in 61 ms on localhost (executor driver) (1/2)
17/12/19 18:01:34 INFO MemoryStore: Block rdd_73_1 stored as values in memory (estimated size 1543.0 KB, free 1996.1 MB)
17/12/19 18:01:34 INFO BlockManagerInfo: Added rdd_73_1 in memory on 127.0.0.1:57204 (size: 1543.0 KB, free: 1997.5 MB)
17/12/19 18:01:34 INFO Executor: Finished task 1.0 in stage 21.0 (TID 21). 30900 bytes result sent to driver
17/12/19 18:01:34 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 21) in 3064 ms on localhost (executor driver) (2/2)
17/12/19 18:01:34 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/12/19 18:01:34 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:196) finished in 3.064 s
17/12/19 18:01:34 INFO DAGScheduler: Job 9 finished: collect at utils.scala:196, took 3.088194 s
17/12/19 18:01:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 18:01:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:01:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:01:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:01:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:01:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 18:01:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 18:01:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 18:01:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:01:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:01:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:01:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:01:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 18:01:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 18:01:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 18:01:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:01:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:01:34 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:01:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:01:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 18:01:34 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 18:01:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:01:35 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 18:01:35 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:01:35 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:01:35 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:01:35 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:01:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 18:01:35 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 18:03:43 INFO SparkContext: Invoking stop() from shutdown hook
17/12/19 18:03:43 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/19 18:03:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/19 18:03:43 INFO MemoryStore: MemoryStore cleared
17/12/19 18:03:43 INFO BlockManager: BlockManager stopped
17/12/19 18:03:43 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/19 18:03:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/19 18:03:43 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-a5009d24-b320-4b18-a57a-7e66bdc934a6\userFiles-5d1f862d-feff-42f8-b19b-3ad6078423fc
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-a5009d24-b320-4b18-a57a-7e66bdc934a6\userFiles-5d1f862d-feff-42f8-b19b-3ad6078423fc
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 18:03:43 INFO SparkContext: Successfully stopped SparkContext
17/12/19 18:03:43 INFO ShutdownHookManager: Shutdown hook called
17/12/19 18:03:43 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-a5009d24-b320-4b18-a57a-7e66bdc934a6\userFiles-5d1f862d-feff-42f8-b19b-3ad6078423fc
17/12/19 18:03:43 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-a5009d24-b320-4b18-a57a-7e66bdc934a6\userFiles-5d1f862d-feff-42f8-b19b-3ad6078423fc
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-a5009d24-b320-4b18-a57a-7e66bdc934a6\userFiles-5d1f862d-feff-42f8-b19b-3ad6078423fc
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 18:03:43 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-a5009d24-b320-4b18-a57a-7e66bdc934a6
17/12/19 18:03:43 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-a5009d24-b320-4b18-a57a-7e66bdc934a6
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-a5009d24-b320-4b18-a57a-7e66bdc934a6
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 18:04:31 INFO SparkContext: Running Spark version 2.1.0
17/12/19 18:04:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/19 18:04:31 INFO SecurityManager: Changing view acls to: conan
17/12/19 18:04:31 INFO SecurityManager: Changing modify acls to: conan
17/12/19 18:04:31 INFO SecurityManager: Changing view acls groups to: 
17/12/19 18:04:31 INFO SecurityManager: Changing modify acls groups to: 
17/12/19 18:04:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(conan); groups with view permissions: Set(); users  with modify permissions: Set(conan); groups with modify permissions: Set()
17/12/19 18:04:31 INFO Utils: Successfully started service 'sparkDriver' on port 57352.
17/12/19 18:04:31 INFO SparkEnv: Registering MapOutputTracker
17/12/19 18:04:31 INFO SparkEnv: Registering BlockManagerMaster
17/12/19 18:04:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/19 18:04:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/19 18:04:31 INFO DiskBlockManager: Created local directory at C:\Users\conan\AppData\Local\Temp\blockmgr-b5d6124a-3ba2-464f-ac9c-cc69618acbee
17/12/19 18:04:31 INFO MemoryStore: MemoryStore started with capacity 2004.6 MB
17/12/19 18:04:31 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/19 18:04:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/19 18:04:32 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/12/19 18:04:32 INFO SparkContext: Added JAR file:/C:/Users/conan/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:57352/jars/sparklyr-2.1-2.11.jar with timestamp 1513706672048
17/12/19 18:04:32 INFO Executor: Starting executor ID driver on host localhost
17/12/19 18:04:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57373.
17/12/19 18:04:32 INFO NettyBlockTransferService: Server created on 127.0.0.1:57373
17/12/19 18:04:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/19 18:04:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 57373, None)
17/12/19 18:04:32 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:57373 with 2004.6 MB RAM, BlockManagerId(driver, 127.0.0.1, 57373, None)
17/12/19 18:04:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 57373, None)
17/12/19 18:04:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 57373, None)
17/12/19 18:04:32 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/12/19 18:04:32 INFO SharedState: Warehouse path is 'C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/12/19 18:04:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/12/19 18:04:33 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/12/19 18:04:33 INFO ObjectStore: ObjectStore, initialize called
17/12/19 18:04:33 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/12/19 18:04:33 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/12/19 18:04:34 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/12/19 18:04:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 18:04:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 18:04:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 18:04:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 18:04:36 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/12/19 18:04:36 INFO ObjectStore: Initialized ObjectStore
17/12/19 18:04:36 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/12/19 18:04:36 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/12/19 18:04:37 INFO HiveMetaStore: Added admin role in metastore
17/12/19 18:04:37 INFO HiveMetaStore: Added public role in metastore
17/12/19 18:04:37 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/12/19 18:04:37 INFO HiveMetaStore: 0: get_all_databases
17/12/19 18:04:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_all_databases	
17/12/19 18:04:37 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/12/19 18:04:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/12/19 18:04:37 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/12/19 18:04:37 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/Temp/77dabcfa-26ef-4248-aec4-5038ee9bc041_resources
17/12/19 18:04:37 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/77dabcfa-26ef-4248-aec4-5038ee9bc041
17/12/19 18:04:37 INFO SessionState: Created local directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/77dabcfa-26ef-4248-aec4-5038ee9bc041
17/12/19 18:04:37 INFO SessionState: Created HDFS directory: C:/Users/conan/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/conan/77dabcfa-26ef-4248-aec4-5038ee9bc041/_tmp_space.db
17/12/19 18:04:37 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersconanAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/12/19 18:04:37 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:04:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:04:37 INFO HiveMetaStore: 0: get_database: global_temp
17/12/19 18:04:37 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/12/19 18:04:37 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/12/19 18:04:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 18:04:39 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:04:39 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:04:39 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:04:39 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:04:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 18:04:39 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 18:04:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:04:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 18:04:41 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:04:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:04:41 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:04:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:04:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 18:04:41 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 18:04:42 INFO CodeGenerator: Code generated in 270.617349 ms
17/12/19 18:04:42 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 18:04:42 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/12/19 18:04:42 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/12/19 18:04:42 INFO DAGScheduler: Parents of final stage: List()
17/12/19 18:04:42 INFO DAGScheduler: Missing parents: List()
17/12/19 18:04:42 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/12/19 18:04:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 2004.6 MB)
17/12/19 18:04:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2004.6 MB)
17/12/19 18:04:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:57373 (size: 4.6 KB, free: 2004.6 MB)
17/12/19 18:04:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/12/19 18:04:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/12/19 18:04:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/12/19 18:04:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/12/19 18:04:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/12/19 18:04:42 INFO Executor: Fetching spark://127.0.0.1:57352/jars/sparklyr-2.1-2.11.jar with timestamp 1513706672048
17/12/19 18:04:42 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:57352 after 16 ms (0 ms spent in bootstraps)
17/12/19 18:04:42 INFO Utils: Fetching spark://127.0.0.1:57352/jars/sparklyr-2.1-2.11.jar to C:\Users\conan\AppData\Local\Temp\spark-9c5e8fd6-4e33-4faa-9b5c-70afbc41fed7\userFiles-750c574a-8bf9-4383-81a6-0b6a77ce0fe0\fetchFileTemp7200624798096922214.tmp
17/12/19 18:04:42 INFO Executor: Adding file:/C:/Users/conan/AppData/Local/Temp/spark-9c5e8fd6-4e33-4faa-9b5c-70afbc41fed7/userFiles-750c574a-8bf9-4383-81a6-0b6a77ce0fe0/sparklyr-2.1-2.11.jar to class loader
17/12/19 18:04:42 INFO CodeGenerator: Code generated in 17.844865 ms
17/12/19 18:04:42 INFO CodeGenerator: Code generated in 14.748699 ms
17/12/19 18:04:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/12/19 18:04:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 325 ms on localhost (executor driver) (1/1)
17/12/19 18:04:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/19 18:04:42 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.353 s
17/12/19 18:04:42 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.518280 s
17/12/19 18:04:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:04:43 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 18:04:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:04:43 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 18:04:43 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 18:04:43 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 18:04:43 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 18:04:43 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double ... 1 more fields>
17/12/19 18:04:43 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 18:04:43 INFO CodeGenerator: Code generated in 8.054562 ms
17/12/19 18:04:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.7 KB, free 2004.3 MB)
17/12/19 18:04:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.0 KB, free 2004.3 MB)
17/12/19 18:04:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:57373 (size: 24.0 KB, free: 2004.6 MB)
17/12/19 18:04:43 INFO SparkContext: Created broadcast 1 from sql at <unknown>:0
17/12/19 18:04:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 18:04:43 INFO CodeGenerator: Code generated in 14.373383 ms
17/12/19 18:04:43 INFO CodeGenerator: Code generated in 11.588722 ms
17/12/19 18:04:43 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 18:04:43 INFO DAGScheduler: Registering RDD 10 (sql at <unknown>:0)
17/12/19 18:04:43 INFO DAGScheduler: Registering RDD 15 (sql at <unknown>:0)
17/12/19 18:04:43 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
17/12/19 18:04:43 INFO DAGScheduler: Final stage: ResultStage 3 (sql at <unknown>:0)
17/12/19 18:04:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/12/19 18:04:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/12/19 18:04:43 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0), which has no missing parents
17/12/19 18:04:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.1 KB, free 2004.3 MB)
17/12/19 18:04:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2004.3 MB)
17/12/19 18:04:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:57373 (size: 7.3 KB, free: 2004.6 MB)
17/12/19 18:04:43 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/12/19 18:04:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at sql at <unknown>:0)
17/12/19 18:04:43 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/12/19 18:04:43 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/12/19 18:04:43 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/12/19 18:04:43 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpwLtPOg/spark_serialize_afa04646cfb9b5d8105c24dc587fd00bac19ea7dc6d7fc34b9045ea65c14539e.csv, range: 0-568560, partition values: [empty row]
17/12/19 18:04:43 INFO CodeGenerator: Code generated in 6.464945 ms
17/12/19 18:04:43 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1632 bytes result sent to driver
17/12/19 18:04:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 247 ms on localhost (executor driver) (1/1)
17/12/19 18:04:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/19 18:04:43 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.247 s
17/12/19 18:04:43 INFO DAGScheduler: looking for newly runnable stages
17/12/19 18:04:43 INFO DAGScheduler: running: Set()
17/12/19 18:04:43 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/12/19 18:04:43 INFO DAGScheduler: failed: Set()
17/12/19 18:04:43 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
17/12/19 18:04:43 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.9 KB, free 2004.2 MB)
17/12/19 18:04:43 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2004.2 MB)
17/12/19 18:04:43 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:57373 (size: 6.0 KB, free: 2004.6 MB)
17/12/19 18:04:43 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/12/19 18:04:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0)
17/12/19 18:04:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
17/12/19 18:04:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5942 bytes)
17/12/19 18:04:43 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5942 bytes)
17/12/19 18:04:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/12/19 18:04:43 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
17/12/19 18:04:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 18:04:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 18:04:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
17/12/19 18:04:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
17/12/19 18:04:44 INFO MemoryStore: Block rdd_12_1 stored as values in memory (estimated size 117.7 KB, free 2004.1 MB)
17/12/19 18:04:44 INFO BlockManagerInfo: Added rdd_12_1 in memory on 127.0.0.1:57373 (size: 117.7 KB, free: 2004.4 MB)
17/12/19 18:04:44 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 117.7 KB, free 2004.0 MB)
17/12/19 18:04:44 INFO BlockManagerInfo: Added rdd_12_0 in memory on 127.0.0.1:57373 (size: 117.7 KB, free: 2004.3 MB)
17/12/19 18:04:44 INFO CodeGenerator: Code generated in 7.135907 ms
17/12/19 18:04:44 INFO CodeGenerator: Code generated in 19.688216 ms
17/12/19 18:04:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 3064 bytes result sent to driver
17/12/19 18:04:44 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 3064 bytes result sent to driver
17/12/19 18:04:44 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 163 ms on localhost (executor driver) (1/2)
17/12/19 18:04:44 INFO DAGScheduler: ShuffleMapStage 2 (sql at <unknown>:0) finished in 0.179 s
17/12/19 18:04:44 INFO DAGScheduler: looking for newly runnable stages
17/12/19 18:04:44 INFO DAGScheduler: running: Set()
17/12/19 18:04:44 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/12/19 18:04:44 INFO DAGScheduler: failed: Set()
17/12/19 18:04:44 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
17/12/19 18:04:44 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 2004.0 MB)
17/12/19 18:04:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 179 ms on localhost (executor driver) (2/2)
17/12/19 18:04:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/12/19 18:04:44 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.0 MB)
17/12/19 18:04:44 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:57373 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 18:04:44 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/12/19 18:04:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0)
17/12/19 18:04:44 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/12/19 18:04:44 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/12/19 18:04:44 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
17/12/19 18:04:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 18:04:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 18:04:44 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 1707 bytes result sent to driver
17/12/19 18:04:44 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 16 ms on localhost (executor driver) (1/1)
17/12/19 18:04:44 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/12/19 18:04:44 INFO DAGScheduler: ResultStage 3 (sql at <unknown>:0) finished in 0.016 s
17/12/19 18:04:44 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.509283 s
17/12/19 18:04:44 INFO CodeGenerator: Code generated in 7.200474 ms
17/12/19 18:04:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:04:44 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 18:04:44 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 18:04:44 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/19 18:04:44 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:196)
17/12/19 18:04:44 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/12/19 18:04:44 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:196)
17/12/19 18:04:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/12/19 18:04:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/12/19 18:04:44 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
17/12/19 18:04:44 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.9 KB, free 2004.0 MB)
17/12/19 18:04:44 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2004.0 MB)
17/12/19 18:04:44 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:57373 (size: 6.0 KB, free: 2004.3 MB)
17/12/19 18:04:44 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/12/19 18:04:44 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[22] at collect at utils.scala:196)
17/12/19 18:04:44 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
17/12/19 18:04:44 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5934 bytes)
17/12/19 18:04:44 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 5934 bytes)
17/12/19 18:04:44 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/12/19 18:04:44 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/12/19 18:04:44 INFO BlockManager: Found block rdd_12_0 locally
17/12/19 18:04:44 INFO BlockManager: Found block rdd_12_1 locally
17/12/19 18:04:44 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1969 bytes result sent to driver
17/12/19 18:04:44 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 31 ms on localhost (executor driver) (1/2)
17/12/19 18:04:44 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 2037 bytes result sent to driver
17/12/19 18:04:44 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 31 ms on localhost (executor driver) (2/2)
17/12/19 18:04:44 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:196) finished in 0.031 s
17/12/19 18:04:44 INFO DAGScheduler: looking for newly runnable stages
17/12/19 18:04:44 INFO DAGScheduler: running: Set()
17/12/19 18:04:44 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/12/19 18:04:44 INFO DAGScheduler: failed: Set()
17/12/19 18:04:44 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/12/19 18:04:44 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196), which has no missing parents
17/12/19 18:04:44 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 2004.0 MB)
17/12/19 18:04:44 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2004.0 MB)
17/12/19 18:04:44 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:57373 (size: 3.7 KB, free: 2004.3 MB)
17/12/19 18:04:44 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/12/19 18:04:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:196)
17/12/19 18:04:44 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/12/19 18:04:44 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/12/19 18:04:44 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
17/12/19 18:04:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 18:04:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 18:04:44 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1707 bytes result sent to driver
17/12/19 18:04:44 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:196) finished in 0.016 s
17/12/19 18:04:44 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.064187 s
17/12/19 18:04:44 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 16 ms on localhost (executor driver) (1/1)
17/12/19 18:04:44 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/12/19 18:04:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:04:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz49`
WHERE (0 = 1)
17/12/19 18:04:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:04:44 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`, `V11` AS `V11`, `V12` AS `V12`, `V13` AS `V13`, `V14` AS `V14`, `V15` AS `V15`, `V16` AS `V16`, `V17` AS `V17`, `V18` AS `V18`, `V19` AS `V19`, `V20` AS `V20`, `V21` AS `V21`, `V22` AS `V22`, `V23` AS `V23`, `V24` AS `V24`, `V25` AS `V25`, `V26` AS `V26`, `V27` AS `V27`, `V28` AS `V28`, `V29` AS `V29`, `V30` AS `V30`, `V31` AS `V31`, `V32` AS `V32`, `V33` AS `V33`, `V34` AS `V34`, `V35` AS `V35`, `V36` AS `V36`, `V37` AS `V37`, `V38` AS `V38`, `V39` AS `V39`, `V40` AS `V40`, `V41` AS `V41`, `V42` AS `V42`, `V43` AS `V43`, `V44` AS `V44`, `V45` AS `V45`, `V46` AS `V46`, `V47` AS `V47`, `V48` AS `V48`, `V49` AS `V49`, `V50` AS `V50`, `V51` AS `V51`, `V52` AS `V52`, `V53` AS `V53`, `V54` AS `V54`, `V55` AS `V55`, `V56` AS `V56`, `V57` AS `V57`, `V58` AS `V58`, `V59` AS `V59`, `V60` AS `V60`, `V61` AS `V61`, `V62` AS `V62`, `V63` AS `V63`, `V64` AS `V64`, `V65` AS `V65`, `V66` AS `V66`, `V67` AS `V67`, `V68` AS `V68`, `V69` AS `V69`, `V70` AS `V70`, `V71` AS `V71`, `V72` AS `V72`, `V73` AS `V73`, `V74` AS `V74`, `V75` AS `V75`, `V76` AS `V76`, `V77` AS `V77`, `V78` AS `V78`, `V79` AS `V79`, `V80` AS `V80`, `V81` AS `V81`, `V82` AS `V82`, `V83` AS `V83`, `V84` AS `V84`, `V85` AS `V85`, `V86` AS `V86`, `V87` AS `V87`, `V88` AS `V88`, `V89` AS `V89`, `V90` AS `V90`, `V91` AS `V91`, `V92` AS `V92`, `V93` AS `V93`, `V94` AS `V94`, `V95` AS `V95`, `V96` AS `V96`, `V97` AS `V97`, `V98` AS `V98`, `V99` AS `V99`, `V100` AS `V100`
FROM (SELECT `S1`, `S2`, `S3`, `S1` + 0.90553851 * RANDN() AS `V1`, `S1` + 0.90553851 * RANDN() AS `V2`, `S3` + 0.93808315 * RANDN() AS `V3`, `S2` + 0.93273791 * RANDN() AS `V4`, `S2` + 0.93273791 * RANDN() AS `V5`, `S3` + 0.93808315 * RANDN() AS `V6`, `S3` + 0.93808315 * RANDN() AS `V7`, `S3` + 0.93808315 * RANDN() AS `V8`, `S3` + 0.93808315 * RANDN() AS `V9`, `S1` + 0.90553851 * RANDN() AS `V10`, `S2` + 0.93273791 * RANDN() AS `V11`, `S1` + 0.90553851 * RANDN() AS `V12`, `S1` + 0.90553851 * RANDN() AS `V13`, `S2` + 0.93273791 * RANDN() AS `V14`, `S2` + 0.93273791 * RANDN() AS `V15`, `S2` + 0.93273791 * RANDN() AS `V16`, `S1` + 0.90553851 * RANDN() AS `V17`, `S3` + 0.93808315 * RANDN() AS `V18`, `S1` + 0.90553851 * RANDN() AS `V19`, `S3` + 0.93808315 * RANDN() AS `V20`, `S2` + 0.93273791 * RANDN() AS `V21`, `S3` + 0.93808315 * RANDN() AS `V22`, `S1` + 0.90553851 * RANDN() AS `V23`, `S1` + 0.90553851 * RANDN() AS `V24`, `S2` + 0.93273791 * RANDN() AS `V25`, `S1` + 0.90553851 * RANDN() AS `V26`, `S2` + 0.93273791 * RANDN() AS `V27`, `S3` + 0.93808315 * RANDN() AS `V28`, `S3` + 0.93808315 * RANDN() AS `V29`, `S3` + 0.93808315 * RANDN() AS `V30`, `S2` + 0.93273791 * RANDN() AS `V31`, `S3` + 0.93808315 * RANDN() AS `V32`, `S3` + 0.93808315 * RANDN() AS `V33`, `S2` + 0.93273791 * RANDN() AS `V34`, `S1` + 0.90553851 * RANDN() AS `V35`, `S1` + 0.90553851 * RANDN() AS `V36`, `S3` + 0.93808315 * RANDN() AS `V37`, `S3` + 0.93808315 * RANDN() AS `V38`, `S3` + 0.93808315 * RANDN() AS `V39`, `S2` + 0.93273791 * RANDN() AS `V40`, `S1` + 0.90553851 * RANDN() AS `V41`, `S2` + 0.93273791 * RANDN() AS `V42`, `S1` + 0.90553851 * RANDN() AS `V43`, `S3` + 0.93808315 * RANDN() AS `V44`, `S2` + 0.93273791 * RANDN() AS `V45`, `S2` + 0.93273791 * RANDN() AS `V46`, `S2` + 0.93273791 * RANDN() AS `V47`, `S1` + 0.90553851 * RANDN() AS `V48`, `S2` + 0.93273791 * RANDN() AS `V49`, `S3` + 0.93808315 * RANDN() AS `V50`, `S2` + 0.93273791 * RANDN() AS `V51`, `S2` + 0.93273791 * RANDN() AS `V52`, `S1` + 0.90553851 * RANDN() AS `V53`, `S1` + 0.90553851 * RANDN() AS `V54`, `S1` + 0.90553851 * RANDN() AS `V55`, `S2` + 0.93273791 * RANDN() AS `V56`, `S1` + 0.90553851 * RANDN() AS `V57`, `S3` + 0.93808315 * RANDN() AS `V58`, `S3` + 0.93808315 * RANDN() AS `V59`, `S2` + 0.93273791 * RANDN() AS `V60`, `S1` + 0.90553851 * RANDN() AS `V61`, `S3` + 0.93808315 * RANDN() AS `V62`, `S1` + 0.90553851 * RANDN() AS `V63`, `S1` + 0.90553851 * RANDN() AS `V64`, `S2` + 0.93273791 * RANDN() AS `V65`, `S1` + 0.90553851 * RANDN() AS `V66`, `S2` + 0.93273791 * RANDN() AS `V67`, `S1` + 0.90553851 * RANDN() AS `V68`, `S3` + 0.93808315 * RANDN() AS `V69`, `S3` + 0.93808315 * RANDN() AS `V70`, `S1` + 0.90553851 * RANDN() AS `V71`, `S2` + 0.93273791 * RANDN() AS `V72`, `S1` + 0.90553851 * RANDN() AS `V73`, `S1` + 0.90553851 * RANDN() AS `V74`, `S3` + 0.93808315 * RANDN() AS `V75`, `S1` + 0.90553851 * RANDN() AS `V76`, `S2` + 0.93273791 * RANDN() AS `V77`, `S3` + 0.93808315 * RANDN() AS `V78`, `S2` + 0.93273791 * RANDN() AS `V79`, `S3` + 0.93808315 * RANDN() AS `V80`, `S1` + 0.90553851 * RANDN() AS `V81`, `S2` + 0.93273791 * RANDN() AS `V82`, `S1` + 0.90553851 * RANDN() AS `V83`, `S1` + 0.90553851 * RANDN() AS `V84`, `S1` + 0.90553851 * RANDN() AS `V85`, `S2` + 0.93273791 * RANDN() AS `V86`, `S2` + 0.93273791 * RANDN() AS `V87`, `S2` + 0.93273791 * RANDN() AS `V88`, `S2` + 0.93273791 * RANDN() AS `V89`, `S1` + 0.90553851 * RANDN() AS `V90`, `S2` + 0.93273791 * RANDN() AS `V91`, `S1` + 0.90553851 * RANDN() AS `V92`, `S3` + 0.93808315 * RANDN() AS `V93`, `S3` + 0.93808315 * RANDN() AS `V94`, `S1` + 0.90553851 * RANDN() AS `V95`, `S3` + 0.93808315 * RANDN() AS `V96`, `S2` + 0.93273791 * RANDN() AS `V97`, `S1` + 0.90553851 * RANDN() AS `V98`, `S1` + 0.90553851 * RANDN() AS `V99`, `S3` + 0.93808315 * RANDN() AS `V100`
FROM `analyis_tbl`) `enaxzcrfwe`
17/12/19 18:04:44 INFO ContextCleaner: Cleaned accumulator 50
17/12/19 18:04:45 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:57373 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/19 18:04:45 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:57373 in memory (size: 6.0 KB, free: 2004.3 MB)
17/12/19 18:04:45 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:57373 in memory (size: 3.7 KB, free: 2004.3 MB)
17/12/19 18:04:45 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:57373 in memory (size: 4.6 KB, free: 2004.3 MB)
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 1
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 0
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 238
17/12/19 18:04:45 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:57373 in memory (size: 6.0 KB, free: 2004.3 MB)
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 51
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 57
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 58
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 59
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 60
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 61
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 62
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 63
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 64
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 65
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 66
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 67
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 68
17/12/19 18:04:45 INFO ContextCleaner: Cleaned accumulator 69
17/12/19 18:04:45 INFO ContextCleaner: Cleaned shuffle 1
17/12/19 18:04:45 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:57373 in memory (size: 7.3 KB, free: 2004.3 MB)
17/12/19 18:04:45 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 18:04:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:04:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz50`
WHERE (0 = 1)
17/12/19 18:04:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:04:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 18:04:45 INFO CodeGenerator: Code generated in 129.999316 ms
17/12/19 18:04:46 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 18:04:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 145 bytes
17/12/19 18:04:46 INFO DAGScheduler: Got job 3 (take at <unknown>:0) with 1 output partitions
17/12/19 18:04:46 INFO DAGScheduler: Final stage: ResultStage 8 (take at <unknown>:0)
17/12/19 18:04:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/12/19 18:04:46 INFO DAGScheduler: Missing parents: List()
17/12/19 18:04:46 INFO DAGScheduler: Submitting ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18), which has no missing parents
17/12/19 18:04:46 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 465.7 KB, free 2003.6 MB)
17/12/19 18:04:46 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 311.3 KB, free 2003.3 MB)
17/12/19 18:04:46 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:57373 (size: 311.3 KB, free: 2004.0 MB)
17/12/19 18:04:46 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/12/19 18:04:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (WorkerRDD[31] at RDD at rdd.scala:18)
17/12/19 18:04:46 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/12/19 18:04:46 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5913 bytes)
17/12/19 18:04:46 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/12/19 18:04:46 INFO BlockManager: Found block rdd_12_0 locally
17/12/19 18:04:46 INFO CodeGenerator: Code generated in 14.38018 ms
17/12/19 18:04:46 INFO CodeGenerator: Code generated in 38.193848 ms
17/12/19 18:05:03 INFO MemoryStore: Block rdd_31_0 stored as values in memory (estimated size 13.5 MB, free 1989.8 MB)
17/12/19 18:05:03 INFO BlockManagerInfo: Added rdd_31_0 in memory on 127.0.0.1:57373 (size: 13.5 MB, free: 1990.5 MB)
17/12/19 18:05:03 WARN Executor: 1 block locks were not released by TID = 8:
[rdd_31_0]
17/12/19 18:05:03 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 16687 bytes result sent to driver
17/12/19 18:05:03 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 17761 ms on localhost (executor driver) (1/1)
17/12/19 18:05:03 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/12/19 18:05:03 INFO DAGScheduler: ResultStage 8 (take at <unknown>:0) finished in 17.761 s
17/12/19 18:05:03 INFO DAGScheduler: Job 3 finished: take at <unknown>:0, took 17.764471 s
17/12/19 18:05:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:05:03 INFO SparkSqlParser: Parsing command: sparklyr_tmp_22506ede56da
17/12/19 18:05:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:05:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22506ede56da` AS `zzz51`
WHERE (0 = 1)
17/12/19 18:05:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:05:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_22506ede56da`
17/12/19 18:05:04 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 18:05:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:05:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz52`
WHERE (0 = 1)
17/12/19 18:05:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:05:04 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.1) AS `V1`, (`V2` < 0.0013) AS `V2`, (`V3` < 0.026) AS `V3`, (`V4` < 0.054) AS `V4`, (`V5` < 0.0035) AS `V5`, (`V6` < 0.0035) AS `V6`, (`V7` < 0.0023) AS `V7`, (`V8` < 0.0045) AS `V8`, (`V9` < 0.0138) AS `V9`, (`V10` < 0.3) AS `V10`, (`V11` < 0.026) AS `V11`, (`V12` < 0.3) AS `V12`, (`V13` < 0.0018) AS `V13`, (`V14` < 0.0185) AS `V14`, (`V15` < 0.0028) AS `V15`, (`V16` < 0.0375) AS `V16`, (`V17` < 0.026) AS `V17`, (`V18` < 0.0138) AS `V18`, (`V19` < 0.0138) AS `V19`, (`V20` < 0.0013) AS `V20`, (`V21` < 0.15) AS `V21`, (`V22` < 0.009) AS `V22`, (`V23` < 0.009) AS `V23`, (`V24` < 0.026) AS `V24`, (`V25` < 0.0185) AS `V25`, (`V26` < 0.054) AS `V26`, (`V27` < 0.075) AS `V27`, (`V28` < 0.0045) AS `V28`, (`V29` < 0.0055) AS `V29`, (`V30` < 0.0138) AS `V30`, (`V31` < 0.0045) AS `V31`, (`V32` < 0.0185) AS `V32`, (`V33` < 0.0045) AS `V33`, (`V34` < 0.0375) AS `V34`, (`V35` < 0.0185) AS `V35`, (`V36` < 0.0185) AS `V36`, (`V37` < 0.075) AS `V37`, (`V38` < 0.15) AS `V38`, (`V39` < 0.0035) AS `V39`, (`V40` < 0.0035) AS `V40`, (`V41` < 0.009) AS `V41`, (`V42` < 0.0045) AS `V42`, (`V43` < 0.1) AS `V43`, (`V44` < 0.0375) AS `V44`, (`V45` < 0.009) AS `V45`, (`V46` < 0.0375) AS `V46`, (`V47` < 0.026) AS `V47`, (`V48` < 0.075) AS `V48`, (`V49` < 0.15) AS `V49`, (`V50` < 0.026) AS `V50`, (`V51` < 0.0185) AS `V51`, (`V52` < 0.0138) AS `V52`, (`V53` < 0.0035) AS `V53`, (`V54` < 0.0023) AS `V54`, (`V55` < 0.009) AS `V55`, (`V56` < 0.009) AS `V56`, (`V57` < 0.075) AS `V57`, (`V58` < 0.054) AS `V58`, (`V59` < 0.0045) AS `V59`, (`V60` < 0.15) AS `V60`, (`V61` < 0.0375) AS `V61`, (`V62` < 0.054) AS `V62`, (`V63` < 0.0045) AS `V63`, (`V64` < 0.026) AS `V64`, (`V65` < 0.075) AS `V65`, (`V66` < 0.075) AS `V66`, (`V67` < 0.026) AS `V67`, (`V68` < 0.009) AS `V68`, (`V69` < 0.0185) AS `V69`, (`V70` < 0.0045) AS `V70`, (`V71` < 3e-04) AS `V71`, (`V72` < 0.0035) AS `V72`, (`V73` < 0.026) AS `V73`, (`V74` < 0.0023) AS `V74`, (`V75` < 0.026) AS `V75`, (`V76` < 0.054) AS `V76`, (`V77` < 0.0028) AS `V77`, (`V78` < 0.15) AS `V78`, (`V79` < 8e-04) AS `V79`, (`V80` < 8e-04) AS `V80`, (`V81` < 0.0138) AS `V81`, (`V82` < 0.054) AS `V82`, (`V83` < 0.0045) AS `V83`, (`V84` < 0.009) AS `V84`, (`V85` < 0.0013) AS `V85`, (`V86` < 0.009) AS `V86`, (`V87` < 0.0185) AS `V87`, (`V88` < 0.0375) AS `V88`, (`V89` < 0.0035) AS `V89`, (`V90` < 0.0045) AS `V90`, (`V91` < 0.0055) AS `V91`, (`V92` < 0.0013) AS `V92`, (`V93` < 0.0023) AS `V93`, (`V94` < 0.0013) AS `V94`, (`V95` < 0.0185) AS `V95`, (`V96` < 0.0375) AS `V96`, (`V97` < 0.026) AS `V97`, (`V98` < 0.009) AS `V98`, (`V99` < 0.0045) AS `V99`, (`V100` < 0.0138) AS `V100`
FROM `analyis_tbl`
17/12/19 18:05:04 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 18:05:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:05:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz53`
WHERE (0 = 1)
17/12/19 18:05:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:05:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 18:05:04 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/12/19 18:05:04 INFO CodeGenerator: Code generated in 73.774834 ms
17/12/19 18:05:04 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 18:05:04 INFO DAGScheduler: Got job 4 (collect at utils.scala:196) with 2 output partitions
17/12/19 18:05:04 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:196)
17/12/19 18:05:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
17/12/19 18:05:04 INFO DAGScheduler: Missing parents: List()
17/12/19 18:05:04 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196), which has no missing parents
17/12/19 18:05:04 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 559.8 KB, free 1989.2 MB)
17/12/19 18:05:04 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 330.3 KB, free 1988.9 MB)
17/12/19 18:05:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:57373 (size: 330.3 KB, free: 1990.2 MB)
17/12/19 18:05:04 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/12/19 18:05:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at collect at utils.scala:196)
17/12/19 18:05:04 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks
17/12/19 18:05:04 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5945 bytes)
17/12/19 18:05:04 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 5945 bytes)
17/12/19 18:05:04 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
17/12/19 18:05:04 INFO Executor: Running task 1.0 in stage 10.0 (TID 10)
17/12/19 18:05:04 INFO BlockManager: Found block rdd_31_0 locally
17/12/19 18:05:04 INFO BlockManager: Found block rdd_12_1 locally
17/12/19 18:05:04 INFO CodeGenerator: Code generated in 33.141812 ms
17/12/19 18:05:05 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:57373 in memory (size: 311.3 KB, free: 1990.5 MB)
17/12/19 18:05:05 INFO CodeGenerator: Code generated in 378.784166 ms
17/12/19 18:05:05 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 131962 bytes result sent to driver
17/12/19 18:05:05 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 954 ms on localhost (executor driver) (1/2)
17/12/19 18:05:23 INFO MemoryStore: Block rdd_31_1 stored as values in memory (estimated size 13.5 MB, free 1976.1 MB)
17/12/19 18:05:23 INFO BlockManagerInfo: Added rdd_31_1 in memory on 127.0.0.1:57373 (size: 13.5 MB, free: 1977.0 MB)
17/12/19 18:05:23 INFO Executor: Finished task 1.0 in stage 10.0 (TID 10). 131863 bytes result sent to driver
17/12/19 18:05:23 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:196) finished in 18.714 s
17/12/19 18:05:23 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 10) in 18714 ms on localhost (executor driver) (2/2)
17/12/19 18:05:23 INFO DAGScheduler: Job 4 finished: collect at utils.scala:196, took 18.732353 s
17/12/19 18:05:23 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/12/19 18:05:23 INFO CodeGenerator: Code generated in 24.435545 ms
17/12/19 18:05:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:05:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 18:05:23 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:05:23 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:05:23 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:05:23 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:05:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 18:05:23 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 18:05:23 INFO CodeGenerator: Code generated in 6.565004 ms
17/12/19 18:05:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:05:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 18:05:23 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:05:23 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:05:23 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:05:23 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:05:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 18:05:23 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 18:05:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:05:24 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 18:05:24 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:05:24 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:05:24 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:05:24 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:05:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 18:05:24 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 18:05:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 18:05:24 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 18:05:24 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:05:24 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:05:24 INFO HiveMetaStore: 0: get_database: default
17/12/19 18:05:24 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 18:05:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 18:05:24 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 18:53:29 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:57373 in memory (size: 330.3 KB, free: 1977.3 MB)
17/12/19 19:20:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 19:20:39 INFO HiveMetaStore: 0: get_database: default
17/12/19 19:20:39 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 19:20:39 INFO HiveMetaStore: 0: get_database: default
17/12/19 19:20:39 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 19:20:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 19:20:39 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 19:20:39 INFO SparkContext: Starting job: collect at utils.scala:58
17/12/19 19:20:39 INFO DAGScheduler: Got job 5 (collect at utils.scala:58) with 1 output partitions
17/12/19 19:20:39 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:58)
17/12/19 19:20:39 INFO DAGScheduler: Parents of final stage: List()
17/12/19 19:20:39 INFO DAGScheduler: Missing parents: List()
17/12/19 19:20:39 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[48] at map at utils.scala:55), which has no missing parents
17/12/19 19:20:39 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 8.7 KB, free 1977.0 MB)
17/12/19 19:20:39 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1977.0 MB)
17/12/19 19:20:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:57373 (size: 4.6 KB, free: 1977.3 MB)
17/12/19 19:20:39 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/12/19 19:20:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[48] at map at utils.scala:55)
17/12/19 19:20:39 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/12/19 19:20:39 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6432 bytes)
17/12/19 19:20:39 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
17/12/19 19:20:39 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 938 bytes result sent to driver
17/12/19 19:20:39 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:58) finished in 0.015 s
17/12/19 19:20:39 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 15 ms on localhost (executor driver) (1/1)
17/12/19 19:20:39 INFO DAGScheduler: Job 5 finished: collect at utils.scala:58, took 0.027825 s
17/12/19 19:20:39 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/12/19 19:20:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:40 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 19:20:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:40 INFO SparkSqlParser: Parsing command: CACHE TABLE `analyis_tbl`
17/12/19 19:20:40 INFO SparkSqlParser: Parsing command: `analyis_tbl`
17/12/19 19:20:40 INFO FileSourceStrategy: Pruning directories with: 
17/12/19 19:20:40 INFO FileSourceStrategy: Post-Scan Filters: 
17/12/19 19:20:40 INFO FileSourceStrategy: Output Data Schema: struct<S1: double, S2: double, S3: double, S4: double, S5: double ... 8 more fields>
17/12/19 19:20:40 INFO FileSourceStrategy: Pushed Filters: 
17/12/19 19:20:40 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 293.7 KB, free 1976.7 MB)
17/12/19 19:20:40 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1976.7 MB)
17/12/19 19:20:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:57373 (size: 24.0 KB, free: 1977.3 MB)
17/12/19 19:20:40 INFO SparkContext: Created broadcast 10 from sql at <unknown>:0
17/12/19 19:20:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/12/19 19:20:40 INFO SparkContext: Starting job: sql at <unknown>:0
17/12/19 19:20:40 INFO DAGScheduler: Registering RDD 52 (sql at <unknown>:0)
17/12/19 19:20:40 INFO DAGScheduler: Registering RDD 57 (sql at <unknown>:0)
17/12/19 19:20:40 INFO DAGScheduler: Got job 6 (sql at <unknown>:0) with 1 output partitions
17/12/19 19:20:40 INFO DAGScheduler: Final stage: ResultStage 14 (sql at <unknown>:0)
17/12/19 19:20:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/12/19 19:20:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/12/19 19:20:40 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[52] at sql at <unknown>:0), which has no missing parents
17/12/19 19:20:40 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.1 KB, free 1976.7 MB)
17/12/19 19:20:40 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.5 KB, free 1976.7 MB)
17/12/19 19:20:40 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:57373 (size: 7.5 KB, free: 1977.3 MB)
17/12/19 19:20:40 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/12/19 19:20:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[52] at sql at <unknown>:0)
17/12/19 19:20:40 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/12/19 19:20:40 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6677 bytes)
17/12/19 19:20:40 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
17/12/19 19:20:40 INFO FileScanRDD: Reading File path: file:///C:/Users/conan/AppData/Local/Temp/RtmpwLtPOg/spark_serialize_284348d6f84b6e38eaca6cf1b0ac4fdee3429cd77ace7c875c27323b55c7b1ef.csv, range: 0-1869188, partition values: [empty row]
17/12/19 19:20:40 INFO CodeGenerator: Code generated in 10.27474 ms
17/12/19 19:20:40 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1632 bytes result sent to driver
17/12/19 19:20:40 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 185 ms on localhost (executor driver) (1/1)
17/12/19 19:20:40 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/12/19 19:20:40 INFO DAGScheduler: ShuffleMapStage 12 (sql at <unknown>:0) finished in 0.185 s
17/12/19 19:20:40 INFO DAGScheduler: looking for newly runnable stages
17/12/19 19:20:40 INFO DAGScheduler: running: Set()
17/12/19 19:20:40 INFO DAGScheduler: waiting: Set(ShuffleMapStage 13, ResultStage 14)
17/12/19 19:20:40 INFO DAGScheduler: failed: Set()
17/12/19 19:20:40 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[57] at sql at <unknown>:0), which has no missing parents
17/12/19 19:20:40 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 15.3 KB, free 1976.7 MB)
17/12/19 19:20:40 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.0 KB, free 1976.6 MB)
17/12/19 19:20:40 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:57373 (size: 7.0 KB, free: 1977.3 MB)
17/12/19 19:20:40 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/12/19 19:20:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[57] at sql at <unknown>:0)
17/12/19 19:20:40 INFO TaskSchedulerImpl: Adding task set 13.0 with 2 tasks
17/12/19 19:20:40 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, ANY, 5943 bytes)
17/12/19 19:20:40 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 14, localhost, executor driver, partition 1, ANY, 5943 bytes)
17/12/19 19:20:40 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
17/12/19 19:20:40 INFO Executor: Running task 1.0 in stage 13.0 (TID 14)
17/12/19 19:20:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 19:20:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 19:20:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/12/19 19:20:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/12/19 19:20:40 INFO MemoryStore: Block rdd_54_0 stored as values in memory (estimated size 392.1 KB, free 1976.3 MB)
17/12/19 19:20:40 INFO BlockManagerInfo: Added rdd_54_0 in memory on 127.0.0.1:57373 (size: 392.1 KB, free: 1976.9 MB)
17/12/19 19:20:40 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 3151 bytes result sent to driver
17/12/19 19:20:40 INFO MemoryStore: Block rdd_54_1 stored as values in memory (estimated size 392.1 KB, free 1975.9 MB)
17/12/19 19:20:40 INFO BlockManagerInfo: Added rdd_54_1 in memory on 127.0.0.1:57373 (size: 392.1 KB, free: 1976.5 MB)
17/12/19 19:20:40 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 38 ms on localhost (executor driver) (1/2)
17/12/19 19:20:40 INFO Executor: Finished task 1.0 in stage 13.0 (TID 14). 3151 bytes result sent to driver
17/12/19 19:20:40 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 14) in 47 ms on localhost (executor driver) (2/2)
17/12/19 19:20:40 INFO DAGScheduler: ShuffleMapStage 13 (sql at <unknown>:0) finished in 0.049 s
17/12/19 19:20:40 INFO DAGScheduler: looking for newly runnable stages
17/12/19 19:20:40 INFO DAGScheduler: running: Set()
17/12/19 19:20:40 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/12/19 19:20:40 INFO DAGScheduler: failed: Set()
17/12/19 19:20:40 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[60] at sql at <unknown>:0), which has no missing parents
17/12/19 19:20:40 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.0 KB, free 1975.9 MB)
17/12/19 19:20:40 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/12/19 19:20:40 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1975.9 MB)
17/12/19 19:20:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:57373 (size: 3.7 KB, free: 1976.5 MB)
17/12/19 19:20:40 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/12/19 19:20:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[60] at sql at <unknown>:0)
17/12/19 19:20:40 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/12/19 19:20:40 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, ANY, 5954 bytes)
17/12/19 19:20:40 INFO Executor: Running task 0.0 in stage 14.0 (TID 15)
17/12/19 19:20:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 19:20:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 19:20:40 INFO Executor: Finished task 0.0 in stage 14.0 (TID 15). 1873 bytes result sent to driver
17/12/19 19:20:40 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 15) in 6 ms on localhost (executor driver) (1/1)
17/12/19 19:20:40 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/12/19 19:20:40 INFO DAGScheduler: ResultStage 14 (sql at <unknown>:0) finished in 0.008 s
17/12/19 19:20:40 INFO DAGScheduler: Job 6 finished: sql at <unknown>:0, took 0.248498 s
17/12/19 19:20:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:40 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `analyis_tbl`
17/12/19 19:20:40 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 19:20:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 145 bytes
17/12/19 19:20:40 INFO DAGScheduler: Registering RDD 64 (collect at utils.scala:196)
17/12/19 19:20:40 INFO DAGScheduler: Got job 7 (collect at utils.scala:196) with 1 output partitions
17/12/19 19:20:40 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:196)
17/12/19 19:20:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
17/12/19 19:20:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
17/12/19 19:20:40 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[64] at collect at utils.scala:196), which has no missing parents
17/12/19 19:20:40 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 15.3 KB, free 1975.9 MB)
17/12/19 19:20:40 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 7.0 KB, free 1975.9 MB)
17/12/19 19:20:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:57373 (size: 7.0 KB, free: 1976.5 MB)
17/12/19 19:20:40 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/12/19 19:20:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[64] at collect at utils.scala:196)
17/12/19 19:20:40 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks
17/12/19 19:20:40 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5935 bytes)
17/12/19 19:20:40 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 17, localhost, executor driver, partition 1, PROCESS_LOCAL, 5935 bytes)
17/12/19 19:20:40 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
17/12/19 19:20:40 INFO Executor: Running task 1.0 in stage 16.0 (TID 17)
17/12/19 19:20:40 INFO BlockManager: Found block rdd_54_1 locally
17/12/19 19:20:40 INFO BlockManager: Found block rdd_54_0 locally
17/12/19 19:20:40 INFO Executor: Finished task 1.0 in stage 16.0 (TID 17). 2124 bytes result sent to driver
17/12/19 19:20:40 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 17) in 18 ms on localhost (executor driver) (1/2)
17/12/19 19:20:40 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 2037 bytes result sent to driver
17/12/19 19:20:40 INFO DAGScheduler: ShuffleMapStage 16 (collect at utils.scala:196) finished in 0.024 s
17/12/19 19:20:40 INFO DAGScheduler: looking for newly runnable stages
17/12/19 19:20:40 INFO DAGScheduler: running: Set()
17/12/19 19:20:40 INFO DAGScheduler: waiting: Set(ResultStage 17)
17/12/19 19:20:40 INFO DAGScheduler: failed: Set()
17/12/19 19:20:40 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[67] at collect at utils.scala:196), which has no missing parents
17/12/19 19:20:40 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 1975.8 MB)
17/12/19 19:20:40 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1975.8 MB)
17/12/19 19:20:40 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 24 ms on localhost (executor driver) (2/2)
17/12/19 19:20:40 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/12/19 19:20:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:57373 (size: 3.7 KB, free: 1976.5 MB)
17/12/19 19:20:40 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/12/19 19:20:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[67] at collect at utils.scala:196)
17/12/19 19:20:40 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/12/19 19:20:40 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/12/19 19:20:40 INFO Executor: Running task 0.0 in stage 17.0 (TID 18)
17/12/19 19:20:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/12/19 19:20:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/12/19 19:20:40 INFO Executor: Finished task 0.0 in stage 17.0 (TID 18). 1873 bytes result sent to driver
17/12/19 19:20:40 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:196) finished in 0.006 s
17/12/19 19:20:40 INFO DAGScheduler: Job 7 finished: collect at utils.scala:196, took 0.043367 s
17/12/19 19:20:40 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 6 ms on localhost (executor driver) (1/1)
17/12/19 19:20:40 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/12/19 19:20:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz54`
WHERE (0 = 1)
17/12/19 19:20:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:40 INFO SparkSqlParser: Parsing command: SELECT `V1` AS `V1`, `V2` AS `V2`, `V3` AS `V3`, `V4` AS `V4`, `V5` AS `V5`, `V6` AS `V6`, `V7` AS `V7`, `V8` AS `V8`, `V9` AS `V9`, `V10` AS `V10`, `V11` AS `V11`, `V12` AS `V12`, `V13` AS `V13`, `V14` AS `V14`, `V15` AS `V15`, `V16` AS `V16`, `V17` AS `V17`, `V18` AS `V18`, `V19` AS `V19`, `V20` AS `V20`, `V21` AS `V21`, `V22` AS `V22`, `V23` AS `V23`, `V24` AS `V24`, `V25` AS `V25`, `V26` AS `V26`, `V27` AS `V27`, `V28` AS `V28`, `V29` AS `V29`, `V30` AS `V30`, `V31` AS `V31`, `V32` AS `V32`, `V33` AS `V33`, `V34` AS `V34`, `V35` AS `V35`, `V36` AS `V36`, `V37` AS `V37`, `V38` AS `V38`, `V39` AS `V39`, `V40` AS `V40`, `V41` AS `V41`, `V42` AS `V42`, `V43` AS `V43`, `V44` AS `V44`, `V45` AS `V45`, `V46` AS `V46`, `V47` AS `V47`, `V48` AS `V48`, `V49` AS `V49`, `V50` AS `V50`, `V51` AS `V51`, `V52` AS `V52`, `V53` AS `V53`, `V54` AS `V54`, `V55` AS `V55`, `V56` AS `V56`, `V57` AS `V57`, `V58` AS `V58`, `V59` AS `V59`, `V60` AS `V60`, `V61` AS `V61`, `V62` AS `V62`, `V63` AS `V63`, `V64` AS `V64`, `V65` AS `V65`, `V66` AS `V66`, `V67` AS `V67`, `V68` AS `V68`, `V69` AS `V69`, `V70` AS `V70`, `V71` AS `V71`, `V72` AS `V72`, `V73` AS `V73`, `V74` AS `V74`, `V75` AS `V75`, `V76` AS `V76`, `V77` AS `V77`, `V78` AS `V78`, `V79` AS `V79`, `V80` AS `V80`, `V81` AS `V81`, `V82` AS `V82`, `V83` AS `V83`, `V84` AS `V84`, `V85` AS `V85`, `V86` AS `V86`, `V87` AS `V87`, `V88` AS `V88`, `V89` AS `V89`, `V90` AS `V90`, `V91` AS `V91`, `V92` AS `V92`, `V93` AS `V93`, `V94` AS `V94`, `V95` AS `V95`, `V96` AS `V96`, `V97` AS `V97`, `V98` AS `V98`, `V99` AS `V99`, `V100` AS `V100`
FROM (SELECT `S1`, `S2`, `S3`, `S4`, `S5`, `S6`, `S7`, `S8`, `S9`, `S10`, `S7` + 0.91651514 * RANDN() AS `V1`, `S6` + 0.91104336 * RANDN() AS `V2`, `S9` + 0.91651514 * RANDN() AS `V3`, `S1` + 0.91104336 * RANDN() AS `V4`, `S2` + 0.9486833 * RANDN() AS `V5`, `S5` + 0.90553851 * RANDN() AS `V6`, `S1` + 0.91104336 * RANDN() AS `V7`, `S5` + 0.90553851 * RANDN() AS `V8`, `S6` + 0.91104336 * RANDN() AS `V9`, `S5` + 0.90553851 * RANDN() AS `V10`, `S5` + 0.90553851 * RANDN() AS `V11`, `S7` + 0.91651514 * RANDN() AS `V12`, `S6` + 0.91104336 * RANDN() AS `V13`, `S3` + 0.89442719 * RANDN() AS `V14`, `S5` + 0.90553851 * RANDN() AS `V15`, `S4` + 0.92195445 * RANDN() AS `V16`, `S4` + 0.92195445 * RANDN() AS `V17`, `S10` + 0.9 * RANDN() AS `V18`, `S5` + 0.90553851 * RANDN() AS `V19`, `S2` + 0.9486833 * RANDN() AS `V20`, `S6` + 0.91104336 * RANDN() AS `V21`, `S3` + 0.89442719 * RANDN() AS `V22`, `S8` + 0.89442719 * RANDN() AS `V23`, `S8` + 0.89442719 * RANDN() AS `V24`, `S6` + 0.91104336 * RANDN() AS `V25`, `S7` + 0.91651514 * RANDN() AS `V26`, `S7` + 0.91651514 * RANDN() AS `V27`, `S7` + 0.91651514 * RANDN() AS `V28`, `S9` + 0.91651514 * RANDN() AS `V29`, `S1` + 0.91104336 * RANDN() AS `V30`, `S1` + 0.91104336 * RANDN() AS `V31`, `S4` + 0.92195445 * RANDN() AS `V32`, `S10` + 0.9 * RANDN() AS `V33`, `S6` + 0.91104336 * RANDN() AS `V34`, `S6` + 0.91104336 * RANDN() AS `V35`, `S8` + 0.89442719 * RANDN() AS `V36`, `S7` + 0.91651514 * RANDN() AS `V37`, `S5` + 0.90553851 * RANDN() AS `V38`, `S1` + 0.91104336 * RANDN() AS `V39`, `S10` + 0.9 * RANDN() AS `V40`, `S3` + 0.89442719 * RANDN() AS `V41`, `S10` + 0.9 * RANDN() AS `V42`, `S3` + 0.89442719 * RANDN() AS `V43`, `S6` + 0.91104336 * RANDN() AS `V44`, `S4` + 0.92195445 * RANDN() AS `V45`, `S2` + 0.9486833 * RANDN() AS `V46`, `S2` + 0.9486833 * RANDN() AS `V47`, `S5` + 0.90553851 * RANDN() AS `V48`, `S10` + 0.9 * RANDN() AS `V49`, `S1` + 0.91104336 * RANDN() AS `V50`, `S7` + 0.91651514 * RANDN() AS `V51`, `S7` + 0.91651514 * RANDN() AS `V52`, `S2` + 0.9486833 * RANDN() AS `V53`, `S8` + 0.89442719 * RANDN() AS `V54`, `S6` + 0.91104336 * RANDN() AS `V55`, `S10` + 0.9 * RANDN() AS `V56`, `S10` + 0.9 * RANDN() AS `V57`, `S6` + 0.91104336 * RANDN() AS `V58`, `S4` + 0.92195445 * RANDN() AS `V59`, `S6` + 0.91104336 * RANDN() AS `V60`, `S5` + 0.90553851 * RANDN() AS `V61`, `S1` + 0.91104336 * RANDN() AS `V62`, `S3` + 0.89442719 * RANDN() AS `V63`, `S4` + 0.92195445 * RANDN() AS `V64`, `S9` + 0.91651514 * RANDN() AS `V65`, `S5` + 0.90553851 * RANDN() AS `V66`, `S9` + 0.91651514 * RANDN() AS `V67`, `S3` + 0.89442719 * RANDN() AS `V68`, `S6` + 0.91104336 * RANDN() AS `V69`, `S5` + 0.90553851 * RANDN() AS `V70`, `S1` + 0.91104336 * RANDN() AS `V71`, `S3` + 0.89442719 * RANDN() AS `V72`, `S1` + 0.91104336 * RANDN() AS `V73`, `S6` + 0.91104336 * RANDN() AS `V74`, `S7` + 0.91651514 * RANDN() AS `V75`, `S3` + 0.89442719 * RANDN() AS `V76`, `S7` + 0.91651514 * RANDN() AS `V77`, `S10` + 0.9 * RANDN() AS `V78`, `S5` + 0.90553851 * RANDN() AS `V79`, `S2` + 0.9486833 * RANDN() AS `V80`, `S3` + 0.89442719 * RANDN() AS `V81`, `S1` + 0.91104336 * RANDN() AS `V82`, `S7` + 0.91651514 * RANDN() AS `V83`, `S5` + 0.90553851 * RANDN() AS `V84`, `S3` + 0.89442719 * RANDN() AS `V85`, `S3` + 0.89442719 * RANDN() AS `V86`, `S3` + 0.89442719 * RANDN() AS `V87`, `S5` + 0.90553851 * RANDN() AS `V88`, `S10` + 0.9 * RANDN() AS `V89`, `S8` + 0.89442719 * RANDN() AS `V90`, `S7` + 0.91651514 * RANDN() AS `V91`, `S5` + 0.90553851 * RANDN() AS `V92`, `S6` + 0.91104336 * RANDN() AS `V93`, `S3` + 0.89442719 * RANDN() AS `V94`, `S3` + 0.89442719 * RANDN() AS `V95`, `S7` + 0.91651514 * RANDN() AS `V96`, `S9` + 0.91651514 * RANDN() AS `V97`, `S4` + 0.92195445 * RANDN() AS `V98`, `S2` + 0.9486833 * RANDN() AS `V99`, `S10` + 0.9 * RANDN() AS `V100`
FROM `analyis_tbl`) `qjzzzmckke`
17/12/19 19:20:41 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 19:20:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz55`
WHERE (0 = 1)
17/12/19 19:20:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 19:20:41 INFO CodeGenerator: Code generated in 49.50316 ms
17/12/19 19:20:41 INFO SparkContext: Starting job: take at <unknown>:0
17/12/19 19:20:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 145 bytes
17/12/19 19:20:41 INFO DAGScheduler: Got job 8 (take at <unknown>:0) with 1 output partitions
17/12/19 19:20:41 INFO DAGScheduler: Final stage: ResultStage 19 (take at <unknown>:0)
17/12/19 19:20:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
17/12/19 19:20:41 INFO DAGScheduler: Missing parents: List()
17/12/19 19:20:41 INFO DAGScheduler: Submitting ResultStage 19 (WorkerRDD[73] at RDD at rdd.scala:18), which has no missing parents
17/12/19 19:20:41 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 1020.1 KB, free 1974.8 MB)
17/12/19 19:20:41 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 858.6 KB, free 1974.0 MB)
17/12/19 19:20:41 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:57373 (size: 858.6 KB, free: 1975.6 MB)
17/12/19 19:20:41 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/12/19 19:20:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (WorkerRDD[73] at RDD at rdd.scala:18)
17/12/19 19:20:41 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/12/19 19:20:41 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)
17/12/19 19:20:41 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
17/12/19 19:20:41 INFO BlockManager: Found block rdd_54_0 locally
17/12/19 19:20:41 INFO CodeGenerator: Code generated in 13.276888 ms
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 495
17/12/19 19:20:58 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:57373 in memory (size: 7.0 KB, free: 1975.6 MB)
17/12/19 19:20:58 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:57373 in memory (size: 3.7 KB, free: 1975.7 MB)
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 733
17/12/19 19:20:58 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:57373 in memory (size: 7.0 KB, free: 1975.7 MB)
17/12/19 19:20:58 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:57373 in memory (size: 3.7 KB, free: 1975.7 MB)
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 496
17/12/19 19:20:58 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:57373 in memory (size: 4.6 KB, free: 1975.7 MB)
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 545
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 546
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 552
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 553
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 554
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 555
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 556
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 557
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 558
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 559
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 560
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 561
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 562
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 563
17/12/19 19:20:58 INFO ContextCleaner: Cleaned accumulator 564
17/12/19 19:20:58 INFO ContextCleaner: Cleaned shuffle 4
17/12/19 19:20:58 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:57373 in memory (size: 7.5 KB, free: 1975.7 MB)
17/12/19 19:20:59 INFO MemoryStore: Block rdd_73_0 stored as values in memory (estimated size 13.5 MB, free 1960.6 MB)
17/12/19 19:20:59 INFO BlockManagerInfo: Added rdd_73_0 in memory on 127.0.0.1:57373 (size: 13.5 MB, free: 1962.1 MB)
17/12/19 19:20:59 WARN Executor: 1 block locks were not released by TID = 19:
[rdd_73_0]
17/12/19 19:20:59 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 16600 bytes result sent to driver
17/12/19 19:20:59 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 17845 ms on localhost (executor driver) (1/1)
17/12/19 19:20:59 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/12/19 19:20:59 INFO DAGScheduler: ResultStage 19 (take at <unknown>:0) finished in 17.845 s
17/12/19 19:20:59 INFO DAGScheduler: Job 8 finished: take at <unknown>:0, took 17.857370 s
17/12/19 19:20:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:59 INFO SparkSqlParser: Parsing command: sparklyr_tmp_225063737643
17/12/19 19:20:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_225063737643` AS `zzz56`
WHERE (0 = 1)
17/12/19 19:20:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_225063737643`
17/12/19 19:20:59 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 19:20:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz57`
WHERE (0 = 1)
17/12/19 19:20:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:59 INFO SparkSqlParser: Parsing command: SELECT (`V1` < 0.0013) AS `V1`, (`V2` < 0.026) AS `V2`, (`V3` < 0.3) AS `V3`, (`V4` < 0.054) AS `V4`, (`V5` < 0.0185) AS `V5`, (`V6` < 0.009) AS `V6`, (`V7` < 0.0035) AS `V7`, (`V8` < 0.1) AS `V8`, (`V9` < 0.0035) AS `V9`, (`V10` < 0.0035) AS `V10`, (`V11` < 0.009) AS `V11`, (`V12` < 0.054) AS `V12`, (`V13` < 0.15) AS `V13`, (`V14` < 8e-04) AS `V14`, (`V15` < 0.054) AS `V15`, (`V16` < 0.0138) AS `V16`, (`V17` < 0.0035) AS `V17`, (`V18` < 0.0018) AS `V18`, (`V19` < 0.054) AS `V19`, (`V20` < 0.054) AS `V20`, (`V21` < 0.0185) AS `V21`, (`V22` < 0.1) AS `V22`, (`V23` < 0.0138) AS `V23`, (`V24` < 0.1) AS `V24`, (`V25` < 0.1) AS `V25`, (`V26` < 0.0138) AS `V26`, (`V27` < 0.1) AS `V27`, (`V28` < 0.0055) AS `V28`, (`V29` < 0.0055) AS `V29`, (`V30` < 0.009) AS `V30`, (`V31` < 0.1) AS `V31`, (`V32` < 0.0138) AS `V32`, (`V33` < 0.0185) AS `V33`, (`V34` < 0.026) AS `V34`, (`V35` < 0.0023) AS `V35`, (`V36` < 0.0055) AS `V36`, (`V37` < 0.0045) AS `V37`, (`V38` < 0.0055) AS `V38`, (`V39` < 0.009) AS `V39`, (`V40` < 0.0018) AS `V40`, (`V41` < 0.009) AS `V41`, (`V42` < 0.0375) AS `V42`, (`V43` < 0.075) AS `V43`, (`V44` < 0.075) AS `V44`, (`V45` < 0.1) AS `V45`, (`V46` < 4e-04) AS `V46`, (`V47` < 0.0185) AS `V47`, (`V48` < 0.0185) AS `V48`, (`V49` < 0.0138) AS `V49`, (`V50` < 0.0375) AS `V50`, (`V51` < 0.0023) AS `V51`, (`V52` < 0.009) AS `V52`, (`V53` < 0.0185) AS `V53`, (`V54` < 0.0045) AS `V54`, (`V55` < 0.0055) AS `V55`, (`V56` < 0.1) AS `V56`, (`V57` < 0.054) AS `V57`, (`V58` < 0.0055) AS `V58`, (`V59` < 0.0028) AS `V59`, (`V60` < 0.0023) AS `V60`, (`V61` < 0.15) AS `V61`, (`V62` < 0.0028) AS `V62`, (`V63` < 8e-04) AS `V63`, (`V64` < 0.0185) AS `V64`, (`V65` < 0.0375) AS `V65`, (`V66` < 0.0375) AS `V66`, (`V67` < 0.0028) AS `V67`, (`V68` < 0.0055) AS `V68`, (`V69` < 0.15) AS `V69`, (`V70` < 0.0185) AS `V70`, (`V71` < 0.0185) AS `V71`, (`V72` < 0.3) AS `V72`, (`V73` < 0.0055) AS `V73`, (`V74` < 0.3) AS `V74`, (`V75` < 0.0018) AS `V75`, (`V76` < 0.0138) AS `V76`, (`V77` < 0.009) AS `V77`, (`V78` < 0.0045) AS `V78`, (`V79` < 0.0035) AS `V79`, (`V80` < 0.075) AS `V80`, (`V81` < 0.009) AS `V81`, (`V82` < 0.0035) AS `V82`, (`V83` < 0.0023) AS `V83`, (`V84` < 0.026) AS `V84`, (`V85` < 0.054) AS `V85`, (`V86` < 0.0375) AS `V86`, (`V87` < 0.0185) AS `V87`, (`V88` < 0.0035) AS `V88`, (`V89` < 0.0185) AS `V89`, (`V90` < 0.0045) AS `V90`, (`V91` < 0.0185) AS `V91`, (`V92` < 0.054) AS `V92`, (`V93` < 0.054) AS `V93`, (`V94` < 0.009) AS `V94`, (`V95` < 0.0035) AS `V95`, (`V96` < 0.075) AS `V96`, (`V97` < 8e-04) AS `V97`, (`V98` < 0.0035) AS `V98`, (`V99` < 0.026) AS `V99`, (`V100` < 0.0045) AS `V100`
FROM `analyis_tbl`
17/12/19 19:20:59 INFO SparkSqlParser: Parsing command: analyis_tbl
17/12/19 19:20:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl` AS `zzz58`
WHERE (0 = 1)
17/12/19 19:20:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:20:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `analyis_tbl`
17/12/19 19:20:59 INFO CodeGenerator: Code generated in 44.116964 ms
17/12/19 19:20:59 INFO SparkContext: Starting job: collect at utils.scala:196
17/12/19 19:20:59 INFO DAGScheduler: Got job 9 (collect at utils.scala:196) with 2 output partitions
17/12/19 19:20:59 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:196)
17/12/19 19:20:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
17/12/19 19:20:59 INFO DAGScheduler: Missing parents: List()
17/12/19 19:20:59 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[80] at collect at utils.scala:196), which has no missing parents
17/12/19 19:20:59 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 1114.0 KB, free 1959.5 MB)
17/12/19 19:20:59 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 877.8 KB, free 1958.6 MB)
17/12/19 19:20:59 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:57373 (size: 877.8 KB, free: 1961.3 MB)
17/12/19 19:20:59 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/12/19 19:20:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[80] at collect at utils.scala:196)
17/12/19 19:20:59 INFO TaskSchedulerImpl: Adding task set 21.0 with 2 tasks
17/12/19 19:20:59 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5947 bytes)
17/12/19 19:20:59 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 5947 bytes)
17/12/19 19:20:59 INFO Executor: Running task 0.0 in stage 21.0 (TID 20)
17/12/19 19:20:59 INFO Executor: Running task 1.0 in stage 21.0 (TID 21)
17/12/19 19:20:59 INFO BlockManager: Found block rdd_73_0 locally
17/12/19 19:20:59 INFO BlockManager: Found block rdd_54_1 locally
17/12/19 19:21:00 INFO Executor: Finished task 0.0 in stage 21.0 (TID 20). 141896 bytes result sent to driver
17/12/19 19:21:00 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 20) in 264 ms on localhost (executor driver) (1/2)
17/12/19 19:21:17 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:57373 in memory (size: 858.6 KB, free: 1962.1 MB)
17/12/19 19:21:18 INFO MemoryStore: Block rdd_73_1 stored as values in memory (estimated size 13.5 MB, free 1946.9 MB)
17/12/19 19:21:18 INFO BlockManagerInfo: Added rdd_73_1 in memory on 127.0.0.1:57373 (size: 13.5 MB, free: 1948.6 MB)
17/12/19 19:21:18 INFO Executor: Finished task 1.0 in stage 21.0 (TID 21). 144416 bytes result sent to driver
17/12/19 19:21:18 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 21) in 18241 ms on localhost (executor driver) (2/2)
17/12/19 19:21:18 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/12/19 19:21:18 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:196) finished in 18.243 s
17/12/19 19:21:18 INFO DAGScheduler: Job 9 finished: collect at utils.scala:196, took 18.264174 s
17/12/19 19:21:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:21:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 19:21:18 INFO HiveMetaStore: 0: get_database: default
17/12/19 19:21:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 19:21:18 INFO HiveMetaStore: 0: get_database: default
17/12/19 19:21:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 19:21:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 19:21:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 19:21:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:21:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 19:21:18 INFO HiveMetaStore: 0: get_database: default
17/12/19 19:21:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 19:21:18 INFO HiveMetaStore: 0: get_database: default
17/12/19 19:21:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 19:21:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 19:21:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 19:21:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:21:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 19:21:18 INFO HiveMetaStore: 0: get_database: default
17/12/19 19:21:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 19:21:18 INFO HiveMetaStore: 0: get_database: default
17/12/19 19:21:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 19:21:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 19:21:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 19:21:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/12/19 19:21:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/12/19 19:21:18 INFO HiveMetaStore: 0: get_database: default
17/12/19 19:21:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 19:21:18 INFO HiveMetaStore: 0: get_database: default
17/12/19 19:21:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_database: default	
17/12/19 19:21:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/12/19 19:21:18 INFO audit: ugi=conan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/12/19 19:27:20 INFO SparkContext: Invoking stop() from shutdown hook
17/12/19 19:27:20 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/12/19 19:27:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/19 19:27:20 INFO MemoryStore: MemoryStore cleared
17/12/19 19:27:20 INFO BlockManager: BlockManager stopped
17/12/19 19:27:20 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/19 19:27:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/19 19:27:21 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-9c5e8fd6-4e33-4faa-9b5c-70afbc41fed7\userFiles-750c574a-8bf9-4383-81a6-0b6a77ce0fe0
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-9c5e8fd6-4e33-4faa-9b5c-70afbc41fed7\userFiles-750c574a-8bf9-4383-81a6-0b6a77ce0fe0
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 19:27:21 INFO SparkContext: Successfully stopped SparkContext
17/12/19 19:27:21 INFO ShutdownHookManager: Shutdown hook called
17/12/19 19:27:21 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-9c5e8fd6-4e33-4faa-9b5c-70afbc41fed7
17/12/19 19:27:21 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-9c5e8fd6-4e33-4faa-9b5c-70afbc41fed7
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-9c5e8fd6-4e33-4faa-9b5c-70afbc41fed7
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/12/19 19:27:21 INFO ShutdownHookManager: Deleting directory C:\Users\conan\AppData\Local\Temp\spark-9c5e8fd6-4e33-4faa-9b5c-70afbc41fed7\userFiles-750c574a-8bf9-4383-81a6-0b6a77ce0fe0
17/12/19 19:27:21 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\conan\AppData\Local\Temp\spark-9c5e8fd6-4e33-4faa-9b5c-70afbc41fed7\userFiles-750c574a-8bf9-4383-81a6-0b6a77ce0fe0
java.io.IOException: Failed to delete: C:\Users\conan\AppData\Local\Temp\spark-9c5e8fd6-4e33-4faa-9b5c-70afbc41fed7\userFiles-750c574a-8bf9-4383-81a6-0b6a77ce0fe0
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
